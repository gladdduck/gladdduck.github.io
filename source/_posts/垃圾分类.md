---
title: 垃圾分类论文
categories:
  - 学习笔记
tags:
  - 垃圾分类论文
toc: false# 是否启用内容索引
---
## 基础网络

### R-CNN
[B 站论文](https://www.bilibili.com/video/BV1CZ4y1a7NP/?spm_id_from=333.999.0.0&vd_source=602787b9249cd70cfca4def5e041f060)
```python
# 之前都是人工提取特征,用机器学习分类

# 把人工提取特征改成CNN提取特征

# 三个模块
# 1.候选区域生成(Selective search)(2000个)(统一大小)
# 2.特征抽取(扩展16个像素)(AlexNet)
# 3.分类,框回归
```
### SPPnet
```python 
# 用CNN提取整个图的特征，把候选区域映射到特征图上
# 最后用空间金字塔(三个层)，一个动态池化层，对候选区域特征图得到固定大小的输出特征，拼接在一起
# 还是用svm分类

# 不能很好的更新cnn权重

```
### Fast R-CNN
[B 站论文](https://www.bilibili.com/video/BV1y94y1Q7QJ/?spm_id_from=333.999.0.0&vd_source=602787b9249cd70cfca4def5e041f060)
```python 
# 针对R-CNN和SPPnet
# 多阶段模型,不同的模块都要分别训练
# 要把提取到的特征存到磁盘里，再给分类器

# 单阶段，不用存特征

# 用CNN得到整张图片的特征
# 根据候选区域在图片上的位置（输入坐标），利用ROI投影获得候选区域在特征图上的特征
# 用ROI池化层（空间金字塔特殊情况，一个层）把候选区域特征转为固定大小的特征图
# 两个并行全连接层，分类、预测坐标

# 其他验证性实验 

# 测试阶段输入图像和候选区域坐标
# 候选区域建议是单独的

```
### Faster R-CNN
[B 站论文](https://www.bilibili.com/video/BV1y94y1Q7QJ/?spm_id_from=333.999.0.0&vd_source=602787b9249cd70cfca4def5e041f060)
```python 
# Fast R-CNN还是需要单独的模块生成候选区域投影

# 解决候选区域选择的问题

# RPNs和特征提取层 共享卷积层
# 用n*n的滑动窗口在特征图上提取，传给small network 判断是否能生成候选区域
# 使用三个尺度（128，256，512 1:1,1:2,2:1，九个框）生成k个anchor boxes，（根据数据集设置框的大小），非极大值抑制
# 与标注狂IOU值最大，与标注框IOU值大于0.7  分给正标签

# 交替训练

```
![](https://image.yayan.xyz/20230315150418.png)
![](https://image.yayan.xyz/20230315150330.png)



### Mask R-CNN
```python
# Faster R-CNN的RoI Pooling 是直接取整,会导致实例偏移,对于像素级  不可取

# 把候选区域的特征图转换为固定大小的ROI feature时 也会取整

# 两次误差

# 骨干网络换成ResNet-FPN

# Mask R-CNN使用双线性插值解决缩放的问题

# 增加MASK 分支,三路并行,MASK head两种实现 1.ResNet  2.ResNet+FPN 变成K*M*M 
# K*M*M 大小,K个类别
# 与FCN方法是不同，FCN是对每个像素进行多类别softmax分类，然后计算交叉熵损失，这种做法是会造成类间竞争的



```



## 论文

### 基于改进 Faster R⁃CNN 的垃圾检测与分类方法

```python
# 把Faster R-CNN 的网络换成了ResNet50

# 把非极大值抑制（NMS）换成了Soft-NMS

# 对比实验把VGG16的7*7 5*5 换成了叠加的3*3

# 五折交叉验证

# 用FasterR-CNN相同的交替训练训练

# 73->81%
```
$NMS:0,IoU(M,b_i) \geq N_t$
$Soft-NMS:s_i(1-IoU(M,b_i)),IoU(M,b_i) \geq N_t$


### Analysis of Object Detection Performance Based on Faster RCNN

`基于Faster R-CNN的目标检测性能分析`

`介绍了R-CNN->Fast R-CNN-> Faster R-CNN的变化过程`
`Faster R-CNN的大概结构`

`对比三个模型在不同数据集上的效果`
### End-to-End Object Detection with Transformers

`里程碑:端到端的方法,不用非极大值抑制`
`变成集合预测问题`
`CNN抽取特征－＞送入Transformer学习全局特征->输出100个框->二分图loss匹配真实框->计算loss`

`问题:小目标,训练epoch长`


### EfficientDet: Scalable and Efficient Object Detection
![](https://image.yayan.xyz/20230317135128.png)

`新的结构,多层特征融合`



### Deformable DETR: Deformable Transformers for End-to-End Object Detection
`解决DETR的两个问题`
![](http://image.yayan.xyz/20230316214546.png)
![](http://image.yayan.xyz/20230316215004.png)
```
1.不用TRansformer原有的自注意力,改为可变注意力(可变卷积变来的)
一个像素向量z根据偏移量选择四个其他像素,然后一层Liner得到权重,和选出的像素进行运算更新

2.多尺度的注意力机制(Mulit-Scale),不同尺度的特征图上做,多头可变注意力机制,然后相加
```



### Deep learning-based waste detection in natural and urban environments

`传统图像分类网络:ResNet,DenseNet,EfficientNet,EfficientNet-B2,EfficientNetv2`

`经典目标检测网络:R-CNN,Fast R-CNN ,Faster R-CNN,SSD,Yolo,DETR,Deformable DETR,EfficientDet`

`垃圾数据集`

![](https://image.yayan.xyz/20230316155331.png)

`对所有数据集进行处理`

`一个目标检测网络EfficientDet-D2,一个图像分类网络EfficientNet-B2`

`训练步骤:分开训练,先训练目标检测网络,再训练图像分类网络`

`问题:小目标,推理时间`


## 开源复现

### FasterR-CNN

[模型链接](https://github.com/chenyuntc/simple-faster-rcnn-pytorch)
```python 
1. 下载到Google Colab

2. 安装依赖
!pip install ipdb visdom torchnet fire

3. 修改代码
data\voc_dataset.py中的VOC_BBOX_LABEL_NAMES修改成自己类别
utils\vis_tool.py 中的VOC_BBOX_LABEL_NAMES修改成自己类别


4. 源代码直接运行会报错
raise ValueError('need at least one array to stack')
ValueError: need at least one array to stack
因为只训练有物体的图片,
在data\dataset.py
76行替换如下
'''
id_list_file = os.path.join(data_dir, 'ImageSets/Main/{0}.txt'.format(split))
id_list_read = [id_.strip() for id_ in open(id_list_file)]
id_list = list()
for i in id_list_read:
  obj = ET.parse(os.path.join(data_dir, 'Annotations', i + '.xml'))
  if obj.findall('object'):
    id_list.append(i)
self.ids = id_list
'''

5.在Google Colab运行不能可视化会报错
! npm install -g localtunnel
get_ipython().system_raw('python3 -m pip install visdom')
get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')
get_ipython().system_raw('lt --port 8097 >> url.txt 2>&1 &')

在运行,打开url.txt 查看可视化的窗口

code_root/
└── data/
    └── VOC2007/
        ├── Annotations/
        ├── JPEGImages/
        └── ImageSets/
        	└── Main/
        	      ├── test.txt
                ├── train.txt
                ├── val.txt
                └── trainval.txt
```


###  EfficientDet
[模型链接](https://github.com/rwightman/efficientdet-pytorch)
```python
# 运行环境Google Colab

1.下载到工作区

2.安装依赖

3. 代码:effdet\data\parsers\parser_voc.py 文件中的DEFAULT_CLASSES改成自己的类别名称

4.! python ..../efficientdet-pytorch-master/train.py /content --dataset VOC2007 --num-classes 自己的类别 

# JPEGImages:所有图片  Annotations:所有xml标注  txt:用作训练测试的文件名,不带后缀
code_root/
└── data/
    └── VOC2007/
        ├── Annotations/
        ├── JPEGImages/
        └── ImageSets/
        	└── Main/
        	      ├── test.txt
                ├── train.txt
                ├── val.txt
                └── trainval.txt
```

### Deformable-DETR

[模型链接](https://github.com/fundamentalvision/Deformable-DETR)
```python 
# 运行环境Google Colab
1.下载到工作区

2.安装相关依赖

3.!python ..(绝对路径..)/Deformable-DETR-main/models/ops/setup.py build install (用的jupyter)(可以用ops文件夹下的test.py测试环境是否正确)

5.代码:...../Deformable-DETR-main/util/misc.py 里面的
# float(torchvision.__version__[:3]) < 0.5/0.7 
需要改动,因为对于0.10.x版本的不适用,自己改成了
# float(torchvision.__version__[:4]) < 0.05:
否则报错cannot import name '_NewEmptyTensorOp' from 'torchvision.ops.misc'

6.! python ...../Deformable-DETR-main/main.py --coco_path ..../coco 

# train2017:训练图片  val2017:测试图片   annotations两个文件下面的标注图片
code_root/
└── data/
    └── coco/
        ├── train2017/
        ├── val2017/
        └── annotations/
        	├── instances_train2017.json
        	└── instances_val2017.json

```


### YOLOv5

[模型链接](https://github.com/ultralytics/yolov5)
```python 
# 运行环境Google Colab
1.下载到工作区

2.安装相关依赖

3.指定数据路径 运行

```


### YOLOv8

[模型链接](https://github.com/ultralytics/ultralytics)
```python 
# 运行环境Google Colab
1.!pip install ultralytics==8.0.20

2.安装相关依赖

3.指定数据路径 运行

```