{"meta":{"title":"Gladdduck","subtitle":"","description":"","author":"syxue","url":"https://gladdduck.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2023-09-19T02:30:05.466Z","updated":"2022-10-17T15:17:42.000Z","comments":false,"path":"/404.html","permalink":"https://gladdduck.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2023-11-13T07:02:11.331Z","updated":"2023-11-13T07:02:11.331Z","comments":false,"path":"about/index.html","permalink":"https://gladdduck.github.io/about/index.html","excerpt":"","text":"这是我. 略略略略略"},{"title":"书单","date":"2022-10-22T00:58:31.965Z","updated":"2022-10-17T15:17:42.000Z","comments":false,"path":"books/index.html","permalink":"https://gladdduck.github.io/books/index.html","excerpt":"","text":""},{"title":"照片墙","date":"2023-12-11T06:24:04.153Z","updated":"2023-12-11T06:24:04.153Z","comments":false,"path":"picturewall/index.html","permalink":"https://gladdduck.github.io/picturewall/index.html","excerpt":"","text":".outer { column-count: 5; } img { width: 100%; transition: 0.2s linear; cursor: pointer; margin: 5px; } img:hover { box-shadow: 0px 0px 20px black; transform: scale(1.02); } .modal { display: none; position: fixed; z-index: 1; padding-top: 100px; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgb(0,0,0); background-color: rgba(0,0,0,0.9); } .modal-content { margin: auto; display: block; width: 80%; max-width: 700px; } .modal-content img { width: 100%; height: auto; } &times; function openModal(img) { var modal = document.getElementById(\"myModal\"); var modalImg = document.getElementById(\"img01\"); modal.style.display = \"block\"; modalImg.src = img.src; modal.onclick = function() { closeModal(); }; } function closeModal() { document.getElementById(\"myModal\").style.display = \"none\"; }"},{"title":"","date":"2023-12-11T06:20:08.328Z","updated":"2023-12-11T06:20:08.328Z","comments":true,"path":"picturewall/test.html","permalink":"https://gladdduck.github.io/picturewall/test.html","excerpt":"","text":".outer { text-align: center; } .outer img { width: 200px; height: auto; margin: 5px; cursor: pointer; } .modal { display: none; position: fixed; z-index: 1; padding-top: 100px; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgb(0,0,0); background-color: rgba(0,0,0,0.9); } .modal-content { margin: auto; display: block; width: 80%; max-width: 700px; } .modal-content img { width: 100%; height: auto; } &times; function openModal(img) { var modal = document.getElementById(\"myModal\"); var modalImg = document.getElementById(\"img01\"); modal.style.display = \"block\"; modalImg.src = img.src; modal.onclick = function() { closeModal(); }; } function closeModal() { document.getElementById(\"myModal\").style.display = \"none\"; }"},{"title":"分类","date":"2022-10-22T00:58:31.965Z","updated":"2022-10-17T15:17:42.000Z","comments":false,"path":"categories/index.html","permalink":"https://gladdduck.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情连接","date":"2023-12-11T05:27:34.676Z","updated":"2023-12-11T05:27:34.676Z","comments":true,"path":"links/index.html","permalink":"https://gladdduck.github.io/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-10-22T00:58:31.967Z","updated":"2022-10-17T15:17:42.000Z","comments":false,"path":"tags/index.html","permalink":"https://gladdduck.github.io/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-10-22T00:58:31.966Z","updated":"2022-10-17T15:17:42.000Z","comments":false,"path":"repository/index.html","permalink":"https://gladdduck.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"SQL刷题笔记","slug":"实习-SQL刷题记录","date":"2024-03-26T11:45:00.778Z","updated":"2024-03-26T13:51:27.550Z","comments":true,"path":"2024/03/26/实习-SQL刷题记录/","link":"","permalink":"https://gladdduck.github.io/2024/03/26/%E5%AE%9E%E4%B9%A0-SQL%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/","excerpt":"","text":"length和char_length函数区别 计算字段长度规则： length是汉字是算三个字符，数字或字母算一个字符，中文标点符号(如：￥、？。，)算三个字符，英文标点符号算一个字符。 char_length是汉字、数字或字母都算是一个字符，包括中英文标点符号也算一个字符。 123456789-- 查询某字符串长度SELECT LENGTH(&quot;中国？￥、&quot;); -- 15SELECT CHAE_LENGTH(&quot;中国？￥、&quot;); -- 5-- 查询表中某字段数据长度最长的10条数据SELECT * from student where length(student_name) &gt; 0 order by length(student_name) desc limit 10;-- 查询表中某字段数据长度最大的值SELECT max(length(student_name)) from student; 偏移量 &amp; 日期函数 表： Weather ±--------------±--------+ | Column Name | Type | ±--------------±--------+ | id | int | | recordDate | date | | temperature | int | ±--------------±--------+ id 是该表具有唯一值的列。 没有具有相同 recordDate 的不同行。 该表包含特定日期的温度信息 编写解决方案，找出与之前（昨天的）日期相比温度更高的所有日期的 id 。 返回结果 无顺序要求 。 偏移量解决方案 lag()和 lead()函数用于获取当前行的前一行和后一行的数据，可以通过偏移量来获取更多的行数据。 第一个为待查询的参数列名，第二个为向上[下]偏移的位数，第三个参数为超出最上面边界的默认值。 OVER子句是用于指定窗口函数操作的条件。通过ORDER BY子句，可以指定要根据哪列来排序，使得LAG()函数的结果按照指定的顺序进行计算。 日期函数解决 DATE_ADD(date,INTERVAL expr type)向日期添加指定的时间间隔。 ADDDATE()有两种形式：ADDDATE(date,INTERVAL expr unit)和 ADDDATE(expr,days) 第一种和DATE_ADD()完全一样，第二种中第二个参数只能是天。其实就是第一种的功能包括第二种。 DATEDIFF(begin,end) 函数返回begin-end的天数。 TIMESTAMPDIFF(unit,begin,end);TIMESTAMPDIFF函数返回begin-end的结果 123456789101112131415161718192021222324252627282930313233-- 偏移select idfrom (select id, temperature, recordDate, lag(recordDate,1) over(order by recordDate) as last_date, lag(temperature,1) over(order by recordDate) as last_temperature from Weather) awhere temperature&gt;last_temperature and DATEDIFF(recordDate,last_date)=1-- 日期函数select a.idfrom weather a join weather b on (a.recorddate = adddate(b.recorddate,INTERVAL 1 day))-- on (a.recorddate = adddate(b.recorddate,1))-- on (a.recorddate = date_add(b.recorddate,INTERVAL 1 day))where a.temperature &gt; b.temperature -- 最快select a.id from weather ajoin weather bwhere DATEDIFF(a.recorddate,b.recorddate)=1and a.temperature&gt;b.temperature-- select a.idfrom weather a,weather bwhere DATEDIFF(a.recorddate,b.recorddate)=1 and a.Temperature &gt;b.Temperature JOIN方式 博客链接 Employee empId name supervisor salary 3 Brad null 4000 1 John 3 1000 2 Dan 3 2000 4 Thomas 3 4000 bouns empId bonus 2 500 4 2000 5 200 JOIN方式 默认inner JOIN 1234select *from employee[inner] JOIN bonus on employee.empId = bonus.empId empId name supervisor salary empId bonus 2 Dan 3 2000 2 500 4 Thomas 3 4000 4 2000 LEFT JOIN方式 1234select *from employeeleft JOIN bonus on employee.empId = bonus.empId empId name supervisor salary empId bonus 3 Brad null 4000 null null 1 John 3 1000 null null 2 Dan 3 2000 2 500 4 Thomas 3 4000 4 2000 RIGHT JOIN方式 123select *from employeeright JOIN bonus on employee.empId = bonus.empId empId name supervisor salary empId bonus 2 Dan 3 2000 2 500 4 Thomas 3 4000 4 2000 null null null null 5 200 FULL JOIN方式 12345678-- mysql中未提供full join 使用左查询 union 右查询 实现select *from employeeleft JOIN employeebonus on employee.empId = employeebonus.empIdUNIONselect *from employeeright JOIN employeebonus on employee.empId = employeebonus.empId empId name supervisor salary empId bonus 3 Brad null 4000 null null 1 John 3 1000 null null 2 Dan 3 2000 2 500 4 Thomas 3 4000 4 2000 null null null null 5 200","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://gladdduck.github.io/tags/SQL/"}]},{"title":"2024暑期实习面经","slug":"实习-2024实习面经","date":"2024-03-26T08:12:27.672Z","updated":"2024-03-26T11:36:01.833Z","comments":true,"path":"2024/03/26/实习-2024实习面经/","link":"","permalink":"https://gladdduck.github.io/2024/03/26/%E5%AE%9E%E4%B9%A0-2024%E5%AE%9E%E4%B9%A0%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"03.26腾讯数据工程一面 20分钟凉凉 自我介绍 Hadoop集群构建中遇到的问题 实习的内容 使用Hadoop处理项目问题的思路 三个SQL题 对数据工程,数据仓库的理解 讲一下对Spark了解多少 讲一下对Hadoop的理解(MapReduce过程) 给一个场景:用户id,观看内容id,找到每天top10的热门内容,会遇见什么问题,怎么解决 只用过逻辑编程解决问题吗,了解其他方式吗 反问 粉丝每天给明星投票 字段 类型 说明 day_time datetime 投票日期 user_id string 粉丝id idle_id string 明星id vote_num bitint 投票数量 1234561. 找到2024.3.1-2024.3.31投票数量最多的明星2. 找到2024.3.1-2024.3.31票数的分布(类似直方图的表达形式)3. 找到每个用户连续最长投票的天数 总结 面试官问的问题都不难,自己掌握的不深 sql题没做出来有点慌,导致后面脑子转的慢 自己说的讲的太少了, 表达不好 技术栈太少, 理解不透彻, 面对场景没有好的思路 3.28饿了么后端开发一面","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"实习面经","slug":"实习面经","permalink":"https://gladdduck.github.io/tags/%E5%AE%9E%E4%B9%A0%E9%9D%A2%E7%BB%8F/"}]},{"title":"MySQL学习笔记","slug":"实习-MySQL知识点","date":"2024-03-23T04:16:40.569Z","updated":"2024-03-26T01:22:59.636Z","comments":true,"path":"2024/03/23/实习-MySQL知识点/","link":"","permalink":"https://gladdduck.github.io/2024/03/23/%E5%AE%9E%E4%B9%A0-MySQL%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"索引详解 日志详解 事务隔离级别","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://gladdduck.github.io/tags/MySQL/"}]},{"title":"2024美团春招笔试","slug":"实习-2024实习笔试","date":"2024-03-18T13:28:14.565Z","updated":"2024-03-28T02:09:23.095Z","comments":true,"path":"2024/03/18/实习-2024实习笔试/","link":"","permalink":"https://gladdduck.github.io/2024/03/18/%E5%AE%9E%E4%B9%A0-2024%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AF%95/","excerpt":"","text":"2024大厂笔试真题B站讲解 2024大厂笔试笔记 3.9美团第一次 题目链接 4.小美的朋友关系 小美认为，在人际交往中，但是随着时间的流逝，朋友的关系也是会慢慢变淡的，最终朋友关系就淡忘了。 现在初始有一些朋友关系，存在一些事件会导致两个人淡忘了他们的朋友关系。小美想知道某一时刻中，某两人是否可以通过朋友介绍互相认识？ 事件共有 2 种： 1 u v：代表编号 u 的人和编号 v 的人淡忘了他们的朋友关系。 2 u v：代表小美查询编号 u 的人和编号 v 的人是否能通过朋友介绍互相认识。 注：介绍可以有多层，比如 2 号把 1 号介绍给 3 号，然后 3 号再把 1 号介绍给 4 号，这样 1 号和 4 号就认识了。 输入描述： 第一行两个整数 n,m，表示人数和事件数(1≤n,m≤105)(1\\leq n,m\\leq 10^5)(1≤n,m≤105)。 接下来 m 行，每行有三个整数 t,u,v，表示事件类型和两个人的编号(1≤t≤2,1≤u,v≤n)(1\\leq t\\leq 2,1\\leq u,v\\leq n)(1≤t≤2,1≤u,v≤n)。 接下来一行一个整数 q，表示小美的查询次数(1≤q≤105)(1\\leq q\\leq 10^5)(1≤q≤105)。 接下来 q 行，每行有两个整数 u,v，表示小美的查询(1≤u,v≤n)(1\\leq u,v\\leq n)(1≤u,v≤n)。 保证没有重复的事件。 输出描述： 对于每个查询，如果 u 和 v 可以通过朋友介绍互相认识，输出 “Yes”，否则输出 “No”。 示例： 输入例子： 5 3 5 1 2 2 3 4 5 1 1 5 2 1 3 2 1 4 1 1 2 2 1 3 输出例子： Yes No No 例子说明： 第一次事件，1 号和 5 号本来就不是朋友，所以无事发生。 第二次事件是询问，1 号和 3 号可以通过 2 号的介绍认识。 第三次事件是询问，显然 1 号和 4 号无法互相认识。 第四次事件，1 号和 2 号淡忘了。 第五次事件，此时 1 号无法再经过 2 号和 3 号互相认识了。 思路： 并查集，但是对于查询反着来，相当于时光倒流，站在后面看之前。 根据初始条件，构建朋友关系边 根据查询条件1，构建淡忘的关系边 然后将初始条件中的并且不在淡忘条件中的边，构建并查集 现在构建的，是最后所有关系淡忘完的朋友圈 此时，对于所有查询逆序。 如果查询的两个人在同一个朋友圈（所有关系都断开了还能相通），输出Yes，否则输出No 如果遇到了淡忘条件，将淡忘条件加入并查集，恢复关系 参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748n, m, q = map(int, input().split())initial_relationship = [list(map(int, input().split())) for _ in range(m)]events = [list(map(int, input().split())) for _ in range(q)]class UnionFind: def __init__(self, n: int) -&gt; None: self.parent = [i for i in range(n)] # 位置i的元素记录其父节点下标 # 查找根节点 def find(self, i: int) -&gt; int: if self.parent[i] == i: return i # 递归查找父节点 self.parent[i] = self.find(self.parent[i]) # 完全压缩 return self.parent[i] def merge(self, i: int, j: int): root_i = self.find(i) root_j = self.find(j) self.parent[root_i] = root_j def query(self, i: int, j: int) -&gt; bool: return self.find(i) == self.find(j)unionFind = UnionFind(n+1)relationship = set()for relation in initial_relationship: relationship.add(tuple(sorted(relation))) # 排序元素，保证关系不重复for event in events: if event[0] == 1: relationship.discard(tuple(sorted(event[1:])))# 将所有未被淡忘的关系加入并查集for relation in relationship: unionFind.merge(*relation)# 倒推事件，出现淡忘关系，将该关系加入并查集ans = []for event in events[::-1]: if event[0] == 1: unionFind.merge(event[1], event[2]) else: ans.append(&#x27;Yes&#x27; if unionFind.query(event[1], event[2]) else &#x27;No&#x27;)# 逆序输出结果print(ans[::-1]) 5.小美的区间删除 小美拿到了一个大小为nnn的数组，她希望删除一个区间后，使得剩余所有元素的乘积末尾至少有kkk个000。小美想知道，一共有多少种不同的删除方案？ 输入描述： 第一行两个整数n,kn,kn,k，表示数组大小和末尾000的个数(1≤n≤105,0≤k≤18)(1\\leq n\\leq 10^5,0\\leq k\\leq 18)(1≤n≤105,0≤k≤18)。 第二行nnn个整数，表示数组中的元素(1≤ai≤109)(1\\leq a_i\\leq 10^9)(1≤ai​≤109)。 输出描述： 一个整数，表示答案。 示例： 输入例子： 5 2 2 5 3 4 20 输出例子： 4 例子说明： 第一个方案，删除[3]。 第二个方案，删除[4]。 第三个方案，删除[3,4]。 第四个方案，删除[2]。 参考1 参考2 思路： 乘积末尾有k个0意味着乘积可以被 10k10^k10k 整除，又 10k=2k∗5k10^k=2^k*5^k10k=2k∗5k。因此，问题转化为找到删除区间后，剩余所有元素的乘积中2和5的因子数量都至少有k个。 预处理每个元素的2和5的因子数量，记录前缀和，分别存储在cnt2和cnt5数组中。 用双指针l和r维护一个区间，使得去除区间内的元素因子数量之外，剩下的至少有k个，那么这个区间就是可以被删除的区间。 每一次，固定l，r向右移动，此时计算剩余的2和5的因子数量，并判断min(remain2,remain5)min(remain2,remain5)min(remain2,remain5)是否小于k，如果小于k，表示剩余的元素不满足条件，那么l向右移动，重新找一个起点区间。如果大于k，表示剩余的元素满足条件，那么r向右移动，查看下一个区间，是否满足条件。 每次移动，都用ans记录所有的区间数（如果大区间删掉没问题，那么小区间也没问题），最后输出ans。 12345678910111213141516171819202122232425262728293031323334n,k=map(int,input().split())nums=list(map(int,input().split()))def countn(n,factor): ans=0 while n: if n%factor==0: ans+=1 n//=factor else: break return anscnt2=[0]*(n+1)cnt5=[0]*(n+1)for i in range(n): cnt2[i+1]=cnt2[i]+countn(nums[i],2) cnt5[i+1]=cnt5[i]+countn(nums[i],5)ans=0l=1r=1while l&lt;=n: while r&lt;=n: range2=cnt2[r]-cnt2[l-1] range5=cnt5[r]-cnt5[l-1] remain2=cnt2[n]-range2 remain5=cnt5[n]-range5 if min(remain2,remain5)&lt;k: break r+=1 ans+=max(r-l,0) l+=1print(ans) 3.16美团第二次 树状数组补充 4.小美的众数 小明要求出一个数组的所有子数组的众数之和，定义子数组的众数为出现次数最多的那个数。如果有多个数出现次数最多，那么众数是其中最小的那个数。 输入描述 第一行输入一个正整数n，代表数组的大小。 第二行输入n个正整数aia_iai​，代表数组的元素(1≤n≤2∗105,1≤ai≤2)(1\\leq n\\leq 2*10^5,1\\leq a_i\\leq 2)(1≤n≤2∗105,1≤ai​≤2)。 输出描述 一个正整数，代表所有区间的众数之和。 示例： 输入 3 2 1 2 输出 9 说明 [2],[2,1,2],[2]的众数是 2。 [2,1],[1],[1,2]的众数是 1。 因此答案是 9。 思路： 我整个子数组的数量为n∗(n+1)2\\frac{n*(n+1)}{2}2n∗(n+1)​，因此我们只需要统计众数2的个数，即可知道众数1的个数，反之亦然 对于这题，我们可以将1视为-1，2视为1，那么区间 [l, r]的和就相当于区间中2的数量减去1的数量，如果该区间的和&gt;0，则说明对于区间 [l, r]而言，区间的众数为2，否则为1。 为了区间和的计算方便，这里采用前缀和来进行处理: -记s[i]为前i个数的和，那么区间 [l, r]的和可以表示为: s[r]-s[l-1] 将本题转换为，对于每个位置r，找到其左侧所有满足 s[r]-s[l]&gt;0. l∈[1,r一1]l \\in [1,r一1]l∈[1,r一1]的数量其中查询左侧满足的数量个数可以用树状数组来维护查询。 值得注意的是:由于这里将所有的1都变成-1了，那么所有的前缀和的范围为[一n, n]，因此在使数状数组的时候要加上偏移量n+1 12 5.小美的逆序对 小明拿到了一个排列，他定义 f(i) 为：将第 i 个元素取反后，形成的数组的逆序对数量。小明希望你求出 f(1) 到 f(n) 的值。（排列是指一个长度为n的数组，1到 n每个元素恰好出现了一次） 输入描述 第一行输入一个正整数n，代表排列的大小。 第二行输入n个正整数aia_iai​，代表排列的元素。 1≤n≤2∗1051 \\le n \\le 2 * 10^51≤n≤2∗105 1≤ai≤n1 \\le a_i \\le n1≤ai​≤n 输出描述 输出n整数，第i整数是 f(i) 的值。 示例： 输入 3 1 2 3 输出 0 1 2 说明 第一个元素取反，数组将变成[-1,2,3]，逆序对数量为 0。 第二个元素取反，数组将变成[1,-2,3]，逆序对数量为 1。 第三个元素取反，数组将变成[1,2,-3]，逆序对数量为 2。 思路： 首先要求出来原来数组的逆序对数量（记为ans），常见的方法是树状数组或者归并排序, 统计逆序对有两种遍历方法，一种是看前面的元素有几个比当前元素大（记为 pre[i]），或者是看后面的元素有几个比当前元素小(记为 suf[i])。 在遍历每个元素求 f(i) 的时候，要分别求出当前元素取反之后，对前面元素和后面元素的影响，f(i) = ans + 对前面的影响 + 对后面的影响 对后面元素：取负之后，后面的元素一定比当前元素大，相比原来少了suf[i]个逆序对，所以ans要减去suf[i]； 对前面元素：取负之后，前面的元素一定比当前元素小，所以现在一定形成了i-1个逆序对，再减去pre[i]，就求出变化量了。 所以 f ( i ) f(i)f(i) = ans + ((i - 1) - pre[i]) + (-suf[i]) 求pre[i]和suf[i]的过程要用到树状数组 3.24拼多多第一次 ×3.超级快递点 多多快递站共有n个快递点，n个快递点之间通过m条单向车道连接。快递员从任何一个快递站点出发，都无法通过单向车道回到该站点。也就是说，n个快递点组成一张有向无环图。对于快递点u，如果对于所有的快递点 v(v!=u)， 快递员都可以从u走到v，或者从v走到u，那么则评定站点u为超级快递点。请你帮忙算一算，一共有多少个超级快递点。 输入描述： 第一行 2个数字n(2&lt;=n&lt;=310^5) , m(1&lt;=m&lt;=310^5) , n为快递点个数，m为单向车道个数。 接下来的m行每行两个数字 u,v(1&lt;=u,v&lt;=n, v!=u)，表示有一条站点u指向v的单向车道。 输出描述： 请输出个数字，表示超级快递点的个数。 示例： 输入示例 7 7 1 2 2 3 3 4 4 7 2 5 5 4 6 4 输出示例 2 说明 快递点 4 可以到达 4，7，可以从1，2，3，5，6 到达， 评为超级快递点 快递点 7 可以到达 7，可以从 1，2，3，4，5，6到达，评为超级快递点 思路： 有点像图中的求关键节点 4.多多的回文修建 多多有一个长度为 n 的字符串, 这个字符串由26个小写字母组成. 多多可以对这个字符串进行多次操作, 每次操作可以把该字符串中一段连续的回文子串删除(单个字符也属于回文串), 删除后剩下的串会拼在一起. 请问最少需要多少次操作可以将这个字符串删光. 输入描述： 第一行, 包含一个正整数 T(1&lt;=T&lt;=20) 代表测试数据的组数. 对于每组测试数据, 仅有一行, 代表这个字符串. (1&lt;=n&lt;=500) 保证 Σn 不超过 3000 输出描述： 对于每组数据输出一行整数, 代表多多在进行最少多少次操作后, 可以将这个字符串删光. 示例： 输入示例 3 mwapd tvuvv yxxmi 输出示例 5 3 4 说明 对于 tvuvv 第一步: 删除u, 此时剩下tvvv 第二步: 删除vvv, 此时剩下t 第三步: 删除t 思路： 【LeetCode - 1246】删除回文子数组(会员题) f[i][j]表示将区间 [i,j]删除的最小次数. 转移时枚举k将区间分为[i,k]和[k+1,j]两部分, 如果 a[i]==a[j]则可以选择从 f[i+1][j-1]转移,因为可以选择再删除 a[i+1][j-1]之后,把i和j作为回文串删掉 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def min_insertions(st): n = len(st) f = [[0 for _ in range(n)] for _ in range(n)] for i in range(n): f[i][i] = 1 for i in range(n - 1): if st[i] == st[i + 1]: f[i][i + 1] = 1 else: f[i][i + 1] = 2 # i代表的枚举长度 for i in range(2, n): for j in range(n - i): if st[j] == st[j + i]: f[j][j + i] = f[j + 1][j + i - 1] else: f[j][j + i] = min(f[j][k] + f[k + 1][j + i] for k in range(j, j + i)) return f[0][n - 1]T = int(input())for _ in range(T): st = input().strip() print(min_insertions(st))# 自己的错误代码def count(s,n): dp=[[0]*n for i in range(n)] for i in range(n): for j in range(n): dp[i][j]=j-i+1 for i in range(n): dp[i][i]=1 if i&lt;n-1 and s[i]==s[i+1]: dp[i][i+1]=1 for i in range(n): for j in range(n): if s[i:j+1]==s[i:j+1][::-1]: dp[i][j]=1 for k in range(i,j): if s[i:k+1]==s[i:k+1][::-1]: dp[i][k]=1 if s[k+1:j+1]==s[k+1:j+1][::-1]: dp[k+1][j]=1 dp[i][j]=min(dp[i][k]+dp[k+1][j],dp[i][j]) return dp[0][n-1]inp=[ &#x27;astgd&#x27;, &#x27;tvuvv&#x27;, &#x27;sfghhgtyujss&#x27;, &#x27;sftyujss&#x27;, &#x27;sdddsdgykkkjginfhsdkkkoiituiuiuiusdtmzptr&#x27;,]for i in range(len(inp)): a=inp[i] if a==a[::-1]: print(1) else: n=len(a) print(count(a,n)) 3.27饿了么第一次","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"实习笔试","slug":"实习笔试","permalink":"https://gladdduck.github.io/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AF%95/"}]},{"title":"Hadoop学习笔记","slug":"实习-Hadoop知识点","date":"2024-03-16T08:26:52.655Z","updated":"2024-03-23T04:06:21.855Z","comments":true,"path":"2024/03/16/实习-Hadoop知识点/","link":"","permalink":"https://gladdduck.github.io/2024/03/16/%E5%AE%9E%E4%B9%A0-Hadoop%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"Hadoop概述 高可靠 高扩展 高效 高容错 大数据 大量(Volume),多样(Variety),高速(Velocity),价值(Volue) 全体数据取代随机样本 混杂性取代精确性 相关关系取代因果关系 Hadoop的体系 Hadoop是对海量数据进行大规模分布式处理的开源软件框架 HDFS—分布式文件系统； MapReduce—分布式处理模型； HBase—分布式数据库（非SQL） HCatalog—Hadoop内部数据整合工具，实现不同数据处理工具的数据类型相互转换机制； Pig—流式数据的数据处理语言及其运行环境； Hive—数据仓库管理工具，提供SQL查询功能； ZooKeeper—分布式协调器。 大数据与云计算关系 云计算就是把一大堆廉价机器组织起来，通过网络向用户提供海量资源的高性能可靠服务。 云计算为大数据处理提供了可能和途径 大数据为云计算具有的大规模与分布式计算能力提供了应用空间，利用云计算解决了传统数据管理系统无法解决的问题 Hadoop集群搭建 略😁 分布式文件系统HDFS HDFS(Hadoop Distributed File System)是一个分布式的文件系统,适合一次写入多次读出的场景,不适合低延时访问,不适合小文件,不支持并发写入 HDFS架构 NameNode:集群的Master 管理HDFS的命名空间 配置副本策略 管理块映射信息 处理客户端读写请求 负责监控各个DataNode的状态 DataNode:集群的Slave 存储实际的数据块 处理数据块的读写请求 每次启动时扫描本地文件发送给NameNode Client:访问HDFS的客户端 文件切分,文件长传时将文件切分为一个个block 与NameNode进行交互,获取文件的位置信息 与DataNode进行交互,读写数据 Secondary NameNode:辅助NameNode 定期合并FsImage和Edits文件,生成新的FsImage文件 在紧急情况下，可辅助恢复NameNode. 但是不是NameNode的热备份 HDFS对文件快大小的设置 HDFS的默认块大小是128M HDFS的块大小设置是全局的,不支持单个文件设置 原因: 文件块越大，寻址时间越短，但磁盘传输时间越长； 文件块越小，寻址时间越长，但磁盘传输时间越短。 经过前人的大量测试发现，寻址时间为传输时间的1%时，为最佳状态 HDFS中平均寻址时间大概为10ms；目前磁盘的传输速率普遍为100MB/s 所以最佳大小为100MB,所以设置最接近的128M 不固定,根据磁盘传输速率设置 HDFS操作 Shell操作 12345678910# 上传hadoop fs -put /home/hadoop/hadoop-3.3.0.tar.gz /user/hadoophadoop fs -copyFromLocal /home/hadoop/hadoop-3.3.0.tar.gz /user/hadoophadoop fs -moveFromLocal /home/hadoop/hadoop-3.3.0.tar.gz /user/hadoophadoop fs -appendToFile /home/hadoop/hadoop-3.3.0.tar.gz /user/hadoop# 下载hadoop fs -get /user/hadoop/hadoop-3.3.0.tar.gz /home/hadoophadoop fs -copyToLocal /user/hadoop/hadoop-3.3.0.tar.gz /home/hadoop# 其他,类似Linux命令 API操作 略 HDFS的读写流程 写流程 客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。 NameNode返回是否可以上传。 客户端请求第一个Block上传到哪几个DataNode服务器上。 NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。 客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。 dn1、dn2、dn3逐级应答客户端。 客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。 当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步） 节点距离计算 在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据 两个节点到达最近的共同祖先的距离总和 副本策略 一个Block的第一个副本放在上传数据的DataNode上， 第二个副本放在与第一个副本在不同的机架上的另一个DataNode上， 第三个副本放在与第二个副本在相同的机架上的另一个DataNode上。 读流程 客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。 挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。 DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。 客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。 HDFS高可用 NameNode和SecondaryNameNode NameNode工作机制 NameNode将集群的文件镜像(FsImage)读到内存,当有新的操作来的时候,先将操作写到Edits文件中,然后再修改内存中文件镜像. NameNode每次启动时,加载FsImage文件和Edits文件,进行合并 NameNode长时间操作会导致Edits文件过大 NameNode滚动正在写的Edits日志到一个新的文件edits_inprogress_002 NameNode将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode Secondary NameNode加载编辑日志和镜像文件到内存，并合并 生成新的镜像文件fsimage.chkpoint,拷贝fsimage.chkpoint到NameNode 此时fsimage.chkpoint加上edits_inprogress_002就是最新的文件影像 问题: 如果Secondary NameNode正在合并的时候出问题了,则会导致期间NameNode的操作丢失 一般不会使用SecondaryNameNode,而是结合Zookeeper配置高可用 SecondaryNameNode合并时机 每隔一小时合并一次 每一分钟检测一下操作次数,如果到了100万,合并一次 DataNode工作机制(心跳检测) DataNode启动后向NameNode注册，通过后，周期性（6小时）的向NameNode上报所有的块信息 心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。 集群运行中可以安全加入和退出一些机器。 DataNode进程死亡或者网络故障造成DataNode无法与NameNode通信 NameNode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。 默认超时时长10分钟+30秒 数据完整性 &amp; 冗余备份 &amp; 存储空间延时回收 &amp; 客户端缓存 &amp; 流水线式复制备份 数据完整性 DataNode读取Block的时候会计算校验码,如果与创建的时候不一样,则Block孙华 读取其他DataNode的Block,使用crc32校验码 DataNode在其文件创建后周期验证CheckSum 冗余备份 NameNode定期检测各个数据块的备份数，并根据复制因子来增加或减少相应数据块的备份 文件备份数量= min(复制因子,DataNode的数量) 存储空间延时回收 删除文件在目录/trash内存放超过6小时，就会被系统彻底清除，并回收其存储空间 负载均衡 当某个DataNode上的空余磁盘空间下降到一定值，系统就把其部分数据块迁移到其它合适节点上去； 当出现对某个文件的访问频率超过一定值时，系统会创建该文件的新备份，对访问实施分流 客户端缓存 客户端写入文件的请求不是立即到达NameNode，而是先把写入数据存入本地缓存； 当本地缓存内数据达到一个数据块的大小（默认为128MB）时，客户端就请求NameNode分配一个文件数据块，并把本地缓存内的数据写入NameNode分配的数据块中 客户端的本地缓存可以极大地减少对网络的访问 流水线式复制备份 客户端写入数据块时，系统同时建立数据块的备份； 当一个DataNode接收数据进行写入操作时，随即把数据传给下一个节点写入，好似流水线一般 分布式计算模型MapReduce MapReduce简介 MapReduce是一个分布式计算框架，MapReduce的设计思想是将计算过程分为两个阶段：Map阶段和Reduce阶段。 MapReduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个Hadoop集群上 缺点: 不适合实时计算 不适合流式计算 MapReduce架构 InputFormat数据输入 切片与MapTask并行度决定机制 数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask 切片大小通常会与HDFS的块大小一致，但是也可以通过InputFormat来自定义切片大小 切片时不考虑数据集整体，而是逐个针对每一个文件单独切片 Job提交流程源码 123456789101112131415161718192021222324252627282930313233343536// 1. 等待任务完成waitForCompletion();// 2. 建立连接connect();// 3. 创建作业提交代理Cluster cluster = new Cluster(getConfiguration());// 4. 初始化作业提交initialize(jobTrackAddr, conf);// 5. 提交作业到集群submitter.submitJobInternal(Job.this, cluster);// 6. 创建作业的暂存区Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);// 7. 获取新的作业IDJobID jobId = submitClient.getNewJobID();// 8. 复制并配置作业提交所需的文件copyAndConfigureFiles(job, submitJobDir);rUploader.uploadFiles(job, jobSubmitDir);// 9. 写入切片并生成切片规划文件writeSplits(job, submitJobDir);maps = writeNewSplits(job, jobSubmitDir);input.getSplits(job);// 10. 将XML配置文件写入暂存区writeConf(conf, submitJobFile);conf.writeXml(out);// 11. 提交作业并获取提交状态status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials()); FileInputFormat切片源码 12345678910111213（1）程序先找到你数据存储的目录。（2）开始遍历处理（规划切片）目录下的每一个文件。（3）遍历第一个文件 ss.txt a）获取文件大小 fs.sizeOf(ss.txt) b）计算切片大小 computeSplitSize(Math.max(minSize, Math.min(maxSize, blocksize))) = blocksize = 128M c）默认情况下，切片大小 = blocksize d）开始切，形成第1个切片：ss.txt—0:128M 第2个切片 ss.txt—128:256M 第3个切片 ss.txt—256M:300M （每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片） e）将切片信息写到一个切片规划文件中 f）整个切片的核心过程在 getSplit() 方法中完成 g）InputSplit 只记录了切片的元数据信息，比如起始位置、长度以及所在的节点列表等。（4）提交切片规划文件到 YARN 上，YARN 上的 MrAppMaster 就可以根据切片规划文件计算开启 MapTask 个数 FileInputFormat切片机制 （1）简单地按照文件的内容长度进行切片 （2）切片大小，默认等于Block大小 （3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片 如果文件大小小于Block大小的1.1倍,默认也是不切片的 TextInputFormat切片机制 TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。 键是存储该行在整个文件中的起始字节偏移量，LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符），Text类型 CombineTextInputFormat切片机制 框架默认的TextInputFormat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下 生成切片过程包括：虚拟存储过程和切片过程二部分 虚拟存储过程： 将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件平均分成2个虚拟存储块（防止出现太小切片） 例如：setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。 剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件平均切分成（2.01M和2.01M）两个文件。 切片过程： 判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。 如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。 测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M。这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）.最终会形成3个切片，大小分别为：（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M MapReduce工作机制 MaperTask工作机制 Read阶段：MapTask通过InputFormat获得的RecordReader，从输入InputSplit中解析出一个个key/value Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中 Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作,溢写阶段详情： 步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序 步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作 步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中 Merge阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件,MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index 在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并mapreduce.task.io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件 让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销 ReducerTask工作机制 Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中 Sort阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可 Reduce阶段：reduce()函数将计算结果写到HDFS上 注意事项 MapTask并行度由切片个数决定，切片个数由输入文件和切片规则决定 ReduceTask的并行度同样影响整个Job的执行并发度和执行效率，但与MapTask的并发数由切片数决定不同，ReduceTask数量的决定是可以直接手动设置 ReduceTask=0，表示没有Reduce阶段，输出文件个数和Map个数一致 ReduceTask默认值就是1，所以输出文件个数为一个 如果数据分布不均匀，就有可能在Reduce阶段产生数据倾斜 ReduceTask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个ReduceTask 如果分区数不是1，但是ReduceTask为1，不执行分区过程。因为在MapTask的源码中，执行分区的前提是先判断ReduceNum个数是否大于1。不大于1肯定不执行分区 Shuffle阶段 Shuffle机制 Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。 Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快 缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb默认100M 当缓冲区达到80%的时候，会启动一个后台线程将缓冲区中的数据写到磁盘上，同时继续接收新的数据 Parition分区 将MapTask输出的数据按照key进行分区，每个分区交给一个ReduceTask处理，默认分区是根据key的hashCode对ReduceTasks个数取模得到的 （1）如果ReduceTask的数量&gt;getPartition的结果数，则会多产生几个空的输出文件part-r-000xx （2）如果1&lt;ReduceTask的数量&lt;getPartition的结果数，则有一部分分区数据无处安放，会Exception； （3）如果ReduceTask的数量=1，则不管MapTask端输出多少个分区文件，最终结果都交给这一个ReduceTask，最终也就只会产生一个结果文件part-r-00000； （4）分区号必须从零开始，逐一累加 WritableComparable排序 MapTask和ReduceTask均会对数据按照key进行排序。该操作属于Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。 默认排序是按照字典顺序排序，且实现该排序的方法是快速排序 对于MapTask，它会将处理的结果暂时放到环形缓冲区中，当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行归并排序 对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序 bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序 Combiner合并 （1）Combiner是MR程序中Mapper和Reducer之外的一种组件。 （2）Combiner组件的父类就是Reducer。 （3）Combiner和Reducer的区别在于运行的位置Combiner是在每一个MapTask所在的节点运行; （4）Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量。 （5）Combiner能够应用的前提是不能影响最终的业务逻辑，而且，Combiner的输出kv应该跟Reducer的输入kv类型要对应起来 OutputFormat数据输出 OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了OutputFormat接口。默认输出格式是TextOutputFormat 自定义一个LogOutputFormat类集成FileOutputFormat 重写getRecordWriter方法，返回一个自定义的LogRecordWriter 编写LogRecordWriter类, 具体改写RecordWriter的write方法，实现输出的逻辑 MapReduce编码 MapReduce编程规范 用户编写的程序分为三个部分:Mapper,Reducer,Driver Mapper阶段 用户自定义Mapper要集成的类 Mapper的输入数据是KV对的形式(确定KV类型) Mapper的业务逻辑写在map()方法中 Mapper的输出数据是KV对的形式(确定KV类型) map()对每个KV调用一次 Reducer阶段 用户自定义Reducer要集成的类 Reducer的输入数据是KV对的形式(确定KV类型) Reducer的业务逻辑写在reduce()方法中 Reducer的输出数据是KV对的形式(确定KV类型) reduce()对每一组相同的K调用一次 Driver阶段 相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象 Hadoop序列化 序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。反序列化就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。 对象一般只存在内存里,序列化后可以存储到磁盘,网络传输. Java序列化是一个重量级框架,一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop自己开发了一套序列化机制（Writable） 自定义bean对象实现序列化接口 实现Writable接口 反序列化时，需要反射调用空参构造函数，所以必须有空参构造 重写序列化方法,重写反序列化方法(反序列化的顺序和序列化的顺序完全一致) 如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为MapReduce框中的Shuffle过程要求对key必须能排序 MapReduce编程 1）输入数据接口：InputFormat （1）默认使用的实现类是：TextInputFormat （2）TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。 （3）CombineTextInputFormat可以把多个小文件合并成一个切片处理，提高处理效率。 2）逻辑处理接口：Mapper 用户根据业务需求实现其中三个方法：map(), setup(), cleanup() 3）Partitioner分区 （1）有默认实现HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces （2）如果业务上有特别的需求，可以自定义分区。 4）Comparable排序 （1）当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo()方法。 （2）部分排序：对最终输出的每一个文件进行内部排序。 （3）全排序：对所有数据进行排序，通常只有一个Reduce。 （4）二次排序：排序的条件有两个。 5）Combiner合并 Combiner合并可以提高程序执行效率，减少IO传输。但是使用时必须不能影响原有的业务处理结果。 6）逻辑处理接口：Reducer 用户根据业务需求实现其中三个方法：reduce(), setup(), cleanup() 7）输出数据接口：OutputFormat （1）默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对，向目标文本文件输出一行。 （2）用户还可以自定义OutputFormat。 Hadoop数据压缩 1）压缩的好处和坏处压缩的优点： 以减少磁盘IO、减少磁盘存储空间。 压缩的缺点：增加CPU开销。 2）压缩原则 （1）运算密集型的Job，少用压缩 （2）IO密集型的Job，多用压缩 3）压缩方式选择 压缩方式选择时重点考虑：压缩/解压缩速度、压缩率（压缩后存储大小）、压缩后是否可以支持切片 4）压缩可以在MapReduce作用的任意阶段启用 5）MR支持的压缩编码 压缩格式 Hadoop自带 算法 文件扩展名 是否支持切片 原程序是否需要修改 DEFLATE 是，直接使用 DEFLATE .deflate 否 和文本处理一样，不需要修改 Gzip 是，直接使用 DEFLATE .gz 否 和文本处理一样，不需要修改 bzip2 是，直接使用 bzip2 .bz2 是 和文本处理一样，不需要修改 LZO 否，需要安装 LZO .lzo 是 需要建索引，还需要指定输入格式 Snappy 是，直接使用 Snappy .snappy 否 和文本处理一样，不需要修改 通用资源管理系统Yarn Yarn简介 Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。 有任务推测执行功能 Yarn架构 ResourceManager:集群的Master 负责整个集群的资源分配和调度(调度策略) 监控NodeManager的运行状态 启动或监控ApplicationMaster的运行状态 处理客户端的请求 NodeManager:集群的Slave 负责单个节点上的资源管理和任务管理 与ResourceManager通信,汇报节点资源使用情况 接收ResourceManager的命令,启动或停止Container 处理来自ApplicationMaster的请求 ApplicationMaster:每个应用程序的Master 负责应用程序的管理和协调 与ResourceManager通信,申请资源,释放资源 与NodeManager通信,启动或停止Container 监控任务与容错 Container:资源分配的基本单位 Yarn工作机制 （1）MR程序提交到客户端所在的节点。 （2）YarnRunner向ResourceManager申请一个Application。 （3）RM将该应用程序的资源路径返回给YarnRunner。 （4）该程序将运行所需资源提交到HDFS上。 （5）程序资源提交完毕后，申请运行mrAppMaster。 （6）RM将用户的请求初始化成一个Task。 （7）其中一个NodeManager领取到Task任务。 （8）该NodeManager创建容器Container，并产生MRAppmaster。 （9）Container从HDFS上拷贝资源到本地。 （10）MRAppmaster向RM 申请运行MapTask资源。 （11）RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。（12）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。 （13）MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。 （14）ReduceTask向MapTask获取相应分区的数据。 （15）程序运行完毕后，MR会向RM申请注销自己。 作业提交 Client调用job.waitForCompletion()方法向集群提交作业 Client向ResourceManager申请一个做业的id ResourceManager返回一个job资源的提交路径和id Client提交jar包,切片信息和配置文件到HDFS指定路径 Client提交完资源后,向ResourceManager申请运行MRAppMaster 作业初始化 6. ResourceManager收到请求后,将该job添加到调度器中 7. 某个空闲的NodeManager领取到任务 8. 该NodeManager创建容器Container,并启动MRAppMaster 9. 从HDFS下载Client提交的资源到本地 任务分配 10. MRAppMaster向ResourceManager申请运行多个MapTask资源 11. ResourceManager将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器 任务执行 12. MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序 13. MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask 14. ReduceTask向MapTask获取相应分区的数据 15. 程序运行完毕后，MR会向RM申请注销自己 进度和状态更新 16. YARN中的任务将其进度和状态(包括counter)返回给应用管理器, 客户端每秒向应用管理器请求进度更新, 展示给用户。 作业完成 17. 除了向应用管理器请求作业进度外, 客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。作业完成之后, 应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。 Yarn的容错机制 ResourceManager的容错 借助Zookeeper实现高可用 ApplicationMaster的容错 RM中的ASM负责监控AM的运行状态，一旦发现它运行失败或超时（在规定时间段内未使用为其分配的Container），就为其重新分配资源并启动它 AM重新启动后如何恢复其内部的状态，则需由AM自己保证，比如MRAppMaster: 在作业运行过程中把状态信息动态记入HDFS中 在出现故障重启后，它就从HDFS中读取并恢复之前的状态，以减少重新计算带来的开销 NodeManager的容错 如果某个NM在规定的时间段内未向RM发送心跳消息（可能是网络方面的原因或NM自身的原因），RM则认为它已经宕机 RM将该NM上所有正在运行的Container（任务）的状态置为失败，并分别通知它们所属作业的AM，由AM对这些Container中运行的任务作出处理 AM替失败的任务向RM重新申请一个Container，并重新启动 如果AM自身使用的Container运行失败，则由RM中的ASM为其重新申请一个Container，并重启AM Contrainer的容错 对于运行任务的Container，RM收回Container，并通知其申请者（AM），由它决定如何处理 对于运行AM的Container，RM收回Container，由RM中的ASM重新为它申请一个Container，并重启 ☆Yarn的资源调度 对当前请求任务的节点进行检查 若该节点上的磁盘容量小于某阈值，则不再给该节点分配任务 若一个作业在该节点上运行失败的任务数量超过某阈值，则不再给该节点分配此作业的任务 Mapper任务调度 优先选择运行失败的任务，以让其尽快获得重新运行的机会； 其次按照数据本地性策略选择尚未运行的任务； 最后从正在运行的任务中推测是否有“拖后腿”任务，若有则为其启动备份任务 Reducer任务调度 Reduce任务的数据来自多个节点，故没有数据本地性可言，即无须考虑本地性 Yarn做业调度主要有三种方式:FIFO,容量调度(默认),公平调度 FIFO调度 先到先得 容量调度 公平调度 Yarn命令 12345678910111213141516171819# 查看所有的队列yarn application -list# 查看状态yarn application -list -appStates RUNNING# Kill掉队列yarn application -kill application_1616350000001_0001# 查看日志yarn logs -applicationId application_1616350000001_0001# 查看Container日志yarn logs -applicationId application_1616350000001_0001 -containerId container_1616350000001_0001_01_000001# 查看容器yarn container -list# 查看节点状态yarn node -list -all# 查看队列yarn queue -list Yarn的生产环境核心参数 123456789101112131415161718192021# 1.ResourceManager相关yarn.resourcemanager.scheduler.class # 配置调度器,默认容量调度yarn.resourcemanager.scheduler.client.thread-count # ResourceManger处理调度器请求的线程数,默认50# 2.NodeManager相关yarn.nodemanager.resource.detect-hardware-capabilities # 是否开启硬件检测,默认falseyarn.nodemanager.resource.count-physical-cores # 是否将物理核数当作CPU核数，默认falseyarn.nodemanager.resource.pcores-vcores-multiplier # 虚拟核数和物理核数乘数，例如：4核8线程，该参数就应设为2，默认1.0yarn.nodemanager.pmem-check-enabled # 是否开启物理内存检查限制container，默认打开yarn.nodemanager.vmem-check-enabled # 是否开启虚拟内存检查限制container，默认打开yarn.nodemanager.vmem-pmem-ratio # 虚拟内存物理内存比例，默认2.1yarn.nodemanager.resource.memory-mbNodeManager # 使用内存，默认8Gyarn.nodemanager.resource.system-reserved-memory-mbNodeManager # 为系统保留多少内存以上二个参数配置一个即可yarn.nodemanager.resource.cpu-vcoresNodeManager # 使用CPU核数，默认8个# 3.Contrainer相关yarn.scheduler.minimum-allocation-mb # 容器最最小内存，默认1Gyarn.scheduler.maximum-allocation-mb # 容器最最大内存，默认8Gyarn.scheduler.minimum-allocation-vcores # 容器最小CPU核数，默认1个yarn.scheduler.maximum-allocation-vcores # 容器最大CPU核数，默认4个 分布式协调器Zookeeper Zookerper简介 Zookeeper是一个开源的分布式的，为分布式框架提供协调服务的Apache项目 是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper就将负责通知已经在Zookeeper上注册的那些观察者做出相应的反应。 Zookerper架构 ZooKeeper是一个由奇数（2n+1）台同构服务器组成的集群，它采用主-从结构 一台主服务器Leader，若干台从服务器Follower，只要有超过半数的服务器能够工作，ZooKeeper集群就能正常工作 集群内所有服务器均保持同步，都接受客户端的读写请求 如果ZooKeeper集群中的Leader出现了故障，那么Follower们就会通过一定的策略，选举出一个新的Leader； Learder功能： 启动或重启时恢复数据 检测Follower的心跳 结束Foller发来的请求根据不同的类型做出处理，比如写 Follower功能： 接受Leader的消息，并完成工作 向Leader发送心跳 接受客户端的请求，如果为读请求，直接返回结果，如果为写请求，转发给Leader Zookerper数据模型 Zookeeper维护一个类似于树状的文件系统 树状结构中有一个根节点，称为&quot;/&quot;，其他节点建立在根节点上，每个节点称为ZNode 每个节点可以存储不超过1MB的数据，持久性的ZNode还可以在创建子节点 ZNode的类型： 持久性节点：一旦创建，除非主动删除，否则一直存在 持久性顺序节点：一旦创建，除非主动删除，否则一直存在，节点名后面会有一个递增的序号 临时节点：客户端断开连接后，该节点会被删除 临时顺序节点：客户端断开连接后，该节点会被删除，节点名后面会有一个递增的序号 ZNode组成： 访问控制列表（ACL）：控制对ZNode的访问权限 ZNode自身状态信息：创建者ID等 ZNode数据：存储的数据 Zookeeper的一致性 会话（Session）机制 当客户端成功连接到ZooKeeper时，就与之建立了一个会话，客户端通过定时向ZooKeeper发送心跳消息来保持会话有效 如果ZooKeeper在规定时间段（默认为180秒）内未能收到某个客户端的心跳消息，则使其会话失效，即导致该客户端与ZooKeeper断开 如果因服务器负载过重、网络阻塞等导致客户端与ZooKeeper集群内某个服务器断开，客户端只要在规定时间段内与ZooKeeper集群内的任何一个服务器连接上，该会话仍然有效。 监视（Watcher）机制 客户端可以在某个Znode上设置一个Watcher（监视器），来监视该Znode的状态； Watcher一次性有效 一旦被设置了Watcher的Znode的状态发生变化，ZooKeeper服务端会将此事件通知设置Watcher的客户端，并根据事件类型触发回调客户端事先设置的处理逻辑 Zookeeper的自身一致性 myid:Zookeeper集群中每个服务器的唯一标识，myid文件中只包含一个数字，这个数字就是这个服务器的编号 ZXID: ZooKeeper为每个事务操作分配一个全局单调递增的事务编号（ZXID），每个ZXID对应于一次事务操作，它随事务一起被记入事务日志. ZXID是一个64位二进制数，其高32位为Leader周期的编号，称作epoch，新选出的Leader的epoch为其前任Leader的epoch值加1 ZXID的低32位是一个单调递增的计数器，Leader在执行一个新的事务操作时，都会对该计数器作加1操作，其与epoch组合成此事务操作的ZXID 每当选举出一个新的Leader时，就从该Leader的事务日志内挑选出数值最大的事务编号ZXID，对其中的epoch值作加1操作，以此作为新Leader的周期编号，并将低32位置0，从而形成新的ZXID 原子广播ZAB (ZooKeeper Atomic Broadcast) 恢复模式： 系统启动或Leader发生故障时，ZAB进入恢复模式 立即进行一次Leader选举，选出一个新的Leader 让集群中至少有超过半数的Follower与Leader具有相同的系统状态，即实现数据同步 ZAB退出恢复模式，进入广播模式 广播模式（写流程）： Leader收到客户端发来的事务操作请求时，Leader通过ZAB的广播模式向集群内的所有Follower进行消息广播，即发送事务操作请求消息 各个Follower收到Leader广播（发送）的事务操作请求后，把将要作的事务操作及其ZXID记入各自的事务日志，然后向Leader回复ack（确认）消息 若Leader收不到超过半数的Follower回复的ack消息，则取消本次更新操作 若Leader收到超过半数的Follower回复的ack（确认）消息，则向Follower们进行消息广播—向它们发送commit（许可）消息 Follower收到Leader的commit消息，就真正执行本次更新操作，即更新内存或Znode内的数据 整个ZAB的广播模式执行过程是一个整体，不能被打断，其结果只有成功或失败，不存在中间状态 Zookeeper的选举机制 选举的基本原则 选举开始时，ZooKeeper集群内各台服务器上的数据不一定会完全一致，在选出Leader之后，就要以该Leader为基准来同步其他服务器上的数据； 应该把集群内拥有最新数据的服务器选为Leader，故必须挑选其事务日志中具有最大ZXID的那台服务器作为Leader，因为该服务器进行了最新的事务操作，故其拥有的数据是最新的，以其作为基准来恢复和同步数据，则可以保证数据的完整性； 若具有最大ZXID的服务器不止一个，则选其中myid最大者为Leader 选举流程 集群内各服务器均进入LOOKING状态，进行一轮选举投票，即各服务器均向其他服务器发送投票消息，消息的内容为自身的myid和自身最大的ZXID，也就是把自身定为候选Leader（争作Leader） 各服务器接收投票消息（包括自己的票），从中挑选出具有最大ZXID的服务器作为候选Leader ，若这样的服务器有多个，则挑选其中myid最大者 各服务器统计本轮投票中候选Leader的得票数 若未过半数，则把前一步挑选出的候选Leader的myid和ZXID记入投票消息，进行下一轮投票 如果候选Leader得票数过半，则判别候选Leader是否是自身，若是，则该服务器进入LEADING状态，否则该服务器进入FOLLOWING状态 ### Zookeeper的操作 Shell操作 1234567891011121314151617181920212223242526# 查看节点ls /# 查看节点详细信息ls -s /# 创建永久节点create /node1 &quot;data1&quot;# 创建永久顺序节点create -s /node2 &quot;data2&quot;# 创建临时节点create -e /node3 &quot;data3&quot;# 创建临时顺序节点create -s -e /node4 &quot;data4&quot;# 查看节点数据get -s /node1# 查看节点详细信息stat /node1# 修改节点数据set /node1 &quot;data1-1&quot;# 删除节点delete /node1# 删除节点并递归删除子节点deleteall /node1 API操作 1234567891011121314151617181920212223// 创建监视点// 1. 创建配置对象private String connectString = &quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;;private int sessionTimeout = 2000;private ZooKeeper zkClient;// 2. 创建zookeeper的连接zkClient = new ZooKeeper(connectString, sessionTimeout, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; System.out.println(&quot;默认回调函数&quot;); &#125;&#125;);// 3. 使用自定义的监视zk.exists(&quot;/path/to/znode&quot;, new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; // 处理监视事件的逻辑 &#125;&#125;);// 4. 使用默认的监视zk.exists(&quot;/path/to/znode&quot;, true); 分布式数据库HBase 简介 HBase是一种以HDFS为依据的分布式可扩展NoSQL列族数据库 NoSQL理论基础: CAP理论与BASE理论 传统关系数据库技术的核心特征：事务操作必须遵循ACID（原子性Atomicity、一致性Consistancy、隔离性Isolation、持久性Durability）原则，具有强事务、强一致性。 NoSQL数据库的特点：NoSQL方案弱化事务处理的ACID特性，一般不持支传统数据库的SQL查询语言 CAP理论：在设计和部署分布式应用时，存在三个核心的系统需求： C：Consistency（一致性）—在对数据进行更新和删除操作后，用户都能看到相同的数据视图。 A：Availability（可用性）—可用性主要是指系统能够很好地为用户服务，不出现用户操作失败或者访问超时等用户体验不佳的情况（比如由强一致性带来的副作用）。 P：Partition Tolerance（分区容错性）—分区容错性和可扩展性是紧密相关的，好的分区容错性要求一个分布式系统就像是一个运转正常的整体，当系统中有部分网络或节点发生故障时，仍然能够依靠系统中其余完好的部分来保证系统正常运作。 CAP理论的核心：一个分布式系统不可能同时很好地满足一致性C，可用性A、分区容错性P这三个需求，最多只能同时较好地满足其中的两个需求。 OldSQL为了不降低可用性，通常对数据采用不分散存储的策略，使可扩展性（即分区容错性P）受到限制，可看作保证C、A，放弃P； NoSQL为了获得可扩展性，又不降低可用性，在设计中就会弱化甚至去除事务的ACID要求，可看作保证A、P，放弃C。 BASE (BA,S,E) 理论：牺牲强一致性，获得可用性或可靠性，表现为以下三点： BA：Basically Availability（基本可用） S：Soft State（软状态）—允许系统中的数据存在中间状态，而这个中间状态不会影响系统的整体可用性。硬状态”是指严格遵循ACID原则的事务功能； E: Eventually Consistency（最终一致性）—系统中的数据经过一段时间后，最终会达到一致的状态。 HBase逻辑结构 HBase的逻辑结构可以看作是一个二维的表格结构,行代表RowKey(唯一,按RowKey排序),列代表列族,其中列族下面可以有多个列限定符,每个列限定符下面存储一个值,这个值可以是多个版本的,每个版本都有一个时间戳,时间戳是一个64位的整数,代表了这个版本的时间,时间戳越大,版本越新 HBase物理结构 HBase的物理结构是基于HDFS的,每个表都会有一个对应的目录,目录下面有两个子目录,分别是data和wal,其中data目录存储了HFile文件,而wal目录存储了WAL文件(Write-Ahead-Log,预写日志). HBase的RegionServer和HMaster不负责存储数据,只负责管理数据,而实际的数据存储在HDFS上 HBase数据模型 Namespace: 命名空间,类似于关系数据库中的database概念.命名空间下可以有多个表,HBase自带两个命名空间,分别是default和hbase,hbase中存放的是HBase内置的表,其中meta表存放了所有表的元数据信息 Table: 表,类似于关系数据库中的table概念,表中存放的是多行数据,每行数据都有一个唯一的RowKey,表中的数据是按照RowKey进行排序的 Row: HBase表中的每行数据都由一个RowKey和多个Column（列）组成，数据是按照RowKey的字典顺序存储的，并且查询数据时只能根据RowKey进行检索，所以RowKey的设计十分重要 Cell: 由{rowkey, columnFamily：columnQualifier, timestamp} 唯一确定的单元。Cell为空时,不会存储在HBase中. 基本架构 Master服务器负责管理所有Region服务器和数据表(hbase:meta) 其本身不存储HBase中的数据； 接收用户对表格创建修改删除的命令并执行 监控region是否需要进行负载均衡，故障转移和region的拆分 Region服务器是HBase中最核心的部分： Region服务器是HBase的读写节点，它为用户提供对数据表数据的读写服务 一张数据表被划分成(横向划分)多个HRegion，这些HRegion被分布到Region服务器集群内进行管理 HRegion是一个HBase表横向切割的结果: 在HRegion中,每个列族又被分为一个Store.每个Store中存储了一个列族的数据,不包含空元素 Store中包含一个MemStore,一个Block Cache和多个HFile,MemStore负责缓存写入的数据(有序,每次flush都回形成一个HFile),Block Cache负责缓存读取的数据,HFile是HBase中的数据存储文件 Zookeeper监视Region服务器和Master服务器的运行状态 各个Region服务器会在ZooKeeper的Z节点/server上建立临时性顺序节点，Master服务器在/server上设置Watcher，可以随时感知到各个Region服务器的运行状态； 当前的Active Master服务器在ZooKeeper上建立临时性Z节点/Master，各个Region服务器和Master集群内的其它服务器均在/Master上设置Watcher，它们可以随时感知到当前的Active Master服务器的工作（运行）状态； HBase操作 Shell操作 基本操作 1234# 创建命名空间create_namespace &#x27;ns1&#x27;# 查看所有命名空间list_namespace DDL操作 12345678910111213141516171819# 创建表# 在ns1命名空间下创建表table1,列族为cf1,cf2create &#x27;ns1:table1&#x27;, &#x27;cf1&#x27;, &#x27;cf2&#x27;# 在ns1命名空间下创建表table1,列族为cf1,cf2,并指定版本数create &#x27;ns1:table1&#x27;, &#123;NAME =&gt; &#x27;cf1&#x27;, VERSIONS =&gt; 3&#125;, &#123;NAME =&gt; &#x27;cf2&#x27;, VERSIONS =&gt; 5&#125;# 查看表list# 查看表详情describe &#x27;ns1:table1&#x27;# 删除表disable &#x27;ns1:table1&#x27;drop &#x27;ns1:table1&#x27;# 修改表# 修改表的列族的版本数alter &#x27;ns1:table1&#x27;, &#123;NAME =&gt; &#x27;cf1&#x27;, VERSIONS =&gt; 5&#125;# 删除表的列族alter &#x27;ns1:table1&#x27;, &#x27;delete&#x27; =&gt; &#x27;cf1&#x27;alter &#x27;ns1:table1&#x27;, &#123;NAME =&gt; &#x27;cf1&#x27;, METHOD =&gt; &#x27;delete&#x27;&#125; DML操作 12345678910111213141516171819202122232425262728# 插入数据# 如果重复写入相同rowKey，相同列的数据，会写入多个版本进行覆盖。# 向ns1:table1表中插入一行数据,行键为row1,列族为cf1,列限定符为col1,值为value1put &#x27;ns1:table1&#x27;, &#x27;row1&#x27;, &#x27;cf1:col1&#x27;, &#x27;value1&#x27;# 读取数据get# 读取ns1:table1表中的一行数据,行键为row1get &#x27;ns1:table1&#x27;, &#x27;row1&#x27;# 读取ns1:table1表中的一行数据,行键为row1,列族为cf1get &#x27;ns1:table1&#x27;, &#x27;row1&#x27;, &#123;COLUMN =&gt; &#x27;cf1&#x27;&#125;# 读取数据scan# 读取ns1:table1表中的所有数据scan &#x27;ns1:table1&#x27;# 读取ns1:table1表中的所有数据,并指定列族scan &#x27;ns1:table1&#x27;, &#123;COLUMN =&gt; &#x27;cf1&#x27;&#125;# 读取ns1:table1表中的所有数据,从row1开始,到row2结束scan &#x27;ns1:table1&#x27;, &#123;STARTROW =&gt; &#x27;row1&#x27;, ENDROW =&gt; &#x27;row2&#x27;&#125;# 删除数据# 删除ns1:table1表中的一行数据,行键为row1delete &#x27;ns1:table1&#x27;, &#x27;row1&#x27;# 删除ns1:table1表中的一行数据,行键为row1,列为cf1中的namedelete &#x27;ns1:table1&#x27;, &#x27;row1&#x27;, &#x27;cf1：name&#x27;# 删除数据的所有版本deleteall &#x27;ns1:table1&#x27;, &#x27;row1&#x27;, &#x27;cf1：name&#x27;# 执行命令会标记数据为要删除，不会直接将数据彻底删除，删除数据只在特定时期清理磁盘时进行 API操作 HBase的客户端连接由ConnectionFactory类来创建，用户使用完成之后需要手动关闭连接。同时连接是一个重量级的，推荐一个进程使用一个连接，对HBase的命令通过连接中的两个属性Admin(DDL)和Table(DML)来实现。 123456789101112131415// 创建连接//1. 创建配置对象Configuration conf = new Configuration();// 2. 添加配置参数conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;hadoop102,hadoop103,hadoop104&quot;);// 3. 创建hbase的连接// 默认使用同步连接Connection connection = ConnectionFactory.createConnection(conf);// 可以使用异步连接// 主要影响后续的DML操作CompletableFuture&lt;AsyncConnection&gt; asyncConnection = ConnectionFactory.createAsyncConnection(conf);// 4. 使用连接System.out.println(connection);// 5. 关闭连接connection.close(); HBase在API操作时使用了装饰者（设计师）模式。因为shell命令的参数很多，所以在API中使用了装饰者模式，将参数封装成对象，然后通过对象的方法来实现shell命令的功能。 HBase一些原理 HBase架构 hbase:meta 表中存储了 Hbase 集群中全部表的所有的Hregion 信息,在list命令中被过滤掉了 StoreFile保存实际数据的物理文件，StoreFile以HFile的形式存储在HDFS上。每个Store会有一个或多个StoreFile（HFile），数据在每个StoreFile中都是有序的。 MemStore写缓存，由于HFile中的数据要求是有序的，所以数据是先存储在MemStore中，排好序后，等到达刷写时机才会刷写到HFile，每次刷写都会形成一个新的HFile。 WAL由于数据要经MemStore排序后才能刷写到HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做Write-Ahead logfile的文件中，然后再写入MemStore中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。 Store HBase的写流程 Client先访问zookeeper，获取hbase:meta表位于哪个RegionServer。 访问对应的Region Server，获取hbase:meta表，根据读请求的namespace:table/rowkey，查询出目标数据位于哪个RegionServer中的哪个Region中。并将该table的region信息以及meta表的位置信息缓存在客户端的meta cache，方便下次访问。 与目标RegionServer进行通讯； 将数据顺序写入（追加）到WAL(HLog)； 将数据写入对应的MemStore，数据会在MemStore进行排序； 向客户端发送ack； 等达到MemStore的刷写时机后，将数据刷写到HFile。 在步骤4，5，源码的步骤是先写入HLog，在写入MemStore，然后再同步HLog。如果HLog如果写入失败，就会事务回滚。 HBase的读流程 误区：HBase的读流程并不是只读BlockCache的数据，考虑这种情况: 第一次写数据的时候成功写入，并flush罗盘了 第二次写数据的时候写入了MemStore，但是此时把ts设置为了比第一次写的ts小，但是没有罗盘 如果只读BlockCache，那么第二次写的数据就会被读到，这样就会出现数据读取不是最新的情况。 Client先访问zookeeper，获取hbase:meta表位于哪个RegionServer。 访问对应的Region Server，获取hbase:meta表，根据读请求的namespace:table/rowkey，查询出目标数据位于哪个RegionServer中的哪个Region中。并将该table的region信息以及meta表的位置信息缓存在客户端的meta cache，方便下次访问。 与目标RegionServer进行通讯； 分别在BlockCache（读缓存），MemStore和StoreFile（HFile）中查询目标数据，并将查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（timestamp）或者不同的类型（Put/Delete） 将从文件中查询到的数据块（Block，HFile数据存储单元，默认大小为64KB）缓存到BlockCache。 将合并后的最终结果返回给客户端。 HBase的Flush操作 Flush操作的基本单位是HRegion，即对HRegion的所有MemStore均进行Flush操作，并各自形成单独的StoreFile MemStore中的数据达到阈值（128M）后，其所在region的所有memstore都会刷写。 到达自动刷写的时间（默认1小时），最后一次刷写的时间到当前时间间隔超过了自动刷写的时间间隔。 HRegion的所有MemStore中的数据总量到达阈值（JVM heap的40%）后，也会触发Flush操作。 当阈值到低位线（总阈值的95%，JVM heap的38%）时，region会按照其所有memstore的大小顺序（由大到小）依次进行刷写。直到region server中所有memstore的总大小减小到上述值以下。 当阈值到高位线时，region会同时阻止继续往所有的memstore写数据。 HBase的Compaction操作 Compaction合并的原因： StoreFile是只读文件，其内容不能被更新（增加、修改、删除），以此提升表数据的安全性 如果要更新StoreFile内的表数据，则必须以新增StoreFile的形式进行，把欲更新的数据（包含属性或版本号）写入新增的StoreFile中 （HBase不停的刷写，导致存储目录中有过多的数据文件，文件太多会导致维护困难、降低数据查询性能和效率。对一堆的文件进行I/O操作，耗时太多。所以HBase定期会对这些琐碎的文件进行整理，即合并Compaction。） Compaction合并的步骤： 分为三步：排序文件、合并文件、代替原文件服务。 HBase首先从待合并的文件中读出HFile中的key-value,再按照由小到大的顺序写入一个新文件(storeFile)中。这个新文件将代替所有之前的文件，对外提供服务。 Compaction操作分为两种： Minor Compaction：只合并相邻的（3个）小文件，不会合并所有的文件，不会清理过期和删除的数据。 major Compaction：合并所有的文件，产生一个新的文件。 Compaction大合并时，清空以下数据： 标记为删除的数据。 当我们删除数据时，HBase并没有把这些数据立即删除，而是将这些数据打了一个个标记，称为“墓碑”标记。在HBase合并时，会将这些带有墓碑标记的数据删除。 TTL过期数据 TTL(time to live)指数据包在网络中的时间。如果列族中设置了TTL过期时间，则在合并的过程中，发现过期的数据将被删除。 版本合并 若版本号超过了列族中预先设定的版本号，则将最早的一条数据删除。 Compaction合并的触发条件： 内存中的数据flush刷写到硬盘上以后，会对当前Store中的文件进行判断，当数量达到阈值，则会触发Compaction。 Compaction Checker线程定期检查是否触发Compaction，Checker会优先检查文件数量是否大于阈值，再判断是否满足major Compaction的条件的时间范围内（7天），如果满足，则触发一次大合并Major Compaction。 手动合并 HBase的Split操作 Split原因： 随着HRegion内的数据被持续追加，StoreFile文件的数量和长度会不断增大，由此引起Store的不断增大，从而导致HRegion的长度持续增大； Split条件： 当1个region中的某个Store下所有StoreFile的总大小超过Min(R^2 * “hbase.hregion.memstore.flush.size”,&quot; hbase.hregion.max.filesize &quot;) 就会拆分，其中R为当前RegionServer中属于该table的region个数 具体的切分策略为： 第一次split：1^3 * 256 = 256MB 第二次split：2^3 * 256 = 2048MB 第三次split：3^3 * 256 = 6912MB 第四次split：4^3 * 256 = 16384MB &gt; 10GB， 因此取较小的值10GB 后面每次split的size都是10GB了。 Split过程： Region的拆分是由HRegionServer完成的，在操作之前需要通过ZK汇报master，修改对应的Meta表信息添加两列info：splitA和info：splitB信息。之后需要操作HDFS上面对应的文件，按照拆分后的Region范围进行标记区分，实际操作为创建文件引用，不会挪动数据。刚完成拆分的时候，两个Region都由原先的RegionServer管理。之后汇报给Master，由Master将修改后的信息写入到Meta表中。等待下一次触发负载均衡机制，才会修改Region的管理服务者，而数据要等到下一次压缩时，才会实际进行移动。 离线数据仓库Hive Hive简介 Hive是一个基于Hadoop的数据仓库工具(一个Hadoop的客户端)，可以将结构化的数据文件映射为一张数据库表，并提供完整的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。 Hive中每张表的数据存储在HDFS Hive分析数据底层的实现是MapReduce（也可配置为Spark或者Tez） 执行程序运行在Yarn上 Hive的架构 Hive Client Hive CLI:Hive提供的命令行接口(只能在安装了Hive的机器上使用) 远程连接的话需要使用JDBC或者ODBC客户端，连接到HiveServer2 Metastore:提供元数据的访问接口 元数据是指:用户创建的数据库,表的一些信息(在HDFS中的路径,字段信息等) 只负责提供元数据的访问接口,不负责存储元数据 元数据通常保存在关系型数据库中,默认是Derby,推荐是MySQL(derby数据库的特点是同一时间只允许一个客户端访问。如果多个Hive客户端同时访问，就会报错。) HiveServer2 提供JDBC或者ODBC的访问接口 提供用户认证功能 Driver:需要用到元数据信息 解析器:将SQL字符串解析成抽象语法树 语义分析:将抽象语法树转换成QueryBlock 逻辑计划生成器:将语法树生成逻辑计划 逻辑优化器:对逻辑计划进行优化 物理计划生成器:将逻辑计划生成物理计划 物理优化器:对物理计划进行优化 执行器:执行物理计划得到结果返回客户端 元数据库配置 安装好MySQL,并新建数据库 create database metastore 将MySQL的JDBC驱动拷贝到Hive的lib目录下 conf目录下新建hive-site.xml文件,添加mysql配置项 123456789101112131415161718192021222324252627&lt;configuration&gt; &lt;!--jdbc连接的URL--&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://hadoop102:3306/metastore?useSSL=false&lt;/value&gt; &lt;/property&gt; &lt;!--jdbc连接的Driver--&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;!--jdbc连接的username--&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;!--jdbc连接的password--&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;/property&gt; &lt;!--Hive默认在HDFS的工作目录--&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 初始化源数据库 bin/schematool -dbType mysql -initSchema -verbose 使用Hive新建表,查看MySQL中的metastore数据库,可以看到Hive的元数据信息 1234567891011-- Hive中创建表show databases;show tables;create table stu(idint,namestring);insert into stu values(1,&quot;ss&quot;);select * from stu;-- 查看MySQL中的metastore数据库show databases;use metastore;show tables;-- table中会出现元数据信息 Hiveserver2服务配置 Hiveserver2说明 在远程访问Hive数据时，客户端并未直接访问Hadoop集群，而是由Hivesever2代理访问。由于Hadoop集群中的数据具备访问权限控制，所以此时需考虑一个问题：那就是访问Hadoop集群的用户身份是谁？是Hiveserver2的启动用户？还是客户端的登录用户？ 答案是都有可能，具体是谁，由Hiveserver2的hive.server2.enable.doAs参数决定，该参数的含义是是否启用Hiveserver2用户模拟的功能。 若启用，则Hiveserver2会模拟成客户端的登录用户去访问Hadoop集群的数据， 不启用，则Hivesever2会直接使用启动用户访问Hadoop集群数据。模拟用户的功能，默认是开启的。 推荐开启用户模拟功能，因为开启后才能保证各用户之间的权限隔离。 Hiveserver2配置 123456789101112131415161718192021222324252627282930313233&lt;!-- # Hadoop# hivesever2的模拟用户功能，依赖于Hadoop提供的proxyuser（代理用户功能），只有Hadoop中的代理用户才能模拟其他用户的身份访问Hadoop集群。因此，需要将hiveserver2的启动用户设置为Hadoop的代理用户--&gt;&lt;!--配置所有节点的atguigu用户都可作为代理用户--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.atguigu.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!--配置atguigu用户能够代理的用户组为任意组--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.atguigu.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!--配置atguigu用户能够代理的用户为任意用户--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.atguigu.users&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!-- # Hive --&gt;&lt;!--指定hiveserver2连接的host--&gt;&lt;property&gt; &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt; &lt;value&gt;hadoop102&lt;/value&gt;&lt;/property&gt;&lt;!--指定hiveserver2连接的端口号--&gt;&lt;property&gt; &lt;name&gt;hive.server2.thrift.port&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt;&lt;/property&gt; 启动 bin/hive--servicehiveserver2 Hiveserver2使用 Hive提供的Beeline命令行客户端 bin/beeline,然后 !connect jdbc:hive2://hadoop102:10000 ,输入用户名密码 Datagrip图形化客户端 MetaStore服务配置 MetaStore的服务模式 Hive的metastore服务的作用是为HiveCLI或者Hiveserver2提供元数据访问接口 metastore有两种运行模式，分别为嵌入式模式和独立服务模式 嵌入式模式下，每个HiveCLI都需要直接连接元数据库，当HiveCLI较多时，数据库压力会比较大。 每个客户端都需要用户元数据库的读写权限，元数据库的安全得不到很好的保证 MetaStore的嵌入服务模式配置 嵌入式模式下，只需保证Hiveserver2和每个HiveCLI的配置文件hive-site.xml中包含连接元数据库所需要的参数即可 MetaStore的独立服务模式配置 保证metastore服务的配置文件hive-site.xml中包含连接元数据库所需的参数 保证Hiveserver2和每个HiveCLI的配置文件hive-site.xml中包含访问metastore服务所需的以下参数 123456&lt;!-- 主机名需要改为metastore服务所在节点，端口号无需修改，metastore服务的默认端口就是9083 --&gt;&lt;!--指定metastore服务的地址--&gt;&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://hadoop102:9083&lt;/value&gt;&lt;/property&gt; 启动 hive --service metastore Hive操作 “-e”不进入hive的交互窗口执行hql语句 1hive -e &quot;show databases&quot; “-f”执行hql文件 1hive -f /opt/module/hive/hive.sql 用户自定义配置会覆盖默认配置,Hive的配置会覆盖Hadoop的配置 可以使用命令行参数设置,但是仅对本次hive启动有效 可以在交互式中用 set设置,但是仅对本次hive会话有效 DDL(Data Definition Language) 数据库操作 创建数据库 12345-- 创建数据库CREATE DATABASE [IF NOT EXISTS] database_name[COMMENT database_comment][LOCATION hdfs_path][WITH DBPROPERTIES (property_name=property_value,...)]; IF NOT EXISTS:如果数据库不存在则创建 COMMENT:数据库的注释 LOCATION:数据库在HDFS上的存储路径 WITH DBPROPERTIES:数据库的属性 查询数据库 12345-- 查看所有数据库SHOW DATABASES [LIKE &#x27;identifier_with_wildcards&#x27;];-- 查看数据库的信息,EXTENDED表示显示详细信息DESCRIBE DATABASE [EXTENDED] db_name; 修改数据库 12345678--修改dbpropertiesALTER DATABASE database_name SET DBPROPERTIES (property_name=property_value, ...);--修改locationALTER DATABASE database_name SET LOCATION hdfs_path;--修改owner userALTER DATABASE database_name SET OWNER USER user_name; 删除数据库 123-- RESTRICT：严格模式，若数据库不为空，则会删除失败，默认为该模式。-- CASCADE：级联模式，若数据库不为空，则会将库中的表一并删除。DROP DATABASE [IF EXISTS] database_name [RESTRICT|CASCADE]; 切换数据库 1USE database_name; 表操作 创建表 普通建表 12345678910CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name [(col_name data_type [COMMENT col_comment], ...)][COMMENT table_comment][PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)][CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS][ROW FORMAT row_format] [STORED AS file_format][LOCATION hdfs_path][TBLPROPERTIES (property_name=property_value, ...)] TEMPORARY:临时表,会话结束后自动删除 EXTERNAL:外部表,表的数据不会被删除,只会删除元数据,对应的是内部表,Hive会自动管理内部表的数据 data_type:数据类型(注意多了复杂类型:array,map,struct) 补充两种类型转换: 小范围类型可以转为更广的范围类型 隐式转换规则 显示转换需要使用cast函数 cast(expr as &lt;type&gt;) PARTITIONED BY:分区字段 CLUSTERED BY,...,INTO BUCKETS:分桶字段 ROW FORMAT:指定SERDE，SERDE是Serializer and Deserializer的简写。Hive使用SERDE序列化和反序列化每行数据。 STORED AS:指定存储格式有，textfile（默认值），sequence file，orc file、parquet file等。 LOCATION:指定表的存储路径若不指定路径，其默认值为 $&#123;hive.metastore.warehouse.dir&#125;/db_name.db/table_name TABLEPROPERTIES:表的属性 ROW FORMAT说明 语法一： DELIMITED关键字表示对文件中的每个字段按照特定分割符进行分割，其会使用默认的SERDE对每行数据进行序列化和反序列化。 123456ROW FORAMT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] [NULL DEFINED AS char] fields terminated by ：列分隔符。 collection items terminated by ： map、struct和array中每个元素之间的分隔符。 map keys terminated by ：map中的key与value的分隔符。 lines terminated by ：行分隔符。 语法二： SERDE关键字可用于指定其他内置的SERDE或者用户自定义的SERDE。例如JSON SERDE，可用于处理JSON字符串。 1ROW FORMAT SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value,property_name=property_value, ...)] Create Table As Select(CTAS)创建表 1234567CREATE [TEMPORARY] TABLE [IF NOT EXISTS] table_name [COMMENT table_comment] [ROW FORMAT row_format] [STORED AS file_format] [LOCATION hdfs_path][TBLPROPERTIES (property_name=property_value, ...)][AS select_statement] 该语法允许用户利用select查询语句返回的结果，直接建表，表的结构和查询语句的结构保持一致，且保证包含select查询语句放回的内容。 Create Table Like创建表 123456CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name[LIKE exist_table_name][ROW FORMAT row_format] [STORED AS file_format] [LOCATION hdfs_path][TBLPROPERTIES (property_name=property_value, ...)] 该语法允许用户复刻一张已经存在的表结构，与上述的CTAS语法不同，该语法创建出来的表中不包含数据。 查看表: 1234-- 查看所有表SHOW TABLES [IN database_name] LIKE [&#x27;identifier_with_wildcards&#x27;]-- 查看表详细信息DESCRIBE [EXTENDED | FORMATTED] [db_name.]table_name 修改表: 12345678910--重命名表ALTER TABLE table_name RENAME TO new_table_name;-- 修改列信息-- 增加列ALTER TABLE table_name ADD COLUMNS (col_name data_type [COMMENT col_comment], ...)-- 更新列ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]-- 替换列ALTER TABLE table_name REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) 删除表: 1DROP TABLE [IF EXISTS] table_name; 清空表: 12-- 仅删除表中数据，保留表结构,不能删除外部表TRUNCATE [TABLE] table_name DML(Data Manipulation Language) Load Load语句可将文件导入到Hive表中 1LOAD DATA [LOCAL] INPATH &#x27;filepath&#x27; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]; （1）local：表示从本地加载数据到Hive表；否则从HDFS加载数据到Hive表。 （2）overwrite：表示覆盖表中已有数据，否则表示追加。 （3）partition：表示上传到指定分区，若目标是分区表，需指定分区。 Insert 将查询结果插入表中 1INSERT (INTO | OVERWRITE) TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement; 将给定的值插入表中 1INSERT (INTO | OVERWRITE) TABLE tablename [PARTITION (partcol1[=val1], partcol2[=val2] ...)] VALUES values_row [, values_row ...] 将查询结果写入目标路径 12INSERT OVERWRITE [LOCAL] DIRECTORY directory [ROW FORMAT row_format] [STORED AS file_format] select_statement; Export&amp;Import Export导出语句可将表的数据和元数据信息一并到处的HDFS路径，Import可将Export导出的内容导入Hive，表的数据和元数据信息都会恢复。Export和Import可用于两个Hive实例之间的数据迁移。 12345--导出EXPORT TABLE tablename TO &#x27;export_target_path&#x27;--导入IMPORT [EXTERNAL] TABLE new_or_original_tablename FROM &#x27;source_path&#x27; [LOCATION &#x27;import_target_path&#x27;] Hive查询语句 官网说明 基础语法 12345678SELECT [ALL | DISTINCT] select_expr, select_expr, ... FROM table_reference -- 从什么表查 [WHERE where_condition] -- 过滤 [GROUP BY col_list] -- 分组查询 [HAVING col_list] -- 分组后过滤 [ORDER BY col_list] -- 排序 [CLUSTER BY col_list | [DISTRIBUTE BY col_list] [SORT BY col_list] ] -- 分桶 [LIMIT number] -- 限制输出的行数 基础查询 &amp; 分组查询 类似SQL Join查询 join连接的作用，是通过连接键将两个表的列组合起来，用于将数据库中的两个或多个表的记录合并起来。join连接可以将其他表的列添加至连接主表，将两个表合并为一个宽表. 内连接 内连接中，只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。 使用内连接时，inner join中的inner关键字可以省略。 表名也可以用子查询替代。 当使用等号连接时，就是等值连接，当使用不等号时，就是不等值连接。 左外连接 右外连接 全外连接 多表连接 oin除了可以实现2个表之间的连接外，还可以实现多表连接。 需要注意的是，连接n个表，至少需要n-1个连接条件。 大多数情况下，Hive会对每对join的连接对象启动一个MapReduce任务 对于多表连接中的每个表，如果在on子句中使用相同的列组成连接条件， Hive 会将多个表的连接转换为单个MapReduce任务 在多表连接时，表的连接顺序和选用的连接类型都会影响到最终的结果集 笛卡尔积 Hive中提供了cross join关键字，用于实现笛卡尔积 在hive.strict.checks.cartesian.product参数设置为true的严格模式下，以上语法是不能实现的，只有将该参数设置为false，以上语法才可以使用 在连接的每个 map/reduce 阶段，序列中的最后一个表会通过 reducer 进行流式传输，而其他表则会被缓冲。因此，通过合理安排join顺序，使得最大的表出现在序列的最后，有助于减少 reducer 中缓冲连接键的特定值的行所需的内存。如以下查询语句 联合(UNION) 1select_statement union [all | distinct] select_statement union [all | distinct] select_statement ... union和union all都是将查询语句的查询结果上下联合，这点和join是有区别的，join是两表的左右连接，union和union all是上下拼接。 union关键字会对联合结果去重，union all不去重。 union和union all在上下拼接查询语句时要求，两个查询语句的结果，列的个数和名称必须相同，且上下对应列的类型必须一致。 排序查询 Order By Order By：全局排序，只有一个 Reduce。 Sort By Sort By：每个 Reduce 内部排序(写入文件能看出来) 对于大规模的数据集 order by 的效率非常低。在很多情况下，并不需要全局 排序，此时可以使用 Sort by。 Sort by 为每个 reduce 产生一个排序文件。每个 Reduce 内部进行排序，对全局结果集 来说不是排序 Distribute By Distribute By：在有些情况下，我们需要控制某个特定行应该到哪个 Reducer，通常是为了进行后续的聚集操作。distribute by 子句可以做这件事。distribute by 类似 MapReduce中 partition（自定义分区），进行分区，结合 sort by 使用。 distribute by 的分区规则是根据分区字段的 hash 码与 reduce 的个数进行相除后，余数相同的分到一个区。 Hive 要求 distribute by 语句要写在 sort by 语句之前。 Cluster By 当 distribute by 和 sort by 字段相同时，可以使用 cluster by 方式。 cluster by 除了具有 distribute by 的功能外还兼具 sort by 的功能。但是排序只能是升序排序，不能指定排序规则为 asc 或者 desc。 函数 12345-- 查看内置函数show functions-- 查看函数的详细信息desc function extended function_name 单行函数 123456789101112131415161718192021222324252627282930313233-- 数值函数-- abs,round,ceil,floor,rand,exp,log,log10,pow,sqrt-- 字符串函数-- concat,substring,substr....-- 日期函数unix_timestamp：返回当前或指定时间的时间戳from_unixtime：转化 UNIX 时间戳到当前时区的时间格式current_date：当前日期current_timestamp：当前的日期加时间，并且精确的毫秒month：获取日期中的月....datediff：两个日期相差的天数（结束日期减去开始日期的天数）date_format:将标准日期解析成指定格式字符串-- 流程控制函数-- 1.nvl(A,B):若A的值不为null，则返回A，否则返回B。-- 2.case whencase when a then b [when c then d]* [else e] endcase a when b then c [when d then e]* [else f] end-- 3.ifif（boolean testCondition, T valueTrue, T valueFalseOrNull）-- 4.coalesce(A,B,C):返回参数列表中第一个不为null的值。 123456789101112131415161718-- 集合函数-- array(array1, array2, ...)：将多个数组合并成一个数组-- array_contains(array, value)：判断array集合中是否包含某个值-- sort_array(array)：对数组进行排序-- size(array)：返回数组的长度-- map(key1, value1, key2, value2, …)：创建一个map-- map_keys(map)：返回map中的所有key-- map_values(map)：返回map中的所有value-- struct(col1, col2, …)：创建一个struct-- named_struct(name1, val1, name2, val2, …)：创建一个具有指定名称的struct 聚合函数 普通聚合 sum(),avg(),count(),max(),min(),... 高级聚合 1234collect_set(col)：返回一个集合，该集合包含了所有的groupby组内不重复的值collect_list(col)：返回一个列表，该列表包含了所有的groupby组内的值 炸裂(UDTF)函数 UDTF的全称是User Defined Table-Generation Function，即用户定义的表生成函数。简单理解，UDTF就是接收一行数据，输出一行或者多行数据。系统内置的常用的UDTF有explode、posexplode、inline等 explode 1234-- 语法一：explode(array&lt;T&gt; a)-- 说明：传入参数为array数组类型，返回一行或多行结果，每行对应array数组中的一个元素。-- 语法二：explode(map&lt;K,V&gt; m)-- 说明：传入参数为map类型，由于map是key-value结构的，所以explode函数会将map参数转换为两列，一列是key，一列是value。 posexplode 12-- posexplode(array&lt;T&gt; a)。-- 说明：posexplode函数的用法与explode函数相似，增加了pos前缀，表明在返回array数组的每一个元素的同时，还会返回元素在数据所处的位置。 inline 12-- inline(array&lt;struct&lt;f1:T1,...,fn:Tn&gt;&gt; a)-- 说明：inline函数接受的参数结构体数组，其可将数组中的每个结构体输出为一行，每个结构体中的列，会展开为一个个单独的列。 lateral view UDTF函数可以将一行数据转换为多行，出现在select语句中时，不能与其他列同时出现，会报如下所示错误信息。 lateral view可以将UDTF应用到原表的每行数据，将每行数据转换为一行或多行，并将源表中每行的输出结果与该行连接起来，形成一个虚拟表。 lateral view一般在from子句后使用，紧跟在UDTF后面的是虚拟表的别名，虚拟表别名不可省略。as关键字后为执行UDTF后的列的别名，UDTF函数生成几列就要给出几个列别名，多个列别名间使用逗号分隔 1234select col1 [,col2,col3……] from 表名 lateral view udtf(expression) 虚拟表别名 as col1 [,col2,col3……] 窗口函数(开窗函数) 窗口函数能够为每行数据划分一个窗口，然后对窗口范围内的数据进行计算，最后将计算结果返回给该行数据。(类似pandas的rolling) 函数 每个窗口中的计算逻辑，都是多（行）进一（行）出，因此绝大多数的聚合函数都可以配合窗口使用 窗口 窗口范围的定义分为两种类型，一种是基于行进行定义，一种是基于值进行定义。它们都用来确定一个窗口中应该包含哪些行，但是确定的逻辑有所不同。 基于行的窗口范围定义，是通过行数的偏移量，来确定窗口范围，例如：某行的窗口范围可以包含当前行的前一行到当前行。 基于值的窗口范围定义，是通过某个列值的偏移量，来确定窗口范围，例如：若某行A列的值为10，其窗口范围可以包含，A列值大于等于10-1且小于等于10的所有行。 1234567-- 使用方法select col_1, col_2, col_3, 函数(col_1) over (窗口范围) as 别名from table_name; 123456789101112-- 基于行sum(amount) over(order by &lt;column&gt; rows between &lt;start&gt; and &lt;end&gt;)-- 基于值sum(amount) over(order by &lt;column&gt; range between &lt;start&gt; and &lt;end&gt;)-- 窗口起点不能超过终点-- unbounded preceding：窗口范围的开始位置是无限制的，即从第一行开始-- unbounded following：窗口范围的结束位置是无限制的，即到最后一行结束-- [num] preceddubg：窗口范围的开始位置是当前行的前num行-- [num] following：窗口范围的结束位置是当前行的后num行-- current row: 本行 分区 定义窗口范围时，还可以使用partition by关键字指定分区列，将每个分区单独划分为窗口。 每个分区内独立计算。 缺省 over后可以使用的窗口划分语句,都可以省略不写,包括: partition by order by (rows|range) between … and …。 ①partition by省略不写，表示不分区。在不进行分区的情况下，将会把整张表的全部内容作为窗口进行划分。 ②order by 省略不写，表示不排序。 ③(rows|range) between … and … 省略不写，则使用其默认值，默认值分以下两种情况。 若over()中包含order by，则默认值为range between unbounded preceding and current row。 若over()中不包含order by，则默认值为rows between unbounded preceding and unbounded following。 常用窗口函数 聚合函数:sum(),avg(),count(),max(),min() 跨行取值函数 lead(col, n, default): 用于获取窗口内当前行往下第n行的值。 lag(col, n, default): 用于获取窗口内当前行往上第n行的值。 lag和lead函数不支持使用rows between和range between的自定义窗口。 first_value (col, boolean):取分组内排序后，截止到当前行的第一个值。 last_value (col, boolean):取分组内排序后，截止到当前行的最后一个值。 第二个参数说明是否跳过null值，可不写。 排名函数:rank()/dense_rank()/row_number() 排名函数会对窗口范围内的数据按照order by后的列进行排名。 rank 、dense_rank、row_number不支持自定义窗口 |score|rank|dense_rank|row_number| |—|—|—|—| |90|1|1|1| |90|1|1|2| |80|3|2|3| |80|3|2|4| |70|5|3|5| 自定义函数 根据用户自定义函数类别分为以下三种： （1）UDF（User-Defined-Function） 一进一出。 （2）UDAF（User-Defined Aggregation Function） 用户自定义聚合函数，多进一出。 类似于：count/max/min （3）UDTF（User-Defined Table-Generating Functions） 用户自定义表生成函数，一进多出。 如lateral view explode() 编程步骤: 继承Hive提供的类 UDF：org.apache.hadoop.hive.ql.udf.generic.GenericUDF UDAF：org.apache.hadoop.hive.ql.udf.generic.GenericUDAFResolver UDTF：org.apache.hadoop.hive.ql.udf.generic.GenericUDTF 实现类中的抽象方法 在hive的命令行窗口中创建函数 临时函数: add jar xxx.jar create temporary function xxxxx as ‘xxx’ select xxxxx(col) from table drop temporary function xxxxx; 临时函数只跟会话有关系，跟库没有关系。只要创建临时函数的会话不断，在当前会话下，任意一个库都可以使用，其他会话全都不能使用。 永久函数: 上传jar到HDFS create function xxxxx as ‘xxx’ using jar ‘hdfs://hadoop102:9000/xxx.jar’ select xxxxx(col) from table drop function xxxxx 永久函数跟会话没有关系，创建函数的会话断了以后，其他会话也可以使用。 永久函数创建的时候，在函数名之前需要自己加上库名，如果不指定库名的话，会默认把当前库的库名给加上。 自定义UDF函数 12345678910111213141516// HQL转为MapReduce任务时,会生成Operator Tree(每个Operator都是一个小动作:扫描,select等)// 数据会逐个经过operator,数据和数据元信息是分开传递的// ObjectInspector是数据的元信息,DeferredObject是数据@Overridepublic ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException &#123; // 接受上一环节的数据,返回这个函数处理完之后数据的元信息&#125;@Overridepublic Object evaluate(DeferredObject[] arguments) throws HiveException &#123; // 接受处理数据&#125;@Overridepublic String getDisplayString(String[] children) &#123;&#125; 分区表和分桶表 分区 通过使用partitionedby子句可以创建分区表，partitionedby后面是分区字段， 一个表可以有一个或多个分区字段 Hive可以为分区字段的每个不同的字段组合创建一个单独的数据目录(文件夹) 当用户通过where子句选择要查询的分区后，就不会查询其他分区的数据 分区字段并不是表中的数据，是伪列，可以当作列用 分区表基本操作 新建分区表 123456789101112131415161718192021222324-- 创建分区表hive(default) &gt; create table dept_partition ( deptno int, dname string, loc string)partitioned by (day string)row format delimitedfields terminated by &#x27;\\t&#x27;;-- 从文件中加载load data local inpath &#x27;/opt/module/hive/datas/dept_20220401.log&#x27; into table dept_partition partition(day=&#x27;20220401&#x27;);-- 插入数据insert overwrite table dept_partition partition (day = &#x27;20220402&#x27;)select deptno, dname, locfrom dept_partitionwhere day = &#x27;2020-04-01&#x27;;-- 读取数据select deptno, dname, loc ,dayfrom dept_partitionwhere day = &#x27;2020-04-01&#x27;; 查看分区表 1show partitions dept_partition; 增加分区 123-- 中间无逗号alter table dept_partition add partition(day=&#x27;20220404&#x27;) partition(day=&#x27;20220405&#x27;); 删除分区 123-- 中间有逗号alter table dept_partition drop partition (day=&#x27;20220404&#x27;), partition(day=&#x27;20220405&#x27;); 修复分区 Hive将分区表的所有分区信息都保存在了元数据中，只有元数据与HDFS上的分区路径一致时，分区表才能正常读写数据。 若用户在HDFS上手动创建/删除分区路径，Hive都是感知不到的，这样就会导致Hive的元数据和HDFS的分区路径不一致。 若分区表为外部表，用户执行drop partition命令后，分区元数据会被删除，而HDFS的分区路径不会被删除同样会导致Hive的元数据和HDFS的分区路径不一致。 123456789101112-- 若手动创建HDFS的分区路径，Hive无法识别，可通过add partition命令增加分区元数据信息，从而使元数据和分区路径保持一致。add partition (day=&#x27;20220404&#x27;) location &#x27;/opt/module/hive/datas/dept_partition/day=20220404&#x27;;-- 若手动删除HDFS的分区路径，Hive无法识别，可通过drop partition命令删除分区元数据信息，从而使元数据和分区路径保持一致。drop partition (day=&#x27;20220404&#x27;);-- 若分区元数据和HDFS的分区路径不一致，还可使用msck命令进行修复，msck repair table table_name [add/drop/sync partitions];-- msck repair table table_name add partitions：该命令会增加HDFS路径存在但元数据缺失的分区信息。-- msck repair table table_name drop partitions：该命令会删除HDFS路径已经删除但元数据仍然存在的分区信息。-- msck repair table table_name sync partitions：该命令会同步HDFS路径和元数据分区信息，相当于同时执行上述的两个命令。-- msck repair table table_name：等价于msck repair table table_name add partitions命令。 二级分区 12345678-- 和一级分区类似，只是多了一个分区字段create table dept_partition2( deptno int, -- 部门编号 dname string, -- 部门名称 loc string -- 部门位置)partitioned by (day string, hour string)row format delimited fields terminated by &#x27;\\t&#x27;; 动态分区 插入数据指定分区很麻烦 动态分区是指向分区表insert数据时，被写往的分区不由用户指定，而是由每行数据的最后一个字段的值来动态的决定。 使用动态分区，可只用一个insert语句将数据写入多个分区。 插入语句的最后一个字段作为分区的字段，不需要指定分区字段，Hive会自动识别。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647-- 开启动态分区set hive.exec.dynamic.partition=true-- 动态分区的模式，默认strict（严格模式），要求必须指定至少一个分区为静态分区，nonstrict（非严格模式）允许所有的分区字段都使用动态分区。set hive.exec.dynamic.partition.mode=nonstrict-- 一条insert语句可同时创建的最大的分区个数，默认为1000。set hive.exec.max.dynamic.partitions=1000-- 单个Mapper或者Reducer可同时创建的最大的分区个数，默认为100。set hive.exec.max.dynamic.partitions.pernode=100-- 一条insert语句可以创建的最大的文件个数，默认100000。hive.exec.max.created.files=100000-- 当查询结果为空时且进行动态分区时，是否抛出异常，默认false。hive.error.on.empty.partition=false-- 建表create table dept_partition_dynamic( id int, name string) partitioned by (loc int) row format delimited fields terminated by &#x27;\\t&#x27;;-- 插入，根据loc动态分区insert into table dept_partition_dynamic partition(loc) select deptno, dname, loc from dept;-- 因为dept_partition_dynamic表中只有两个字段，所以当我们查询了三个字段时（多了loc字段），所以系统默认以最后一个字段city为分区名，-- 因为分区表的分区字段默认也是该表中的字段，且依次排在表中字段的最后面。所以分区需要分区的字段只能放在后面，不能把顺序弄错。-- 如果我们查询了四个字段的话，则会报错，因为该表加上分区字段也才三个。要注意系统是根据查询字段的位置推断分区名的，而不是字段名称。-- 多个分区字段，实现半自动（部分字段静态分区，注意静态分区字段要在动态前面）-- 1.创建一个只有一个字段，两个分区字段的分区表create table ds_parttion(id int ) partitioned by (state string ,ct string );-- 2.往该分区表半动态分区插入数据 insert overwrite table ds_parttionpartition(state=&#x27;china&#x27;,ct) #state分区为静态，ct为动态分区，以查询的city字段为分区名-- 多个分区字段时，全部实现动态分区插入数据insert overwrite table ds_parttionpartition(state,ct)select id ,country,city from mytest_tmp2_p; 分桶 分区提供一个隔离数据和优化查询的便利方式 对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分 分区针对的是数据的存储路径，分桶针对的是数据文件。 分桶表的基本原理是，首先为每行数据计算一个指定字段的数据的hash值，然后模以一个指定的分桶数，最后将取模运算结果相同的行，写入同一个文件中，这个文件就称为一个分桶（bucket）。 基本语法 创建分桶表 12345678-- cluster by后面指定分桶字段，into后面指定分桶数create table stu_buck( id int, name string)clustered by(id) into 4 bucketsrow format delimited fields terminated by &#x27;\\t&#x27;; 表中的文件数据会被分为四个桶，对应四个文件，每个文件中的数据都是根据id字段的hash值模4的结果相同的数据。 分桶排序表 Hive的分桶排序表是一种优化技术，用于提高大数据存储和查询的效率。它将数据表按照指定的列进行分桶（bucket），每个桶内的数据再按照指定的列进行排序，这样就可以在查询时快速定位到需要的数据，减少数据扫描的时间。 使用分桶排序表的主要优点是可以提高查询效率，特别是在大数据量的情况下。相比于无序表，分桶排序表在查询时可以跳过不需要的数据，减少数据扫描的时间。 12345678-- clustered by关键字指定按照哪个列进行分桶，sorted by关键字指定在每个桶内按照哪个列进行排序。create table stu_buck_sort( id int, name string)clustered by(id) sorted by(id)into 4 bucketsrow format delimited fields terminated by &#x27;\\t&#x27;; 文件格式和压缩 文件格式 在创建表时，使用关键字stored as 文件格式[textfile|sequencefile|orc|parquet]指定文件格式。 使用列式存储格式（orc和parquet）的查询性能和存储效率都要优于默认的文本文件格式，其中orc的性能略微优于parquet。 TextFile 文本文件是Hive默认使用的文件格式，文本文件中的一行内容，就对应Hive表中的一行记录。 ORC ORC是一种列式存储的文件格式，ORC文件能够提高Hive读写数据和处理数据的性能 列式存储(操作系统里的文件排列方式) 每个Orc文件由Header、Body和Tail三部分组成。 Body由1个或多个stripe组成(HRegion)，每个stripe一般为HDFS的块大小，每一个stripe包含多条记录，这些记录按照列进行独立存储，每个stripe里有三部分组成，分别是Index Data，Row Data，Stripe Footer。 Index Data：一个轻量级的index，默认是为各列每隔1W行做一个索引。每个索引会记录第n万行的位置，和最近一万行的最大值和最小值等信息。 Row Data：存的是具体的数据，按列进行存储，并对每个列进行编码，分成多个Stream来存储。 Stripe Footer：存放的是各个Stream的位置以及各column的编码信息 Tail由File Footer和PostScript组成。 File Footer中保存了各Stripe的其实位置、索引长度、数据长度等信息，各Column的统计信息等； PostScript记录了整个文件的压缩类型以及File Footer的长度信息等。 在读取ORC文件时，会先从最后一个字节读取PostScript长度，进而读取到PostScript，从里面解析到File Footer长度，进而读取FileFooter，从中解析到各个Stripe信息，再读各个Stripe，即从后往前读。 建表 1234create table orc_table(column_specs)stored as orctblproperties (property_name=property_value, ...); 参数 默认值 说明 orc.compress ZLIB 压缩格式，可选项：NONE、ZLIB,、SNAPPY orc.compress.size 262144 每个压缩块的大小（ORC文件是分块压缩的） orc.stripe.size 67108864 每个stripe的大小 orc.row.index.stride 10000 索引步长（每隔多少行数据建一条索引） Parquet Parquet也是一个列式存储的文件格式。 文件的首尾都是该文件的Magic Code，用于校验它是否是一个Parquet文件。 首尾中间由若干个Row Group和一个Footer（File Meta Data）组成。 每个Row Group包含多个Column Chunk，每个Column Chunk包含多个Page。 行组（Row Group）：一个行组对应逻辑表中的若干行。 列块（Column Chunk）：一个行组中的一列保存在一个列块中。 页（Page）：一个列块的数据会划分为若干个页。 Footer（File Meta Data）中存储了每个行组中的每个列快的元数据信息，元数据信息包含了该列的数据类型、该列的编码方式、该类的Data Page位置等信息。 建表 建表语句和ORC类似 参数 默认值 说明 parquet.compression uncompressed 压缩格式，可选项：uncompressed，snappy，gzip，lzo，lz4 parquet.block.size 134217728 行组大小，通常与HDFS块大小保持一致 parquet.page.size 1048576 页大小 压缩 在Hive表中和计算过程中，保持数据的压缩，对磁盘空间的有效利用和提高查询性能都是十分有益的。 Hadoop中的压缩格式 压缩格式 算法 文件扩展名 是否可切分 DEFLATE DEFLATE .deflate 否 Gzip DEFLATE .gz 否 bzip2 bzip2 .bz2 是 LZO LZO .lzo 是 Snappy Snappy .snappy 否 压缩算法 原始文件大小 压缩文件大小 压缩速度 解压速度 gzip 8.3GB 1.8GB 17.5MB/s 58MB/s bzip2 8.3GB 1.1GB 2.4MB/s 9.5MB/s LZO 8.3GB 2.9GB 49.3MB/s 74.6MB/s 对Hive数据表进行压缩 TextFile 123456- 若一张表的文件类型为TextFile，若需要对该表中的数据进行压缩，多数情况下，无需在建表语句做出声明。直接将压缩后的文件导入到该表即可，Hive在查询表中数据时，可自动识别其压缩格式，进行解压。- 需要注意的是，在执行往表中导入数据的SQL语句时，用户需设置以下参数，来保证写入表中的数据是被压缩的。--SQL语句的最终输出结果是否压缩set hive.exec.compress.output=true;--输出结果的压缩格式（以下示例为snappy）set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec; ORC和Parquet 若一张表的文件类型为ORC/Parquet，若需要对该表数据进行压缩，需在建表语句中声明压缩格式如下： 1234567create table orc_table(column_specs)stored as orctblproperties (&quot;orc.compress&quot;=&quot;snappy&quot;);/stored as parquettblproperties (&quot;parquet.compression&quot;=&quot;snappy&quot;); 计算过程中使用压缩 单个MR的中间结果压缩 单个MR的中间结果是指Mapper输出的数据，对其进行压缩可降低shuffle阶段的网络IO， 1234--开启MapReduce中间数据压缩功能set mapreduce.map.output.compress=true;--设置MapReduce中间数据数据的压缩方式（以下示例为snappy）set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec; 单条SQL的中间结果压缩 单条SQL语句的中间结果是指，两个MR（一条SQL语句可能需要通过MR进行计算）之间的临时数据 1234--是否对两个MR之间的临时数据进行压缩set hive.exec.compress.intermediate=true;--压缩格式（以下示例为snappy）set hive.intermediate.compression.codec= org.apache.hadoop.io.compress.SnappyCodec; ★企业级调优 Yarn资源配置 YARN的内存调优的相关参数可以在yarn-site.xml文件中修改，需要调整的YARN参数均与CPU、内存等资源有关 123456789101112131415161718192021222324252627282930313233&lt;!-- （1）yarn.nodemanager.resource.memory-mb --&gt;&lt;!-- 该参数的含义是，一个NodeManager节点分配给Container使用的内存。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量。 --&gt;&lt;!-- 考虑上述因素，本书所搭建集群的服务器的内存资源为64GB，且未运行其他服务，此处可将该参数设置为64G，如下： --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;65536&lt;/value&gt;&lt;/property&gt;&lt;!-- （2）yarn.nodemanager.resource.cpu-vcores该参数的含义是，一个NodeManager节点分配给Container使用的CPU核数。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。考虑上述因素，本书所搭建集群的服务器的CPU核数为16，且未运行其他服务，此处可将该参数设置为16。 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;16&lt;/value&gt;&lt;/property&gt;&lt;!-- （3）yarn.scheduler.maximum-allocation-mb该参数的含义是，单个Container能够使用的最大内存。推荐配置如下： --&gt;&lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;16384&lt;/value&gt;&lt;/property&gt;&lt;!-- （4）yarn.scheduler.minimum-allocation-mb该参数的含义是，单个Container能够使用的最小内存，推荐配置如下： --&gt;&lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;512&lt;/value&gt;&lt;/property&gt; MapReduce资源配置 MapReduce资源配置主要包括Map Task的内存和CPU核数，以及Reduce Task的内存和CPU核数。 123456789101112131415161718191）mapreduce.map.memory.mb 该参数的含义是，单个Map Task申请的container容器内存大小，其默认值为1024。该值不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：set mapreduce.map.memory.mb=2048;2）mapreduce.map.cpu.vcores 该参数的含义是，单个Map Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。3）mapreduce.reduce.memory.mb 该参数的含义是，单个Reduce Task申请的container容器内存大小，其默认值为1024。该值同样不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：set mapreduce.reduce.memory.mb=2048;4）mapreduce.reduce.cpu.vcores 该参数的含义是，单个Reduce Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。 Explain查看执行计划 Explain执行计划概述 Hive中可以使用explain命令来查看Hive SQL的执行计划， 用户通过分析执行计划可以看到该条HQL的执行情况，了解性能瓶颈，最后对Hive SQL进行优化。 Explain呈现的执行计划，由一系列Stage组成，这一系列Stage具有依赖关系，每个Stage对应一个MapReduce Job，或者一个文件系统操作等。 若某个Stage对应的一个MapReduce Job，其Map端和Reduce端的计算逻辑分别由Map Operator Tree和Reduce Operator Tree进行描述，Operator Tree由一系列的Operator组成，一个Operator代表在Map或Reduce阶段的一个单一的逻辑操作 TableScan：表扫描操作，通常map端第一个操作肯定是表扫描操作 Select Operator：选取操作 Group By Operator：分组聚合操作 Reduce Output Operator：输出到 reduce 操作 Filter Operator：过滤操作 Join Operator：join 操作 File Output Operator：文件输出操作 Fetch Operator 客户端获取数据操作 Explain语法 1EXPLAIN [FORMATTED | EXTENDED | DEPENDENCY] query-sql FORMATTED：将执行计划以JSON字符串的形式输出 EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息 DEPENDENCY：输出执行计划读取的表及分区 Explain输出结果解读 123456explainselect user_id, count(*)from order_detailgroup by user_id; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748STAGE DEPENDENCIES: Stage-1 is a root stage Stage-0 depends on stages: Stage-1STAGE PLANS: Stage: Stage-1 Map Reduce Map Operator Tree: TableScan alias: order_detail Statistics: Num rows: 13066777 Data size: 11760099340 Basic stats: COMPLETE Column stats: NONE Select Operator expressions: user_id (type: string) outputColumnNames: user_id Statistics: Num rows: 13066777 Data size: 11760099340 Basic stats: COMPLETE Column stats: NONE Group By Operator aggregations: count() keys: user_id (type: string) mode: hash outputColumnNames: _col0, _col1 Statistics: Num rows: 13066777 Data size: 11760099340 Basic stats: COMPLETE Column stats: NONE Reduce Output Operator key expressions: _col0 (type: string) sort order: + Map-reduce partition columns: _col0 (type: string) Statistics: Num rows: 13066777 Data size: 11760099340 Basic stats: COMPLETE Column stats: NONE value expressions: _col1 (type: bigint) Execution mode: vectorized Reduce Operator Tree: Group By Operator aggregations: count(VALUE._col0) keys: KEY._col0 (type: string) mode: mergepartial outputColumnNames: _col0, _col1 Statistics: Num rows: 6533388 Data size: 5880049219 Basic stats: COMPLETE Column stats: NONE File Output Operator compressed: false Statistics: Num rows: 6533388 Data size: 5880049219 Basic stats: COMPLETE Column stats: NONE table: input format: org.apache.hadoop.mapred.SequenceFileInputFormat output format:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe Stage: Stage-0 Fetch Operator limit: -1 Processor Tree: ListSink 分组聚合优化 优化说明 Hive中未经优化的分组聚合，是通过一个MapReduce Job实现的。 Map端负责读取数据，并按照分组字段分区，通过Shuffle，将数据发往Reduce端，各组数据在Reduce端完成最终的聚合运算。 Hive对分组聚合的优化主要围绕着减少Shuffle数据量进行，具体做法是map-side聚合。 所谓map-side聚合，就是在map端维护一个hash table，利用其完成部分的聚合，然后将部分聚合的结果，按照分组字段分区，发送至reduce端，完成最终的聚合。 map-side聚合能有效减少shuffle的数据量，提高分组聚合运算的效率。 map-side，理解为MapReduce中的Combiner 12345678910111213141516--启用map-side聚合set hive.map.aggr=true;--用于检测源表数据是否适合进行map-side聚合。-- 检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；-- 否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。-- 不是随机抽取，是取连续一段数据，考虑数据倾斜，可能不会执行set hive.map.aggr.hash.min.reduction=0.5;--用于检测源表是否适合map-side聚合的条数。set hive.groupby.mapaggr.checkinterval=100000;--map-side聚合所用的hash table，占用map task堆内存的最大比例，-- 若超出该值，则会对hash table进行一次flush。-- 类似MapReduce中的Map磁盘溢写set hive.map.aggr.hash.force.flush.memory.threshold=0.9; ★Join优化 Join算法介绍 Common Join Common Join是Hive中最稳定的join算法，其通过一个MapReduce Job完成一个join操作。 Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。 sql语句中的join操作和执行计划中的Common Join任务并非一对一的关系，一个sql语句中的相邻的且关联字段相同的多个join操作可以合并为一个Common Join任务。 sql语句中的两个join操作关联字段各不相同，则该语句的两个join操作需要各自通过一个Common Join任务实现，也就是通过两个Map Reduce任务实现。 Map阶段 读取源表的数据，Map输出时候以Join on条件中的列为key，如果Join有多个关联键，则以这些关联键的组合作为key; Map输出的value为join之后所关心的(select或者where中需要用到的)列；同时在value中还会包含表的Tag信息，用于标明此value对应哪个表； 按照key进行排序 Shuffle阶段 根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中 一个reduce中可能会处理多个key Reduce阶段 根据key的值完成join操作，期间通过Tag来识别不同表中的数据。 Map Join Map Join算法可以通过两个只有map阶段的Job完成一个join操作。其适用场景为大表join小表。 若某join操作满足要求，则第一个Job会读取小表数据，将其制作为hash table，并上传至Hadoop分布式缓存（本质上是上传至HDFS）。 第二个Job会先从分布式缓存中读取小表数据，并缓存在Map Task的内存中，然后扫描大表数据，这样在map端即可完成关联操作。 类似Hadoop案例中的Join案例 Bucket Map Join Bucket Map Join是对Map Join算法的改进，其打破了Map Join只适用于大表join小表的限制，可用于大表join大表的场景。 若能保证参与join的表均为分桶表，且关联字段为分桶字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍，就能保证参与join的两张表的分桶之间具有明确的关联关系，所以就可以在两表的分桶间进行Map Join操作了。 这样一来，第二个Job的Map端就无需再缓存小表的全表数据了，而只需缓存其所需的分桶即可。 tableA的BucketA-0和BucketsA-2 与 tableB的BucketB-0 key是一样的(因为取模都为偶数) 所以tableA的BucketA-0的Mapper直接拉取tableB的BucketB-0的数据(hash table缓存)，进行join操作 Sort Merge Bucket Map Join SMB Map Join要求，参与join的表均为分桶表，且需保证分桶内的数据是有序的，且分桶字段、排序字段和关联字段为相同字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍。 SMB Map Join同Bucket Join一样，同样是利用两表各分桶之间的关联关系，在分桶之间进行join操作 Bucket Map Join，两个分桶之间的join实现原理为Hash Join算法；而SMB Map Join，两个分桶之间的join实现原理为Sort Merge Join算法。 SMB Map Join在进行Join操作时，Map端是无需对整个Bucket构建hash table，也无需在Map端缓存整个Bucket数据的，每个Mapper只需按顺序逐个key读取两个分桶的数据进行join即可。 Map Join优化 1.手动Hint触发(过时) 123456select /*+ mapjoin(ta) */ ta.id, tb.idfrom table_a tajoin table_b tbon ta.id=tb.id; 2.自动触发 Hive在编译SQL语句阶段，起初所有的join操作均采用Common Join算法实现。 之后在物理优化阶段，Hive会根据每个Common Join任务所需表的大小判断该Common Join任务是否能够转换为Map Join任务，若满足要求，便将Common Join任务自动转换为Map Join任务。 Hive会在编译阶段生成一个条件任务（Conditional Task），其下会包含一个计划列表，计划列表中包含转换后的Map Join任务以及原有的Common Join任务。最终具体采用哪个计划，是在运行时决定的。 1234567891011--启动Map Join自动转换set hive.auto.convert.join=true;--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的已知大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。set hive.mapjoin.smalltable.filesize=250000;--开启无条件转Map Joinset hive.auto.convert.join.noconditionaltask=true;--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。set hive.auto.convert.join.noconditionaltask.size=10000000; 流程讲解 是否启用自动转换，false则用Common Join 根据Join的方式查看是否有满足条件的大表,没有大表则用Common Join 判断是否启用条件任务 启用条件任务： 尝试以每个大表候选人作为大表生成map join计划 如果大表候选人的大小已知，且其他已知表大小总和大于hive.mapjoin.smalltable.filesize(不是小表)，则不生成map join计划 如果最终没有生成map join计划，则使用Common Join 如果有生成map join计划，将所有的map join计划和common join计划放入人物列表 最终的执行计划是在运行时决定的 不启用条件任务： 某个大表候选人的大小已知，且其他已知表大小总和小于hive.auto.convert.join.noconditionaltask.size，如果为false(其他表总和太多大)，则自动转向条件任务 生成最优计划，如果子任务也是map join（对应三个表的join），且子任务和当前任务的所有小表都小于hive.auto.convert.join.noconditionaltask.size，false则不合并， true则合并为一个map join任务(两个小表) Map Join优化案例 12345select *from order_detail odjoin product_info product on od.product_id = product.idjoin province_info province on od.province_id = province.id; 无任何优化 第一个join执行了一个Common Join，第二个join执行了一个Common Join 方案一 1234567-- 启用Map Join自动转换。set hive.auto.convert.join=true;-- 使用条件转Map Join。set hive.auto.convert.join.noconditionaltask=false;-- 调整hive.mapjoin.smalltable.filesize参数，使其大于等于product_info。-- 使hive.mapjoin.smalltable.filesize可以判断是小表set hive.mapjoin.smalltable.filesize=25285707; 会走条件转换，分多个Map Join任务 方案二 1234567-- 启用Map Join自动转换。set hive.auto.convert.join=true;-- 不使用条件转Map Join。set hive.auto.convert.join.noconditionaltask=true;-- 调整hive.auto.convert.join.noconditionaltask.size参数，使其大于等于product_info和province_info之和。-- 使其判断两表之和是小表set hive.auto.convert.join.noconditionaltask.size=25286076; 直接将两个Common Join operator转为两个Map Join operator， 并且由于两个Map Join operator的小表大小之和小于等于hive.auto.convert.join.noconditionaltask.size，故两个Map Join operator任务可合并为同一个 *方案三 1234567-- 启用Map Join自动转换。set hive.auto.convert.join=true;-- 不使用条件转Map Join。set hive.auto.convert.join.noconditionaltask=true;-- 调整hive.auto.convert.join.noconditionaltask.size参数，使其等于product_info。-- 使其判断两表之和是大表set hive.auto.convert.join.noconditionaltask.size=25285707; 这样可直接将两个Common Join operator转为Map Join operator，但不会将两个Map Join的任务合并。 Bucket Map Join优化 Bucket Map Join不支持自动转换，发须通过用户在SQL语句中提供如下Hint提示，并配置如下相关参数，方可使用。 1234567891011121314-- Hint提示select /*+ mapjoin(ta) */ ta.id, tb.idfrom table_a tajoin table_b tb on ta.id=tb.id;-- 参数配置--关闭cbo优化，cbo会导致hint信息被忽略set hive.cbo.enable=false;--map join hint默认会被忽略(因为已经过时)，需将如下参数设置为falseset hive.ignore.mapjoin.hint=false;--启用bucket map join优化功能set hive.optimize.bucketmapjoin = true; order_detail和payment_detail是没有分桶的 123456789101112131415select *from( select * from order_detail where dt=&#x27;2020-06-14&#x27;)odjoin( select * from payment_detail where dt=&#x27;2020-06-14&#x27;)pdon od.id=pd.order_detail_id; 先分桶 12345678910111213141516171819202122232425--订单表hive (default)&gt; insert overwrite table order_detail_bucketedselect id, user_id, product_id, province_id, create_time, product_num, total_amount from order_detailwhere dt=&#x27;2020-06-14&#x27;;--分桶表hive (default)&gt; insert overwrite table payment_detail_bucketedselect id, order_detail_id, user_id, payment_time, total_amountfrom payment_detailwhere dt=&#x27;2020-06-14&#x27;; 重写SQL 1234select /*+ mapjoin(pd) */ *from order_detail_bucketed odjoin payment_detail_bucketed pd on od.id = pd.order_detail_id; 详细执行计划中，如在Map Join Operator中看到 “BucketMapJoin: true”，则表明使用的Join算法为Bucket Map Join。 Sort Merge Bucket Map Join优化 配置自动优化参数 1234--启动Sort Merge Bucket Map Join优化set hive.optimize.bucketmapjoin.sortedmerge=true;--使用自动转换SMB Joinset hive.auto.convert.sortmerge.join=true; Join优化总结 在条件优化中的参数: 12345--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的已知大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。set hive.mapjoin.smalltable.filesize=250000;--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。set hive.auto.convert.join.noconditionaltask.size=10000000; 这两个条件的大小代表的表的实际大小,不是内存大小 内存大小与实际大小的比值经验约为:10:1,因为要有类对象信息等 Bucket Map Join 分多少桶要根据Map的内存大小来决定一个桶的大小约50M差不多 ★数据倾斜优化 数据倾斜问题，通常是指参与计算的数据分布不均，即某个key或者某些key的数据量远超其他key，导致在shuffle阶段，大量相同key的数据被发往同一个Reduce，进而导致该Reduce所需的时间远超其他Reduce，成为整个任务的瓶颈。 常见于分组聚合和join操作的场景中 分组聚合导致的数据倾斜 Hive中未经优化的分组聚合，是通过一个MapReduce Job实现的。Map端负责读取数据，并按照分组字段分区，通过Shuffle，将数据发往Reduce端，各组数据在Reduce端完成最终的聚合运算。 如果group by分组字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。 第一种:Map-Side聚合 开启Map-Side聚合后，数据会现在Map端完成部分聚合工作。这样一来即便原始数据是倾斜的，经过Map端的初步聚合后，发往Reduce的数据也就不再倾斜了。最佳状态下，Map-端聚合能完全屏蔽数据倾斜问题。 类似Combiner 1234567891011--启用map-side聚合set hive.map.aggr=true;--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。set hive.map.aggr.hash.min.reduction=0.5;--用于检测源表是否适合map-side聚合的条数。set hive.groupby.mapaggr.checkinterval=100000;--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。set hive.map.aggr.hash.force.flush.memory.threshold=0.9; 第二种:Skew-Groupby优化 Skew-GroupBy的原理是启动两个MR任务， 第一个MR按照随机数分区，将数据分散发送到Reduce(均匀的,因为是随机数)，按随机数完成部分聚合， 第二个MR,拿到第一个Reduce的输出(部分聚合,减少了key的数量),按照分组字段分区，完成最终聚合。 12--启用分组聚合数据倾斜优化set hive.groupby.skewindata=true; Join导致的数据倾斜 未经优化的join操作，默认是使用common join算法，也就是通过一个MapReduce Job完成计算。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。 如果关联字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。 第一种:map join优化 使用map join算法，join操作仅在map端就能完成，没有shuffle操作，没有reduce阶段，自然不会产生reduce端的数据倾斜。该方案适用于大表join小表时发生数据倾斜的场景。 第二种:skew join优化 skew join的原理是，为倾斜的大key单独启动一个map join任务进行计算，其余key进行正常的common join。 刚开始是一个common join,在reduce中检测到数据倾斜 将数据(A表和B表)写到HDFS中,然后启动一个map join任务 将小表数据读取到内存中,大表数据切片，每个map一个切片处理 1234--启用skew join优化set hive.optimize.skewjoin=true;--触发skew join的阈值，若某个key的行数超过该参数值，则触发set hive.skewjoin.key=100000; 第三种:优化SQL语句 若参与join的两表均为大表，其中一张表的数据是倾斜的，此时也可通过以下方式对SQL语句进行相应的调整。 12345select *from Ajoin Bon A.id=B.id; 1234567891011121314151617181920select *from( select --打散操作 concat(id,&#x27;_&#x27;,cast(rand()*2 as int)) id, value from A)tajoin( select --扩容操作 concat(id,&#x27;_&#x27;,0) id, value from B union all select concat(id,&#x27;_&#x27;,1) id, value from B)tbon ta.id=tb.id; 任务并行度优化 Map端 Map端的并行度，也就是Map的个数。是由输入文件的切片数决定的。一般情况下，Map端的并行度无需手动调整。 以下情况下，可以考虑调整Map端的并行度： 查询的表中存在大量小文件 使用Hive提供的CombineHiveInputFormat，多个小文件合并为一个切片，从而控制map task个数 set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; map端有复杂的查询逻辑 若SQL语句中有复杂耗时的查询逻辑时，map端的计算会相对慢一些。可令map task多一些，每个map task计算的数据少一些。 set mapreduce.input.fileinputformat.split.maxsize=256000000; Reduce端 Reduce端的并行度，可由用户自己指定，也可由Hive自行根据该MR Job输入的文件大小进行估算。 123456--指定Reduce端并行度，默认值为-1，表示用户未指定set mapreduce.job.reduces;--Reduce端并行度最大值set hive.exec.reducers.max;--单个Reduce Task计算的数据量，用于估算Reduce并行度set hive.exec.reducers.bytes.per.reducer; 若指定参数mapreduce.job.reduces的值为一个非负整数，则Reduce并行度为指定值。否则，Hive自行估算Reduce并行度，估算逻辑如下： 假设Job输入的文件大小为totalInputBytes 参数hive.exec.reducers.bytes.per.reducer的值为bytesPerReducer。 参数hive.exec.reducers.max的值为maxReducers。 则Reduce端的并行度为： min(cell(totalInputBytesbytesPerReducer),maxReducers)min(cell(\\frac{totalInputBytes}{bytesPerReducer}),maxReducers)min(cell(bytesPerReducertotalInputBytes​),maxReducers) 自动估算存在的问题 Hive自行估算Reduce并行度时，是以整个MR Job输入的文件大小作为依据的。 整个文件的输入大小,和Map端输出的大小不一定一致,甚至差距很大(map side) 小文件合并优化 Map端输入的小文件合并 12--可将多个小文件切片，合并为一个切片，进而由一个map任务处理set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; Reduce端输出的小文件合并 合并Reduce端输出的小文件，是指将多个小文件合并成大文件。目的是减少HDFS小文件数量。 其原理是根据计算任务输出文件的平均大小进行判断，若符合条件，则单独启动一个额外的任务进行合并。 1234567891011--开启合并map only任务输出的小文件set hive.merge.mapfiles=true;--开启合并map reduce任务输出的小文件set hive.merge.mapredfiles=true;--合并后的文件大小set hive.merge.size.per.task=256000000;--触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并set hive.merge.smallfiles.avgsize=16000000; 其他优化 CBO优化 CBO(cost based optimizer),基于成本的优化 在Hive中，计算成本模型考虑到了：数据的行数、CPU、本地IO、HDFS IO、网络IO等方面。 Hive会计算同一SQL语句的不同执行计划的计算成本，并选出成本最低的执行计划。 主要用于join的join顺序 优化前 优化后 三表join,三个表个最后的result都一样,区别在于中间的middle表 CBO优化使得中间结果尽可能小,减少内存使用(product_info是大表) 谓词下推 谓词下推是指将Hive SQL中的过滤条件下推至数据源，以减少数据的读取量，提高查询效率。 CBO优化也会完成一部分的谓词下推优化工作，因为在执行计划中，谓词越靠前，整个计划的计算成本就会越低 12--是否启动谓词下推（predicate pushdown）优化set hive.optimize.ppd = true; 矢量化查询 Hive的矢量化查询优化，依赖于CPU的矢量化计算 矢量化查询减少了cpu计算的频次 1set hive.vectorized.execution.enabled=true; Fetch抓取 Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：select * from emp;在这种情况下，Hive可以简单地读取emp对应的存储目录下的文件，然后输出查询结果到控制台。 12345--是否在特定场景转换为fetch 任务--设置为none表示不转换--设置为minimal表示支持select *，分区字段过滤，Limit等--设置为more表示支持select 任意字段,包括函数，过滤，和limit等set hive.fetch.task.conversion=more; 本地模式 大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。 不过，有时Hive的输入数据量是非常小的。 在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。 对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。 对于小数据集，执行时间可以明显被缩短。 12345678--开启自动转换为本地模式set hive.exec.mode.local.auto=true; --设置local MapReduce的最大输入数据量，当输入数据量小于这个值时采用local MapReduce的方式，默认为134217728，即128Mset hive.exec.mode.local.auto.inputbytes.max=50000000;--设置local MapReduce的最大输入文件个数，当输入文件个数小于这个值时采用local MapReduce的方式，默认为4set hive.exec.mode.local.auto.input.files.max=10; 并行执行 Hive会将一个SQL语句转化成一个或者多个Stage，每个Stage对应一个MR Job。 默认情况下，Hive同时只会执行一个Stage。但是某SQL语句可能会包含多个Stage，但这多个Stage可能并非完全互相依赖，也就是说有些Stage是可以并行执行的。 此处提到的并行执行就是指这些Stage的并行执行。 12345--启用并行执行优化set hive.exec.parallel=true; --同一个sql允许最大并行度，默认为8set hive.exec.parallel.thread.number=8; 严格模式 Hive可以通过设置某些参数防止危险操作 分区表不使用分区过滤 将hive.strict.checks.no.partition.filter设置为true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。 使用order by没有limit过滤 将hive.strict.checks.orderby.no.limit设置为true时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reduce中进行处理，强制要求用户增加这个limit语句可以防止Reduce额外执行很长一段时间（开启了limit可以在数据进入到Reduce之前就减少一部分数据）。 禁止使用笛卡尔积 将hive.strict.checks.cartesian.product设置为true时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。 案例练习 Spark","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://gladdduck.github.io/tags/Hadoop/"}]},{"title":"Kaggle-OTTO比赛回顾","slug":"实习-Kaggle-OTTO比赛回顾","date":"2024-03-14T10:50:22.943Z","updated":"2024-03-16T05:34:08.341Z","comments":true,"path":"2024/03/14/实习-Kaggle-OTTO比赛回顾/","link":"","permalink":"https://gladdduck.github.io/2024/03/14/%E5%AE%9E%E4%B9%A0-Kaggle-OTTO%E6%AF%94%E8%B5%9B%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"1. 比赛任务 The goal of this competition is to predict e-commerce clicks, cart additions, and orders. You’ll build a multi-objective recommender system based on previous events in a user session. 这场比赛的目标是预测电子商务点击量、购物车添加量和订单。您将基于用户会话中以前的事件构建一个多目标推荐系统。 The training data contains full e-commerce session information. For each session in the test data, your task it to predict the aid values for each session type thats occur after the last timestamp ts in the test session. In other words, the test data contains sessions truncated by timestamp, and you are to predict what occurs after the point of truncation. 训练数据包含完整的电子商务会话信息。对于测试数据中的每个会话，您的任务是预测测试会话中最后一个时间戳ts之后出现的每个会话类型的商品编号(20个)。换句话说，测试数据包含按时间戳截断的会话，您要预测截断点之后会发生什么。 总结: 给定每个用户每个时刻的行为(点击,加购,付款)的商品编号,给出下一个时刻,该用户三种行为最可能的20个商品编号. 2. 数据集 数据描述: 2,899,779 sessions 1,855,603 items 216,716,096 events 194,720,954 clicks 16,896,191 carts 5,098,951 orders 训练数据: 提交样例文件: 3. 思路 Candidate Generation Candidate Generation方法 原因:像这个数据量的数据直接放到模型里是不可能的事,所以按照上面的流程一步步来. Step 1 - Generate Candidates 用来选择候选商品的一些标准： 以前购买的物品 回购的物品 总体上最受欢迎的项目 基于某种聚类技术的相似项目 基于共同访问矩阵等类似项目 Step 2 - ReRank and Choose 20 通过上一步,商品会少很多,然后可以按照一些规则来选择20个商品. Ranker Model Handcrafted Rules What is the co-visitation matrix, really? What is the co-visitation matrix, really? It is very interesting to think of modern techniques in the context of their roots. “Radek is a _”.当我们预测横线上的词的时候, 三元模型会从&quot;Radek&quot;, “is”, and “a” 看,然后统计哪个单词和着三个单词出现的次数最多. 但是可能并没有那么多的&quot;Radek&quot;, “is”, and &quot;a&quot;的出现过. 所以这就是RNN(or word2vec)的出现,他们会看 “Radek was an _”, &quot;Tommy is a __&quot;作为例子. 那么，这与共访矩阵有什么关系呢？ 共访问矩阵统计两个动作在非常接近的情况下的共出现。 如果用户购买了a，在购买B后不久，我们将这些值存储在一起。 我们计算计数，并根据最近的历史来估计未来行动的概率。 理解共同访问矩阵方法中发生的事情是非常重要的… Candidate ReRank Model - [LB 0.575] Candidate ReRank Model - LB 0.575 Step 1 - Generate Candidates 对每一个用户生成候选商品,五种方法: 用户点击、购物车、订单的用户历史记录 测试数据一周内最受欢迎的20次点击、购物车、订单 点击/购物车/订单到购物车/订单 的共同访问矩阵(带有类型权重) 称为buy2buy的购物车/订单到购物车/订单的共访问矩阵 点击/购物车/订单与点击的共访问矩阵（带时间权重） Step 2 - ReRank and Choose 20 从上面的候选列表中选择20个作为最终预测结果,选取的顺序为: 最近访问过的项目 以前多次访问的项目 以前在购物车或订单中的项目 购物车/订单到购物车/订单的共同访问矩阵 当前热门项目 候选商品生成 “Carts Orders” Co-visitation Matrix - Type Weighted 12345678910111213141516171819202122232425262728&quot;&quot;&quot;构建思路:按照用户和时间进行排序df.groupby(&#x27;session&#x27;).cumcount()求出每个用户的行数保留每个用户最近的30个行为df.merge(df, on=&#x27;session&#x27;)创建每个用户的行为对其他行为的关系(目的是构建商品和商品的关系)筛选出时间间隔小于1天 且商品编号不相同的行,删除重复的值根据行为的权重系数,对商品之间的关系进行赋值得到了每个商品之间的权重系数&quot;&quot;&quot;# type_weight = &#123;0:1, 1:6, 2:3&#125;df = df.sort_values([&#x27;session&#x27;, &#x27;ts&#x27;], ascending=[True, False]) # 根据&#x27;session&#x27;和&#x27;ts&#x27;排序数据框，先升序排&#x27;session&#x27;再降序排&#x27;ts&#x27;# 使用SESSION的TAILdf = df.reset_index(drop=True) # 重设索引并删除原索引df[&#x27;n&#x27;] = df.groupby(&#x27;session&#x27;).cumcount() # 对&#x27;session&#x27;进行分组计数df = df.loc[df.n &lt; 30].drop(&#x27;n&#x27;, axis=1) # 保留每个&#x27;session&#x27;组的前30行，然后删除计数列&#x27;n&#x27;# 创建对关系df = df.merge(df, on=&#x27;session&#x27;) # 在&#x27;session&#x27;列上合并数据框自身，创建对关系df = df.loc[((df.ts_x - df.ts_y).abs() &lt; 24 * 60 * 60) &amp; (df.aid_x != df.aid_y)] # 选择时间间隔小于1天且&#x27;aid_x&#x27;不等于&#x27;aid_y&#x27;的行# 内存管理，分部计算df = df.loc[(df.aid_x &gt;= PART*SIZE) &amp; (df.aid_x &lt; (PART+1)*SIZE)] # 根据&#x27;aid_x&#x27;值进行分块处理# 分配权重df = df[[&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;type_y&#x27;]].drop_duplicates([&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;]) # 根据指定列去除重复行，选择指定列df[&#x27;wgt&#x27;] = df.type_y.map(type_weight) # 根据&#x27;type_y&#x27;映射权重值到&#x27;wgt&#x27;列df = df[[&#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;wgt&#x27;]] # 保留&#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;wgt&#x27;三列df.wgt = df.wgt.astype(&#x27;float32&#x27;) # 将&#x27;wgt&#x27;列转换为float32类型df = df.groupby([&#x27;aid_x&#x27;, &#x27;aid_y&#x27;]).wgt.sum() # 根据&#x27;aid_x&#x27;, &#x27;aid_y&#x27;分组，并求&#x27;wgt&#x27;列的和 “Buy2Buy” Co-visitation Matrix 123456789101112131415161718192021222324252627282930&quot;&quot;&quot;构建思路:按照用户和时间进行排序df.groupby(&#x27;session&#x27;).cumcount()求出每个用户的行数保留每个用户最近的30个行为df.merge(df, on=&#x27;session&#x27;)创建每个用户的行为对其他行为的关系(目的是构建商品和商品的关系)筛选出时间间隔小于14天 且商品编号不相同的行,删除重复的值权重全部是1(加购和加购之间的关系),对商品和商品之间的关系进行分组求和得到了每个商品之间的权重系数&quot;&quot;&quot;# df = df.loc[df[&#x27;type&#x27;].isin([1,2])] # 仅保留购物车和订单df = df.sort_values([&#x27;session&#x27;,&#x27;ts&#x27;],ascending=[True,False]) # 按&#x27;session&#x27;和&#x27;ts&#x27;降序排序# 使用SESSION的TAILdf = df.reset_index(drop=True) # 重新设置索引并丢弃原索引df[&#x27;n&#x27;] = df.groupby(&#x27;session&#x27;).cumcount() # 计算每个&#x27;session&#x27;组的行数# 保留用户最近的30个行为df = df.loc[df.n&lt;30].drop(&#x27;n&#x27;,axis=1) # 仅保留每个&#x27;session&#x27;组的前30行，并删除&#x27;n&#x27;列# 创建成对关系df = df.merge(df, on=&#x27;session&#x27;) # 在&#x27;session&#x27;上合并数据框自身，创建成对关系df = df.loc[((df.ts_x - df.ts_y).abs() &lt; 14 * 24 * 60 * 60) &amp; (df.aid_x != df.aid_y)] # 筛选出时间间隔小于14天且&#x27;aid_x&#x27;不等于&#x27;aid_y&#x27;的行# 内存管理，分部计算df = df.loc[(df.aid_x &gt;= PART*SIZE) &amp; (df.aid_x &lt; (PART+1)*SIZE)] # 根据&#x27;aid_x&#x27;的值对数据框进行分块处理# 分配权重df = df[[&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;type_y&#x27;]].drop_duplicates([&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;]) # 根据&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;列去除重复行，并选择指定列df[&#x27;wgt&#x27;] = 1 # 添加&#x27;wgt&#x27;列，并赋值为1df = df[[&#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;wgt&#x27;]] # 仅保留&#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;wgt&#x27;三列df.wgt = df.wgt.astype(&#x27;float32&#x27;) # 将&#x27;wgt&#x27;列的数据类型转换为float32df = df.groupby([&#x27;aid_x&#x27;, &#x27;aid_y&#x27;]).wgt.sum() # 根据&#x27;aid_x&#x27;, &#x27;aid_y&#x27;分组，并对&#x27;wgt&#x27;列求和 “Clicks” Co-visitation Matrix - Time Weighted 1234567891011121314151617181920212223242526272829&quot;&quot;&quot;构建思路:按照用户和时间进行排序df.groupby(&#x27;session&#x27;).cumcount()求出每个用户的行数保留每个用户最近的30个行为df.merge(df, on=&#x27;session&#x27;)创建每个用户的行为对其他行为的关系(目的是构建商品和商品的关系)筛选出时间间隔小于1天 且商品编号不相同的行,删除重复的值按时间顺序对商品和商品之间的关系进行赋值,时间越近权重越大得到了每个商品之间的权重系数&quot;&quot;&quot;# df = df.sort_values([&#x27;session&#x27;, &#x27;ts&#x27;], ascending=[True, False]) # 按&#x27;session&#x27;和&#x27;ts&#x27;排序，&#x27;session&#x27;升序，&#x27;ts&#x27;降序# 使用SESSION的TAILdf = df.reset_index(drop=True) # 重置索引并删除旧索引df[&#x27;n&#x27;] = df.groupby(&#x27;session&#x27;).cumcount() # 对&#x27;session&#x27;进行计数df = df.loc[df.n &lt; 30].drop(&#x27;n&#x27;, axis=1) # 保留每个&#x27;session&#x27;组的前30行，然后删除计数列# 创建对关系df = df.merge(df, on=&#x27;session&#x27;) # 在&#x27;session&#x27;上合并数据框自身，创建对关系df = df.loc[((df.ts_x - df.ts_y).abs() &lt; 24 * 60 * 60) &amp; (df.aid_x != df.aid_y)] # 选择时间间隔小于1天且&#x27;aid_x&#x27;不等于&#x27;aid_y&#x27;的行# 内存管理，分部计算df = df.loc[(df.aid_x &gt;= PART*SIZE) &amp; (df.aid_x &lt; (PART+1)*SIZE)] # 根据&#x27;aid_x&#x27;的值对数据框进行分块处理# 分配权重df = df[[&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;ts_x&#x27;]].drop_duplicates([&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;]) # 根据指定列去除重复行df[&#x27;wgt&#x27;] = 1 + 3*(df.ts_x - 1659304800) / (1662328791 - 1659304800) # 根据公式计算权重df = df[[&#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;wgt&#x27;]] # 保留&#x27;aid_x&#x27;, &#x27;aid_y&#x27;, &#x27;wgt&#x27;三列df.wgt = df.wgt.astype(&#x27;float32&#x27;) # 将&#x27;wgt&#x27;列的数据类型转换为float32df = df.groupby([&#x27;aid_x&#x27;, &#x27;aid_y&#x27;]).wgt.sum() # 根据&#x27;aid_x&#x27;, &#x27;aid_y&#x27;分组，并对&#x27;wgt&#x27;列求和 12345678910111213141516171819# 商品的矩阵构建完成之后都经历下面的步骤tmp = tmp.reset_index()# 按照权重进行排序tmp = tmp.sort_values([&#x27;aid_x&#x27;,&#x27;wgt&#x27;],ascending=[True,False])tmp = tmp.reset_index(drop=True)# 保留每个商品的前15(不定)个关系tmp[&#x27;n&#x27;] = tmp.groupby(&#x27;aid_x&#x27;).aid_y.cumcount()tmp = tmp.loc[tmp.n&lt;15].drop(&#x27;n&#x27;,axis=1)tmp.groupby(&#x27;aid_x&#x27;).aid_y.apply(list).to_dict()&#x27;&#x27;&#x27;总结:1. &quot;Carts Orders&quot; Co-visitation Matrix - Type Weighted含义:根据用户的历史行为分配商品之间的权重系数对应top_20_buys2. &quot;Buy2Buy&quot; Co-visitation Matrix含义:根据用户的加购和购买行为分配商品之间的权重系数对应top_20_buy2buy3. &quot;Clicks&quot; Co-visitation Matrix - Time Weighted含义:根据用户的行为时间分配商品之间的权重系数对应top_20_clicks&#x27;&#x27;&#x27; 重排名与最终选择 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263type_weight_multipliers = &#123;0: 1, 1: 6, 2: 3&#125;def suggest_clicks(df): # USER HISTORY AIDS AND TYPES aids = df.aid.tolist() # 获取用户历史商品id ty = df.type.tolist() # 获取用户历史行为 unique_aids = list(dict.fromkeys(aids[::-1])) # 获取不重复的商品id # 如果历史商品id大于等于20个,则返回前20个商品id if len(unique_aids) &gt;= 20: # 根据商品id出现的时间,对商品id进行排序 weights = np.logspace(0.1, 1, len(aids), base=2, endpoint=True) - 1 # 记录商品id:权重 aids_temp = Counter() # 商品,权重,类型 for aid, w, t in zip(aids, weights, ty): # id权重=时间权重*类型权重 aids_temp[aid] += w * type_weight_multipliers[t] # 返回权重最大的前20个商品id sorted_aids = [k for k,v in aids_temp.most_common(20)] return sorted_aids # 如果不够20个, 从点击最高的商品关系中找到最近点击的商品 然后取出最关联的20个商品 aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_click])) # 从最近点击的商品的最关联的商品中找打出现次数最多的商品 top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(20) if aid2 not in unique_aids] # 将这些商品和用户历史商品合并 result = unique_aids + top_aids2[:20 - len(unique_aids)] # 如果历史商品加上最关联的商品还不够20个,则从test中的历史数据中找到点击最高的商品 return result + list(top_clicks)[:20 - len(result)]def suggest_buys(df): # USER HISTORY AIDS AND TYPES aids = df.aid.tolist() # 获取用户历史商品id ty = df.type.tolist() # 获取用户历史行为 unique_aids = list(dict.fromkeys(aids[::-1])) # 获取所有行为不重复的商品id # 只保留用户历史加购和购买的行为(商品id) df = df.loc[(df[&#x27;type&#x27;] == 1) | (df[&#x27;type&#x27;] == 2)] # 获取加购和购买的不重复商品id unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1])) # 如果历史行为商品id大于等于20个,则根据历史行为返回商品id if len(unique_aids) &gt;= 20: # 时间权重 weights = np.logspace(0.5, 1, len(aids), base=2, endpoint=True) - 1 aids_temp = Counter() # id权重=时间权重*类型权重 for aid, w, t in zip(aids, weights, types): aids_temp[aid] += w * type_weight_multipliers[t] # 找到与用户历史购买/加购行为最相关的20个商品id aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy])) # 对这些商品id的权重增加0.1 for aid in aids3: aids_temp[aid] += 0.1 # 返回权重最大的前20个商品id sorted_aids = [k for k, v in aids_temp.most_common(20)] return sorted_aids # 找到与用户历史所有行为的商品行为上最相关的20个商品id aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys])) # 找到与用户历史购买/加购行为的商品最相关的20个商品id aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy])) # 对这些商品出现的次数进行统计 top_aids2 = [aid2 for aid2, cnt in Counter(aids2 + aids3).most_common(20) if aid2 not in unique_aids] # 获取最终结果,历史行为商品id+最相关的商品id result = unique_aids + top_aids2[:20 - len(unique_aids)] # 如果这些商品还不够20个,则从test中的历史数据中找到购买最高的商品 return result + list(top_orders)[:20 - len(result)] 12345678910111213141516# 生成预测结果pred_df_clicks = test_df.sort_values([&quot;session&quot;, &quot;ts&quot;]).groupby([&quot;session&quot;]).apply( lambda x: suggest_clicks(x))pred_df_buys = test_df.sort_values([&quot;session&quot;, &quot;ts&quot;]).groupby([&quot;session&quot;]).apply( lambda x: suggest_buys(x))clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(&quot;_clicks&quot;), columns=[&quot;labels&quot;]).reset_index()orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(&quot;_orders&quot;), columns=[&quot;labels&quot;]).reset_index()carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(&quot;_carts&quot;), columns=[&quot;labels&quot;]).reset_index()pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])pred_df.columns = [&quot;session_type&quot;, &quot;labels&quot;]pred_df[&quot;labels&quot;] = pred_df.labels.apply(lambda x: &quot; &quot;.join(map(str,x)))pred_df.to_csv(&quot;submission.csv&quot;, index=False)pred_df.head() Co-visitation Matrix Co-visitation Matrix Step 1 - Generate Candidates 总会有一些商品是经常点击的并且一起买,利用这个思想构建一个协同矩阵 首先，我们查看同一会话中在时间上彼此接近（&lt;1天）的所有事件对。我们计算共同访问矩阵Maid1，aid2M_{aid1，aid2}Maid1，aid2​通过对所有会话中的每对事件对的全局数量进行计数。 对于每个商品id,我们发现前20个最频繁的aid2=argsort（M[aid]）[−20:]aid2=argsort（M[aid]）[-20:]aid2=argsort（M[aid]）[−20:] Step 2 - ReRank and Choose 20 从上面的候选列表中选择出现频率最高的20个作为最终预测结果 候选商品生成 123456789101112131415161718192021222324252627282930import sys # 导入sys模块import gc # 导入gc模块def gen_pairs(df): # 定义一个函数用于生成pairs df = df.query(&#x27;session % @SAMPLING == 0&#x27;).groupby(&#x27;session&#x27;, as_index=False, sort=False).apply(lambda g: g.tail(30)).reset_index(drop=True) # 根据条件筛选数据并截取每个会话的最后30条记录 df = pd.merge(df, df, on=&#x27;session&#x27;) # 在会话上进行自连接 pairs = df.query(&#x27;abs(ts_x - ts_y) &lt; 24 * 60 * 60 * 1000 and aid_x != aid_y&#x27;)[[&#x27;session&#x27;, &#x27;aid_x&#x27;, &#x27;aid_y&#x27;]].drop_duplicates() # 筛选满足条件的数据对 return pairs[[&#x27;aid_x&#x27;, &#x27;aid_y&#x27;]].values # 返回数据对中的&#x27;aid_x&#x27;和&#x27;aid_y&#x27;值def gen_aid_pairs(): # 定义一个函数生成aid_pairs all_pairs = defaultdict(lambda: Counter()) # 初始化一个空字典用于存储所有数据配对 all_pair_chunks = [] # 初始化一个空列表用于存储所有的数据块 with tqdm(glob.glob(&#x27;../input/otto-chunk-data-inparquet-format/*_parquet/*&#x27;), desc=&#x27;Chunks&#x27;) as prog: # 使用tqdm来展示进度条，并遍历文件 for idx, chunk_file in enumerate(prog): # 遍历文件 with multiprocessing.Pool() as p: # 创建多进程池 chunk = pd.read_parquet(chunk_file).drop(columns=[&#x27;type&#x27;]) # 从parquet文件中读取数据块 pair_chunks = p.map(gen_pairs, np.array_split(chunk, 120)) # 将数据块拆分并使用gen_pairs函数生成数据对 pair_chunks = np.concatenate(pair_chunks, axis=0) # 将数据块连接成一个数组 all_pair_chunks.append(pair_chunks) # 将数据块添加到数据块列表中 if DEBUG and idx &gt;= 3: # 如果处于DEBUG模式且索引大于等于3时，跳出循环 break del chunk, pair_chunks # 删除数据块和数据对 gc.collect() # 回收内存 df = pd.DataFrame(data=np.concatenate(all_pair_chunks), columns=[&#x27;aid1&#x27;, &#x27;aid2&#x27;]) # 创建包含所有数据对的数据框 top_aids = df.groupby(&#x27;aid1&#x27;).apply(lambda df: Counter(df.aid2).most_common(40)).to_dict() # 根据&#x27;aid1&#x27;分组，并获取前40个最常见的&#x27;aid2&#x27;值 return top_aids # 返回每个&#x27;aid1&#x27;对应的前40个最常见的&#x27;aid2&#x27;值的字典# top_aids的数据结构如下：# &#123;aid1: [(aid2, count), (aid2, count), ...], aid1: [(aid2, count), (aid2, count), ...], ...&#125; 重排名与最终选择 123456789101112131415161718192021222324import itertoolsdef suggest_aids(df): # 选择用户最后操作的20个商品id aids = df.tail(20).aid.tolist() if len(aids) &gt;= 20: return aids # 最后的行为不够20个,就从top_40_cnt中找到与用户最后行为最相关的商品 aids = set(aids) new_aids = Counter() for aid in aids: new_aids.update(top_40_cnt.get(aid, Counter())) # 选取出现次数最多的商品 top_aids2 = [aid2 for aid2, cnt in new_aids.most_common(20) if aid2 not in aids] return list(aids) + top_aids2[:20 - len(aids)]pred_df = test_df.sort_values([&quot;session&quot;, &quot;type&quot;, &quot;ts&quot;]).groupby([&quot;session&quot;]).apply( lambda x: suggest_aids(x))################### BELOW IS CODE ADDED BY CHRIS# 将click, order, cart的预测结果分开处理 How To Build a GBT Ranker Model 🏆 Training an XGBoost Ranker on the GPU 🔥🔥🔥 💡 [polars] Proof of concept: LGBM Ranker🧪🧪🧪 How To Build a GBT Ranker Model Step 1 - Generate Candidates 使用上面的方法生成候选商品列表 每行一个session一个aid,数据内容如下 session (i.e. user) aid (i.e. item) user features item features user-item interaction features click target (i.e 0 or 1) cart target (i.e. 0 or 1) order target (i.e. 0 or 1) Step 2 - ReRank and Choose 20 使用GBT模型最终的20个商品进行预测 Step 1 构建模型的数据集:训练数据是公开数据的前三周,验证数据是第四周. 验证数据又被分为valid A 和valid B, B是ground truth 对每个session先给出50个候选商品id,然后得到了一个(number_of_session * 50, 2)大小的dataframe,类似: | session | aid | | — | — | | 1 | 1234 | | 1 | 9841 | | 2 | 5845 | | 2 | 8984 | Setp 2 创建商品特征(item feature),使用训练数据和验证数据A 123item_features = train.groupby(&#x27;aid&#x27;).agg(&#123;&#x27;aid&#x27;:&#x27;count&#x27;,&#x27;session&#x27;:&#x27;nunique&#x27;,&#x27;type&#x27;:&#x27;mean&#x27;&#125;)item_features.columns = [&#x27;item_item_count&#x27;,&#x27;item_user_count&#x27;,&#x27;item_buy_ratio&#x27;]# 分别是商品-商品的关系,商品-用户的火热度,商品-购买系数概率 Setp 3 创建用户特征(user feature),使用验证数据A 123user_features = train.groupby(&#x27;session&#x27;).agg(&#123;&#x27;session&#x27;:&#x27;count&#x27;,&#x27;aid&#x27;:&#x27;nunique&#x27;,&#x27;type&#x27;:&#x27;mean&#x27;&#125;)user_features.columns = [&#x27;user_user_count&#x27;,&#x27;user_item_count&#x27;,&#x27;user_buy_ratio&#x27;]# 分别是用户-用户的关系,用户-商品的购买了,用户-购买系数概率 Setp 4 创建用户-商品交互特征(user-item interaction feature),使用验证数据A 思路很多没有具体给出.例如: 创建用户-商品点击交互特征 | session | aid | item_click| | — | — | — | Setp 5 将特征添加到candidate dataframe中 12candidates = candidates.merge(item_features, left_on=&#x27;aid&#x27;, right_index=True, how=&#x27;left&#x27;).fillna(-1)candidates = candidates.merge(user_features, left_on=&#x27;session&#x27;, right_index=True, how=&#x27;left&#x27;).fillna(-1) 然后candidate dataframe类似: session aid item_feat1 item_feat2 user_feat1 user_feat2 1 1234 1 2 3 4 1 9841 5 6 7 8 2 5845 9 10 11 12 2 8984 13 14 15 16 Setp 6 构建ground truth,例如test_labels.parquet: | session | type | ground_truth | | — | — | — | | 1 | carts | [5456,4545,98741,2355] | | 2 | carts | [1257,8653,2547] | 然后将其转换为如下: session aid cart 1 5456 1 1 4545 1 1 98741 1 然后将其合并到candidate dataframe中 1candidates = candidates.merge(cart_target,on=[&#x27;user&#x27;,&#x27;item&#x27;],how=&#x27;left&#x27;).fillna(0) candidates dataframe类似: session aid item_feat1 item_feat2 user_feat1 user_feat2 cart 1 1234 1 2 3 4 0 1 9841 5 6 7 8 1 2 5845 9 10 11 12 0 2 8984 13 14 15 16 1 Setp 7 训练,不适用user和aid列: 12345678910111213141516171819202122232425import xgboost as xgb # 导入XGBoost库from sklearn.model_selection import GroupKFold # 从sklearn库中导入GroupKFold模块skf = GroupKFold(n_splits=5) # 使用GroupKFold方法划分数据集为5折交叉验证# groups参数的作用是指定用于分组的特征列。在GroupKFold交叉验证中，通过指定groups参数，可以确保在交叉验证过程中，同一组内的数据样本不会同时出现在训练集和验证集中，以避免数据泄露和提高模型的准确性。在这里，candidates[&#x27;user&#x27;]列被用作分组的特征列，以确保每个用户的数据在交叉验证时能够保持独立。for fold, (train_idx, valid_idx) in enumerate(skf.split(candidates, candidates[&#x27;click&#x27;], groups=candidates[&#x27;user&#x27;])): # 遍历每一个交叉验证折数 X_train = candidates.loc[train_idx, FEATURES] # 获取训练集特征数据 y_train = candidates.loc[train_idx, &#x27;click&#x27;] # 获取训练集标签数据 X_valid = candidates.loc[valid_idx, FEATURES] # 获取验证集特征数据 y_valid = candidates.loc[valid_idx, &#x27;click&#x27;] # 获取验证集标签数据 # 如果有50个候选项，则使用50个作为分组信息# 创建一个XGBoost中的DMatrix对象，用于存储训练集的特征数据、标签数据以及分组信息。# 创建DMatrix对象，可以使训练数据更高效地传递给XGBoost模型，并且能够利用分组信息优化模型的学习过程。 dtrain = xgb.DMatrix(X_train, y_train, group=[50] * (len(train_idx)//50) ) # 创建训练集的DMatrix dvalid = xgb.DMatrix(X_valid, y_valid, group=[50] * (len(valid_idx)//50) ) # 创建验证集的DMatrix xgb_parms = &#123;&#x27;objective&#x27;:&#x27;rank:pairwise&#x27;, &#x27;tree_method&#x27;:&#x27;gpu_hist&#x27;&#125; # 设置XGBoost的参数 model = xgb.train(xgb_parms, dtrain=dtrain, evals=[(dtrain,&#x27;train&#x27;),(dvalid,&#x27;valid&#x27;)], num_boost_round=1000, verbose_eval=100) # 训练XGBoost模型 model.save_model(f&#x27;XGB_fold&#123;fold&#125;_click.xgb&#x27;) # 保存训练好的模型 Setp 8 推理:为了进行推理，我们创建了一个新的候选数据帧，但这次是根据Kaggle的测试数据。然后，我们从Kaggle训练的所有4周加上Kaggle测试的1周中制作项目特征(item feature)。我们通过Kaggle测试制作用户特征(user feature)。我们将这些特征合并到我们的候选者中。然后，我们使用保存的模型来推断点击量的预测。最后，我们通过对预测进行排序并选择20个。 1234567891011121314151617181920212223preds = np.zeros(len(test_candidates)) # 初始化一个全零数组用于存储预测值for fold in range(5): # 遍历5个交叉验证折数 model = xgb.Booster() # 创建一个XGBoost模型 model.load_model(f&#x27;XGB_fold&#123;fold&#125;_click.xgb&#x27;) # 载入训练好的XGBoost模型 model.set_param(&#123;&#x27;predictor&#x27;: &#x27;gpu_predictor&#x27;&#125;) # 设置模型参数为GPU加速预测 dtest = xgb.DMatrix(data=test_candidates[FEATURES]) # 创建测试集的DMatrix对象# 结果是每个候选值的预测得分（概率） preds += model.predict(dtest)/5 # 对测试集进行预测，并将结果累加求平均predictions = test_candidates[[&#x27;user&#x27;,&#x27;item&#x27;]].copy() # 复制测试集的&#x27;user&#x27;和&#x27;item&#x27;列作为预测结果的基础predictions[&#x27;pred&#x27;] = preds # 将预测结果添加到predictions中predictions = predictions.sort_values([&#x27;user&#x27;,&#x27;pred&#x27;], ascending=[True,False]).reset_index(drop=True) # 对预测结果按&#x27;user&#x27;和&#x27;pred&#x27;进行排序，并重置索引predictions[&#x27;n&#x27;] = predictions.groupby(&#x27;user&#x27;).item.cumcount().astype(&#x27;int8&#x27;) # 根据&#x27;user&#x27;分组后，计算每个用户的条目数量作为序号predictions = predictions.loc[predictions.n&lt;20] # 保留每个用户前20个预测结果sub = predictions.groupby(&#x27;user&#x27;).item.apply(list) # 根据用户分组，将预测结果转换为列表sub = sub.to_frame().reset_index() # 将预测结果转换为DataFrame格式sub.item = sub.item.apply(lambda x: &quot; &quot;.join(map(str,x))) # 将列表中的数字转换为字符串并拼接成一个字符串sub.columns = [&#x27;session_type&#x27;,&#x27;labels&#x27;] # 重命名DataFrame的列名sub.session_type = sub.session_type.astype(&#x27;str&#x27;)+ &#x27;_clicks&#x27; # 修改&#x27;session_type&#x27;列的数据类型 💡 Word2Vec How-to [training and submission]🚀🚀🚀 💡 Word2Vec How-to [training and submission]🚀🚀🚀 A session where one action follows another action is very much like a sentence! 类似地，在这里我们可以利用这样一个事实，即在一个紧密的序列中出现的商品id可能有一些相似之处。 所以我们使用word2vec模型来训练商品id的嵌入向量，然后使用这些向量来计算商品id之间的相似度。 这样给定一个商品的id就可以找到和她类似的商品id。 使用word2vec直接获取20个商品 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 将用户的所有行为的商品id转换为一个句子,[&#x27;aid1&#x27;,&#x27;aid2&#x27;,&#x27;aid3&#x27;,&#x27;aid4&#x27;]sentences_df = pl.concat([train, test]).groupby(&#x27;session&#x27;).agg( pl.col(&#x27;aid&#x27;).alias(&#x27;sentence&#x27;))sentences = sentences_df[&#x27;sentence&#x27;].to_list()# 训练word2vec模型w2vec = Word2Vec(sentences=sentences, vector_size=32, min_count=1, workers=4)# 构建aid到索引的映射字典aid2idx = &#123;aid: i for i, aid in enumerate(w2vec. index_to_key)&#125; # 创建一个Annoy索引对象，指定向量维度为32，距离度量方式为欧氏距离index = AnnoyIndex(32, &#x27;euclidean&#x27;) # 遍历aid2idx字典for aid, idx in aid2idx.items(): index.add_item(idx, w2vec.wv.vectors[idx]) # 将向量添加到Annoy索引对象中 index.build(10) # 构建Annoy索引，其中10表示构建索引时要使用的树的数量# index存储的是 索引-&gt;向量# aid2idx存储的是 商品id-&gt;索引sample_sub = pd.read_csv(&#x27;../input/otto-recommender-system//sample_submission.csv&#x27;) # 从CSV文件中读取sample_sub数据&#x27;&#x27;&#x27;选择最近的20个商品&#x27;&#x27;&#x27;# 从测试集中获取每个用户的AID列表和类型列表test_session_AIDs = test.to_pandas().reset_index(drop=True).groupby(&#x27;session&#x27;)[&#x27;aid&#x27;].apply(list)test_session_types = test.to_pandas().reset_index(drop=True).groupby(&#x27;session&#x27;)[&#x27;type&#x27;].apply(list)labels = [] # 初始化一个空列表用于存储标签结果type_weight_multipliers = &#123;0: 1, 1: 6, 2: 3&#125; # 定义类型权重for AIDs, types in zip(test_session_AIDs, test_session_types): # 遍历测试集中的每个用户的AID和类型 if len(AIDs) &gt;= 20: # 如果AID数量大于等于20 # 如果我们有足够的AID（大于等于20）我们不需要查找候选项！我们只需使用旧的逻辑 weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1 # 根据AID数量生成对应的权重 aids_temp=defaultdict(lambda: 0) # 初始化一个默认值为0的字典 for aid,w,t in zip(AIDs,weights,types): # 遍历AID，权重和类型 aids_temp[aid]+= w * type_weight_multipliers[t] # 根据AID和类型计算加权得分 sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])] # 按照加权得分对AID进行排序 labels.append(sorted_aids[:20]) # 将前20个AID添加到标签中 else: # 如果AID数量小于20 # 这里我们没有20个AID要输出-我们将使用word2vec嵌入来生成候选项！ AIDs = list(dict.fromkeys(AIDs[::-1])) # 移除重复项并反转AID列表 # 获取时间最近的AID most_recent_aid = AIDs[0] # most_recent_aid是商品id,aid2idx[most_recent_aid]拿到对应的索引 # index.get_nns_by_item(aid2idx[most_recent_aid], 21)根据索引获取向量并计算最近的21个商品 # 寻找一些邻居 nns = [w2vec.wv.index_to_key[i] for i in index.get_nns_by_item(aid2idx[most_recent_aid], 21)[1:]] # 使用Annoy索引找到最近邻的AID labels.append((AIDs+nns)[:20]) # 将AID和邻居的AID组合，取前20个作为标签 使用word2vec 获取候选商品 和covisiation matrix类似,使用word2vec可以获取最相关的商品 数据为: session aid type 1 10 0 1 20 0 2 20 1 2 30 0 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061假如通过上面的代码我们已经类似的获取到了最相关的商品| session | aid || --- | --- || 1 | 11 | | 1 | 20 || 2 | 25 | | 2 | 6 | 那么下面还有几个步骤1. Step 1: Add ordering information to our candidates.word2vec模型是按照相似度评分来排序的,所以我们需要添加一些排序信息| session | aid | rank || --- | --- | --- || 1 | 11 | 1 || 1 | 20 | 2 || 2 | 25 | 1 || 2 | 6 | 2 |2. 将这些信息合并到candidates中| session | aid | rank | type || --- | --- | --- | --- || 1 | 11 | 1 | null || 1 | 20 | 2 | 0 || 1 | 10 | null | 0 || 2 | 25 | 1 | null || 2 | 6 | 2 | null || 2 | 20 | null | 1 || 2 | 30 | null | 0 |3. 使用Ranker模型进行预测,### 💡 [2 methods] How-to ensemble predictions 🏅🏅🏅[💡 [2 methods] How-to ensemble predictions 🏅🏅🏅](https://www.kaggle.com/code/radek1/2-methods-how-to-ensemble-predictions)对预测结果集成:- 投票集成(voting ensemble)- 加权投票集成(voting ensemble with weights),对好结果有更大的权重```pythondef read_sub(path, weight=1): # 定义一个函数用于加载和预处理提交结果 &#x27;&#x27;&#x27;a helper function for loading and preprocessing submissions&#x27;&#x27;&#x27; return ( pl.read_csv(path) # 从路径中读取CSV文件 .with_column(pl.col(&#x27;labels&#x27;).str.split(by=&#x27; &#x27;)) # 将&#x27;labels&#x27;列按空格拆分为列表 .with_column(pl.lit(weight).alias(&#x27;vote&#x27;)) # 新增名为&#x27;vote&#x27;的列，其中填充权重值 .explode(&#x27;labels&#x27;) # 展开&#x27;labels&#x27;列中的列表 .rename(&#123;&#x27;labels&#x27;: &#x27;aid&#x27;&#125;) # 重命名&#x27;labels&#x27;为&#x27;aid&#x27; .with_column(pl.col(&#x27;aid&#x27;).cast(pl.UInt32)) # 将&#x27;aid&#x27;列转换为UInt32类型 .with_column(pl.col(&#x27;vote&#x27;).cast(pl.UInt8)) # 将&#x27;vote&#x27;列转换为UInt8类型 )# 有无权重subs = [read_sub(path) for path in paths]subs = [read_sub(path, weight) for path, weight in zip(paths, [1, 0.55, 0.55])] 读取后的数据为: session_type aid vote 1_clicks 1234 1 1_clicks 9841 1 2_clicks 5845 1 由于内存限制,只能进行join: 12subs = subs[0].join(subs[1], how=&#x27;outer&#x27;, on=[&#x27;session_type&#x27;, &#x27;aid&#x27;]).join(subs[2], how=&#x27;outer&#x27;, on=[&#x27;session_type&#x27;, &#x27;aid&#x27;], suffix=&#x27;_right2&#x27;)subs.head() 合并后的数据 session_type aid vote vote_right vote_right2 1_clicks 1234 1 1 1 1_clicks 9841 1 null 1 2_clicks 5845 1 1 null 2_clicks 8984 1 null null 用0填充null值,然后对vote求和,排序: 1234567subs = (subs .fill_null(0) .with_column((pl.col(&#x27;vote&#x27;) + pl.col(&#x27;vote_right&#x27;) + pl.col(&#x27;vote_right2&#x27;)).alias(&#x27;vote_sum&#x27;)) .drop([&#x27;vote&#x27;, &#x27;vote_right&#x27;, &#x27;vote_right2&#x27;]) .sort(by=&#x27;vote_sum&#x27;) .reverse()) 数据如下: session_type aid vote_sum 1_clicks 1234 3 2_clicks 5845 2 1_clicks 9841 2 然后对每个类型选择前20个商品,然后聚合成数组: 12345preds = subs.groupby(&#x27;session_type&#x27;).agg([ pl.col(&#x27;aid&#x27;).head(20).alias(&#x27;labels&#x27;)])preds = preds.with_column(pl.col(&#x27;labels&#x27;).apply(lambda lst: &#x27; &#x27;.join([str(aid) for aid in lst]))) 💡Matrix Factorization [PyTorch+Merlin Dataloader] 与word2vec类似,使用矩阵分解来获取商品的嵌入向量 💡Matrix Factorization with GPU [PyTorch+Merlin Dataloader] 使用Pytorch的Embedding层来训练商品的嵌入向量,然后使用这些向量来计算商品id之间的相似度. 123456# 构建aid_pairstrain_pairs = cudf.concat([train, test])[[&#x27;session&#x27;, &#x27;aid&#x27;]]del train, testtrain_pairs[&#x27;aid_next&#x27;] = train_pairs.groupby(&#x27;session&#x27;).aid.shift(-1)train_pairs = train_pairs[[&#x27;aid&#x27;, &#x27;aid_next&#x27;]].dropna().reset_index(drop=True) aid aid_next 1 2 2 3 3 4 123456789101112131415161718192021222324252627282930313233343536import torchfrom torch import nn# WordEmbedding模型class MatrixFactorization(nn.Module): def __init__(self, n_aids, n_factors): super().__init__() self.aid_factors = nn.Embedding(n_aids, n_factors, sparse=True) def forward(self, aid1, aid2): aid1 = self.aid_factors(aid1) aid2 = self.aid_factors(aid2) return (aid1 * aid2).sum(dim=1)# 评价指标class AverageMeter(object): &quot;&quot;&quot;Computes and stores the average and current value&quot;&quot;&quot; def __init__(self, name, fmt=&#x27;:f&#x27;): self.name = name self.fmt = fmt self.reset() def reset(self): self.val = 0 self.avg = 0 self.sum = 0 self.count = 0 def update(self, val, n=1): self.val = val self.sum += val * n self.count += n self.avg = self.sum / self.count def __str__(self): fmtstr = &#x27;&#123;name&#125; &#123;val&#x27; + self.fmt + &#x27;&#125; (&#123;avg&#x27; + self.fmt + &#x27;&#125;)&#x27; return fmtstr.format(**self.__dict__) 12345678910111213141516171819202122232425262728293031323334# 训练model.to(&#x27;cuda&#x27;)for epoch in range(num_epochs): for batch, _ in train_dl_merlin: model.train() losses = AverageMeter(&#x27;Loss&#x27;, &#x27;:.4e&#x27;) aid1, aid2 = batch[&#x27;aid&#x27;], batch[&#x27;aid_next&#x27;] aid1 = aid1.to(&#x27;cuda&#x27;) aid2 = aid2.to(&#x27;cuda&#x27;) output_pos = model(aid1, aid2) output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])]) output = torch.cat([output_pos, output_neg]) targets = torch.cat([torch.ones_like(output_pos), torch.zeros_like(output_pos)]) loss = criterion(output, targets) losses.update(loss.item()) optimizer.zero_grad() loss.backward() optimizer.step() model.eval() with torch.no_grad(): accuracy = AverageMeter(&#x27;accuracy&#x27;) for batch, _ in valid_dl_merlin: aid1, aid2 = batch[&#x27;aid&#x27;], batch[&#x27;aid_next&#x27;] output_pos = model(aid1, aid2) output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])]) accuracy_batch = torch.cat([output_pos.sigmoid() &gt; 0.5, output_neg.sigmoid() &lt; 0.5]).float().mean() accuracy.update(accuracy_batch, aid1.shape[0]) print(f&#x27;&#123;epoch+1:02d&#125;: * TrainLoss &#123;losses.avg:.3f&#125; * Accuracy &#123;accuracy.avg:.3f&#125;&#x27;) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 获取嵌入并计算相似度embeddings = model.aid_factors.weight.detach().cpu().numpy()knn = NearestNeighbors(n_neighbors=21, metric=&#x27;euclidean&#x27;)knn.fit(embeddings)_, aid_nns = knn.kneighbors(embeddings)sample_sub = pd.read_csv(&#x27;../input/otto-recommender-system//sample_submission.csv&#x27;)test = cudf.read_parquet(&#x27;../input/otto-full-optimized-memory-footprint/test.parquet&#x27;)session_types = [&#x27;clicks&#x27;, &#x27;carts&#x27;, &#x27;orders&#x27;]gr = test.reset_index(drop=True).to_pandas().groupby(&#x27;session&#x27;)test_session_AIDs = gr[&#x27;aid&#x27;].apply(list)test_session_types = gr[&#x27;type&#x27;].apply(list)labels = []type_weight_multipliers = &#123;0: 1, 1: 6, 2: 3&#125;for AIDs, types in zip(test_session_AIDs, test_session_types): if len(AIDs) &gt;= 20: # if we have enough aids (over equals 20) we don&#x27;t need to look for candidates! we just use the old logic weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1 aids_temp=defaultdict(lambda: 0) for aid,w,t in zip(AIDs,weights,types): aids_temp[aid]+= w * type_weight_multipliers[t] sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])] labels.append(sorted_aids[:20]) else: # here we don&#x27;t have 20 aids to output -- we will use approximate nearest neighbor search and our embeddings # to generate candidates! AIDs = list(dict.fromkeys(AIDs[::-1])) # let&#x27;s grab the most recent aid most_recent_aid = AIDs[0] # and look for some neighbors! nns = list(aid_nns[most_recent_aid]) labels.append((AIDs+nns)[:20])labels_as_strings = [&#x27; &#x27;.join([str(l) for l in lls]) for lls in labels]predictions = pd.DataFrame(data=&#123;&#x27;session_type&#x27;: test_session_AIDs.index, &#x27;labels&#x27;: labels_as_strings&#125;)prediction_dfs = []for st in session_types: modified_predictions = predictions.copy() modified_predictions.session_type = modified_predictions.session_type.astype(&#x27;str&#x27;) + f&#x27;_&#123;st&#125;&#x27; prediction_dfs.append(modified_predictions)submission = pd.concat(prediction_dfs).reset_index(drop=True)submission.to_csv(&#x27;submission.csv&#x27;, index=False) 226th (?!) Place Solution &amp; Two-cents from a First-timer 226th (?!) Place Solution &amp; Two-cents from a First-timer Item Co-visitation Matrix entirely based one Chris’ notebook Order matrix: Click/cart/order to click/cart/order with type weighting Buy2buy matrix: Cart/order to cart/order Click matrix: click/cart/order to clicks with time weighting Feature Feneration Item features (for each aid) Count of events (click/cart/order) Sum of event weight Quarter of day (QoD) with most events (0-3) Day of week (DoW) with most events (0-6) User features (for each session) Count of events (click/cart/order) and interacted items (aid) Sum of event weight QoD with most events (0-3) DoW with most events (0-6) Number of days with events Days from first to last events User-item features (for each session-aid pair) Count of events (click/cart/order) and interacted items (aid) Sum of event weight QoD with most events in both categorical (0-3) and one-hot encoded (0/1 for each) format DoW with most events in both categorical (0-6) and one-hot encoded (0/1 for each) format last_n = item_chronological_rank / user_total_event_count last_ts = (user_item_last_timestamp - start_week_timestamp) / (end_week_timestamp - start_week_timestamp) Candidate Selection partly based on Chris’ notebook For each session,I select top X most relevant items in each event type 会话单击/点选/订购项目的次数 共访权总和 该商品是否为本周点击次数最多/购买次数最多的商品 Ranker Rule-base ranker in Chris’ notebook XGBRanker with rank:pairwise objective the model is overfitting and requires a lot of hyperparameter tuning Solution Ensemble use their public LB scores as weights Ensemble of XGBRanker above and public submissions Ensemble of above two ranker methods and public submissions 6, what have I learned read the discussion and notebooks forums try as many ideas as possible know every line of code you write","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Kaggle","slug":"Kaggle","permalink":"https://gladdduck.github.io/tags/Kaggle/"}]},{"title":"vscode免密连接服务器","slug":"配置-vscode免密连接服务器","date":"2024-03-11T07:09:42.878Z","updated":"2024-03-11T07:16:15.000Z","comments":true,"path":"2024/03/11/配置-vscode免密连接服务器/","link":"","permalink":"https://gladdduck.github.io/2024/03/11/%E9%85%8D%E7%BD%AE-vscode%E5%85%8D%E5%AF%86%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"看尚硅谷的视频知道了免密连接的原理 本地 生成公钥和私钥 12ssh-keygen -t rsa # 一路回车即可,如果已经存在了,可以起个名字方便区分 生成的公钥和私钥在C:/user/xxx/.ssh目录下 12id_rsa:是私钥 ,私钥存在自己电脑上id_rsa.pub:是公钥, 公钥放在服务器上(想连谁就把公钥发给谁) 3.在vscode中安装Remote - SSH插件, 然后按步骤连接服务器,在配置文件中填写服务器的ip地址,用户名,密码,端口号等信息 123456Host 服务器名称 HostName ip User 用户名 PreferredAuthentications publickey IdentityFile &quot;C:/Users/[用户名]/.ssh/id_rsa&quot; 服务器 在服务器上进入.ssh文件夹 1cd ~/.ssh 创建/打开一个authorized_keys文件 123touch authorized_keys或者vim authorized_keys 把本地的公钥内容复制到authorized_keys文件中保存 12或者上传id_rsa.pub到.ssh文件夹cat id_rsa.pub &gt;&gt; authorized_keys 完成","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Vscode","slug":"Vscode","permalink":"https://gladdduck.github.io/tags/Vscode/"}]},{"title":"位运算技巧分类总结","slug":"算法-位运算技巧分类总结","date":"2024-03-06T02:05:35.115Z","updated":"2024-03-06T02:28:44.290Z","comments":true,"path":"2024/03/06/算法-位运算技巧分类总结/","link":"","permalink":"https://gladdduck.github.io/2024/03/06/%E7%AE%97%E6%B3%95-%E4%BD%8D%E8%BF%90%E7%AE%97%E6%8A%80%E5%B7%A7%E5%88%86%E7%B1%BB%E6%80%BB%E7%BB%93/","excerpt":"","text":"从集合论到位运算，常见位运算技巧分类总结！ 1.集合与集合 2.集合与元素 3.遍历集合 设元素范围从 000到 n−1n-1n−1，挨个判断每个元素是否在集合 sss中： 123for i in range(n): if (s &gt;&gt; i) &amp; 1: # i 在 s 中 # 处理 i 的逻辑 4.枚举集合 设元素范围从 000到 n−1n-1n−1，从空集∅\\empty∅枚举到全集UUU: 12for s in range(1 &lt;&lt; n): # 处理 s 的逻辑 从大到小枚举所有非空子集： 1234sub=swhile sub: # 处理 sub 的逻辑 sub=(sub-1)&amp;s 5.练习 位运算练习: LeetCode 78. 子集 LeetCode 77. 组合 LeetCode 46. 全排列 状态压缩 DP。这类题目通常和排列/子集有关，可以先从暴力回溯开始思考，再过渡到记忆化搜索和递推。 LeetCode 2172. 数组的最大与和 LeetCode 1125. 最小的必要团队 LeetCode 2305. 公平分发饼干 LeetCode 1494. 并行课程 II LeetCode LCP 53. 守护太空城 LeetCode 1879. 两个数组最小的异或值之和 LeetCode 1986. 完成任务的最少工作时间段","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"Few-shot Object Detection应用论文","slug":"学术-Few-shotDetection应用论文","date":"2023-12-28T04:19:17.803Z","updated":"2023-12-28T04:21:07.648Z","comments":true,"path":"2023/12/28/学术-Few-shotDetection应用论文/","link":"","permalink":"https://gladdduck.github.io/2023/12/28/%E5%AD%A6%E6%9C%AF-Few-shotDetection%E5%BA%94%E7%94%A8%E8%AE%BA%E6%96%87/","excerpt":"","text":"1. Prototype-CNN for Few-Shot Object Detection in Remote Sensing Images 2. An Efficient Few-Shot Object Detection Method for Railway Intrusion via Fine-tune Approach and Contrastive learning 3. Rethinking Few-Shot Object Detection on a Multi-Domain Benchmark 4. Robust Few-Shot Aerial Image Object Detection via Unbiased Proposals Filtration 5. Industrial few-shot fractal object detection 6. A New Few-Shot Learning-Based Model for Prohibited Objects Detection in Cluttered Baggage X-Ray Images Through Edge Detection and Reverse Validation.pdf","categories":[{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Few-shotObjectDetection","slug":"Few-shotObjectDetection","permalink":"https://gladdduck.github.io/tags/Few-shotObjectDetection/"}]},{"title":"DEViT代码阅读","slug":"学术-DEViT代码阅读","date":"2023-12-15T06:48:19.603Z","updated":"2023-12-15T06:49:27.773Z","comments":true,"path":"2023/12/15/学术-DEViT代码阅读/","link":"","permalink":"https://gladdduck.github.io/2023/12/15/%E5%AD%A6%E6%9C%AF-DEViT%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/","excerpt":"","text":"detectron2代码阅读 DEViT代码阅读","categories":[{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"代码阅读","slug":"代码阅读","permalink":"https://gladdduck.github.io/tags/%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"}]},{"title":"LeetCode每日一题2023-12","slug":"算法-LeetCode每日一题2023-12","date":"2023-12-11T11:42:27.397Z","updated":"2024-01-02T12:45:48.598Z","comments":true,"path":"2023/12/11/算法-LeetCode每日一题2023-12/","link":"","permalink":"https://gladdduck.github.io/2023/12/11/%E7%AE%97%E6%B3%95-LeetCode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%982023-12/","excerpt":"","text":"2023.12LeetCode每日一题 2023.12.11 最小体力消耗路径[中等] 1631. 最小体力消耗路径 思路: 深搜\\宽搜:统计所有路径，然后找到最小的路径 动态规划:dp[i][j]表示到达i,j的最小消耗，dp[i][j]=min(dp[i-1][j],dp[i][j-1])+abs(heights[i][j]-heights[i-1][j-1]) 错误: 题目求的不是最小消耗的路径,而是这个路径上最大绝对值差值的最小() 题解: 二分:二分的是最大绝对值差值,然后判断是否能够到达终点(深搜宽搜),能到就继续缩小差值,不能就增大差值 并查集:将所有边按照权值从小到大排序,然后依次加入并查集,如果起点和终点连通,那么这个权值就是答案 最短路径算法:当前最短路径可以表示为这条路径上最大的权重(普通的最短路径应该表示为这条路径上权重的和),然后使用最短路径算法求解 2023.12.12 😒用邮票贴满网格图[困难] 2132. 用邮票贴满网格图 2023.12.13 下一个更大元素 IV[困难] 下一个更大元素 I[简单] 先在nums2中找到当前元素的位置,然后从这个位置开始遍历,找到第一个比当前元素大的元素,如果找不到就返回-1 单调栈+Hash表,先对nums2进行单调栈处理(从后往前记录(相当于当前元素和他左边的元素无关),从栈底到栈顶递增),然后用一个map记录每个数字对应的右边第一个比它大的数字,最后遍历nums1,直接从map中取值 下一个更大元素 II[中等] 单调栈+循环数组,循环数组使用取余的方式实现, 单调栈里存的是数组下标(元素从栈底到栈顶递减),当栈顶的元素被弹出来时,说明当前元素是栈顶元素右边第一个比它大的元素,栈顶元素的答案就是遍历到的当前元素 下一个更大元素 III[中等] 分析＋单调栈,对一个数字:564973,从后往前找(因为是最小的,动后面的肯定最小) 对于3,后面没有比它大的数字,所以3不动 对于73,没有比7大的数字,所以不动 对于973,没有比9大的数字,所以不动 对于4973,找到后面比4大的最小的数字,交换4和7,得到567,在对剩下的数字排序,得到349,答案就是567349 类似31.下一个排列 [31.下一个排列],从后往前先找到第一个正序对,然后再从后往前找到第一个比这个正序对中的第一个数字大的数字,交换这两个数字,然后将后面的数字排序 [31.下一个排列]也可以用1的方法做 下一个更大元素 IV[困难] 用一个最小堆q来存储已经找到下一个比他大的元素,用一个单调栈st来存储还没找到下一个比他大的元素的元素,具体操作: 如果q非空,且堆顶元素小于栈顶元素,说明堆顶的这个元素找到了第二个比他大的元素,重复操作直到堆顶元素大于栈顶元素或者堆为空 如果st非空,且栈顶元素小于当前元素,说明栈顶元素找到了第一个比他大的元素,将栈顶元素弹出加入到堆中,重复操作直到栈顶元素大于当前元素或者栈为空 将当前元素入栈 最小堆复杂度是O(nlogn)O(nlogn)O(nlogn),使用单调栈替换掉最小堆,复杂度就是O(n)O(n)O(n) 用一个stack2代替最小堆,只要保证stack2是一个从栈底到栈顶单调递减的栈,如何保证stack2是单调递减的:从1可知堆顶的元素一定是大于栈里的,因此在stack1弹出来的时候,不要一个个弹,用切片弹,然后把整个切片加入到stack2中,这样就保证了stack2是单调递减的 2023.12.13 字典序最小回文串[简单] 2697. 字典序最小回文串 思路: 从左开始遍历到字符串长度的中间,如果遇到不相等的字符,那么就将这两个字符替换为二者之间最小的(双指针) 2023.12.15 反转二叉树的奇数层[中等] 2415. 反转二叉树的奇数层 思路: 宽搜,难点在于如何存储每一层的节点,想法是用两个队列,一个从左往右搜左子树的,一个从右往左搜右子树的,这样顺序就是对称的.到奇数层直接交换两个队列的当前节点的值就行 想复杂了,只要交换值就行,不用交换节点 题解: 宽搜,把每一层的节点都存到list里,奇数层交换 深搜, 传递两个节点,一个从最左边往下搜, 一个从最右边往下搜,奇数层则交换这两个节点的值 2023.12.16 统计区间中的整数数目[苦难] 2276. 统计区间中的整数数目 线段树解决的是「区间和」问题，并且该「区间」会被修改。 线段树最简单模板 思想:将数组看成一棵树,叶子节点是数组的值,非叶子节点代表了其叶子节点区间的和/最大值/最小值. 307. 区域和检索 - 数组可修改 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class SegTreeSimple: def __init__(self, nums): self.tree = [0] * (4 * len(nums)) self.nums=nums self.build(1,0,len(nums)-1) def build(self, cur, left, right): &#x27;&#x27;&#x27; l,r表示的是当前需要构建的区间 cur是[l,r]区间的在树中的节点 l==r说明到达了树的叶子节点,那么cur的值就是数组的值 &#x27;&#x27;&#x27; # 到达当前节点 if left==right: self.tree[cur] = self.nums[left] return mid = (left + right) // 2 # 构建左右子树 self.build(cur * 2, left, mid) self.build(cur * 2 + 1, mid + 1, right) # 向上更新 self.pushup(cur) def pushup(self, root): # 求区间 和/最大值/最小值 self.tree[root] = self.tree[root * 2] + self.tree[root * 2 + 1] # 区间更新 def updateArrange(self, cur, left, right, start, end , val): &#x27;&#x27;&#x27; cur是当前在数中的节点 l,r是要更新的区间 start,end是当前区间 val是要更新的值 &#x27;&#x27;&#x27; if start == end: self.tree[cur] = val return if left&lt;start or right&gt;end: return mid = (start + end) // 2 if left &lt;= mid: self.updateArrange(cur * 2, left, right, start, mid, val) if right&gt;mid: self.updateArrange(cur * 2 + 1, left, right, mid+1, end, val) self.pushup(cur) # 单点更新 def update(self, cur, left, right, index, val): &#x27;&#x27;&#x27; cur是当前区间在树中的节点 l,r是要更新的数组的区间 index是要更新的数组的索引 val是要更新的值 &#x27;&#x27;&#x27; if left == right: # 覆盖式,也可是增量式 self.tree[cur] = val return mid = (left + right) // 2 if index &lt;= mid: self.update(cur * 2, left, mid, index, val) else: self.update(cur * 2 + 1, mid + 1, right, index, val) self.pushup(cur) # 区间查询 def query(self, cur, left, right, start, end): &#x27;&#x27;&#x27; left,right是要查询的区间 cur是当前区间对应的树的节点 start,end是当前区间 &#x27;&#x27;&#x27; # 当前区间完全处于查询区间之内 if left &lt;= start and end &lt;= right: return self.tree[cur] mid = (start + end) // 2 ans = 0 if left &lt;= mid: ans += self.query(cur * 2, left, right, start, mid) if right &gt; mid: ans += self.query(cur * 2 + 1, left, right, mid + 1, end) return ans 线段树Lazy模板 思想: 在上面查询的时候,如果当前区间包括在查询区间里面,那么就可以直接返回当前区间的值而不用向下传递. 在区间修改时,如果当前区间包括在修改区间里面,那么也可以直接修改当前区间的值而不用向下传递(如果向下传递的话相当于遍历其子树时间复杂度为O(n)O(n)O(n)). 做法是使用一个lazy数组记录当前区间需要向下传递的值,在查询,如果当前区间需要向下传递的值不为0,那么就向下传递,并且将当前区间的lazy值清零 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394class SegTreeLazy: def __init__(self, nums): self.tree = [0] * (4 * len(nums)) self.lazy = [0] * (4 * len(nums)) self.nums=nums self.build(1,0,len(nums)-1) def build(self, cur, left, right): &#x27;&#x27;&#x27; l,r表示的是当前需要构建的区间 cur是[l,r]区间的在树中的节点 l==r说明到达了树的叶子节点,那么cur的值就是数组的值 &#x27;&#x27;&#x27; # 到达当前节点 if left==right: self.tree[cur] = self.nums[left] return mid = (left + right) // 2 # 构建左右子树 self.build(cur * 2, left, mid) self.build(cur * 2 + 1, mid + 1, right) # 向上更新 self.pushup(cur) def pushup(self, root): # 求区间 和/最大值/最小值 self.tree[root] = self.tree[root * 2] + self.tree[root * 2 + 1] # 单点更新 def update(self, cur, left, right, index, val): &#x27;&#x27;&#x27; cur是当前区间在树中的节点 l,r是要更新的数组的区间 index是要更新的数组的索引 val是要更新的值 &#x27;&#x27;&#x27; if left == right: # 覆盖式,也可是增量式 self.tree[cur] = val return mid = (left + right) // 2 if index &lt;= mid: self.update(cur * 2, left, mid, index, val) else: self.update(cur * 2 + 1, mid + 1, right, index, val) self.pushup(cur) # 区间更新 def updateRange(self, cur, left, right, start, end, val): # 当前区间完全处于查询区间之内 if left &lt;= start and end &lt;= right: # 只更新当前区间的值,不向下传递 self.tree[cur] += val * (end - start + 1) # 记录当前区间需要向下传递的值,如果不是区间没必要向下传递 if start != end: self.lazy[cur] += val return mid = (start + end) // 2 # 向下传递lazy值,如果是覆盖式更新,不能使用self.lazy!-0判断,需要使用额外的bool数组 if self.lazy[cur] != 0: self.pushdown(cur, start, end, mid) if left &lt;= mid: self.updateRange(cur * 2, left, right, start, mid, val) if right &gt; mid: self.updateRange(cur * 2 + 1, left, right, mid + 1, end, val) self.pushup(cur) def pushdown(self, cur, start, end, mid): # 向下传递lazy值,值传递到子节点 self.tree[cur * 2] += self.lazy[cur] * (mid - start + 1) self.tree[cur * 2 + 1] += self.lazy[cur] * (end - mid) self.lazy[cur * 2] += self.lazy[cur] self.lazy[cur * 2 + 1] += self.lazy[cur] self.lazy[cur] = 0 # 区间查询 def query(self, cur, left, right, start, end): &#x27;&#x27;&#x27; left,right是要查询的区间 cur是当前区间对应的树的节点 start,end是当前区间 &#x27;&#x27;&#x27; # 当前区间完全处于查询区间之内 if left &lt;= start and end &lt;= right: return self.tree[cur] mid = (start + end) // 2 ans = 0 if self.lazy[cur] != 0: self.pushdown(cur, start, end, mid) if left &lt;= mid: ans += self.query(cur * 2, left, right, start, mid) if right &gt; mid: ans += self.query(cur * 2 + 1, left, right, mid + 1, end) return ans 线段树离散化模板 思想: 需要直到全部的区间坐标 做好原数组与离散后数组的映射关系 699. 掉落的方块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384class SegTreeDiscrete: def __init__(self, n ): self.tree = [0] * (4 * n) self.lazy = [0] * (4 * n) self.build(1,0,n-1) def build(self, cur, left, right): if left==right: self.tree[cur] = 0 return mid = (left + right) // 2 self.build(cur * 2, left, mid) self.build(cur * 2 + 1, mid + 1, right) self.pushup(cur) def pushup(self, root): self.tree[root] = max(self.tree[root * 2] , self.tree[root * 2 + 1]) def updateRange(self, cur, left, right, start, end, val): if left &lt;= start and end &lt;= right: self.tree[cur] = val if start != end: self.lazy[cur] = val return mid = (start + end) // 2 if self.lazy[cur] != 0: self.pushdown(cur, start, end, mid) if left &lt;= mid: self.updateRange(cur * 2, left, right, start, mid, val) if right &gt; mid: self.updateRange(cur * 2 + 1, left, right, mid + 1, end, val) self.pushup(cur) def pushdown(self, cur, start, end, mid): self.tree[cur * 2] = self.tree[cur] self.tree[cur * 2 + 1] = self.tree[cur] self.lazy[cur * 2] = self.lazy[cur] self.lazy[cur * 2 + 1] = self.lazy[cur] self.lazy[cur] = 0 def query(self, cur, left, right, start, end): if left &lt;= start and end &lt;= right: return self.tree[cur] mid = (start + end) // 2 ans = -1 if self.lazy[cur] != 0: self.pushdown(cur, start, end, mid) if left &lt;= mid: ans = max(self.query(cur * 2, left, right, start, mid), ans) if right &gt; mid: ans = max(self.query(cur * 2 + 1, left, right, mid + 1, end), ans) return ansclass Solution: # 离散化,原值-&gt;离散后的索引(值) def discrete(self,nums): num_set = set(nums) num_list = sorted(list(num_set)) return &#123;num: idx + 1 for idx, num in enumerate(num_list)&#125; def fallingSquares(self, positions: List[List[int]]) -&gt; List[int]: n = len(positions) arr = [0] * (2 * n) size = 0 for i in range(n): arr[i * 2] = positions[i][0] arr[i * 2 + 1] = positions[i][0] + positions[i][1] size = max(size, arr[i * 2 + 1]) arr_map = self.discrete(arr) st = SegTreeDiscrete(len(arr_map)) res = [] height = 0 max_height = 0 for i in range(n): l = arr_map[positions[i][0]] h = positions[i][1] r = arr_map[positions[i][0] + h] height = st.query(1, l, r-1 , 0, len(arr_map)-1) st.updateRange(1, l, r-1,0,len(arr_map)-1, height + h) max_height = max(max_height, height + h) res.append(max_height) return res 线段树动态开点模板 思想: 不能在程序开始时就完成初始线段树的构建，在区间查询或区间修改时，根据传入的区间信息来动态地创建结点 2276. 统计区间中的整数数目 715. Range 模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class Node: def __init__(self): self.leftChild = None self.rightChild = None self.val = 0 self.lazy = 0class SegTreeDynamicPointer: def __init__(self): self.root = Node() def pushup(self, curNode): curNode.val=curNode.leftChild.val+curNode.rightChild.val def AddNode(self, curNode): if curNode.leftChild == None: curNode.leftChild = Node() if curNode.rightChild == None: curNode.rightChild = Node() def pushdown(self, curNode, start, end, mid): curNode.leftChild.val = (mid - start + 1) curNode.rightChild.val = (end - mid) curNode.leftChild.lazy = curNode.lazy curNode.rightChild.lazy = curNode.lazy curNode.lazy = 0 # 区间更新 def updateRange(self, curNode, left, right, start, end, val): # 当前区间完全处于查询区间之内 if left &lt;= start and end &lt;= right: curNode.val = (end-start+1) if start != end: curNode.lazy = 1 return # 动态开点 self.AddNode(curNode) mid = (start + end) // 2 if curNode.lazy != 0: self.pushdown(curNode, start, end, mid) if left &lt;= mid: self.updateRange(curNode.leftChild, left, right, start, mid, val) if right &gt; mid: self.updateRange(curNode.rightChild, left, right, mid + 1, end, val) self.pushup(curNode) # 区间查询 def query(self, curNode, left, right, start, end): if left &lt;= start and end &lt;= right: return curNode.val self.AddNode(curNode) mid = (start + end) // 2 if curNode.lazy != 0: self.pushdown(curNode, start, end, mid) ans = 0 if left &lt;= mid: ans += self.query(curNode.leftChild, left, right, start, mid) if right &gt; mid: ans += self.query(curNode.rightChild, left, right, mid + 1, end) return int(ans)class CountIntervals: def __init__(self): self.tree=SegTreeDynamicPointer() self.N=1e9+1 self.node=self.tree.root self.max_num=0 def add(self, left: int, right: int) -&gt; None: self.max_num=max(self.max_num,right) self.tree.updateRange(self.node,left,right,0,self.N,1) def count(self) -&gt; int: return self.tree.query(self.node,0,self.max_num,0,self.N) 2023.12.17 使用最小花费爬楼梯[简单] 746. 使用最小花费爬楼梯 思路:简单动态规划,第一阶和第二阶应该是0 2023.12.18 寻找峰值[中等] 162. 寻找峰值 思路:单调栈从栈底到栈顶递增,栈底元素一定大于其左边元素,同时也大于栈中其他元素,因此答案就是栈底元素 2023.12.19 寻找峰值 II[中等] 1901. 寻找峰值 II 思路:一维的峰值扩展到二维,无思路 题解:二分,使用二分分行,然后找到每一行的最大值,用这一行的最大值和他的上下两行的值比较,如果上面的大则继续二分上面的行,否则二分下面的行 2023.12.20 判别首字母缩略词[简单] 2828. 判别首字母缩略词 思路:数组里面每个单次的首字符看看能不能组成这个单词,先判断两个长度是不是一样 2023.12.21 美丽塔 II[中等] 思路:暴力,两重循环,判断每个点的左右两边是否满足条件,但是肯定超时 题解:先预处理每个点左右两边,左边为例,用单调栈(从栈底到栈顶递增,存下标),如果当前元素比栈顶元素小,那么就弹出栈顶元素,直到栈顶元素大于当前元素,那么栈顶元素到当前元素之间的元素都是比当前元素大的,这区间只能选择当前元素的高度,然后再加上栈顶元素左边的高度和,得到了当前元素左边的高度和,右边的高度和同理,然后再遍历每个点,每个点的答案就是左边的高度和+右边的高度和-当前点的高度 12345# 预处理代码prefix[i]=(long)(i-left.Peek())*maxHeights[i]+prefix[left.Peek()];suffix[i]=(long)(right.Peek()-i)*maxHeights[i]+suffix[right.Peek()];# 答案代码res=Math.Max(suffix[i]-maxHeights[i]+prefix[i],res); 2023.12.22 得到山形数组的最少删除次数[困难] 最长递增子序列模板 动态规划O(N2)O(N^2)O(N2) 12345678def MaxSeqInN2(self,nums): n=len(nums) dp=[1]*(n) for i in range(n): for j in range(i): if nums[i]&gt;nums[j]: dp[i]=max(dp[i],dp[j]+1) return max(dp) 长度数组O(NlogN)O(NlogN)O(NlogN) 12345678910def MaxSeqInLogn(self,nums): n=len(nums) len2num=[float(&#x27;inf&#x27;)]*(n+1) len2num[0]=float(&#x27;-inf&#x27;) ans=-1 for i,num in enumerate(nums): lengthIndex=bisect_left(len2num,num) len2num[lengthIndex]=num ans=max(ans,lengthIndex) return ans 得到山形数组的最少删除次数 1671. 得到山形数组的最少删除次数 思路:以为和美丽塔 II一样,但是区别在于这一题需要左边的长度越长越好,美丽塔 II有个高度 题解:预处理每个点左右两边的最长递增子序列,遍历每个点,当前点的答案就是左边的最长递增子序列+右边的最长递增子序列-1(当前点被计算了两次) 2023.12.23 移除石子使总数最小[中等] 1962. 移除石子使总数最小 思路:贪心,用优先队列(最大堆),每次取堆顶的元素然后整除2再放回堆里,重复k次 2023.12.24 收集足够苹果的最小花园周长[中等] 1954. 收集足够苹果的最小花园周长 思路:两重循环遍历(x,y)的坐标 题解:找规律,计算出如何用n表示苹果的数量,然后二分找到n&gt;=neededApples的最小的n,然后计算出边长,公式为2n(n+1)(2n+1)2n(n+1)(2n+1)2n(n+1)(2n+1). 2023.12.25 不浪费原料的汉堡制作方案[中等] 1276. 不浪费原料的汉堡制作方案 思路:小的和巨无霸都只用一个奶酪片,枚举一个的数量,另一个就是奶酪片-枚举的数量,然后判断是否满足条件 题解:二元一次方程,解方程组 2023.12.26 😒参加考试的最大学生数[困难] 1349. 参加考试的最大学生数 位运算基础 参加考试的最大学生数 2023.12.27 保龄球游戏的获胜者[简单] 2660. 保龄球游戏的获胜者 思路:模拟,重要的是代码的复用 2023.12.28 收集巧克力[中等] 2735. 收集巧克力 思路:无思路,因为对当前节点每操作一次都会对后面的节点造成影响,无头绪 题解: 最多移动n-1次,因为移动n次就没动了,所以枚举移动次数(1,n-1),那么对于每个节点,他的选择就是移动或者不移动dp[i][k]=min(dp[i][k−1],nums[(i+k)%n])dp[i][k]=min(dp[i][k-1],nums[(i+k)\\%n])dp[i][k]=min(dp[i][k−1],nums[(i+k)%n]),答案就是当前移动次数的所有节点的总和ans=min(ans,k∗x+∑i=0n−1dp[i][k]ans=min(ans,k * x+\\sum_{i=0}^{n-1}dp[i][k]ans=min(ans,k∗x+∑i=0n−1​dp[i][k] 二次差分:看不懂 优化:二维dp之和k-1有关系,可以改成一维的 2023.12.29 购买两块巧克力[简单] 2706. 购买两块巧克力 2023.12.30 一周中的第几天[简单] 1185. 一周中的第几天 思路:模拟 题解:巧用语言中的库函数 2023.12.31 一年中的第几天[简单] 1154. 一年中的第几天 思路:模拟 题解:语言的类库多看看","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"Hexo博客新增菜单栏","slug":"配置-hexo新增菜单栏","date":"2023-12-11T06:27:08.586Z","updated":"2023-12-11T06:36:17.828Z","comments":true,"path":"2023/12/11/配置-hexo新增菜单栏/","link":"","permalink":"https://gladdduck.github.io/2023/12/11/%E9%85%8D%E7%BD%AE-hexo%E6%96%B0%E5%A2%9E%E8%8F%9C%E5%8D%95%E6%A0%8F/","excerpt":"","text":"1. 新增菜单栏 打开主题配置文件_config.yml 找到menu字段，新增菜单栏 12345678menu: Home: . Archives: archives # 归档 Categories: categories # 分类 Repository: repository # github repositories About: about # 关于 # 新增的菜单栏 Picture: picturewall # 图片墙 修改菜单栏对应的图标,具体的图标名称可以在主题的themes\\pure\\source\\css\\style.css中找到,是以icon-开头的类名. 但是看不到图标什么样,文件都在fonts文件夹里了 12345678910menu_icons: enable: true # 是否启用导航菜单图标 home: icon-home-fill archives: icon-archives-fill categories: icon-folder tags: icon-tags repository: icon-project books: icon-book-fill picture: icon-starfish about: icon-cup-fill 修改菜单栏的名称themes\\pure\\languages\\zh-CN.yml中修改: 1234567891011menu: Home: 首页 Archives: 归档 Categories: 分类 Tags: 标签 Repository: 项目 Books: 书单 Movies: 电影 Links: 友链 About: 关于 Picture: 图片墙 # 新增的 在source目录下新建picturewall文件夹,就是第一步中menu菜单对应的,并在该文件夹下新建index.md文件,内容如下: 1234567---title: 照片墙layout: xxxxcomments: falsesidebar: none---#layout可以设置为现有的布局,比如links,books这些,也可以直接把layout删掉 后续public/picturewall文件夹下的index.html就会根据这个index.md渲染 固定菜单栏的页面(如果这个页面不需要改动的话,可以设置为跳过渲染),在_config.yml中设置(这一段还没太搞明白): 12skip_render: - picturewall/index.html","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://gladdduck.github.io/tags/Hexo/"}],"author":"gladdduck"},{"title":"mmfewshot配置","slug":"配置-mmfewshot配置","date":"2023-12-10T07:46:36.918Z","updated":"2024-01-02T12:42:26.081Z","comments":true,"path":"2023/12/10/配置-mmfewshot配置/","link":"","permalink":"https://gladdduck.github.io/2023/12/10/%E9%85%8D%E7%BD%AE-mmfewshot%E9%85%8D%E7%BD%AE/","excerpt":"","text":"基配置础信息 1234567891011121314151617181920212223# 关于mmfewshot1. 配置时间:2023/12/102. mmfewshot版本: 0.1.0# 关于mmcv1. mmcv 2.x版本之前叫做mmcv-full2. mmcv 2.x版本之后改名--之前-- |--现在--mmcv-full | mmcvmmcv | mmcv-lite3. mmcv是2023年4月份才改名的,所以mmfewshot要安装mmcv-full这个名字# 关于mmdet1. mmdet 3.x版本之前的版本,mmdet/datasets/custome.py文件用到的numpy的一个方法是np.int,这个是numpy的1.20版本丢弃的,所以使用mmdet3.x之前的版本要安装numpy 1.20一下办的2. 使用mmdet3.x的版本会提示,mmcv版本过低,需要安装mmcv2.x版本(但是mmcv-full这个版本最高只能是1.x,所以无解(不知道理解的对不对)),意味着mmfewshot 0.1.0可能不支持mmdet3.x版本# 总之:mmcvmmdetmmfewshot这三个库之间的版本相互依赖,所以要安装对应的版本,否则会报错 安装 安装mmcv-full(如果已经有mmcv,需要把mmcv卸载) 123# 这个要加上-f参数,不然 MMCV CUDA Compiler: not available# MMCV CUDA Compiler: 10.1 是正确的pip install mmcv-full==1.5.0 -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.7.0/index.html 安装mmdet 1pip install mmdet==2.24.0 安装mmcls,这个库好像没有特别大的区别 1pip install mmcls==0.23.2 安装mmfewshot 12345# git下来之后进入mmfewshot目录pip install -r requirements/build.txtpip install -v -e . # or &quot;python setup.py develop&quot; 安装numpy 12345pip install numpy==1.19.5# matplotlib和pandas现在要求的最低的numpy版本是1.20.0,所以要安装旧版的pandas和matplotlib# 这两个版本是支持numpy1.19.5的pip install matplotlib==3.6.0pip install pandas==1.4.4 最后的版本 1234567mmcls 0.23.2mmcv-full 1.5.0mmdet 2.24.0mmfewshot 0.1.0 Pillow 8.4.0pandas 1.4.4matplotlib 3.6.0 ### 可能的报错 TypeError: FormatCode() got an unexpected keyword argument 'verify' Issue 安装yapf解决 1pip install yapf==0.40.1 RuntimeError: roi_align_forward_impl: implementation for device cuda:0 not found. 运行mmfewshot/utils/collect_env.py的文件,看看cuda是否可用,安装对应的cuda版本 参考上面 安装mmcv-full 1pip install mmcv -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.7.0/index.html 初始安装版本不对的报错 Issue 123456789101112131415161718192021222324252627282930313233343536373839===================================mmcls 0.25.0 https://github.com/open-mmlab/mmclassificationmmcv-lite 2.1.0 https://github.com/open-mmlab/mmcvmmdet 3.0.0 https://github.com/open-mmlab/mmdetectionmmengine 0.10.1 https://github.com/open-mmlab/mmengineGPU 0: Tesla V100-SXM2-32GB (UUID: GPU-828d98d3-ad2a-0a92-d4d9-0dac21a5439f)/public/home/zhaol/syxue20225227095/fewshotdetection/mmfewshot-mainTraceback (most recent call last): File &quot;tools/detection/train.py&quot;, line 12, in &lt;module&gt; from mmcv import Config, DictActionImportError: cannot import name &#x27;Config&#x27; from &#x27;mmcv&#x27; (/public/home/zhaol/anaconda3/envs/syxue2/lib/python3.8/site-packages/mmcv/__init__.py)===================================mmcls 0.25.0 https://github.com/open-mmlab/mmclassificationmmcv 2.1.0 https://github.com/open-mmlab/mmcvmmdet 3.2.0 https://github.com/open-mmlab/mmdetectionmmengine 0.10.1 https://github.com/open-mmlab/mmengineGPU 0: Tesla V100-SXM2-32GB (UUID: GPU-828d98d3-ad2a-0a92-d4d9-0dac21a5439f)/public/home/zhaol/syxue20225227095/fewshotdetection/mmfewshot-mainTraceback (most recent call last): File &quot;tools/detection/train.py&quot;, line 12, in &lt;module&gt; from mmcv import Config, DictActionImportError: cannot import name &#x27;Config&#x27; from &#x27;mmcv&#x27; (unknown location)===================================mmcls 0.25.0 https://github.com/open-mmlab/mmclassificationmmdet 3.0.0 https://github.com/open-mmlab/mmdetectionmmengine 0.10.1 https://github.com/open-mmlab/mmenginemmcv-full 1.7.1 https://github.com/open-mmlab/mmcvGPU 0: Tesla V100-SXM2-32GB (UUID: GPU-828d98d3-ad2a-0a92-d4d9-0dac21a5439f)/public/home/zhaol/syxue20225227095/fewshotdetection/mmfewshot-main/public/home/zhaol/anaconda3/envs/syxue2/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details. warnings.warn(Traceback (most recent call last): File &quot;tools/detection/train.py&quot;, line 15, in &lt;module&gt; from mmdet.utils import collect_env File &quot;/public/home/zhaol/anaconda3/envs/syxue2/lib/python3.8/site-packages/mmdet/__init__.py&quot;, line 16, in &lt;module&gt; assert (mmcv_version &gt;= digit_version(mmcv_minimum_version)AssertionError: MMCV==1.7.1 is used but incompatible. Please install mmcv&gt;=2.0.0rc4, &lt;2.1.0. RuntimeError: CUDA error: no kernel image is available for execution on the device 错误 安装的pytorch版本和cuda版本不对应 刚开始安装的pytorch 1.6.0 + cuda 10.1, 1pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117 第二次安装完成-增加xformers 123456789101112131415conda create -n mmfew python=3.9conda activate mmfewpip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113conda install linux-64_xformers-0.0.22-py39_cu11.6.2_pyt1.12.1.tar.bz2pip install mmcv-full==1.6.0 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.12/index.htmlpip install mmdet==2.24.0 mmcls==0.23.2cd mmfewshot-mainpip install -r requirements/build.txtpip install -v -e .pip install yapf==0.40.1pip install triton","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"mmfewshot","slug":"mmfewshot","permalink":"https://gladdduck.github.io/tags/mmfewshot/"}]},{"title":"Hexo博客参数记录","slug":"配置-Hexo博客参数记录","date":"2023-12-03T05:54:00.181Z","updated":"2023-12-03T06:05:39.077Z","comments":true,"path":"2023/12/03/配置-Hexo博客参数记录/","link":"","permalink":"https://gladdduck.github.io/2023/12/03/%E9%85%8D%E7%BD%AE-Hexo%E5%8D%9A%E5%AE%A2%E5%8F%82%E6%95%B0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"Hexo官网API 官网API 官网仓库 文章属性","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://gladdduck.github.io/tags/Hexo/"}],"author":"gladdduck"},{"title":"Few-shot Object Detection论文总结","slug":"学术-Few-shotDetection论文总结","date":"2023-11-24T12:54:49.892Z","updated":"2023-12-22T02:15:38.099Z","comments":true,"path":"2023/11/24/学术-Few-shotDetection论文总结/","link":"","permalink":"https://gladdduck.github.io/2023/11/24/%E5%AD%A6%E6%9C%AF-Few-shotDetection%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/","excerpt":"","text":"Few-shot Object Detection 综述 Few-Shot Object Detection: A Comprehensive Survey 问题定义:N-way K-shot表示使用K个样本来训练N个类别 和few-shot learning,semi-supervised learning,increamental learning的区别 使用到的技术:1)迁移学习2)度量学习3)元学习 Dual-Branch meta learning: 实现思路:一个Query Branch用来提取待检测图像的特征,然后通过RPN和一个RoI Align得到Query Feature,再和Support Feature提取出来的Support特征(K shot,K&gt;1取平均),进行Aggregation,然后送入RoI Head进行分类和回归. 聚合相关改进 Variant For Aggregation: 缺点:在RPN之后进行聚合,需要RPN为新类别生成Proposal,但是RPN可能无法为新类别生成Proposal 改进:在RPN之前进行聚合(AttentionRPN),然后将增强的特征送入RPN,生成Proposal 改进:使用second-order pooling替换avg pooling,减少Support Feature的颜色,条纹,斑点带来的噪声 Variant For Aggregation Operation 缺点:简单的channel-wise 乘法不能充分利用Query和Support的特征 改进:添加比例因子,使用卷积,利用更复杂的操作等 Keep Spatial Information for Aggregation 缺点:average pooling会丢失空间信息,convolution会导致空间信息不对齐 改进:attention-based aggregation Attention-base Aggregation Dual-Awareness Attention for Few-Shot Object Detection:增强前景,抑制背景并使用Query Feature Map促进空间位置的对齐 Object detection based on few-shot learning via instance-level feature correlation and aggregation:IFC module用于构造实例特征的相关性,ASA module增强查询和支持之间的特征灵敏度,减少冗余信息 Few-shot object detection with affinity relation reasoning:设计了一个亲和关系推理模块（ARRM）来促进支持特征和感兴趣区域特征的交互 One-Shot Object Detection with Co-Attention and Co-Excitation:使用非局部操作来探索每个查询-目标对中体现的共同注意,并且使用改进的SeNet分配候选区域的重要性 Adaptive Image Transformer for One-Shot Object Detection:将支持和查询作为Transformer的输入,来充分融合信息 Multi-Level Aggregation 缺点:只在特征抽取之后进行了一次聚合 改进:使用PVTv2(Pyramid Vision Transformer)在特征抽取的时候进行多次融合 Aggregation of Several Support Images 缺点:多个Support Image的情况下,对特征图取平均,忽略了不同的信息 改进:1)使用可学习的权重 2)使用softmax分配权重 Incorporate Relation between Caregories 缺点:基本类别可以帮助识别新的稀疏类 改进:1)融入语言特征 2)构建图关系(多类别关系增强特征,合并相似类别特征) 3)捕获类间相似性,增强泛化能力 Increase Discriminative power 缺点:1)在聚合之后,通常使用交叉熵损失判别分类,更好的方法是使用度量学习 2)元学习学习去区分前景和背景,这导致有可能检测到不存在的物体 改进:-1)GenDet和Meta DETR通过相似度矩阵最小化类间差异,最大化不同的支持向量 2)MM-FSOD使用皮尔斯系数聚合支持向量和查询向量 3)CME擦除最具辨别力的像素 -1)AttentionRPN使用多关系检测器来判断是否存有物体 2)对比学习测量用来区分不同的类别 3)GenDet使用额外的检测器检测基类,增强骨干网络提取更具代表性的特征 Improve representation capability 缺点:base categories被视为负类,导致识别新类的表达能力不足 改进:SPCN通过选择与基类不同的区域,并使用自监督的方式检测数据增强前后相同的非基类区域 Proposal-free Detector 缺点:许多方法基于Faster RCNN,1)可能生成不准确的区域建议框,2)决定在区域建议框之前还是之后进行聚合 改进:1)无提议框的模型更容易实现 2)基于YOLO 3)基于DETR Keep the Performance on Base Categories 缺点:学习新的类别之后,模型可能会导致灾难性遗忘 改进:1)Meta Faster R-CNN使用一个额外的branch预测base categories,在训练期间固定 2)Sylph每个类别使用独立的分类器 Increase the Variance of Novel Categories 缺点:直接应用数据增强效果不佳 改进:TIP使用additional transformed guidance consistency loss,使得变化前后的图像特征保持一致 Incorporate Context Information 缺点:在RoI pool或者RoI Align之后,可能导致丢失信息 改进:DCNet使用三种不同分辨率执行并行池化 Category-agnostic Bounding Box Regression Single-Branch meta learning: 用的太少,且精确度不高 Transfer Learning 略… Modifications of the Region Proposal Network Modifications of the Feature Pyramid Network Increase the Variance of Novel Categories Transfer Knowledge Between Base and Novel Categories Keep the Performance on Base Categories Modify the Training Objective Use Attention Modify Architecture 论文 1. (MetaYOLO,FSRW) Few-shot Object Detection via Feature Reweighting 思想: 一个元特征抽取模块(meta feature extractor:YOLOv2中的Darknet19),用来提取查询图像的元特征 一个特征重加权模块(feature reweighting module),将支持图像抽取出全局特征(class-specific representation),用于调整元特征的贡献,获得(理解为抽取出支持图像的特征然后和查询图像的特征做一个channel-wise的乘法,来形成一个reweighting的特征(class-specific features)). 另一个理解:把支持图像的特征抽取成一个权重参数,用这个参数来动态调整查询图中的特征贡献,得到一个新的class-specific features 将class-specific features送入YOLOv2的检测器中进行检测 输入是一个图形和二进制掩码,掩码只支持一个目标 训练: 基础训练阶段,正常目标检测训练,目的是让模型学会通过参考reweighting向量来检测感兴趣的预取 微调训练阶段,在基类和新类上训练模型,每个类K个support images, 模拟K-shot 损失函数中的分类损失,使用softmax之后的类别 补充 Deep Traffic 微信公众号:FSRW 2. (MetaRCNN) Meta R-CNN: Towards General Solver for Instance-Level Low-Shot Learning 思想: 查询集图片经过特征提取网络和RPN网络（与Faster/Mask R-CNN中相同）得到感兴趣区域的特征图ziz_izi​。 支持集图像和对应的真实标签图经过预测器重建模网络（Predictor-head Remodeling Network）得到每个类别对应的类别注意力向量（class-attentive vectors），PRN网络的主体部分与Faster/Mask R-CNN的特征提取网络结构相同且权重共享，得到对应特征图后,通过逐元素Sigmoid函数得到对应的注意力向量vcv_cvc​. 最后将RPN网络输出的感兴趣区域特征图zcz_czc​和PRN网络输出的注意力向量vcv_cvc​通过逐通道相乘的方式进行融合,再利用Faster/Mask R-CNN中预测头得到对应个检测图或分割图. 符号说明: 含义 含义 含义 含义 CbaseC_{base}Cbase​ 基类 CnovalC_{noval}Cnoval​ 新类 CmetaC_{meta}Cmeta​ 基类新类的混合 DtrainD_{train}Dtrain​ 训练数据 DmetaD_{meta}Dmeta​ 测试数据 h(⋅,θ)h(·,\\theta )h(⋅,θ) 原始预测头 h(⋅,Dmeta,θ)h(·,D_{meta},\\theta )h(⋅,Dmeta​,θ) 重建后的预测头 PRN: PRN从DmetaD_{meta}Dmeta​中推断类别注意向量vmeta=f(Dmeta;ϕ)\\mathbf{v}^{m e t a}=f\\left(D_{m e t a} ; \\phi\\right)vmeta=f(Dmeta​;ϕ). 具体而言,PRN输入的DmetaD_{meta}Dmeta​是一系列物体的图像,共CmetaC_{meta}Cmeta​个类别,每类KKK个样本,每个物体由RGB图像和前景掩码标记四个通道表示,经过一层卷积之后,送入共享参数的backbone,最后经过通道软注意力生成目标注意力向量v\\mathbf{v}v,经过平均池化得到类别注意向量vcmeta=1K∑j=1Kvk(c)\\mathbf{v}_{c}^{m e t a}=\\frac{1}{K} \\sum_{j=1}^{K} \\mathbf{v}_{k}^{(c)}vcmeta​=K1​∑j=1K​vk(c)​,将其与 RoI 特征(Z^i\\hat{\\mathbf{Z}}_{i}Z^i​)进行通道层级的点乘，将h(⋅,θ)h(·,\\theta )h(⋅,θ)转为h(⋅,Dmeta,θ)h(·,D_{meta},\\theta )h(⋅,Dmeta​,θ) $ h\\left(\\hat{\\mathbf{z}}{i, j}, D{\\text {meta }} ; \\boldsymbol{\\theta}^{\\prime}\\right) \\= h\\left(\\hat{\\mathbf{z}}{i, j} \\otimes \\mathbf{v}^{\\text {meta }}, \\boldsymbol{\\theta}\\right) \\=h\\left(\\hat{\\mathbf{z}}{i, j} \\otimes f\\left(D_{\\text {meta }} ; \\boldsymbol{\\phi}\\right), \\boldsymbol{\\theta}\\right) $ 关键点: Mini-batch construction: 一个训练的mini-batch包含 m个类CmetaC_{meta}Cmeta​,K-shot m-class的meta-set DmetaD_{meta}Dmeta​ (测试数据), m个类的训练数据 DtrainD_{train}Dtrain​. DtrainD_{train}Dtrain​就是Faster RCNN的输入对象. Channel-wise soft-attention layer 执行空间池化来对齐图像特征,保持相同大小的Roi特征(z^i,j\\hat{z}_{i,j}z^i,j​),特征经过逐元素的 sigmoid 以产生注意力向量 Meta-loss 不同类对象的注意向量应该导致对Roi特征的不同选择,为此提出一个Meta−lossMeta-lossMeta−loss,使元学习中推断的对象注意力向量多样化。通过交叉熵损失实现的，鼓励对象注意力向量落在每个对象所属的类中 Roi meta-learning 训练分为两部分,1. meta-train:只使用基类对象构建 2.meta-test:使用基类和新类对象构建 inference 训练时的object attentive vectors将替换class-attentive vectors,用于在Roi特征上作用sotf-attention 在测试时,PRN接受K-shot来生成class-attentive vectors,然后用于Roi特征上的soft-attention.但是测试时,class-attentive vectors可以提取预处理,然后用于Roi特征上的soft-attention. 补充 Deep Traffic 微信公众号:Meta-RCNN 补充 3. (AttentionRPF) Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector 思想: Attention-RPN:通过注意力机制向 RPN 引入支持信息来指导 RPN 产生相关的候选框,抑制其他类别的候选框.将support feature变成S×S×CS×S×CS×S×C的向量(作者发现s=1效果最好,就是1×1的卷积核),然后在query feature上进行卷积,建立注意力map(这种卷积其本质是按通道的点积，可以视为求余弦相似度的过程),然后将这个注意力map经过一个卷积送到RPN中. Multi-Relation Detector:测量来自查询和支持对象的提议框之间的相似性,分类三个(全局关联，局部关联，以及patch关联);最终得到的是支持对象和候选框直接的匹配得分(matching score). 对比实验,提出相同类别的对象重要,不同类别的对象更重要.构建了一个三元组(查询对象类比,支持对象类别,支持对象其他类别),来增强模型对前景和背景的区分能力. 解决: RPN对novel class的提议不好 现有的模型都需要fine-tune Deep Traffic 微信公众号:Attention-RPN 4. (MetaDETR) Meta-DETR: Image-Level Few-Shot Object Detection with Inter-Class Correlation Exploitation 问题: 低质量的新类区域建议 单次推理只能检测一个类,忽略了不同类的类间相关性 思想: 共享的特征抽取器把查询图像和支持图像提取到相同的特征空间中 通过相关聚合模块(CAM)执行查询和支持直接的匹配，CAM进一步把支持类映射到一组预定义的任务编码中,这些任务编码以类无关的方式区分支持类 最后,通过transformer架构(Deformable-DETR)预测对象位置和相应任务编码 关键点: Feature Matching:通过稍微修改注意力机制实现特征匹配,旨在过滤掉与支持类无关的特征; A=Attn⁡(Q,S)=Softmax⁡((QW)(SW)Td),\\mathbf{A}=\\operatorname{Attn}(\\mathbf{Q}, \\mathbf{S})=\\operatorname{Softmax}\\left(\\frac{(\\mathbf{Q W})(\\mathbf{S W})^{\\mathrm{T}}}{\\sqrt{d}}\\right),A=Attn(Q,S)=Softmax(d​(QW)(SW)T​), QF=Aσ(S)⊙Q\\mathbf{Q}_{\\mathbf{F}}=\\mathbf{A} \\sigma(\\mathbf{S}) \\odot \\mathbf{Q}QF​=Aσ(S)⊙Q Encoding Matching:为了实现相关元学习，给每个支持类的预定义任务编码，并将查询特征与其对应的任务编码进行匹配，以便可以对任务编码而不是特定类进行最终预测。 此处的任务编码就是Transformer中的正弦函数位置编码 QE=ATQ_E=\\mathbf{A}\\mathbf{T}QE​=AT Modeling Background for Open-Set Prediction,给背景一个支持占位和任务编码 训练: 给定一个查询图像，随机抽取代表不同支持类的K张支持图像。只保留属于采样支持类的Ground Truth真实标注框作为检测目标。此外，每个对象的分类目标是真是标注类的任务编码，而不是真实标注类本身。 标注类转任务编码:χ(si)=i,i∈{1,2,⋯ ,C}\\chi\\left(s_{i}\\right)=i, \\quad i \\in\\{1,2, \\cdots, C\\}χ(si​)=i,i∈{1,2,⋯,C},具体实现不重要… 最终的任务是:将目标类的标签映射到相应任务编码的标签 代码: Meta-DETR 理解: 作者没有把CAM单独抽取出来一个模块(找不到命名为CAM的模块),而是继承DeformableDETR,整个模型就是一个DeformableDETR,CAM就是DeformableDETR的Encoder的第一个层,(就是 DeformableTransformermodel中的第一个 TransformerEncoderLayer) CAM的实现核心代码: 1234567891011121314151617181920# CAM中# Multi-Head Attentionsrc2 = self.self_attn(self.with_pos_embed(src, pos), reference_points, src, spatial_shapes, level_start_index, padding_mask)src = src + self.dropout1(src2)src = self.norm1(src)# Single-Head Attentionsrc, tsp = self.siamese_attn(src, inverse_sigmoid(category_codes), category_codes, tsp)# FFNsrc = self.forward_ffn(src + tsp)# Single-Head Attention中# q是query, k是Sigmoid(support), v是support# output是QF,tsp是QE# 这个地方感觉和论文中的公式不一样# 这里A=Attn(Q,Sigmoid(S))# 文章里A=Attn(Q,S)output, attn, log_attn = self.attention(q, k, v)tsp, _, _ = self.attention(q, k, tsp) 5. (TFA) Frustratingly Simple Few-Shot Object Detection 微调方法: 使用Faster RCNN作为检测器,第一阶段正常训练 在新类上微调时,只微调分类器,前面的固定,并且分类器改为cosine similarity classifier si,j=αF(x)i⊤wj∥F(x)i∥∥wj∥s_{i, j}=\\frac{\\alpha \\mathcal{F}(x)_{i}^{\\top} w_{j}}{\\left\\|\\mathcal{F}(x)_{i}\\right\\|\\left\\|w_{j}\\right\\|}si,j​=∥F(x)i​∥∥wj​∥αF(x)i⊤​wj​​ si,js_{i,j}si,j​代表了第iii个区域建议框和第jjj个类别的相似度 6. (MetaDet) Meta-Learning to Detect Rare Objects 思想: 和5.Frustratingly Simple Few-Shot Object Detection 有共同的发现 根据CNN的研究,模型分为两部分,1)类别无关(CNN底层) 2)类别相关(CNN顶层) 类别无关的部分可以直接迁移到新类上(参数共享),类别相关的部分使用一个元参数预测类别相关部分的模型 Weight Prediction Meta-Model 从大批量数据中学习到的参数为wdetc,∗w_{det}^{c,*}wdetc,∗​,从k-shot样本中学习到的参数是wdetcw_{det}^{c}wdetc​,mete-model T的任务是: wdetc,∗=T(wdetc,θT)w_{det}^{c,*}=T\\left(w_{det}^{c}, \\theta_{T}\\right)wdetc,∗​=T(wdetc​,θT​),使用L2L2L2损失函数 7. (CoAttention) One-Shot Object Detection with Co-Attention and Co-Excitation 思想: 通过非局部操作(每个点的计算都考虑到全图其他点的相似度)来探索每个查询-目标对中体现的共同注意(为了丰富RPN对novel class的提议,与query image提供的类别参考具有外观相似性的RoIs), $ F(I)=\\phi(I) \\oplus \\psi(I ; p) \\in \\mathbb{R}^{N \\times W_{I} \\times H_{I}} \\quad for target image, I F(p)=\\phi(p) \\oplus \\psi(p ; I) \\in \\mathbb{R}^{N \\times W_{p} \\times H_{p}} \\quad for image patch, p , \\phi(I)表示抽取出的特征,表示抽取出的特征,表示抽取出的特征,\\psi(I ; p)$代表non-local操作 利用Squeeze and co-excitation(SCE模块)自适应地重新加权 N 个通道上的重要性分布来灵活地匹配候选提议(强调那些在评估相似性度量方面起着至关重要的作用的特征通道). 首先对支持特征做全局平均池化,得到一个向量,用这个向量调整支持特征和查询特征的权重. 候选框排名,将RoI(RPN提供的128个候选框)与支持特征Concat,然后对每个候选框进行分类(分为前景和背景,标签根据与真实框的关系(IoU&gt;0.5)得到).为了与支持特征最相关的候选框排在前面. 关键点: 增强RPN对novel class的提议 通道注意力 8. (FSDetView) Few-Shot Object Detection and Viewpoint Estimation for Objects in the Wild. Viewpoint Estimation和少样本检测的结合,忽略Viewpoint Estimation,只看Few-Shot Object Detection 思想: 一个稍微复杂点的聚合模块,其他和Meta R-CNN类似,Meta RCNN 和Meta Yolo中的聚合: A(fqry,fcls)=fqry⊙fcls,\\mathcal{A}\\left(\\mathrm{f}^{\\mathrm{qry}}, \\mathrm{f}^{\\mathrm{cls}}\\right)=\\mathrm{f}^{\\mathrm{qry}} \\odot \\mathrm{f}^{\\mathrm{cls}},A(fqry,fcls)=fqry⊙fcls, 本文提出的聚合: A(fqry,fcls)=[fqry⊙fcls,fqry−fcls,fqry],\\mathcal{A}\\left(\\mathrm{f}^{\\mathrm{qry}}, \\mathrm{f}^{\\mathrm{cls}}\\right)=\\left[\\mathrm{f}^{\\mathrm{qry}} \\odot \\mathrm{f}^{\\mathrm{cls}}, \\mathrm{f}^{\\mathrm{qry}}-\\mathrm{f}^{\\mathrm{cls}}, \\mathrm{f}^{\\mathrm{qry}}\\right],A(fqry,fcls)=[fqry⊙fcls,fqry−fcls,fqry], fqry−fcls\\mathrm{f}^{\\mathrm{qry}}-\\mathrm{f}^{\\mathrm{cls}}fqry−fcls,特征减法衡量图像特征之间的相似性,嵌入fqry\\mathrm{f}^{\\mathrm{qry}}fqry本身，没有任何重新加权，也包含相关信息. 9. (MetaFasterRCNN) Meta Faster R-CNN: Towards Accurate Few-Shot Object Detection with Attentive Feature Alignment. 问题: RPN对novel class的提议不好 novel class的候选框和支持特征中的对象位置不对齐 思想: 对Base Class训练一个单独的Faster RCNN用来检测 提出Meta-RPN module,用于增强RPN对novel class的提议 首先对支持特征对查询特征进行卷积然后生成锚框,对支持特征进行spatial average pool得到和锚框大小一样的特征(多个查询图形取平均),然后送入Meta-RPN module,就是图三中左边上下两个特征图. fqc=[ΦMult (fq⊙fpool c),ΦSub (fq−fpool c),ΦCat [fq,fpool c]]f_{q}^{c}=\\left[\\Phi_{\\text {Mult }}\\left(f_{q} \\odot f_{\\text {pool }}^{c}\\right), \\Phi_{\\text {Sub }}\\left(f_{q}-f_{\\text {pool }}^{c}\\right), \\Phi_{\\text {Cat }}\\left[f_{q}, f_{\\text {pool }}^{c}\\right]\\right]fqc​=[ΦMult ​(fq​⊙fpool c​),ΦSub ​(fq​−fpool c​),ΦCat ​[fq​,fpool c​]] Feature Fusion的公式,Based on 8.Few-Shot Object Detection and Viewpoint Estimation for Objects in the Wild. 使用高分辨率的支持特征来计算和候选框直接的相似度,但是候选框和支持特征中的对象位置不对齐,所以基于注意力的特征对齐方法来解决空间错位问题. (Spatial Alignment)首先通过计算亲和矩阵来建立两个输入特征之间的软对应关系(每个像素点之间的关系,矩阵大小为HW×HWHW×HWHW×HW),然后计算每个像素点之间的相似度: A(i,j)′=exp⁡(A(i,j))∑kexp⁡(A(i,k))A(i, j)^{\\prime}=\\frac{\\exp (A(i, j))}{\\sum_{k} \\exp (A(i, k))}A(i,j)′=∑k​exp(A(i,k))exp(A(i,j))​ 然后每个空间位置i就通过聚合类原型中所有位置的嵌入来计算: fˉc(i)=∑jA(i,j)′f^c(j)\\bar{f}^{c}(i)=\\sum_{j} A(i, j)^{\\prime} \\hat{f}^{c}(j)fˉ​c(i)=∑j​A(i,j)′f^​c(j) (Foreground Attention Module)生成一个Attention mask来抑制背景,增强前景.候选框中的每个像素i与每个空间位置的相似度: M(i)=σ(∑jA(i,j))=11+exp⁡(−∑jA(i,j))M(i)=\\sigma\\left(\\sum_{j} A(i, j)\\right)=\\frac{1}{1+\\exp \\left(-\\sum_{j} A(i, j)\\right)}M(i)=σ(∑j​A(i,j))=1+exp(−∑j​A(i,j))1​ 其中 M 中的较高值表示候选框中的对应位置更类似于对齐原型类的位置，并且更有可能是相同的语义部分。背景区域很难在类原型中找到相似度较高的位置，导致M中的值较低,最后将M和fˉc\\bar{f}^{c}fˉ​c相乘,再通过类似残差连接的一个可学习参数,得到最终的特征: (Non-linear Classifier Module)为了衡量最终的候选框和支持类之间的相似性,使用特征融合网络来聚合两个高分辨率的特征， f=[ΨMult(f~c⊙f~p),ΨSub(f~c−f~p),ΨCat[f~c,f~p]]f=\\left[\\Psi_{M u l t}\\left(\\widetilde{f}^{c} \\odot \\widetilde{f}_{p}\\right), \\Psi_{S u b}\\left(\\widetilde{f}^{c}-\\widetilde{f}_{p}\\right), \\Psi_{C a t}\\left[\\widetilde{f}^{c}, \\widetilde{f}_{p}\\right]\\right]f=[ΨMult​(f​c⊙f​p​),ΨSub​(f​c−f​p​),ΨCat​[f​c,f​p​]] 然后将fff送入预测类和框的层 训练: 使用base class进行元学习,不需要微调就可以应用到novel class上 训练完之后,用novel class+base class的数据进行微调(这不作弊吗?) 10. (FSCE) FSCE: Few-Shot Object Detection via Contrastive Proposal Encoding 问题: transfer learning的方法通常精确度高 精确度的退化主要来自将新实例错误分类为易混淆的类,定位基本准确(现有模型并没有学习到一个好的类别特征嵌入) 思想: 减小类内方差,增大类间方差,使用对比学习(To learn instance-level discriminative feature representations, contrastive learning has demonstrated its effectiveness in tasks including recognition, identification and the recent successful self-supervised models. ) RPN推荐的novel class只有base class的四分之一 在NMS（非极大值抑制）之后保留的提议数量×2。这样的话，能够为后续提供更多可能包含前景的提议 将RoI头中用于计算损失的候选框减少一半,因为一半多的候选框都包含的是背景(提升前景框的比例) 对比提议编码（ Contrastive Proposal Encoding） RoI features因为有Relu激活,部分为0,所以用一个FC层来编码,获取到128维的对比特征 使用余弦相似度计算候选框之间的相似度,并优化对比目标使得类间方差大,类内方差小 Contrastive Proposal Encoding (CPE) Loss $\\mathcal{L}{C P E}=\\frac{1}{N} \\sum{i=1}^{N} f\\left(u_{i}\\right) \\cdot L_{z_{i}} L_{z_{i}}=\\frac{-1}{N_{y_{i}}-1} \\sum_{j=1, j \\neq i}^{N} \\mathbb{I}\\left{y_{i}=y_{j}\\right} \\cdot \\log \\frac{\\exp \\left(\\tilde{z_{i}} \\cdot \\tilde{z_{j}} / \\tau\\right)}{\\sum_{k=1}^{N} \\mathbb{I}{k \\neq i} \\cdot \\exp \\left(\\tilde{z{i}} \\cdot \\tilde{z_{k}} / \\tau\\right)} z_i是对比特征,是对比特征,是对比特征,y_i是类别,是类别,是类别,u_i是与真实框的IoU分数,是与真实框的IoU分数,是与真实框的IoU分数,N_y是类别y的样本数量,是类别y的样本数量, 是类别y的样本数量,f\\left(u_{i}\\right)作用是为质量不同的预测框赋予不同的权重,实验证明常量更好上述公式中衡量了特征作用是为质量不同的预测框赋予不同的权重,实验证明常量更好 上述公式中衡量了特征作用是为质量不同的预测框赋予不同的权重,实验证明常量更好上述公式中衡量了特征z_i和和和\\tilde{z_{i}}之间的余弦相似度。当两个RoI（之间的余弦相似度。当两个RoI（之间的余弦相似度。当两个RoI（i和和和j$）为相同类别时，其相似度越高，该损失的值就越小，这将引导相同类别的特征嵌入在学习过程中变得更紧凑，而不同类别的特征嵌入将变得更分散， 11. (AFDNet) AFD-Net: Adaptive Fully-Dual Network for Few-Shot Object Detection 问题: 在目标检测中,分类和定位是完全不同的两个子任务,使用相同的特征进行这两个任务不好 思想: 提出了Adaptive Fully-Dual Network(AFD-Net,自适应全双网络),将分类和定位解耦 查询图像使用双询问编码（Dual Query Encoder，DQE）输出用于分类和定位的查询他特征 支持图像使用双注意力生成（Dual Attention Generator，DAG）输出用于分类和定位的类被注意(支持)特征 用于分类和定位的查询特征和支持特征分别送入双聚合器（Dual Aggregator，DA）用于分类和定位 Dual Attention Generator比Dual Query Encoder多了一个Max Pool来保证支持特征的大小和查询特征的大小一致 分类分支使用卷积处理,回归任务使用全连接处理,最后各乘一个可学习的权重,concat在一起 Dual Aggregator的聚合方式和8.(FSDetView) Few-Shot Object Detection and Viewpoint Estimation for Objects in the Wild.一样 12. (DeFRCN) DeFRCN: Decoupled Faster R-CNN for Few-Shot Object Detection 问题: multi-stage (RPN vs. RCNN) RPN应该是类无关的 RCNN应该是类相关的 但是二者共用一个backbone,梯度会回流到backbone带来冲突 通过梯度调整三个模块(backbone,RPN,RCNN)之间的解耦程度来缓解整个模型不被其中一个支配 multi-task (classification vs. localization). 分类任务需要平移不变性,而定位任务对位置敏感 在分类分支上使用一个有效的分数校准模块来实现解耦两个任务 思想: 在RPN,RCNN和backbone之间引入GDL,使用一个decoupling coefficient λ\\lambdaλ来控制梯度的流动,从而减少不同模块之间的相互影响, G(A,λ)(x)=A(x)\\mathbb{G}_{(\\mathcal{A}, \\lambda)}(x) =\\mathcal{A}(x)G(A,λ)​(x)=A(x) dG(A,λ)dx=λ∇A\\frac{\\mathrm{d} \\mathbb{G}_{(\\mathcal{A}, \\lambda)}}{\\mathrm{d} x} =\\lambda \\nabla_{\\mathcal{A}}dxdG(A,λ)​​=λ∇A​ λ\\lambdaλ有三种可能,分开讨论 PCB由一个预训练模型，一个ROIAlign层和一个分类器组成.首先从支持集中提取特征 ,然后使用RoIAlign与GroundTruth生成MK个实例,然后对k个实例的特征取平均,得到m个类别原型pcp_cpc​. 然后给定y^\\hat{y}y^​(由检测器得到),利用预测出来的框,使用RoIAlign对齐,得到预测特征,计算预测特征xix_ixi​和类原型pcp_cpc​之间的相似度分数sicoss_i^{cos}sicos​,最后的预测类别得分为: si‡=α⋅si+(1−α)⋅sicos⁡s_{i}^{\\ddagger}=\\alpha \\cdot s_{i}+(1-\\alpha) \\cdot s_{i}^{\\cos }si‡​=α⋅si​+(1−α)⋅sicos​ 13. (FCT) Few-Shot Object Detection with Fully Cross-Transformer 问题: 之前的工作,支持分支和查询分支的交互仅限于在检测头,剩余的几百个层的特征都是独立的, 思想: backbone中的Cross-Transformer之前 在送入之前,把图像分成4×4×34×4×34×4×3大小的patches.然后展平扩展通道数为C1C_1C1​ 加上位置编码,和批次编码之后(Xq′=Xq+Eqpos+Ebra[0],Xs′=Xs+Espos+Ebra[1]X_{q}^{\\prime}=X_{q}+\\mathbf{E}_{q}^{p o s}+\\mathbf{E}^{b r a}[0], X_{s}^{\\prime}=X_{s}+\\mathbf{E}_{s}^{p o s}+\\mathbf{E}^{b r a}[1]Xq′​=Xq​+Eqpos​+Ebra[0],Xs′​=Xs​+Espos​+Ebra[1]),再经过映射得到KVQ(为了减少计算量,使用了空间缩减) The Asymmetric-Batched Cross-Attention,非对称批处理交叉注意 支持图像通常大于1,且不固定,这个模块一次计算查询图像与同一类的所有支持图像之间的注意。 对支持图像进行平均池化,使得匹配查询分支的批量大小 对查询图像进行重复,使得匹配支持分支的批量大小 聚合之后做多头注意力+MLP The Cross-Transformer Detection Head用于在最终检测之前联合提取建议和支持图像的RoI特征 从支持分支提取出100个候选框取平均,只有一个 从查询分支提取出100个候选框 使用3.Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector中的两两匹配方法进行预测 14. (DeDETR) Decoupled DETR For Few-shot Object Detection 问题: FasterRCNN存在定位准确,分类不准确的问题,DETR同样存在(因为极端样本不平衡导致参数优化中数据丰富的类的旧知识占主导地位，这意味着模型总是对数据丰富的类有一定的偏向。) 解码器只会使用编码器最后一层的输出作为输入,但是编码器到解码器是一个从浅到深再回到浅的过程,所以浅编码器可能会更好地匹配浅解码器 不仅解码器的最后一层能产生正确的预测结果，解码器中间层的输出有时也能产生更好的预测结果。 思想: Decoupled prompts (DePrompt): 来自新类的少数样本很难将像 DETR 这样的大型模型推向合适的最优值,因此为新类和基类分配单独的权重集 分别为base class 和novel class构建独立的deformable selfattention modules,DePrompt的输出作为编码器的输入,DePrompt的输出由公式决定(w的三种设置) fDePrompt (x)=w∗fbpmt(x)+(1−w)∗fnpmt(x)f_{\\text {DePrompt }}(x)=w * f_{b_{p m t}}(x)+(1-w) * f_{n_{p m t}}(x)fDePrompt ​(x)=w∗fbpmt​​(x)+(1−w)∗fnpmt​​(x) 编码器和解码器之间的Skip connection,有两种方式 可学习的连接,每一层解码器的输入都有前面所有编码器层的输出乘可学习的权重矩阵得到 Mem_newj=∑ii=6Aij∗Men_oriiMem\\_new^j=\\sum_{i}^{i=6} A_{i j} * Men\\_ori^iMem_newj=∑ii=6​Aij​∗Men_orii 软连接,每一层解码器的输入都有前面对应的6−j6-j6−j层和最后一层编码器的输出得到 Mem_newj=A∗Mem_ori{6}+(1−A)∗Mem−ori{i}Mem\\_new^j=A * M e m \\_o r i^{\\{6\\}}+(1-A) * M e m_{-} o r i^{\\{i\\}}Mem_newj=A∗Mem_ori{6}+(1−A)∗Mem−​ori{i} Adaptive decoder selection来解决5个中间层解码器的输出可能比最后一层获得更好的检测结果 Dec_new=∑jj=6Bj∗Dec_orijDec\\_new =\\sum_{j}^{j=6} B_{j} * Dec\\_ori^jDec_new=∑jj=6​Bj​∗Dec_orij 用可学习的参数动态调整每个层输出的权重 15. (FSRC) Few-shot Object Detection with Refined Contrastive Learning 问题: 各个类别的检测精度的标准差很大,表明模型对不同类别的检测能力差异很大 思想: 1.在RoiPool前都和FasterRCNN一样,不同的地方在于加上了RCL模块 2. 使用细粒度的对比学习增强学习能力(和10.FSCE: Few-Shot Object Detection via Contrastive Proposal Encoding的区别在于FSCE把所有的类(前景和背景)都考虑进去进行对比),本文先把类间距小的类(相似类)挑出来,然后在这些Resemblance Group中使用对比学习 3. 找到相似类对 需要IoU和真实框大于阈值,并且分类错误 当一个相似类对出现的次数超过某个阈值后,把这些相似类对中的类都记录下来,作为一个Resemblance Group 只有当预测的类别或者真实的类别属于Resemblance Group中的类时,才会进行对比学习 这个测量应该在训练过程中使用,因为在刚开始的时候,模型倾向于基类 损失函数 LRCL=1NRCL∑i=1NRCLw(ui)⋅LziL_{R C L}=\\frac{1}{N_{R C L}} \\sum_{i=1}^{N_{R C L}} w\\left(u_{i}\\right) \\cdot L_{z_{i}}LRCL​=NRCL​1​∑i=1NRCL​​w(ui​)⋅Lzi​​ NRCL=Nall,Ic&lt;ImN_{R C L} = N_{a l l}, I_{c}&lt;I_{m}NRCL​=Nall​,Ic​&lt;Im​. NRCL=NGR,Ic⩾ImN_{R C L} = N_{G_{R}}, I_{c} \\geqslant I_{m}NRCL​=NGR​​,Ic​⩾Im​. Lzi=−1Nyi−1∑j=1,j≠iNI{yi=yj}⋅log⁡ezi~⋅zj/τ~∑k=1NIk≠i⋅ezi~⋅zk~/τL_{z_{i}}=\\frac{-1}{N_{y_{i}}-1} \\sum_{j=1, j \\neq i}^{N} I\\left\\{y_{i}=y_{j}\\right\\} \\cdot \\log \\frac{e^{\\tilde{z_{i}} \\cdot \\tilde{z_{j} / \\tau}}}{\\sum_{k=1}^{N} I_{k \\neq i} \\cdot e^{\\tilde{z_{i}} \\cdot \\tilde{z_{k}} / \\tau}}Lzi​​=Nyi​​−1−1​∑j=1,j=iN​I{yi​=yj​}⋅log∑k=1N​Ik=i​⋅ezi​~​⋅zk​~​/τezi​~​⋅zj​/τ~​​ 16. (ECEA) ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection 问题: 很少考虑到局部到全局的定位(kshot样本可能只能提供novel class的一部分,比如只有狗头,但是要检测出狗身子) Related Work值得借鉴 思想: 提出了一个Extensible Co-Existing Attention(ECEA)模块，使模型能够根据局部部分推断全局对象。本质上，该模型在具有丰富样本的基本阶段不断学习可扩展的能力，并将其转移到新的阶段，可以帮助少镜头模型快速适应将局部区域扩展到共存区域。 使用ResNet101的后三层构建多尺度模块经过特征融合之后送到ECEA模块中 将特征图划分为一系列patch,表示为xqx_qxq​,每个patch利用deformable cnn来获得N个extensible regions,…看不懂了 EA⁡(xq)=∑n=1NexqWq⋅(xqWnk)T∑n=1NexqWq⋅(xqWnk)T⋅xqWnv,\\operatorname{EA}\\left(x_{q}\\right)=\\sum_{n=1}^{N} \\frac{e^{x_{q} W^{q} \\cdot\\left(x_{q} W_{n}^{k}\\right)^{T}}}{\\sum_{n=1}^{N} e^{x_{q} W^{q} \\cdot\\left(x_{q} W_{n}^{k}\\right)^{T}}} \\cdot x_{q} W_{n}^{v},EA(xq​)=∑n=1N​∑n=1N​exq​Wq⋅(xq​Wnk​)Texq​Wq⋅(xq​Wnk​)T​⋅xq​Wnv​, (类似与:一个patch经过WWW得到K,V,QK,V,QK,V,Q,然后和其他patch计算相似度,然后和其他patch的VVV相乘,得到最终的特征) 补充3: Extensible Liner (应该是Deformable 实现)学习到N个可扩展区域的位置和形状,然后和当前的区域进行点积运算,得到相似度分数,然后在和另一个Extensible Liner学习到N个可扩展区域VVV相乘,得到最终的特征(也是K,V,QK,V,QK,V,Q的形式,但是K,VK,VK,V中包含了N个相关的扩展区域?) 构建了级联的多头多层的Extensible Module,扩展的区域更大,视野更大,更能获得对象的定位 MHEA⁡(x)=∑m=1MWmEA⁡(x)\\operatorname{MHEA}(x)=\\sum_{m=1}^{M} W_{m} \\operatorname{EA}(x)MHEA(x)=∑m=1M​Wm​EA(x) 17. (VFA) Few-Shot Object Detection via Variational Feature Aggregation 问题: class-specific aggregation和class-agnostic aggregation的区别没看懂,没看出来带来什么影响 因为novel class的样本太少了,样本间的方差太大,预测结果和样本的质量关系很大 思想: 使用class-agnostic aggregation聚合,即在训练时随机挑选一个支持类和查询的RoIfeature进行聚合得到聚合特征 使用Variational Feature Aggregation(VFA),先将支持特征转为分布,然后从分布中采样出特征.由于分布不特定于特定的示例,所以方差具有鲁棒性 18. (BCYOLO) Bi-path Combination YOLO for Real-time Few-shot Object Detection 问题: 提高模型的检测速度,为了保持较高的推理速度和可接受的检测精度 提升 transfer learning的泛化能力 思想: 提出了一种双路径组合YOLO（BCYOLO）模型,即base class一个路径,novel class一个路径,novel class的路径由base class蒸馏得到 提出一种Attentive DropBlock模块(基于 DropBlock:卷积的dropout可能会根据周围像素点构建出来,因此作用不大,dropblock丢弃的是连续区域),该算法不仅受保持概率和块大小的参数的影响，还受对象语义特征的影响。 19. (CoRPN) Cooperating RPN’s Improve Few-Shot Object Detection 问题: RPN对新类的提议不好,RPN 必须尽可能报告尽可能多的高 IOU 框，否则分类器将太弱而无法建模外观出现变化的新类。不能简单地报告大量框来逃避这种影响，因为这样做将需要分类器非常擅长拒绝误报。 思想: 训练多个RPN,这些RPN应该是不同的,但是合作的 应该选用哪个RPN(不能单单选择分数最高的,其他的没用了): 对框i的所有评分取sigmoid,把接近[0,1]的取出来,只有被选择的框才获取到梯度 多样性: N个RPN和M个锚候选框,构建一个矩阵,最大化矩阵的秩 协同(防止有RPN一直拒绝任何前景框): Lcoop i,j:=max⁡{0,ϕ−fij}\\mathcal{L}_{\\text {coop }}^{i, j}:=\\max \\left\\{0, \\phi-f_{i}^{j}\\right\\}Lcoop i,j​:=max{0,ϕ−fij​},ϕ−fij\\phi-f_{i}^{j}ϕ−fij​充当每个 RPN 分配给前景框的概率的下限。如果 RPN 的响应低于 φ，则 RPN 将受到惩罚。 19. ★(DEVit) Detect Every Thing with Few Examples 应用 总结 发表时间 meta-learning or fine-turning 解决的问题 使用的方法","categories":[{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Few-shotObjectDetection","slug":"Few-shotObjectDetection","permalink":"https://gladdduck.github.io/tags/Few-shotObjectDetection/"}]},{"title":"C#学习中的小知识点","slug":"笔记-C#知识点","date":"2023-11-24T12:54:49.890Z","updated":"2023-11-24T09:14:47.621Z","comments":true,"path":"2023/11/24/笔记-C#知识点/","link":"","permalink":"https://gladdduck.github.io/2023/11/24/%E7%AC%94%E8%AE%B0-C#%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"字符串前面的字符 123456//正常字符串 类似python中的&#x27;&#x27;string one = &quot;\\\\&quot;;//模板字符串 类似python中的f&#x27;&#x27;或者&#x27;&#x27;.format() 可以加入变量string two = $&quot;\\\\&quot;;//逐字字符串 类似python中的r&#x27;&#x27; 每个字符是本身的意思,不转义string three = @&quot;\\&quot;;","categories":[{"name":"快捷命令","slug":"快捷命令","permalink":"https://gladdduck.github.io/categories/%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"CSharp","slug":"CSharp","permalink":"https://gladdduck.github.io/tags/CSharp/"}]},{"title":"C#使用PaddleOCRSharp","slug":"配置-C#使用PaddleOCRSharp","date":"2023-11-24T12:54:49.886Z","updated":"2023-11-26T05:19:59.766Z","comments":true,"path":"2023/11/24/配置-C#使用PaddleOCRSharp/","link":"","permalink":"https://gladdduck.github.io/2023/11/24/%E9%85%8D%E7%BD%AE-C#%E4%BD%BF%E7%94%A8PaddleOCRSharp/","excerpt":"","text":"1. Nuget安装 2.本地编译 编译 gitee上拉下来源码,github的版本比较老 VS2022打开项目,双击项目名称打开.csproj文件.在 TargetFrameworks中修改需要的版本,例如: 1234567891011121314151617&lt;TargetFrameworks&gt; net35; net40; net45; net451; net452; net46; net461; net462; net47; net471; net472; net48; net481; netstandard2.0;netcoreapp3.1; net5.0;net6.0;net7.0;net8.0&lt;/TargetFrameworks&gt; 如果是 .Net8.0,会报错 不存在ImageToBytes, 因为在 EngineBase.cs中有 if !NET8_0_OR_GREATER,ImageToBytes只针对 .Net8.0以下版本,所以在 #endif后面加上: 12345678910#if NET8_0_OR_GREATERinternal protected byte[] ImageToBytes(Image image)&#123; using (MemoryStream ms = new MemoryStream()) &#123; image.Save(ms, image.RawFormat); // 保存图片到内存流 return ms.ToArray(); // 返回字节数组 &#125;&#125;#endif 清理项目,重新生成,就可以在 bin文件夹下找到对应版本的dll文件了 使用 新建项目,在依赖项中,右键添加项目引用,找到生成的dll文件,添加引用 测试代码可以用下面的 123456789101112131415161718192021222324252627282930OpenFileDialog ofd = new OpenFileDialog();ofd.Filter = &quot;*.*|*.bmp;*.jpg;*.jpeg;*.tiff;*.tiff;*.png&quot;;if (ofd.ShowDialog() != DialogResult.OK) return;var imagebyte = File.ReadAllBytes(ofd.FileName);Bitmap bitmap = new Bitmap(new MemoryStream(imagebyte));OCRModelConfig config = null;OCRParameter oCRParameter = new OCRParameter();OCRResult ocrResult = new OCRResult();//建议程序全局初始化一次即可，不必每次识别都初始化，容易报错。 PaddleOCREngine engine = new PaddleOCREngine(config, oCRParameter);&#123; ocrResult = engine.DetectText(bitmap);&#125;if (ocrResult != null)&#123; label1.Text = ocrResult.Text;&#125; 如果不出意外的话,应该会报错,一个错误是 无法加载文件或程序集System.Drawing.Common, Version=0.0.0.0, culture=....这个是因为没有安装 System.Drawing.Common这个包,在这个项目中用Nuget安装就可以了 另一个错误是 找不到xxxxx.dll或 什么dll文件不存在或 ch-xxxxxxx找不到,不存在.解决方法: 第一种,先显示全部文件,在bin/debug/对应的版本文件夹下,把PaddleOCRSharp项目中的 PaddleOCRLib文件下的内容全部复制到这个文件夹下 第二种,把 PaddleOCRLib文件夹下的所有文件复制到解决方案同目录,然后把每一个文件的属性都设置位 始终复制或者 如果较新则复制,但是这样文件结构就复杂了 第三种,把 PaddleOCRLib文件夹复制过来,","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"PaddleOCRSharp","slug":"PaddleOCRSharp","permalink":"https://gladdduck.github.io/tags/PaddleOCRSharp/"}]},{"title":"VS2022快捷键","slug":"杂谈-VS2022快捷键","date":"2023-11-24T12:54:49.882Z","updated":"2023-11-24T09:14:47.861Z","comments":true,"path":"2023/11/24/杂谈-VS2022快捷键/","link":"","permalink":"https://gladdduck.github.io/2023/11/24/%E6%9D%82%E8%B0%88-VS2022%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"复制一行 1Ctrl+D 注释 121. 注释:Ctrl+K 接上 Ctrl+C2. 取消注释:Ctrl+K 接上 Ctrl+U 代码折叠 1231. 折叠光标所在部分:Ctrl+M 接上 Ctrl+M2. 折叠全部函数:Ctrl+M 接上 Ctrl+O(打开同理) 代码格式化 1Ctrl+K 接上 Ctrl+D F开头的快捷键 12345671. F5:开始调试2. F7:页面跳转代码3. F9:设置断点4. F10:单步执行5. F11:单步进入6. F12:转到定义7. Shift+F12:查找变量所有引用","categories":[{"name":"快捷命令","slug":"快捷命令","permalink":"https://gladdduck.github.io/categories/%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"VS2022","slug":"VS2022","permalink":"https://gladdduck.github.io/tags/VS2022/"}]},{"title":"VSCode登录Github账号同步","slug":"配置-VSCode登录Github","date":"2023-11-20T04:44:58.504Z","updated":"2023-11-20T04:52:43.741Z","comments":true,"path":"2023/11/20/配置-VSCode登录Github/","link":"","permalink":"https://gladdduck.github.io/2023/11/20/%E9%85%8D%E7%BD%AE-VSCode%E7%99%BB%E5%BD%95Github/","excerpt":"","text":"问题 多个设备使用vscode,每次都要配置(快捷键,插件这些),很麻烦 登录GitHub账号(Microsoft账号也可以),提示:vscode 登录github 尚未完成授权此扩展使用 GitHub 的操作。是否要尝试其他方式? (本地服务器) 方法 原因是本地电脑连不上github,需要一个全局代理(没有) 方法:在C:\\Windows\\System32\\drivers\\etc下找到hosts文件,添加 12345140.82.112.4 github.com185.199.108.153 vscode-auth.github.com185.199.109.153 vscode-auth.github.com185.199.110.153 vscode-auth.github.com185.199.111.153 vscode-auth.github.com 可以先把host文件复制到桌面,修改桌面的host,然后替换,这样就不存在权限问题了","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"VSCode Github","slug":"VSCode-Github","permalink":"https://gladdduck.github.io/tags/VSCode-Github/"}]},{"title":"BingChat国内使用","slug":"配置-Bing Chat使用","date":"2023-11-20T01:35:57.276Z","updated":"2023-11-26T05:19:19.444Z","comments":true,"path":"2023/11/20/配置-Bing Chat使用/","link":"","permalink":"https://gladdduck.github.io/2023/11/20/%E9%85%8D%E7%BD%AE-Bing%20Chat%E4%BD%BF%E7%94%A8/","excerpt":"","text":"好处 不需要申请,网络Ok都可以用 DALL·E 3 免费用 据说是ChatGPT 4.0,多模态,可以上传图片 后续可以增加插件 使用 打开bing.com(这个地方如果打开的是cn.bing.com,就不会出现Chat窗口),不需要登录 调整国家和地区,随便国家 左边标签页就有Chat了 注意 每天好像只有30次查询机会,不登录只有5次(在Chrome上只有5次,在Edge上是30次) 图片生成可以直接在bing.com/create上生成,需要登录","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"BingChat","slug":"BingChat","permalink":"https://gladdduck.github.io/tags/BingChat/"}]},{"title":"杂七杂八小知识","slug":"杂谈-杂记知识点","date":"2023-11-19T07:27:51.051Z","updated":"2023-11-26T05:18:31.885Z","comments":true,"path":"2023/11/19/杂谈-杂记知识点/","link":"","permalink":"https://gladdduck.github.io/2023/11/19/%E6%9D%82%E8%B0%88-%E6%9D%82%E8%AE%B0%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"cookie和token的区别是什么","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"知识点","slug":"知识点","permalink":"https://gladdduck.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9/"}]},{"title":"Zero-shot Detection论文总结","slug":"学术-Zero-shotDetection论文总结","date":"2023-11-14T12:57:15.167Z","updated":"2023-11-14T12:59:53.394Z","comments":true,"path":"2023/11/14/学术-Zero-shotDetection论文总结/","link":"","permalink":"https://gladdduck.github.io/2023/11/14/%E5%AD%A6%E6%9C%AF-Zero-shotDetection%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/","excerpt":"","text":"Zero-shot Object Detection 缺点: 需要结合文本信息,没办法完全根据图片进行检测 综述 A Survey of Vision-Language Pre-Trained Models 视觉语言多模态综述 介绍了视觉语言多模态的1. 特征表示 2. 模态交互 3. 预训练任务 4. 下游任务 5. 方向 2022年之前的VL预训练模型和常用数据集 网页 Zero-Shot Object Detection介绍 介绍了Zero-Shot Object Detection的基本概念，以及如何使用Region-CLIP进行Zero-Shot Object Detection Zero-Shot Object Detection案例 一个样例代码,使用CLIP进行检测 论文 Zero-Shot Detection 利用BackBone抽出来图像的特征TFT_FTF​ 在TFT_FTF​上进行检测,得到目标的位置信息TLT_LTL​ 在TFT_FTF​上进行语义预测,得到目标的文本信息TST_STS​ 把TF,TL,TST_F,T_L,T_STF​,TL​,TS​拼接起来,进行置信度的预测,得到了最终的预测结果(x,y,w,h,cls) 损失函数由1)位置损失 2)语义损失 3)置信度损失组成 在验证过程中分为Test-Seen,Test-Unseen,Test-Mix三种情况 解决问题: RPN可能无法提议出那么多没见过的物体 基于YOLOv2,性能强大 简单容易理解 Zero-Shot Object Detection 方法: 两阶段检测器结构,对区域建议框内的物体抽取出图像特征 通过映射将图像特征映射到文本特征空间(通过wordEmbedding得到) 在公共空间计算图像特征和文本特征的相似度,得到未见物体的类别 解决问题: 将未见物体分为背景的解决 使用固定的背景类:在嵌入空间中为背景添加一个固定的向量 将多个潜在的类分配给背景对象,不断的将背景框标记为对象反复训练 密集采样嵌入空间:数据集中可见类太少了导致公共空间稀疏,未见类的语义和视觉之间无法对齐 使用除了未见类之外的额外数据补充训练 Region-CLIP 利用RPN从图像中提取出region,抽取出特征 利用现有文本解析器,从文本中提取出concept,抽取出特征 利用CLIP计算region和concept的相似度,得到region-text的配对 利用三个损失函数训练模型","categories":[{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Zero-shot Detection","slug":"Zero-shot-Detection","permalink":"https://gladdduck.github.io/tags/Zero-shot-Detection/"}]},{"title":"Blazor中的Localization","slug":"配置-Blazor中的Localization","date":"2023-10-09T11:38:30.993Z","updated":"2023-11-26T05:19:29.773Z","comments":true,"path":"2023/10/09/配置-Blazor中的Localization/","link":"","permalink":"https://gladdduck.github.io/2023/10/09/%E9%85%8D%E7%BD%AE-Blazor%E4%B8%AD%E7%9A%84Localization/","excerpt":"","text":"参考连接 1.根据浏览器语言显示语言 项目中新建Resources文件夹 新建Text.resx文件(这个不用加语言的后缀,会报错 自定义工具 PublicResXFileCodeGenerator 未能对输入文件产生输出) 新建其他语言的Text文件,比如Text.zh.resx resx文件中访问修饰符需要设置 public,每个文件中的名称需要相同,值是各个语言 完成之后,类似下图 在 Program.cs中添加 builder.Services.AddLocalization(); 在 _Imports.razor中添加 @using Microsoft.Extensions.Localization @using 项目名.文件夹名称,例如:@using BlazorWasmLocalization.Shared.ResourceFiles 在页面中添加代码,其中Text就是resx文件的名称 12345@page &quot;/&quot;@inject IStringLocalizer&lt;Text&gt; localizer&lt;h1&gt;@localizer[&quot;resx文件中的一个名称&quot;]&lt;/h1&gt;@localizer[&quot;resx文件中的一个名称&quot;] 2.根据用户选择的语言显示语言 可以新建一个组件也可以直接在页面中添加 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- 下拉选框 --&gt;&lt;strong&gt;Culture:&lt;/strong&gt;&lt;select class=&quot;form-control&quot; @bind=&quot;Culture&quot; style=&quot;width:300px; margin-left:10px;&quot;&gt; @foreach (var culture in cultures) &#123; &lt;option value=&quot;@culture&quot;&gt;@culture.DisplayName&lt;/option&gt; &#125;&lt;/select&gt;&lt;!-- 组件代码 --&gt;public partial class CultureSelector&#123; [Inject] public NavigationManager NavManager &#123; get; set; &#125; [Inject] public IJSRuntime JSRuntime &#123; get; set; &#125; &lt;!-- 语言列表,和resx文件对应 --&gt; CultureInfo[] cultures = new[] &#123; new CultureInfo(&quot;en-US&quot;), new CultureInfo(&quot;zh-CN&quot;) &#125;; CultureInfo Culture &#123; get =&gt; CultureInfo.CurrentCulture; set &#123; if (CultureInfo.CurrentCulture != value) &#123; var js = (IJSInProcessRuntime)JSRuntime; js.InvokeVoid(&quot;blazorCulture.set&quot;, value.Name); &lt;!-- 每次选择之后会刷新一下页面 --&gt; NavManager.NavigateTo(NavManager.Uri, forceLoad: true); &#125; &#125; &#125;&#125; 在项目下新建一个 Extensions文件夹,新建一个 WebAssemblyHostExtension.cs文件 123456789101112131415161718public static class WebAssemblyHostExtension&#123; public async static Task SetDefaultCulture(this WebAssemblyHost host) &#123; var jsInterop = host.Services.GetRequiredService&lt;IJSRuntime&gt;(); var result = await jsInterop.InvokeAsync&lt;string&gt;(&quot;blazorCulture.get&quot;); CultureInfo culture; if (result != null) culture = new CultureInfo(result); else culture = new CultureInfo(&quot;zh-CN&quot;); CultureInfo.DefaultThreadCurrentCulture = culture; CultureInfo.DefaultThreadCurrentUICulture = culture; &#125;&#125; 在 Program.cs中添加 123var host = builder.Build();await host.SetDefaultCulture();await host.RunAsync(); 在 wwwroot/index.html中添加 123456&lt;script&gt; blazorCulture = &#123; get: () =&gt; localStorage[&#x27;BlazorCulture&#x27;], set: (value) =&gt; localStorage[&#x27;BlazorCulture&#x27;] = value &#125;; &lt;/script&gt; 在csproj文件中添加 1&lt;BlazorWebAssemblyLoadAllGlobalizationData&gt;true&lt;/BlazorWebAssemblyLoadAllGlobalizationData&gt; 运行即可","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"BlazorLocalization","slug":"BlazorLocalization","permalink":"https://gladdduck.github.io/tags/BlazorLocalization/"}]},{"title":"Blazor学习笔记","slug":"笔记-C#-Blazor笔记","date":"2023-09-16T05:56:55.560Z","updated":"2023-11-26T05:19:32.110Z","comments":true,"path":"2023/09/16/笔记-C#-Blazor笔记/","link":"","permalink":"https://gladdduck.github.io/2023/09/16/%E7%AC%94%E8%AE%B0-C#-Blazor%E7%AC%94%E8%AE%B0/","excerpt":"","text":"😍😍😍 Blazor 用C#代替JavaScript创建丰富的UI 页面组件 组件 以razor结尾,文件名首字母大写,HTML和C#代码的组合. 类似vue,在组件中可以使用@来引用变量 1234567&lt;h1 style=&quot;font-style:@_headingFontStyle&quot;&gt;@_headingText&lt;/h1&gt;@code &#123; private string _headingFontStyle = &quot;italic&quot;; private string _headingText = &quot;你好,世界!&quot;;&#125; 组件参数 定义一个带有[Parameter]的公共属性,在父类使用这个组件时,可以传参 1234567891011// 子组件:Child&lt;h1&gt;@Title&lt;/h1&gt;@code &#123; [Parameter] public string Title &#123; get; set; &#125;&#125;// 父组件&lt;Child Title=&quot;传递参数&quot; /&gt; 组件多参数 当子组件可携带多个参数时,不用每个参数都进行定义. 使用@attributes语法关联字段进行绑定 12345678910111213141516171819202122// 第一种方式,单独传参&lt;input title=&quot;@Title&quot; value=&quot;@Value&quot; /&gt;// 第二种方式,attribute字典传参&lt;input @attributes=&quot;ButtonAttributes&quot; /&gt;@code &#123; [Parameter] public string Title &#123; get; set; &#125; = &quot;Hello&quot;; [Parameter] public string Value &#123; get; set; &#125; = &quot;10&quot;; [Parameter] public Dictionary&lt;string, object&gt; ButtonAttributes &#123; get; set; &#125; = new Dictionary&lt;string, object&gt;()&#123; &#123; &quot;title&quot;,&quot;Hello&quot; &#125; , &#123; &quot;value&quot;,&quot;10&quot; &#125; , &#125;;&#125; 组件生命周期 组件模板 父组件在使用子组件时，可以向子组件中插入代码片段.类似vue中的插槽? 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 子组件，构建一个RenderFragment模板@typeparam IData&lt;table&gt; &lt;thead&gt; @HeaderTemplate &lt;/thead&gt; &lt;tbody&gt; @foreach (var item in Data) &#123; &lt;tr&gt; &lt;td&gt;@RowTemplate(item)&lt;/td&gt; &lt;/tr&gt; &#125; &lt;/tbody&gt;&lt;/table&gt;@code &#123; [Parameter] public RenderFragment HeaderTemplate &#123; get; set; &#125; [Parameter] public RenderFragment&lt;IData&gt; RowTemplate &#123; get; set; &#125; [Parameter] public IReadOnlyList&lt;IData&gt; Data &#123; get; set; &#125;&#125;// 父组件使用时传递html标签&lt;TableTemplate Data=&quot;students&quot;&gt; &lt;HeaderTemplate&gt; &lt;th&gt;Id&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;/HeaderTemplate&gt; &lt;RowTemplate&gt; &lt;td&gt;@context.Id&lt;/td&gt; &lt;td&gt;@context.Name&lt;/td&gt; &lt;/RowTemplate&gt;&lt;/TableTemplate&gt;@code&#123; public List&lt;Student&gt; students &#123; get; set; &#125; protected override Task OnInitializedAsync() &#123; students = new List&lt;Student&gt;(); students.Add(new Student() &#123; Id = 1, Name = &quot;John&quot; &#125;); students.Add(new Student() &#123; Id = 2, Name = &quot;Mary&quot; &#125;); students.Add(new Student() &#123; Id = 3, Name = &quot;Jane&quot; &#125;); students.Add(new Student() &#123; Id = 4, Name = &quot;Peter&quot; &#125;); return base.OnInitializedAsync(); &#125;&#125; 组件方法 子组件时间完成之后的一个回调,当子组件发生某个事件之后通知父组件，父组件的一个响应函数 下面的例子，当子组件发生点击事件之后，父组件可做出相应的反应 123456789101112131415161718192021222324252627282930// 子组件：ChildCallBack&lt;button @onclick=&quot;OnClickChild&quot;&gt; Click&lt;/button&gt;@code &#123; [Parameter] public EventCallback&lt;MouseEventArgs&gt; OnClickCallback &#123; get; set; &#125; // private async void OnClickChild()&#123; // do somethings // ()传递参数 OnClickCallback.InvokeAsync(1); &#125;&#125;// 父组件&lt;ChildCallBack OnClickCallback=&quot;ReceiveDataFromSideBar&quot;&gt;&lt;/ChildCallBack&gt;@code&#123; private void ReceiveDataFromSideBar(int number) &#123; // 可接受参数做处理 &#125;&#125; 事件处理 在标签中使用@绑定一个事件，一种使用lambda表达式直接处理，一种使用函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 1.lambda&lt;input @onchange=&quot;@(()=&gt;Console.WriteLine(&quot;Hello&quot;))&quot; /&gt;&lt;button @onclick=&quot;@(()=&gt;Console.WriteLine(&quot;Hello&quot;))&quot; /&gt;// 2.@code中使用函数&lt;button @onclick=&quot;Show&quot; /&gt;@code&#123; public void Show() &#123; //当按钮被点击, 将执行下面代码 &#125;&#125;// 3.携带事件参数，在默认的情况下, 我们如果只编写一个事件触发的方法, 并且明确它是否有参数, 在UI元素绑定方法上, 我们都无需传递参数&lt;button @onclick=&quot;Show&quot; /&gt;@code&#123; public async Task Show(MouseEventArgs e) &#123; //... &#125;&#125;// 4.可重载，带有事件或不带事件&lt;button @onclick=&quot;@(e=&gt;Show(e))&quot; /&gt; //调用带事件参数的方法&lt;button @onclick=&quot;@(()=&gt;Show())&quot; /&gt; //调用不带事件参数的方法@code&#123; //不带事件参数的方法 public void Show() &#123; &#125; //带事件参数的方法 public void Show(MouseEventArgs e) &#123; &#125;&#125; 数据绑定 绑定字段 类似vue中的v-bind，可以绑定C#字段,双向绑定 @xxx和@bind的区别：value=“@xxx”: 只能做到属性呈现到UI元素当中, 元素发生变化并不会影响到属性变更。 1234567&lt;input @bind=&quot;Name&quot; /&gt;@code &#123; private string Name&#123; get; set; &#125;&#125; 绑定对象的属性 123456789101112131415&lt;input @bind=&quot;Stu.Name&quot;/&gt;@code&#123; public Student Stu &#123; get; set; &#125; = new Student() &#123; Name = &quot;123&quot; &#125;; public class Student &#123; public string Name &#123; get; set; &#125; &#125;&#125; 绑定数据格式化 12345678&lt;input @bind=&quot;StartDate&quot; @bind:format=&quot;yyyy-MM-dd&quot; /&gt;@code &#123; [Parameter] public DateTime StartDate &#123; get; set; &#125; = new DateTime(2020, 1, 1);&#125; 父组件参数绑定到子组件 当父组件的参数改变时，子组件中的参数也会同时改变 123456789101112131415161718192021222324// ChildComponent &lt;p&gt;Year: @Year&lt;/p&gt;@code &#123; [Parameter] public int Year &#123; get; set; &#125; [Parameter] public EventCallback&lt;int&gt; YearChanged &#123; get; set; &#125;&#125;// 父组件&lt;ChildComponent @bind-Year=&quot;ParentYear&quot; /&gt;&lt;input @bind=&quot;ParentYear&quot; /&gt;@code &#123; [Parameter] public int ParentYear &#123; get; set; &#125; = 1978;&#125; 路由和页面导航 @page “/xxx” 组件的路由 @page “/xxx/{aaa}” aaa是路由传参，在@code中添加一个公共字段aaa， @page “/xxx/{aaa:int}” 指定参数类型 NavigationManager.NavigateTo(“/test/999”); 跳转页面(NavLink 也可以) Blazor Server和Blazor WebAssembly 官网说明 服务器把东西全部运行在浏览器的沙盒里, Blazor WebAssembly的优点 在浏览器中执行C#代码，不需要额外的插件 可以基于WebAssembly的性能优势和可在浏览器内执行的能力，获得更快页面处理速度 支持无服务器和离线场景 Blazor WebAssembl的缺点 需要加载太多资源，首次展现速度较慢 由于所有代码都在浏览器中执行，不能嵌入机密数据 Blazor Server类似MVC,但是Server是长连接,在服务器端计算结果差异,浏览器拿到差异渲染(blazor.server.js) Blazor Server的优点 页面加载是轻量级的 服务器可以使用机密数据，例如访问数据库 它支持100%的浏览器，即使是那些没有WASM支持的浏览器，如Internet Explorer。 Blazor Server的缺点 需要一个http://ASP.NET Core服务器 不支持无服务器和离线场景 大量SignalR连接可能引发性能问题,保持连接","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Blazor","slug":"Blazor","permalink":"https://gladdduck.github.io/tags/Blazor/"}]},{"title":"Git学习笔记","slug":"实习-Git学习笔记","date":"2023-09-09T02:24:47.503Z","updated":"2023-11-26T05:22:17.136Z","comments":true,"path":"2023/09/09/实习-Git学习笔记/","link":"","permalink":"https://gladdduck.github.io/2023/09/09/%E5%AE%9E%E4%B9%A0-Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"😍😍😍 流程 远程仓库(github) 本地仓库(本机) 缓冲区(防止误提交) 工作区(写代码的地方) github用户名密码存储在用户管理中的管理Windows凭据. git status 查看文件当前所处位置 gitignore 忽略文件 根目录创建 .gitignore 每个配置项单独一行 可以有空行,方便阅读 可以是文明目录名,路径或者匹配模式 如果一个文件已经被提交过了,再ignore没有用 12345678910111213141516171819202122232425262728293031323334模式匹配# 用于注释 \\用于转义* 匹配任意字符任意次 ?匹配任意字符1次 但都不匹配/[] 用于匹配列表里面的一个字符**用于匹配多级目录/用户分隔目录 1)如果/在开头,则匹配根目录下的文件, 否则 所有子文件夹里的文件都会匹配 2)/ 在末尾时, 只匹配目录, 否则同名的文件和目录都会匹配! 用于重新包含某个文件, 如果这个文件的父级目录被排除了,那么它不回被包含了例:1) 忽略所哟内容 *2) 忽略所有目录 */3) 忽略public 目录下的某个文件 public/* !public/xxxxxxx4) 只保留public目录下的某个文件 /* !/public/ /public/* !/public/a?z.*如何检查自己写的ignore规则是否对git check-ignore [-v] &#123;文件或目录路径&#125; 分支操作 12345678910111213git branch -a 查看所有分支git branch dev 创建分支git checkout dev 切换分支git branch -d dev 删除分支git branch -m 旧名称 新名称 重命名分支git checkout -b dev 创建并切换分支git merge dev 合并分支 切换到主分支上,然后再合并子分支,将dev合并到当前分支# 将本地分支推送到远程git push origin --allgit push origin 分支名git push origin -d 分支名 删除远端分支 修改分支名称:参考 Merge 合并 修改之前尽量先pull一下 远程仓库已更新,本地没pull,直接修改,之后push,会显示push失败,会提示git pull. 在git pull之后, 可能会有自动合并,auto-merging, 修改同一文件不同位置 需要手动合并,此时解决冲突需要和冲突者商量,合并时会新建一个临时分支 ,修改之后重新提交,add commit push,修改同一文件同一位置 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;HEAD 冲突开始 =============== 不同的内容分隔符 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;冲突结束 版本回退 123456789101112131415161718192021# 整个文件夹回退# 查看历史记录,这个说明commit里面的说明一定要写详细,只会显示当前提交之前的版本git log --oneline# 回退到某一个版本,后面提交的就看不到了git reset --hard 输入版本号# 查看从现在到最新的commit idgit reflog # 回到最新的版本git reset --hard commit id# 单个文件回退,提交修正# 对错误文件修正,提交时漏交文件,提交信息修正,长开发中小提交过多# 修正之后不会在log中显示git commit --amend -m &quot;提交说明&quot; 文件恢复 修改或删除之后,没有add git checkout 文件名 会还原成上一次add的文件 修改或删除之后,add了,但没有commit git checkout commit_id 文件名 修改或删除之后,已commit git checkout commit_id 文件名 查看日志 普通日志 引用日志 12345# 项目的最后一根稻草# 本地日志,不会上传到远端,会把文件回退修正的记录也列出来git reflog 标签管理 发行: 在github上create a new release fork 复制别人的仓库 然后克隆到本地 修改提交… 向原仓库发生和并请求,contribute,open a pull request 等待原始仓库同意合并 本地库与远程库进行关联 github新建仓库 本地git init初始化 git remote add origin https:// 关联远程 git push -u origin 分支名称 如果添加第二个远程仓库,修改origin为一个新的 *git remote 参数,设置远程仓库的信息 -h查看命令帮助 git remote -v 查看仓库 git push 远端库名称 分支名称 github仓库美化 图标修改 流程 git发布流程 分支合并发布流程： git add . # 将所有新增、修改或删除的文件添加到暂存区 git commit -m “版本发布” # 将暂存区的文件发版 git status # 查看是否还有文件没有发布上去 git checkout test # 切换到要合并的分支 git pull # 在test 分支上拉取最新代码，避免冲突 git merge dev # 在test 分支上合并 dev 分支上的代码 git push # 上传test分支代码","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://gladdduck.github.io/tags/Git/"}]},{"title":"AcWing算法基础课","slug":"算法-AcWing算法基础课,","date":"2023-06-04T14:26:33.383Z","updated":"2023-06-09T06:10:38.786Z","comments":true,"path":"2023/06/04/算法-AcWing算法基础课,/","link":"","permalink":"https://gladdduck.github.io/2023/06/04/%E7%AE%97%E6%B3%95-AcWing%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E8%AF%BE,/","excerpt":"","text":"基础算法 快速排序 12345678910111213141516171819202122232425262728293031def quick_sort(lst,start,end): # 边界条件 if start&gt;=end: return None # 选择哨兵点 standby=lst[(start+end)&gt;&gt;1] # 左右指针 left=start-1 right=end+1 while left&lt;right: left+=1 while lst[left]&lt;standby: left+=1 right-=1 while lst[right]&gt;standby: right-=1 if left&lt;right: lst[left],lst[right]=lst[right],lst[left] # if j-l+1&gt;=m: # return quick_sort(nums,l,j,m) # else: # return quick_sort(nums,j+1,r,m-(j-l+1)) quick_sort(lst,start,right) quick_sort(lst,right+1,end)import sysn=int(input())nums=list(map(int,sys.stdin.read().split()))quick_sort(nums,0,len(nums)-1)for item in nums: print(item,end=&quot; &quot;) 选择排序 123456789101112131415161718192021222324252627282930313233n=int(input())lst=list(map(int,input().split()))def merge(a,b): lena=len(a) lenb=len(b) i=j=0 c=[] while i&lt;lena and j&lt;lenb: if a[i]&lt;b[j]: c.append(a[i]) i+=1 else: # ans+=len(l)-i c.append(b[j]) j+=1 if i==lena: c.extend(b[j:]) else: c.extend(a[i:]) return c def sort(nums): if len(nums)&lt;=1: return nums mid=len(nums)&gt;&gt;1 l=sort(nums[:mid]) r=sort(nums[mid:]) return merge(l,r)ret=sort(lst)for item in ret: print(item,end=&quot; &quot;) 二分 123456789101112131415161718192021222324252627282930313233343536373839404142n,m=list(map(int,input().split()))lst=list(map(int,input().split()))for _ in range(m): q=int(input()) l=0 r=n-1 while l&lt;r: mid=(l+r)&gt;&gt;1 if lst[mid]&gt;=q: r=mid else: l=mid+1 if lst[l]!=q: print(&quot;-1 -1&quot;) else: print(l,end=&#x27; &#x27;) l=0 r=n-1 while l&lt;r: mid=(r+l+1)&gt;&gt;1 if lst[mid]&gt;q: r=mid-1 else: l=mid print(l)# --------import bisectn,m=list(map(int,input().split()))lst=list(map(int,input().split()))for _ in range(m): q=int(input()) l=bisect.bisect_left(lst,q) r=bisect.bisect_right(lst,q) if l&gt;=n or r&lt;=0: print(&quot;-1 -1&quot;) elif r!=0 and lst[r-1]!=q: print(&quot;-1 -1&quot;) else: r-=1 print(f&#x27;&#123;l&#125; &#123;r&#125;&#x27;) 前缀和 12 差分 1234567891011121314n,m=map(int,input().split())nums=list(map(int,input().split()))diff=[0]*(n+1)diff[0]=nums[0]for i in range(1,len(nums)): diff[i]=nums[i]-nums[i-1]for i in range(m): a,b,c=map(int,input().split()) diff[a-1]+=c diff[b]-=ctemp=0for i in range(n): temp+=diff[i] print(temp,end=&#x27; &#x27;) 双指针 12 位运算 12 离散化 12345678910111213141516171819202122232425262728293031323334n,m=map(int,input().split())all=set()add=[]query=[]for _ in range(n): x,c=map(int,input().split()) all.add(x) add.append((x,c))for _ in range(m): l,r=map(int,input().split()) all.add(l) all.add(r) query.append((l,r)) all=sorted(all)nums=[0]*len(all)nums2index=&#123;&#125;for i,x in enumerate(all): nums2index[x]=i for k,v in add: nums[nums2index[k]]+=vsums=[0]*(len(all)+1)for i in range(len(nums)): sums[i+1]=sums[i]+nums[i]for l,r in query: indexl=nums2index[l] indexr=nums2index[r] print(sums[indexr+1]-sums[indexl]) 区间和并 12345678910111213141516n=int(input())nums=[]for _ in range(n): a,b=list(map(int,input().split())) nums.append((a,b))nums=sorted(nums)left,right=nums[0][0],nums[0][1]ans=1for i in range(1,len(nums)): a,b=nums[i][0],nums[i][1] if a&lt;=right: right=max(b,right) else: ans+=1 left,right=a,bprint(ans) 数据结构 单链表 双链表 栈 12345678910111213141516171819202122232425262728293031323334353637383940414243s=input()num_stack=[]op_stack=[]pro=&#123;&#x27;+&#x27;:1,&#x27;-&#x27;:1,&#x27;*&#x27;:2,&#x27;/&#x27;:2&#125;def eval(): b=num_stack.pop() a=num_stack.pop() op=op_stack.pop() if op==&#x27;+&#x27;: num_stack.append(a+b) elif op==&#x27;-&#x27;: num_stack.append(a-b) elif op==&#x27;*&#x27;: num_stack.append(a*b) else: num_stack.append(int(a/b))i=0while i&lt;len(s): if s[i].isdigit(): temp=0 while i&lt;len(s) and s[i].isdigit(): temp=temp*10+int(s[i]) i+=1 num_stack.append(temp) continue elif s[i]==&#x27;(&#x27;: op_stack.append(&#x27;(&#x27;) elif s[i]==&#x27;)&#x27;: while op_stack[-1]!=&#x27;(&#x27;: eval() op_stack.pop() else: while op_stack and op_stack[-1]!=&#x27;(&#x27; and pro[s[i]]&lt;=pro[op_stack[-1]]: eval() op_stack.append(s[i]) i+=1while op_stack: eval()print(num_stack[0]) 队列 单调栈 12345678910111213141516n=int(input())lst=list(map(int,input().split()))stack=[lst[0]]ans=[-1]for i in range(1,len(lst)): while stack and stack[-1]&gt;=lst[i]: stack.pop() ans.append(stack[-1] if stack else -1) stack.append(lst[i])for i in ans: print(i,end=&#x27; &#x27;) 单调队列 1234567891011121314151617181920212223242526272829from collections import dequen,k=map(int,input().split())lst=list(map(int,input().split()))ans=[]dq=deque()ans2=[]dq2=deque()for i in range(n): while (dq and lst[dq[-1]]&lt;lst[i]): dq.pop() while dq and i-dq[0]&gt;=k: dq.popleft() dq.append(i) ans.append(lst[dq[0]]) for i in range(n): while (dq2 and lst[dq2[-1]]&gt;lst[i]): dq2.pop() while dq2 and i-dq2[0]&gt;=k: dq2.popleft() dq2.append(i) ans2.append(lst[dq2[0]]) for item in ans2[k-1:]: print(item ,end=&#x27; &#x27;) print()for item in ans[k-1:]: print(item ,end=&#x27; &#x27;) Tire 1234567891011121314151617181920212223242526272829303132333435n=int(input())lst=list(map(int,input().split()))tire=[[0]*2 for i in range(3000000)]count=0def insert(x): p=0 for i in range(32,-1,-1): t=(x&gt;&gt;i)&amp;1 if not tire[p][t]: global count count+=1 tire[p][t]=count p=tire[p][t] def find(x): p=0 res=0 for i in range(32,-1,-1): t=(x&gt;&gt;i)&amp;1 if tire[p][not t]: res+=(1&lt;&lt;i) p=tire[p][not t] else: p=tire[p][t] return resans=-1for i in lst: insert(i) ans=max(ans,find(i)) print(ans) 并查集 123456789101112131415161718192021222324252627282930n,m=map(int,input().split())size=[1]*(n+1)p=[i for i in range(n+1)]def find(x): if x!=p[x]: p[x]=find(p[x]) return p[x]def merge(a,b): fa=find(a) fb=find(b) p[fa]=fb size[fb]+=size[fa]for _ in range(m): inp=input().split() q=inp[0] if q==&#x27;C&#x27;: a,b=int(inp[1]),int(inp[2]) if find(a)!=find(b): merge(a,b) elif q==&#x27;Q1&#x27;: a,b=int(inp[1]),int(inp[2]) if find(a)==find(b): print(&quot;Yes&quot;) else: print(&#x27;No&#x27;) else: a=int(inp[1]) print(size[find(a)]) 堆 12import heapq 哈希表 12345678910111213141516171819202122232425import sysN=100010n,m=map(int,sys.stdin.readline().split())h=[0]*Np=[0]*Nseed=131Q=1&lt;&lt;64s=&#x27; &#x27;+input()def get(l,r): return (h[r]-h[l-1]*p[r-l+1])%Q p[0]=1for i in range(1,n+1): p[i]=(p[i-1]*seed)%Q h[i]=(h[i-1]*seed+ord(s[i]))%Q while m: m-=1 a,b,x,y=map(int,sys.stdin.readline().split()) if get(a,b)==get(x,y): print(&quot;Yes&quot;) else: print(&quot;No&quot;) 搜索与图论 深搜&amp;广搜 拓扑排序 123456789101112131415161718192021222324252627282930313233n,m=map(int,input().split())from collections import defaultdict,dequegraph=defaultdict(list)degr=[0]*(n+1)for i in range(m): a,b=map(int,input().split()) graph[a].append(b) degr[b]+=1def topsort(): ans=[] dq=deque() for i in range(1,n+1): if degr[i]==0: dq.append(i) while dq: cur = dq.pop() ans.append(cur) for neigh in graph.get(cur,[]): degr[neigh]-=1 if degr[neigh]==0: dq.append(neigh) return ans if len(ans)==n else Noneans=topsort()if ans: for i in ans: print(i,end=&#x27; &#x27;)else: print(-1) dijkstra 1234567891011121314151617181920212223242526272829303132333435363738from collections import defaultdictimport heapqn,m=list(map(int,input().split()))graph=[[-1]*(n+1) for _ in range(n+1)]for i in range(m): a,b,c=list(map(int,input().split())) graph[a-1][b-1]=c if graph[a-1][b-1]==-1 else min(graph[a-1][b-1],c) def dijkstra(): dis=[float(&#x27;inf&#x27;)]*(n) dis[0]=0 visited=set() min_heap=[(0,0)] # 依次确定n个点的距离 for i in range(n): # 没有可达的点了 if len(min_heap)==0: break # 未确定点最近的一个 _,min_index=heapq.heappop(min_heap) visited.add(min_index) # 寻找邻居 for v in range(n): # 可达且未访问 if v not in visited and graph[min_index][v]&gt;0: new_dis=dis[min_index]+graph[min_index][v] # 更新 if dis[v]&gt;new_dis: dis[v]=new_dis heapq.heappush(min_heap,(dis[v],v)) return disd=dijkstra()print(d[n-1] if d[n-1]!=float(&#x27;inf&#x27;) else -1) 123456789101112131415161718192021222324252627282930from collections import defaultdictimport heapqimport sysn,m=map(int,input().split())graph=defaultdict(list)for i in range(m): a,b,c=map(int,sys.stdin.readline().split()) graph[a-1].append((b-1,c)) def dijkstra(): dis=[float(&#x27;inf&#x27;)]*n dis[0]=0 visit=set() min_heap=[(0,0)] while len(min_heap): _,node=heapq.heappop(min_heap) if node in visit:continue visit.add(node) for v,d in graph.get(node,[]): new_dis=dis[node]+d if dis[v]&gt;new_dis: dis[v]=new_dis heapq.heappush(min_heap,(dis[v],v)) return disd=dijkstra()print(d[n-1] if d[n-1]!=float(&#x27;inf&#x27;) else -1) bellman-ford 12345678910111213141516171819202122232425from collections import defaultdictimport heapqimport sysn,m,k=map(int,input().split())graph=[]for i in range(m): a,b,c=map(int,sys.stdin.readline().split()) graph.append((a,b,c)) def bellmen_ford(): dis=[float(&#x27;inf&#x27;)]*(n+1) dis[1]=0 backup=[] for _ in range(k): backup=dis.copy() for a,b,c in graph: dis[b]=min(backup[a]+c,dis[b]) if float(dis[n])&gt;float(&#x27;inf&#x27;)/2 or dis[n]==float(&#x27;inf&#x27;): return &#x27;impossible&#x27; return dis[n]ans=bellmen_ford()print(ans) spfa 1234567891011121314151617181920212223242526272829303132from collections import defaultdict,dequeimport sysn,m=map(int,input().split())graph=defaultdict(list)for i in range(m): a,b,c=map(int,sys.stdin.readline().split()) graph[a].append((b,c)) def spfa(): dist = [float(&#x27;inf&#x27;)] * (n+1) dist[1] = 0 visited = [0] * (n+1) q=deque() q.append(1) visited[1]=1 while q: cur=q.popleft() visited[cur]=0 for b,c in graph.get(cur,[]): if dist[b]&gt;dist[cur]+c: dist[b]=dist[cur]+c if not visited[b]: visited[b]=1 q.append(b) return dist[n] if dist[n]!=float(&#x27;inf&#x27;) else &#x27;impossible&#x27;ans=spfa()print(ans) floyd 1234567891011121314151617181920212223import sysn,m,k=map(int,input().split())dist = [[float(&#x27;inf&#x27;)] * (n+1) for _ in range(n+1)]for i in range(m): a,b,c=map(int,sys.stdin.readline().split()) dist[a][b]=min(c,dist[a][b]) for i in range(n+1): dist[i][i]=0def floyd(): for k in range(1,n+1): for i in range(1,n+1): for j in range(1,n+1): dist[i][j]=min(dist[i][j],dist[i][k]+dist[k][j])ans=floyd()for _ in range(k): a,b=map(int,sys.stdin.readline().split()) print(&#x27;impossible&#x27; if dist[a][b]==float(&#x27;inf&#x27;) else dist[a][b]) prime 1234567891011121314151617181920212223242526272829303132333435import sysn,m=map(int,input().split())INF=float(&#x27;inf&#x27;)graph = [[INF] * (n+1) for _ in range(n+1)]for i in range(m): a,b,c=map(int,sys.stdin.readline().split()) graph[b][a]=min(c,graph[b][a]) graph[a][b]=graph[b][a]for i in range(n+1): graph[i][i]=0def prime(): dist= [INF] * (n+1) visit= [False] * (n+1) res=0 for i in range(n): t=-1 for j in range(1,n+1): if not visit[j] and (t==-1 or dist[t]&gt;dist[j] ): t=j if i and dist[t]==INF:return INF if i:res+=dist[t] for j in range(1,n+1): dist[j]=min(dist[j],graph[t][j]) visit[t]=True return resans=prime()print(ans if ans!=INF else &#x27;impossible&#x27;) kruskal 12345678910111213141516171819202122232425262728293031323334import sysfrom collections import defaultdictn,m=map(int,input().split())INF=float(&#x27;inf&#x27;)graph = []p = [i for i in range(n+1)]for i in range(m): a,b,c=map(int,sys.stdin.readline().split()) graph.append((c,a,b)) graph=sorted(graph)def find(x): if p[x]!=x: p[x]=find(p[x]) return p[x]def kruskal(): res=0 cnt=0 for w,a,b in graph: a=find(a) b=find(b) if a!=b: p[a]=b cnt+=1 res+=w return INF if cnt&lt;n-1 else resans=kruskal()print(ans if ans!=INF else &#x27;impossible&#x27;) 数学知识 筛质数 123456789101112131415161718192021222324252627282930313233343536373839404142def get_prime(n): count=0 isprime=[1]*(n+1) isprime[0]=isprime[1]=0 for i in range(2,n+1): if isprime[i]: count+=1 for j in range(2,n+1): if j*i&gt;n: break isprime[i*j]=0 return count# 埃式筛法def get_prime2(n): count=0 isprime=[1]*(n+1) isprime[0]=isprime[1]=0 for i in range(2,n+1): if isprime[i]: count+=1 for j in range(2,n+1): if j*i&gt;n: break isprime[i*j]=0 return count# 线性筛法def get_prime3(n): nums=[1]*(n+1) isprime=[] for i in range(2,n+1): if nums[i]: isprime.append(i) for j in range(len(isprime)): if i*isprime[j]&gt;n: break nums[i*isprime[j]]=0 if i%isprime[j]==0: break return len(isprime)n=int(input())print(get_prime3(n)) 约数 12def gcd(a,b): return a if b==0 else gcd(b,a%b) 约数定理 n=∏piai=p1a1∗p2a2∗...∗pkakn=\\prod p_i^{a_i}= p_1^{a_1}* p_2^{a_2}*...*p_k^{a_k}n=∏piai​​=p1a1​​∗p2a2​​∗...∗pkak​​ 约数个数:f(n)=∏(ai+1)=(a1+1)∗(a2+1)∗...∗(ak+1)f(n)=\\prod (a_i+1)= (a_1+1)*(a_2+1)*...*(a_k+1)f(n)=∏(ai​+1)=(a1​+1)∗(a2​+1)∗...∗(ak​+1) 约数和:σ(n)=(p10+p11+p12+⋯p1a1)(p20+p21+p22+⋯p2a2)⋯(pk0+pk1+pk2+⋯pkak)\\sigma(n)=\\left(p_{1}^{0}+p_{1}^{1}+p_{1}^{2}+\\cdots p_{1}^{a_{1}}\\right)\\left(p_{2}^{0}+p_{2}^{1}+p_{2}^{2}+\\cdots p_{2}^{a_{2}}\\right) \\cdots\\left(p_{k}^{0}+p_{k}^{1}+p_{k}^{2}+\\cdots p_{k}^{a_{k}}\\right)σ(n)=(p10​+p11​+p12​+⋯p1a1​​)(p20​+p21​+p22​+⋯p2a2​​)⋯(pk0​+pk1​+pk2​+⋯pkak​​) 互质个数:ϕ(n)=n×p1−1p1×p2−1p2×…×pk−1pk\\phi(n)=n \\times \\frac{p_{1}-1}{p_{1}} \\times \\frac{p_{2}-1}{p_{2}} \\times \\ldots \\times \\frac{p_{k}-1}{p_{k}}ϕ(n)=n×p1​p1​−1​×p2​p2​−1​×…×pk​pk​−1​ 12345678# 约数个数# 约数之和# 1~n中与n互质的数的个数(欧拉函数) 欧拉函数 1234567891011121314151617181920212223# 筛法求欧拉函数n=int(input())def oula(): nums=[1]*(n+1) oula=[0]*(n+1) oula[1]=1 prime=[] for i in range(2,n+1): if nums[i]: prime.append(i) oula[i]=i-1 for j in range(len(prime)): if i*prime[j]&gt;n: break nums[i*prime[j]]=0 if i%prime[j]==0: oula[i*prime[j]]=oula[i]*prime[j] break oula[i*prime[j]]=oula[i]*(prime[j]-1) return sum(oula)print(oula()) 快速幂 12345678910111213n=int(input())for _ in range(n): a,b,c=list(map(int,input().split())) ans=1 while b: if b&amp;1: ans*=a ans%=c a*=a a%=c b//=2 print(int(ans)) 求组合数 数据量 数据范围 方法 复杂度 十万 1&lt;=b&lt;=a&lt;=2000 递推 N2N^2N2 一万 1&lt;=b&lt;=a&lt;=10510^5105 预处理打表 NlogNNlogNNlogN 二十 1&lt;=b&lt;=a&lt;=101810^181018 卢卡斯定理(Lucas) PlogpmPlog_pmPlogp​m 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# 1&lt;=b&lt;=a&lt;=2000n=int(input())MOD=10**9+7C=[[0]*(2005+1) for _ in range(2005+1)]def init(): for i in range(2005+1): for j in range(i+1): if j==0: C[i][j]=1 else: C[i][j]=(C[i-1][j]+C[i-1][j-1])%MODinit()for _ in range(n): a,b=map(int,input().split()) print(C[a][b])# 1&lt;=b&lt;=a&lt;=$10^5$n=int(input())MOD=10**9+7N=100010fact=[0]*(N)infact=[0]*Ndef qmi(a,b,m): res=1 while b : if b&amp;1: res=(res*a)%MOD a=(a*a)%MOD b&gt;&gt;=1 return resdef init(): fact[0]=infact[0]=1 for i in range(1,N): fact[i]=(fact[i-1]*i)%MOD infact[i]=infact[i-1]*qmi(i,MOD-2,MOD)%MODinit()for _ in range(n): a,b=map(int,input().split()) print(fact[a]*infact[a-b]%MOD*infact[b]%MOD)# 1&lt;=b&lt;=a&lt;=$10^18$n=int(input())p=0def qmi(x,q): res=1 while q: if q&amp;1: res=res*x%p x=(x*x)%p q&gt;&gt;=1 return resdef C(a,b): res=1 i=1 j=a for _ in range(1,b+1): res=(res*j)%p res=(res*qmi(i,p-2))%p i+=1 j-=1 return resdef lucas(a,b): if a&lt;p and b&lt;p: return C(a,b) else: return C(a%p,b%p)*lucas(a//p,b//p)%pfor _ in range(n): a,b,p=map(int,input().split()) print(lucas(a,b)) 容斥原理 1234567891011121314151617181920n,m=map(int,input().split())lst=list(map(int,input().split()))res=0for num in range(1,1&lt;&lt;m): t=1 s=0 for i in range(m): if num&gt;&gt;i&amp;1: if t*lst[i]&gt;n: t=-1 break s+=1 t*=lst[i] if t!=-1: if s&amp;1: res+=(n//t) else: res-=(n//t)print(res) 博弈论 12345678910111213141516171819202122232425262728n=int(input())count=list(map(int,input().split()))m=int(input())store=list(map(int,input().split()))memory=[-1]*10005def sg(x): if memory[x]!=-1: return memory[x] mex=set() for i in count: if x&gt;=i: mex.add(sg(x-i)) i=0 while True: if i not in mex: memory[x]=i return memory[x] i+=1res=0for num in store: res^=sg(num)print(&#x27;Yes&#x27; if res else &#x27;No&#x27;) 动态规划 0-1背包 1234567891011121314151617181920212223242526n,m=map(int,input().split())weight=[0]value=[0]for _ in range(n): a,b=map(int,input().split()) weight.append(a) value.append(b)def dp1(): dp=[[0]*1005 for i in range(1005)] for i in range(1,n+1): for j in range(m+1): dp[i][j]=dp[i-1][j] if j&gt;=weight[i]: dp[i][j]=max(dp[i-1][j],dp[i-1][j-weight[i]]+value[i]) print(dp[n][m])def dp2(): dp=[0]*1005 for i in range(1,n+1): for j in range(m,-1,-1): if j&gt;=weight[i]: dp[j]=max(dp[j],dp[j-weight[i]]+value[i]) print(dp[m])dp2() 完全背包 12345678910111213141516171819202122232425262728293031n,m=map(int,input().split())weight=[0]value=[0]for _ in range(n): a,b=map(int,input().split()) weight.append(a) value.append(b)def dp1(): dp=[[0]*1005 for i in range(1005)] for i in range(1,n+1): for j in range(m+1): dp[i][j]=dp[i-1][j] if j&gt;=weight[i]: # dp[i][j]=max(dp[i-1][j],dp[i-1][j-weight[i]]+value[i],dp[i][j-weight[i]]+value[i]) # dp[i][j]=max(dp[i-1][j],dp[i-1][j-weight]+value,dp[i-1][j-2*weight]+2*value,...) # dp[i][j-weight]=max(dp[i-1][j-weight],dp[i-1][j-2*weight]+value,dp[i-1][j-3*weight]+2*value,...) # dp[i][j]=max(dp[i-1][j],dp[i][j-weight]+value) dp[i][j]=max(dp[i-1][j],dp[i][j-weight[i]]+value[i]) print(dp[n][m])def dp2(): dp=[0]*1005 for i in range(1,n+1): for j in range(m+1): if j&gt;=weight[i]: dp[j]=max(dp[j],dp[j-weight[i]]+value[i]) print(dp[m])dp2() 多重背包 1234567891011121314151617181920212223242526272829303132333435363738n,m=map(int,input().split())weight=[0]value=[0]nums=[0]for _ in range(n): a,b,c=map(int,input().split()) weight.append(a) value.append(b) nums.append(c)def dp1(): dp=[[0]*1005 for i in range(1005)] for i in range(1,n+1): for j in range(m+1): dp[i][j]=dp[i-1][j] for k in range(nums[i]+1): if j&lt;k*weight[i]: break dp[i][j]=max(dp[i][j],dp[i-1][j-k*weight[i]]+k*value[i]) # dp[i][j]=max(dp[i-1][j],dp[i-1][j-weight]+value,dp[i-1][j-2*weight]+2*value,...) # dp[i][j-weight]=max(dp[i-1][j-weight],dp[i-1][j-2*weight]+value,dp[i-1][j-3*weight]+2*value,...) # dp[i][j]=max(dp[i-1][j],dp[i][j-weight]+value) # dp[i][j]=max(dp[i-1][j],dp[i][j-weight[i]]+value[i]) print(dp[n][m])def dp2(): dp=[0]*1005 for i in range(1,n+1): for j in range(m+1,-1,-1): for k in range(nums[i]+1): if j&lt;k*weight[i]: break dp[j]=max(dp[j],dp[j-k*weight[i]]+k*value[i]) print(dp[m])dp2() 分组背包 12345678910111213141516171819202122232425262728293031323334n,m=map(int,input().split())from collections import defaultdictweight=defaultdict(list)value=defaultdict(list)for i in range(1,1+n): nums=int(input()) for j in range(nums): a,b=map(int,input().split()) weight[i].append(a) value[i].append(b)def dp1(): dp=[[0]*105 for i in range(10005)] for i in range(1,1+n): for j in range(m+1): dp[i][j]=dp[i-1][j] for k in range(len(weight[i])): if j&gt;=weight[i][k]: dp[i][j]=max(dp[i][j],dp[i-1][j-weight[i][k]]+value[i][k]) print(dp[n][m])def dp2(): dp=[0]*10005 for i in range(1,n+1): for j in range(m+1,-1,-1): for k in range(len(weight[i])): if j&gt;=weight[i][k]: dp[j]=max(dp[j],dp[j-weight[i][k]]+value[i][k]) print(dp[m])dp2() 最长递增子序列 12345678910111213141516171819202122232425262728n=int(input())nums=list(map(int,input().split()))dp=[0]*nans=float(&#x27;-inf&#x27;)for i in range(n): dp[i]=1 for j in range(i): if nums[j]&lt;nums[i]: dp[i]=max(dp[i],dp[j]+1) ans=max(ans,dp[i])print(ans)# ----------import bisectn=int(input())nums=list(map(int,input().split()))INF=float(&#x27;inf&#x27;)length=[INF]*(n+1)ans=1length[0]=-INFfor index,num in enumerate(nums): i=bisect.bisect_left(length,num) length[i]=num ans=max(ans,i)print(ans) 最长公共子序列 1234567891011121314n,m=map(int,input().split())s=&#x27; &#x27;+input()t=&quot; &quot;+input()dp=[[0]*(m+1) for _ in range(n+1)]for i in range(1,n+1): for j in range(1,m+1): if s[i]==t[j]: dp[i][j]=dp[i-1][j-1]+1 else: dp[i][j]=max(dp[i-1][j],dp[i][j-1])print(dp[n][m]) 最短编辑距离 123456789101112131415161718n=int(input())s=&#x27; &#x27;+input()m=int(input())t=&quot; &quot;+input()dp=[[0]*(m+1) for _ in range(n+1)]for i in range(n+1): dp[i][0]=ifor j in range(m+1): dp[0][j]=jfor i in range(1,n+1): for j in range(1,m+1): if s[i]==t[j]: dp[i][j]=min(dp[i-1][j-1],dp[i-1][j]+1,dp[i][j-1]+1) else: dp[i][j]=min(dp[i-1][j-1],dp[i-1][j],dp[i][j-1])+1print(dp[n][m]) 贪心 区间覆盖 123456789101112131415161718192021222324252627282930s,t=map(int,input().split())n=int(input())pair=[]for _ in range(n): a,b=map(int,input().split()) if a&gt;t or b&lt;s: continue pair.append([a,b])pair=sorted(pair)start=send=float(&#x27;-inf&#x27;)count=1i=0while end&lt;t and i &lt;len(pair): a,b=pair[i] if a&lt;=start: end=max(end,b) i+=1 elif a&gt;start: if i==0: break start=end count+=1 if end&gt;=t: break if a&gt;end: end=float(&#x27;-inf&#x27;) breakprint(count if end&gt;=t else -1) 区间分组 1234567891011121314151617n=int(input())pair=[]for _ in range(n): pair.append(list(map(int,input().split())))pair=sorted(pair)import heapqcount=[]for i in range(len(pair)): a,b=pair[i] if len(count)==0 or a&lt;=count[0]: heapq.heappush(count,b) else: heapq.heappop(count) heapq.heappush(count,b)print(len(count)) 最大不相交区间 1234567891011121314151617181920212223n=int(input())pair=[]for _ in range(n): pair.append(list(map(int,input().split())))pair=sorted(pair,key=lambda x:x[1])start=pair[0][0]end=pair[0][1]count=1for i in range(1,len(pair)): a,b=pair[i] if a&lt;=end and b&gt;end: continue elif a&lt;=end and b&lt;=end: continue elif a&gt;end: start=a end=b count+=1print(count) 区间选点 123456789101112131415161718192021222324n=int(input())pair=[]for _ in range(n): pair.append(list(map(int,input().split())))pair=sorted(pair)start=pair[0][0]end=pair[0][1]count=1for i in range(1,len(pair)): a,b=pair[i] if a&lt;=end and b&gt;end: start=a elif a&lt;=end and b&lt;=end: start=a end=b elif a&gt;end: start=a end=b count+=1print(count) 哈夫曼树 123456789101112131415n=int(input())nums=list(map(int,input().split()))import heapqheapq.heapify(nums)ans=0for i in range(n-1): a=heapq.heappop(nums) b=heapq.heappop(nums) ans+=(a+b) heapq.heappush(nums,a+b)print(ans) 耍杂技的牛 12345678910111213141516n=int(input())pair=[]for _ in range(n): a,b=list(map(int,input().split())) pair.append((a,b))pair=sorted(pair,key=lambda x:x[0]+x[1])ans=float(&#x27;-inf&#x27;)weight=0for i in range(len(pair)): temp=weight-pair[i][1] ans=max(ans,temp) weight+=pair[i][0]print(ans)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"2023目标检测CCF-C会议","slug":"学术-垃圾检测会议","date":"2023-06-03T07:02:51.042Z","updated":"2023-11-26T04:44:16.828Z","comments":true,"path":"2023/06/03/学术-垃圾检测会议/","link":"","permalink":"https://gladdduck.github.io/2023/06/03/%E5%AD%A6%E6%9C%AF-%E5%9E%83%E5%9C%BE%E6%A3%80%E6%B5%8B%E4%BC%9A%E8%AE%AE/","excerpt":"","text":"call for paper ASIG 2023 7.15 Asia Symposium on Image and Graphics ICCPR 2023 7.05 International Conference on Computing and Pattern Recognition ICGIP 2023 6.25 International Conference on Graphics and Image Processing ISVC 2023 7.20 International Symposium on Visual Computing ICMV 2023 7.05 International Conference on Machine Vision ICTAI 2023 6.25 -CCFC International Conference on Tools with Artificial Intelligence ICVISP 2023 7.15 International Conference on Vision, Image and Signal Processing","categories":[{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"目标检测会议","slug":"目标检测会议","permalink":"https://gladdduck.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BC%9A%E8%AE%AE/"}]},{"title":"垃圾检测相关论文","slug":"学术-垃圾检测论文总结","date":"2023-04-15T08:51:40.893Z","updated":"2023-11-13T07:05:38.024Z","comments":true,"path":"2023/04/15/学术-垃圾检测论文总结/","link":"","permalink":"https://gladdduck.github.io/2023/04/15/%E5%AD%A6%E6%9C%AF-%E5%9E%83%E5%9C%BE%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/","excerpt":"","text":"数据增强、改进Backbone、改进FPN、改进检测头、改进loss、改进后处理 基础网络 R-CNN B 站论文 12345678# 之前都是人工提取特征,用机器学习分类# 把人工提取特征改成CNN提取特征# 三个模块# 1.候选区域生成(Selective search)(2000个)(统一大小)# 2.特征抽取(扩展16个像素)(AlexNet)# 3.分类,框回归 SPPnet 123456# 用CNN提取整个图的特征，把候选区域映射到特征图上# 最后用空间金字塔(三个层)，一个动态池化层，对候选区域特征图得到固定大小的输出特征，拼接在一起# 还是用svm分类# 不能很好的更新cnn权重 FPN,ASFF,PANet,NASFPN,BiFPN结构 FPN 1612 PANet 1803:FPN是自上而下,首次提出了自下而上 CSPnet 梯度分流,减少计算量和内存 SPP 1406 SPPF Fast R-CNN B 站论文 12345678910111213141516# 针对R-CNN和SPPnet# 多阶段模型,不同的模块都要分别训练# 要把提取到的特征存到磁盘里，再给分类器# 单阶段，不用存特征# 用CNN得到整张图片的特征# 根据候选区域在图片上的位置（输入坐标），利用ROI投影获得候选区域在特征图上的特征# 用ROI池化层（空间金字塔特殊情况，一个层）把候选区域特征转为固定大小的特征图# 两个并行全连接层，分类、预测坐标# 其他验证性实验 # 测试阶段输入图像和候选区域坐标# 候选区域建议是单独的 Faster R-CNN B 站论文 1234567891011# Fast R-CNN还是需要单独的模块生成候选区域投影# 解决候选区域选择的问题# RPNs和特征提取层 共享卷积层# 用n*n的滑动窗口在特征图上提取，传给small network 判断是否能生成候选区域# 使用三个尺度（128，256，512 1:1,1:2,2:1，九个框）生成k个anchor boxes，（根据数据集设置框的大小），非极大值抑制# 与标注狂IOU值最大，与标注框IOU值大于0.7 分给正标签# 交替训练 Mask R-CNN 1234567891011121314# Faster R-CNN的RoI Pooling 是直接取整,会导致实例偏移,对于像素级 不可取# 把候选区域的特征图转换为固定大小的ROI feature时 也会取整# 两次误差# 骨干网络换成ResNet-FPN# Mask R-CNN使用双线性插值解决缩放的问题# 增加MASK 分支,三路并行,MASK head两种实现 1.ResNet 2.ResNet+FPN 变成K*M*M # K*M*M 大小,K个类别# 与FCN方法是不同，FCN是对每个像素进行多类别softmax分类，然后计算交叉熵损失，这种做法是会造成类间竞争的 论文 Analysis of Object Detection Performance Based on Faster RCNN 基于Faster R-CNN的目标检测性能分析 介绍了R-CNN-&gt;Fast R-CNN-&gt; Faster R-CNN的变化过程 Faster R-CNN的大概结构 对比三个模型在不同数据集上的效果 End-to-End Object Detection with Transformers 里程碑:端到端的方法,不用非极大值抑制 变成集合预测问题 CNN抽取特征－＞送入Transformer学习全局特征-&gt;输出100个框-&gt;二分图loss匹配真实框-&gt;计算loss 问题:小目标,训练epoch长 EfficientDet: Scalable and Efficient Object Detection 新的结构,多层特征融合 Deformable DETR: Deformable Transformers for End-to-End Object Detection 解决DETR的两个问题 12341.不用TRansformer原有的自注意力,改为可变注意力(可变卷积变来的)一个像素向量z根据偏移量选择四个其他像素,然后一层Liner得到权重,和选出的像素进行运算更新2.多尺度的注意力机制(Mulit-Scale),不同尺度的特征图上做,多头可变注意力机制,然后相加 ★Deep learning-based waste detection in natural and urban environments 传统图像分类网络:ResNet,DenseNet,EfficientNet,EfficientNet-B2,EfficientNetv2 经典目标检测网络:R-CNN,Fast R-CNN ,Faster R-CNN,SSD,Yolo,DETR,Deformable DETR,EfficientDet 垃圾数据集 对所有数据集进行处理 对比模型:Efficentdet, DETR和Mask RCNN，发现Efficentdet能产生最高的mAP 一个目标检测网络EfficientDet-D2,一个图像分类网络EfficientNet-B2 训练步骤:分开训练,先训练目标检测网络,再训练图像分类网络 问题:小目标,推理时间 Garbage object detection method based on improved Faster R-CNN 对Faster R-CNN进行了两点改进: 1.基础网络从VGG16改成了ResNet50 2.增加了FPN特征金字塔 3.将原本的ROI改成ROI Align(Mask R-CNN) 4.修改了RPN结构参数 基于改进 Faster R⁃CNN 的垃圾检测与分类方法 1234567891011# 把Faster R-CNN 的网络换成了ResNet50# 把非极大值抑制（NMS）换成了Soft-NMS# 对比实验把VGG16的7*7 5*5 换成了叠加的3*3# 五折交叉验证# 用FasterR-CNN相同的交替训练训练# 73-&gt;81% NMS:0,IoU(M,bi)≥NtNMS:0,IoU(M,b_i) \\geq N_tNMS:0,IoU(M,bi​)≥Nt​ Soft−NMS:si(1−IoU(M,bi)),IoU(M,bi)≥NtSoft-NMS:s_i(1-IoU(M,b_i)),IoU(M,b_i) \\geq N_tSoft−NMS:si​(1−IoU(M,bi​)),IoU(M,bi​)≥Nt​ Object detection for autonomous trash and litter collection(毕业论文) 针对垃圾收集机器人,管道方法:从数据收集到预测出结果的一系列 介绍:在机器人上部署最先进的目标检测模型 背景:深度学习(MLP,CNN,YOLO),目标检测,垃圾检测数据集 管道方法组成(收集,预处理,增强,训练,验证) 自己的管道定义与实现(tile数据增强方法,光强归一化,不同模型) 结果与分析 Future work 123456789101. 根据数据集中物体大小不同使用不同模型,参数2. 专门为小目标设计一个检测器(Yolo-z)3. 无监督学习,创建全功能检测器4. 对图像的不同位置使用不同的检测器5. 稍微扩大边界框,获取更多上下文信息6. 利用GAN生成更多的类别均衡数据集7. 开发减少假阳性数量的方法8. 集成学习,使用多个较小的模型,加权盒融合9. 更多的数据增广10. 统一处理类别不可知的垃圾,避免对垃圾进行分类 Tiny Object Detection based on YOLOv5 1234567891011121. 生成4幅特征图像进行融合2. 在Neck部分,使用FPN和PANet对特征进行融合3. 使用GIoU损失函数替换IoU4. 用SWISH激活函数替换ReLU5. 马赛克数据增强和学习率余弦退火# 自己数据集上# map@50: 45+ =&gt; 55+# mAP@0.5:0.95 : 25+ =&gt; 30+# recall,precision,.... YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles 在自动驾驶领域,对小物体检测和检测速度要求很高 很多模型没有修改模型的架构,修改的不痛不痒 12345678910111213141516171819202122修改:1. ResNet50与DenseNet作为主干网络的比较2. PanNet换成FPN和BiFPN3. 对head部分的输入,将neck不同的特征图送入head(最有效)结果分析:1.DenseNet效果比ResNet好,这可能是由于网络深度不够，无法获得ResNet主干的好处，而DenseNet在保存特征图的细节方面做得很好2. 在小模型上FPN比BiFPN效果好,因为较简单的模型受益于保持特征图相对不变，而其他比例需要额外的步骤来适应添加的特征图处理，并最终优于前者。但都优于传统模型.3. 特征图的修改最有效果,因为在头部包含更高分辨率的特征图后，小对象最终会占用更多像素，因此具有更大的影响，而不是在主干的卷积阶段丢失。同样，删除原始较低分辨率的要素特征图会减少所需的处理量，并防止模型抵消较高分辨率贴图提供的细节级别。4. 小模型anchor少比较好,大模型多了好,因为更复杂或更深入的模型确实可能受益于额外的锚，或者换句话说，可能更有能力利用额外锚提供的细节5.其他学习率,深度宽度影响, Accuracy and Efficiency Comparison of Object Detection Open-Source Models 1234自己构建的杂草检测数据集,使用多种数据增强方法使用EfficientDet,Faster R-CNN,YOLOv5,Detectron2 四个开源模型实验 The Object Detection of Underwater Garbage with an Improved YOLOv5 Algorithm 123456使用K-means对anchor进行聚类，产生九个新的框大小将IoU或者GIoU损失函数改为CIoU损失函数没有使用数据增强 An Irregularly Dropped Garbage Detection Method Based on Improved YOLOv5s 1234567CBAM 注意力模块EIoU LossDeepSort 过滤静态物品--只选取了小部分垃圾种类 Towards Lightweight Neural Networks for Garbage Object Detection 12345678910111213141516Yolov3用DarkNet53做分类器Yolov4的backbone是CSPDarkNet53对CSPResNet优化得到DCSPResNet对结构进行替换轻量型Yolov4 的1/10 的参数激活函数的修改 SiLU LReLUDCSPDarkNet+膨胀卷积/膨胀变形卷积使用膨胀变形卷积对CSPResNet结构进行了改进没有考虑垃圾堆场景不能在价格较低、性能较低的CPU设备上实时运行对于目标遮挡和相对少见的目标识别，YOLOG的识别效果较差 Real-Time Garbage Object Detection With Data Augmentation and Feature Fusion Using SUAV Low-Altitude Remote Sensing Images 123456修改Yolov4使用不同结构FPN,ASFF,PANet,NASFPN,BiFPN加上数据增强 Yolov5 Yolox Yolov3 1234提出了Darknet53修修补补 Yolov4 Yolov4分析 1234567891011针对input,backbone,neck,head选择不同的结构Bag of freebies:在训练时的技巧不影响推测时间数据增广,损失函数,归一化Bag of special:应用到模型中的技巧特征聚合结构块,注意力机制,激活函数,NMS,骨干网络选择检测头继续用yolov3 Yolov5 yolov5分析 123456789101112131415161718192021222324252627282930313233343536373839# YOLOv5 v6.0 backbonebackbone: # [from, number, module, args] [[-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2 [-1, 1, Conv, [128, 3, 2]], # 1-P2/4 [-1, 3, C3, [128]], [-1, 1, Conv, [256, 3, 2]], # 3-P3/8 [-1, 6, C3, [256]], [-1, 1, Conv, [512, 3, 2]], # 5-P4/16 [-1, 9, C3, [512]], [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32 [-1, 3, C3, [1024]], [-1, 1, SPPF, [1024, 5]], # 9 ]# YOLOv5 v6.0 headhead: [[-1, 1, Conv, [512, 1, 1]], [-1, 1, nn.Upsample, [None, 2, &#x27;nearest&#x27;]], [[-1, 6], 1, Concat, [1]], # cat backbone P4 [-1, 3, C3, [512, False]], # 13 [-1, 1, Conv, [256, 1, 1]], [-1, 1, nn.Upsample, [None, 2, &#x27;nearest&#x27;]], [[-1, 4], 1, Concat, [1]], # cat backbone P3 [-1, 3, C3, [256, False]], # 17 (P3/8-small) [-1, 1, Conv, [256, 3, 2]], [[-1, 14], 1, Concat, [1]], # cat head P4 [-1, 3, C3, [512, False]], # 20 (P4/16-medium) [-1, 1, Conv, [512, 3, 2]], [[-1, 10], 1, Concat, [1]], # cat head P5 [-1, 3, C3, [1024, False]], # 23 (P5/32-large) [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5) ] 开源复现 FasterR-CNN 模型链接 123456789101112131415161718192021222324252627282930313233343536373839404142434445461. 下载到Google Colab2. 安装依赖!pip install ipdb visdom torchnet fire3. 修改代码data\\voc_dataset.py中的VOC_BBOX_LABEL_NAMES修改成自己类别utils\\vis_tool.py 中的VOC_BBOX_LABEL_NAMES修改成自己类别4. 源代码直接运行会报错raise ValueError(&#x27;need at least one array to stack&#x27;)ValueError: need at least one array to stack因为只训练有物体的图片,在data\\voc_dataset.py76行替换如下&#x27;&#x27;&#x27;id_list_file = os.path.join(data_dir, &#x27;ImageSets/Main/&#123;0&#125;.txt&#x27;.format(split))id_list_read = [id_.strip() for id_ in open(id_list_file)]id_list = list()for i in id_list_read: obj = ET.parse(os.path.join(data_dir, &#x27;Annotations&#x27;, i + &#x27;.xml&#x27;)) if obj.findall(&#x27;object&#x27;): id_list.append(i)self.ids = id_list&#x27;&#x27;&#x27;5.在Google Colab运行不能可视化会报错! npm install -g localtunnelget_ipython().system_raw(&#x27;python3 -m pip install visdom&#x27;)get_ipython().system_raw(&#x27;python3 -m visdom.server -port 8097 &gt;&gt; visdomlog.txt 2&gt;&amp;1 &amp;&#x27;)get_ipython().system_raw(&#x27;lt --port 8097 &gt;&gt; url.txt 2&gt;&amp;1 &amp;&#x27;)在运行,打开url.txt 查看可视化的窗口code_root/└── data/ └── VOC2007/ ├── Annotations/ ├── JPEGImages/ └── ImageSets/ └── Main/ ├── test.txt ├── train.txt ├── val.txt └── trainval.txt EfficientDet 模型链接 12345678910111213141516171819202122# 运行环境Google Colab1.下载到工作区2.安装依赖3. 代码:effdet\\data\\parsers\\parser_voc.py 文件中的DEFAULT_CLASSES改成自己的类别名称4.! python ..../efficientdet-pytorch-master/train.py /content --dataset VOC2007 --num-classes 自己的类别 # JPEGImages:所有图片 Annotations:所有xml标注 txt:用作训练测试的文件名,不带后缀code_root/└── data/ └── VOC2007/ ├── Annotations/ ├── JPEGImages/ └── ImageSets/ └── Main/ ├── test.txt ├── train.txt ├── val.txt └── trainval.txt Deformable-DETR 模型链接 1234567891011121314151617181920212223242526272829303132333435363738394041# 运行环境Google Colab1.下载到工作区2.安装相关依赖3.!python ..(绝对路径..)/Deformable-DETR-main/models/ops/setup.py build install (用的jupyter)(可以用ops文件夹下的test.py测试环境是否正确)#错误名称:找不到....h文件如果报错,添加 export CUDA_PATH=/usr/local/cuda-你的版本# 错误名吧这一段修改到setup.py里面extra_compile_args[&quot;nvcc&quot;] = [ &quot;-DCUDA_HAS_FP16=1&quot;, &quot;-D__CUDA_NO_HALF_OPERATORS__&quot;, &quot;-D__CUDA_NO_HALF_CONVERSIONS__&quot;, &quot;-D__CUDA_NO_HALF2_OPERATORS__&quot;, &quot;-arch=sm_60&quot;, &quot;-gencode=arch=compute_60,code=sm_60&quot;, &quot;-gencode=arch=compute_61,code=sm_61&quot;, &quot;-gencode=arch=compute_70,code=sm_70&quot;, &quot;-gencode=arch=compute_75,code=sm_75&quot;,]5.代码:...../Deformable-DETR-main/util/misc.py 里面的# float(torchvision.__version__[:3]) &lt; 0.5/0.7 需要改动,因为对于0.10.x版本的不适用,自己改成了# float(torchvision.__version__[:4]) &lt; 0.05:否则报错cannot import name &#x27;_NewEmptyTensorOp&#x27; from &#x27;torchvision.ops.misc&#x27;6.! python ...../Deformable-DETR-main/main.py --coco_path ..../coco # train2017:训练图片 val2017:测试图片 annotations两个文件下面的标注图片code_root/└── data/ └── coco/ ├── train2017/ ├── val2017/ └── annotations/ ├── instances_train2017.json └── instances_val2017.json YOLOv5 模型链接 1234567# 运行环境Google Colab1.下载到工作区2.安装相关依赖3.指定数据路径 运行 YOLOv8 模型链接 1234567# 运行环境Google Colab1.!pip install ultralytics==8.0.202.安装相关依赖3.指定数据路径 运行","categories":[{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"垃圾检测","slug":"垃圾检测","permalink":"https://gladdduck.github.io/tags/%E5%9E%83%E5%9C%BE%E6%A3%80%E6%B5%8B/"}]},{"title":"Involution卷积理解","slug":"学术-图像处理","date":"2023-04-11T12:46:41.871Z","updated":"2023-11-26T05:18:03.146Z","comments":true,"path":"2023/04/11/学术-图像处理/","link":"","permalink":"https://gladdduck.github.io/2023/04/11/%E5%AD%A6%E6%9C%AF-%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/","excerpt":"","text":"一种介乎CNN和selfAttention之间的操作 将空间不变性(平移不变性)与通道变换性 交换了 普通卷积 好处 1.不同位置之间重用卷积核,减少参数 2.不同通道代表不同含义的信息 缺点 1.通道冗余 2.卷积的接受范围 3.不能根据输入自适应卷积核大小 Involution 空间互异,通道不变 在通道之间共享卷积核,不同位置卷积核不同 Involution 卷积核大小 H×W×K×K×GH×W×K×K×GH×W×K×K×G GGG是group KKK是邻域 表示:对于HW(核的HW是根据输出特征图大小计算得到)个像素点,每个像素点都有一个K*K大小的卷积核,把C个通道分成G组,组内的通道共享卷积核 对于一个像素点 1×1×C1×1×C1×1×C -(两层线性变换)&gt; 1×1×K2×G1×1×K^2×G1×1×K2×G -(Reshape)&gt; 1×1×K×K×G1×1×K×K×G1×1×K×K×G -(注意力机制)&gt; 1×1×K×K×C1×1×K×K×C1×1×K×K×C -(聚合)&gt; 1×1×C1×1×C1×1×C 与自注意力的区别 是一种更加简洁通用的自注意力机制 自注意力公式: Q=XWQQ=XW^QQ=XWQ, K=XWKK=XW^KK=XWK ,V=XWVV=XW^VV=XWV Involution: 通用描述: Hi,j=(XWQ)(XWK)H_{i,j}=(XW^Q)(XW^K)Hi,j​=(XWQ)(XWK) 多头注意力头数&lt;-&gt;通道组数 相似矩阵:QKQKQK&lt;-&gt;核:H 位置编码&lt;-&gt;生成的核有序的","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"AcWing每日一题","slug":"算法-AcWing每日一题","date":"2023-04-06T11:15:17.545Z","updated":"2023-04-22T10:51:26.840Z","comments":true,"path":"2023/04/06/算法-AcWing每日一题/","link":"","permalink":"https://gladdduck.github.io/2023/04/06/%E7%AE%97%E6%B3%95-AcWing%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/","excerpt":"","text":"前缀和 将区间求和求差,改为两个值的运算 差分 前缀和的逆运算,可以在O(1)O(1)O(1)的时间内更新区间 二分 下标二分 答案二分 注意边界 双指针 区间问题,最大最小值,但是左指针是递增(单调性) 递推 根据规律或者推断,找解 递归 树的遍历 并查集 集合划分与合并 哈希 重复值或者出现的次数 单调队列 之前或者之后的最大最小值 KMP 字符串匹配 Trie 字典树,最大的异或对 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;using namespace std;int tire[3100005][3];int index=1;void build(int num)&#123; int p=0; for(int i=31;i&gt;=0;i--)&#123; int temp=(num&gt;&gt;i)&amp;1; if(tire[p][temp]==0)&#123; tire[p][temp]=index++; &#125; p=tire[p][temp]; &#125;&#125;int query(int num)&#123; int p=0,ans=0; for (int i=31;i&gt;=0;i--)&#123; int temp=(num&gt;&gt;i)&amp;1; if(tire[p][!temp])&#123; ans+=(1&lt;&lt;i); p=tire[p][!temp]; &#125;else&#123; p=tire[p][temp]; &#125; &#125; return ans;&#125;int main()&#123; int n; scanf(&quot;%d&quot;,&amp;n); int ans=-1; for(int i=0;i&lt;n;i++)&#123; int t; scanf(&quot;%d&quot;,&amp;t); build(t); ans=max(ans,query(t)); &#125; cout&lt;&lt;ans&lt;&lt;endl; return 0;&#125; BFS DFS 拓扑排序 Dijkstra Dijkstra算法是一种广泛使用的最短路径算法，可以求解从单个源节点到其他所有节点的最短路径。其基本思路是维护两个集合，一个集合存储已经确定最短路径的节点，另一个集合存储未确定路径的节点。初始时，只有源节点在已确定的路径集合中，其他节点在未确定路径的集合中。每次从未确定节点中选择距离源节点最近的节点加入到已确定路径的集合中，更新该节点到其他未确定节点的最短距离。重复此步骤直到已确定的路径集合中包含所有节点。 12345678910111213141516171819202122232425262728293031323334353637383940import heapqdef dijkstra(graph): n = len(graph) dist = [float(&#x27;inf&#x27;)] * (n) dist[0] = 0 visited = set() min_heap = [(0, 0)] for _ in range(n): # 找到还没确定的里面距离最小的 if len(min_heap)==0: break temp, min_index = heapq.heappop(min_heap) # 已经确定了 visited.add(min_index) for v in range(n): if v not in visited and graph[min_index][v] &gt; 0: # graph[min_index][v] &gt; 0 表示存在这个路径 new_dist = dist[min_index] + graph[min_index][v] if dist[v] &gt; new_dist: # 表示值得被更新 dist[v] = new_dist heapq.heappush(min_heap, (dist[v], v)) return distn,m=list(map(int,input().split()))graph = [[0]*(n+2) for i in range(n+2)]for i in range(m): a,b=list(map(int,input().split())) graph[a-1][b-1]=1 graph[b-1][a-1]=1ans=dijkstra(graph) for item in ans[1:n]: print(item) 质数问题 筛质数 1.埃氏筛 O(NloglogN)O(NloglogN)O(NloglogN) 可优化 123456789101112const int N=1e6+5;bool vis[N];void esieve(int n)&#123;//标记0~n的数字的质数状态,并统计质数个数 vis[0]=vis[1]=1;//0，1属于非质数 for(int i=2;i&lt;=n;i++)&#123;//标记剩下的2~n的数字的状态 if(vis[i]==0)&#123;//判断i是不是质数 思考：为什么这样就能判断i是质数？ for(int j=2*i;j&lt;=n;j+=i)&#123;//遍历范围内的i的倍数 vis[j]=1;//将倍数标记为1（非质数） &#125; &#125; &#125;&#125; 优化后 123456789101112const int N=1e6+5;bool vis[N];void esieve(int n)&#123;//标记0~n的数字的质数状态,并统计质数个数 vis[0]=vis[1]=1; for(int i=2;i*i&lt;=n;i++)&#123;//标记剩下的2~n的数字的状态 优化：到根号n即可停止 if(vis[i]==0)&#123;//判断i是不是质数 for(int j=i*i;j&lt;=n;j+=i)&#123;//遍历范围内的i的倍数 从i*i开始，减少重复筛选 vis[j]=1;//将倍数标记为1（非质数） &#125; &#125; &#125;&#125; 2.欧拉筛 O(N)O(N)O(N) 线性筛 12345678910111213141516171819const int N=1e8+5;bool vis[N];//标记数组int prime[N/10];//质数表，存放质数int erla(int n)&#123; vis[0]=vis[1]=1;//0.1不是质数 int cnt=0;//统计质数的个数 for(int i=2;i&lt;=n;i++)&#123; if(!vis[i])&#123;//判断i是不是质数 prime[cnt++]=i;//将质数存到质数表中 &#125; //遍历质数表 新序列 prime[j]*i for(int j=0;prime[j]*i&lt;=n&amp;&amp;j&lt;cnt;j++)&#123; vis[prime[j]*i]=1;//标记组成的序列为非质数 if(i%prime[j]==0) break;//prime[j]是i的最小质因子 ，不能继续组合，避免重复 &#125; &#125; return cnt;//返回质数个数&#125; 3.欧拉函数 对正整数n欧拉函数是小于或等于n的正整数中与n互质的数的数目 12345678910111213141516171819202122232425bool vis[N];//标记数组int prime[N];//质数表，存放质数int phi[N];int erla(int n)&#123; vis[0]=vis[1]=1;//0.1不是质数 int cnt=0;//统计质数的个数 phi[1]=1;//1的欧拉函数值是1 for(int i=2;i&lt;=n;i++)&#123; if(!vis[i])&#123;//判断i是不是质数 prime[cnt++]=i;//将质数存到质数表中 phi[i]=i-1;//性质1 &#125; //遍历质数表 新序列 prime[j]*i for(int j=0;prime[j]*i&lt;=n&amp;&amp;j&lt;cnt;j++)&#123; vis[prime[j]*i]=1;//标记组成的序列为非质数 if(i%prime[j]==0)&#123; phi[i*prime[j]]=prime[j]*phi[i];//性质2 break;//prime[j]是i的最小质因子 ，不能继续组合，避免重复 &#125;else&#123; phi[i*prime[j]]=(prime[j]-1)*phi[i];//性质3 &#125; &#125; &#125; return cnt;//返回质数个数&#125; 最大公约数 最近公共祖先 排列组合","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"算法刷题杂题","slug":"算法-刷题杂题","date":"2023-04-03T09:24:36.314Z","updated":"2023-11-26T05:33:12.207Z","comments":true,"path":"2023/04/03/算法-刷题杂题/","link":"","permalink":"https://gladdduck.github.io/2023/04/03/%E7%AE%97%E6%B3%95-%E5%88%B7%E9%A2%98%E6%9D%82%E9%A2%98/","excerpt":"","text":"A 题目连接 n个人,从第一个开始传球,经过m次回到第一个人手里的方法数 做题思路:笨比方法:1作为root,建了棵二叉树,每次分裂出两个节点,然后再dfs,搜索路径数量(叶节点是1),超内存了 正确思路:dp[i][j] 表示传了i次在j手里的可能,判断一下1和n的边界情况 12345678910111213141516n,m=input().split()n=int(n)m=int(m)dp=[[0 for _ in range(n)] for _ in range(m+1)]# dp[i][j] 穿了i次在j手里的可能dp[0][0]=1for i in range(1,m+1): for j in range(n): if j==n-1: dp[i][j]=dp[i-1][0]+dp[i-1][j-1] elif j==0: dp[i][j]=dp[i-1][n-1]+dp[i-1][j+1] else: dp[i][j]=dp[i-1][j+1]+dp[i-1][j-1] print(dp[m][0]) B 题目连接 n对果子,一堆堆合并,果子的数量是消耗的体力,求n堆合成一堆的最小体力 思路:哈夫曼树 1234567891011121314151617import heapqn=int(input())nums=[]numstr=input().split()for i in range(n): heapq.heappush(nums,int(numstr[i])) ans=0while len(nums)!=1: a=heapq.heappop(nums) b=heapq.heappop(nums) temp=a+b ans+=temp heapq.heappush(nums,temp) print(ans) C 题目链接 一个矩阵,每个点有对应的值,从(0,0)走到(n,n),走两次,每次走过之后会把矩阵的值清零,问这两次能得到的最大值 思路:笨比方法:以为两次BFS就行,每次都拿到最大的,这样有可能本来上三角一次,下三角一次最大,但是第一次走最大路径把这个打破了,会导致上下三角有的没拿到 正确思路:f[i][j][h][k];表示两条路同时走，第一条路径走到(i,j)时，第二条走到（h,k）时的最大数字和； 123456789101112131415161718192021222324252627n=int(input())m=[[0]*(n+1) for _ in range(n+1)]for _ in range(n*n): x,y,v=list(map(int,input().split())) if v==0 and x==0 and y==0: break m[x][y]=vdp=[[[[0]*(n+1) for _ in range(n+1)] for _ in range(n+1)] for _ in range(n+1)]for i in range(1,n+1): for j in range(1,n+1): for h in range(1,n+1): for k in range(1,n+1): dp[i][j][h][k]=max( dp[i-1][j][h-1][k], dp[i-1][j][h][k-1], dp[i][j-1][h-1][k], dp[i][j-1][h][k-1] )+m[i][j]+m[h][k] if i==h and j==k: dp[i][j][h][k]-=m[h][k] print(dp[n][n][n][n]) D 题目链接 一个数是两个质数的乘积,返回较大的质数 80%思路:从nnn到n0.5n^{0.5}n0.5遍历,余数为0就返回,80莫名其妙(答案错误),笨比,写的是n0.5n^{0.5}n0.5到nnn遍历了 正确思路:从222到n0.5n^{0.5}n0.5,余数为0,返回商 1234567n=int(input())right=int(n**0.5)for i in range(2,right+1): if n%i==0: print(n//i) break E 题目链接\\ 难,略 F 题目链接 n种不同面额的货币,但是有的面值能表示,有的面值不能表示,求最少只要几种货币,能和n种表示的面值一样 80%思路:如果n里面有的数能够被其他数表示,这个就是多余的,可以去掉(???抄别人100的代码也是80),判断一个数能不能被其他的表示有点背包的感觉 1234567891011121314151617181920212223T=int(input())# n=100def check(x,lst): if len(lst)==0: return False dp=[False]*(x+1) dp[0]=True for num in lst: for index,item in enumerate(dp): if index-num&gt;=0: dp[index]|=dp[index-num] if dp[x]: return True return dp[x]for _ in range(T): n=int(input()) nums=list(map(int,input().split())) nums.sort(reverse=True) temp=0 for index,item in enumerate(nums): if check(item,nums[index+1:]): temp+=1 print(n-temp) G 题目链接 n个囚犯,两个犯人中间有怨气值,把他们分成两个监狱,求一个监狱内怨气值最大的,如果监狱内的犯人之间没有怨气值,返回0 思路:不会,随便想的,想到并查集了,但是感觉更像二分图匹配,没做出来,0蛋 正确思路:并查集,但是不是两个有怨气的犯人之间,如果A和B有怨气,B和C有怨气,那么应该把A和C归并,B单独,先按照怨气值从大到小排序,如果这两个人在一个集里面了,那就说明不可避免了, 1234567891011121314151617181920212223242526272829303132333435363738394041n,m=input().split()n=int(n)m=int(m)parent=[-1]*(n+1)def findx(x): if parent[x]!=-1: return findx(parent[x]) return xdef merge(a,b): a_p=findx(a) b_p=findx(b) if a_p!=b_p: parent[a_p]=b_pvalues=[]for _ in range(m): a,b,c=list(map(int,input().split())) values.append((a,b,c)) values=sorted(values,key=lambda x:x[2],reverse=True)disfriend=[0]*(n+1)def solve(): for a,b,c in values: if findx(a)==findx(b): print(c) return True if disfriend[a]==0: disfriend[a]=b else: merge(disfriend[a],b) if disfriend[b]==0: disfriend[b]=a else: merge(disfriend[b],a)if not solve(): print(0) H 题目链接 在有向图G中，每条边的长度均为1，现给定起点和终点，请你在图中找一条从起点到终点的路径，该路径满足以下条件： 1．路径上的所有点的出边所指向的点都直接或间接与终点连通。 2．在满足条件1的情况下使路径最短。 难,略 建双向边，对于正边和反边我们标记一下即可。 那么建完边后我们先从终点bfs一遍，只跑反向边，对于每个遍历到的边进行标记，这样我们就可以找出不能直接或间接到达终点的点。 得到这些点后，我们再遍历这些点的反向边的出边，将与这些点相连的点进行标记。 标记完后我们剩下的没有被第二次标记的点就是可以走的点。这时我们再从起点bfs一遍，只跑正向边，且不走被第二次标记过的点，那么第一次到达终点的时候就是可到达的最短路。 背包问题 背包问题 0-1背包 123456789for (int i = 1; i &lt;= N; ++i) &#123; for (int j = 0; j &lt;= V; ++j) &#123; backpack[i][j] = backpack[i - 1][j]; if (j &gt;= cap[i]) &#123; backpack[i][j] = Math.max(backpack[i][j], backpack[i - 1][j - cap[i]] + val[i]); &#125; &#125;&#125; 多重背包 1234567891011for (int i = 1; i &lt;= N; ++i) &#123; for (int j = 0; j &lt;= V; ++j) &#123; backpack[i][j] = backpack[i - 1][j]; for (int k = 1; k &lt;= num[i]; ++k) &#123; if (j &gt;= k * cap[i]) &#123; backpack[i][j] = Math.max(backpack[i][j], backpack[i - 1][j - k * cap[i]] + k * val[i]); &#125; &#125; &#125;&#125; 完全背包 12345678for (int i = 1; i &lt;= N; ++i) &#123; for (int k = 1; k * cap[i] &lt;= V; ++k) &#123; for (int j = V; j &gt;= cap[i]; --j) &#123; f[j] = Math.max(f[j], f[j - cap[i]] + val[i]); &#125; &#125;&#125; 动态规划补充 从集合的角度 有限集中的最优化 动态规划 01背包 完全背包 `` 最长公共子序列 字符串编辑距离 最短路径 快速幂 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 矩阵相乘def mul(A, B): # A:m*n, B:n*p 结果m*p m = len(A) n1 = len(A[0]) n2 = len(B) p = len(B[0]) if n1 !=n2: return n = n1= n2 ans = [] # 初始化ans for i in range(m): ans.append([0]*p) # 都用同一个变量row = [0]*p，会同时修改，所以不用同一个变量 for i in range(m): for j in range(p): temp = 0 for q in range(n): temp += A[i][q]*B[q][j] temp%=9999991 ans[i][j] = temp return ans def fib(n): if n==0: return 0 elif n==1 or n==2: return 1 base = [[1,1],[1,0]] n = n-2 ans = [[1,0],[0,1]] while n: if n&amp;1: ans = mul(base,ans) base = mul(base,base) n = n&gt;&gt;1 # temp=mul([[1,1]],ans) # print(temp[0][0],ans[0][0] + ans[0][1]) return ans[0][0] + ans[0][1] if __name__==&#x27;__main__&#x27;: # 前20个斐波那契数列 # 0是第0个 # 2023040313301730 print(fib(2023040313301730)%9999991) # for i in range(20230403%1330173): # print(fib(i),end=&#x27; &#x27;) 真题C语言网 真题官网","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"python标准库-3","slug":"笔记-python3lib-3","date":"2023-04-02T03:24:30.616Z","updated":"2023-04-02T03:25:48.386Z","comments":true,"path":"2023/04/02/笔记-python3lib-3/","link":"","permalink":"https://gladdduck.github.io/2023/04/02/%E7%AC%94%E8%AE%B0-python3lib-3/","excerpt":"","text":"网络通信 ipaddress 12import ipaddress# ipaddress:解析ip地址 socket 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import socket# 网络通信# 多线程网络服务&#x27;&#x27;&#x27;服务器端&#x27;&#x27;&#x27;from socket import socket, SOCK_STREAM, AF_INETfrom base64 import b64encodefrom json import dumpsfrom threading import Threaddef main(): # 自定义线程类 class FileTransferHandler(Thread): def __init__(self, cclient): super().__init__() self.cclient = cclient def run(self): my_dict = &#123;&#125; my_dict[&#x27;filename&#x27;] = &#x27;guido.jpg&#x27; # JSON是纯文本不能携带二进制数据 # 所以图片的二进制数据要处理成base64编码 my_dict[&#x27;filedata&#x27;] = &#x27;data&#x27; # 通过dumps函数将字典处理成JSON字符串 json_str = dumps(my_dict) # 发送JSON字符串 self.cclient.send(json_str.encode(&#x27;utf-8&#x27;)) self.cclient.close() # 1.创建套接字对象并指定使用哪种传输服务 server = socket() # 2.绑定IP地址和端口(区分不同的服务) server.bind((&#x27;localhost&#x27;, 5566)) # 3.开启监听 - 监听客户端连接到服务器 server.listen(512) print(&#x27;服务器启动开始监听...&#x27;) while True: client, addr = server.accept() # 启动一个线程来处理客户端的请求 FileTransferHandler(client).start()if __name__ == &#x27;__main__&#x27;: main()&#x27;&#x27;&#x27;客户端&#x27;&#x27;&#x27;from socket import socketfrom json import loadsfrom base64 import b64decodedef main(): client = socket() client.connect((&#x27;localhost&#x27;, 5566)) # 定义一个保存二进制数据的对象 in_data = bytes() # 由于不知道服务器发送的数据有多大每次接收1024字节 data = client.recv(1024) while data: # 将收到的数据拼接起来 in_data += data data = client.recv(1024) # 将收到的二进制数据解码成JSON字符串并转换成字典 # loads函数的作用就是将JSON字符串转成字典对象 my_dict = loads(in_data.decode(&#x27;utf-8&#x27;)) print(my_dict) print(&#x27;图片已保存.&#x27;)if __name__ == &#x27;__main__&#x27;: main() selectors 123import selectors# io多路复用抽象 select 12import select# 高效等待IO socketserver 12import socketserver# 创建网络服务器 互联网 urllib.parase 123from urllib import parase# 分解url urllib.request 1234from urllib import request# 根据url获取web资源# get/post/参数/头文件/ urllib.robotparser 123456789101112131415161718192021222324252627from urllib import robotparser# 获得网页的robots.txt文件,测试是否允许爬取页面from urllib import parsefrom urllib import robotparserAGENT_NAME = &#x27;Googlebot&#x27;URL_BASE = &#x27;https://zhuanlan.zhihu.com/&#x27;parser = robotparser.RobotFileParser()parser.set_url(parse.urljoin(URL_BASE, &#x27;robots.txt&#x27;))parser.read()PATHS = [ &#x27;/&#x27;, &#x27;/search-special&#x27;, &#x27;/login&#x27;, &#x27;/s&#x27;,]for path in PATHS: print(&#x27;&#123;!r:&gt;6&#125; : &#123;&#125;&#x27;.format( parser.can_fetch(AGENT_NAME, path), path)) url = parse.urljoin(URL_BASE, path) print(&#x27;&#123;!r:&gt;6&#125; : &#123;&#125;&#x27;.format( parser.can_fetch(AGENT_NAME, url), url)) print() True : / True : https://zhuanlan.zhihu.com/ False : /search-special False : https://zhuanlan.zhihu.com/search-special False : /login False : https://zhuanlan.zhihu.com/login True : /s True : https://zhuanlan.zhihu.com/s base64 12345678910111213import base64# 将二进制数据转换为适合使用文本协议传输的ASCII的一个子集initial_data=&#x27;Copyright (c) 2008 Doug Hellmann All rights reserved.&#x27;print(f&#x27;initial_data:&#123;initial_data&#125;&#x27;)byte_string = initial_data.encode(&#x27;utf-8&#x27;)encoded_data = base64.b64encode(byte_string)print(f&#x27;base64 data:&#123;encoded_data&#125;&#x27;)encoded_data = b&#x27;VGhpcyBpcyB0aGUgZGF0YSwgaW4gdGhlIGNsZWFyLg==&#x27;decoded_data = base64.b64decode(encoded_data)print(&#x27;Encoded :&#x27;, encoded_data)print(&#x27;Decoded :&#x27;, decoded_data) initial_data:Copyright (c) 2008 Doug Hellmann All rights reserved. base64 data:b'Q29weXJpZ2h0IChjKSAyMDA4IERvdWcgSGVsbG1hbm4gQWxsIHJpZ2h0cyByZXNlcnZlZC4=' Encoded : b'VGhpcyBpcyB0aGUgZGF0YSwgaW4gdGhlIGNsZWFyLg==' Decoded : b'This is the data, in the clear.' http.server 123from http import server# 自己实现do_GET(),do_POST()方法的web服务器 http.cookie 123from http import cookie# webbrowser 123456import webbrowser# 浏览器打开界面webbrowser.open_new_tab( &#x27;https://docs.python.org/3/library/webbrowser.html&#x27;) True uuid 1234import uuidprint(uuid.getnode())print(uuid.uuid1()) 4943745048992 1e4a5d1c-cc80-11ed-8e72-047f0e2ae1a0 json 12345678910import json# 键必须是字符串类型# tuple会转成list# 文件json.load()json.dump()# 字符串json.loads()json.dumps() email 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from smtplib import SMTP,SMTP_SSLfrom email.header import Headerfrom email.mime.text import MIMETextfrom email.mime.image import MIMEImagefrom email.mime.multipart import MIMEMultipartdef main(): # 创建一个带附件的邮件消息对象 message = MIMEMultipart() # 创建文本内容 text_content = MIMEText(&#x27;附件中有本月数据请查收&#x27;, &#x27;plain&#x27;, &#x27;utf-8&#x27;) message[&#x27;From&#x27;] = Header(&#x27;gladdduck&#x27;, &#x27;utf-8&#x27;) message[&#x27;To&#x27;] = Header(&#x27;亚哥&#x27;, &#x27;utf-8&#x27;) message[&#x27;Subject&#x27;] = Header(&#x27;本月数据&#x27;, &#x27;utf-8&#x27;) # 将文本内容添加到邮件消息对象中 message.attach(text_content) # 读取文件并将文件作为附件添加到邮件消息对象中 with open(&#x27;words.txt&#x27;, &#x27;rb&#x27;) as f: txt = MIMEText(f.read(), &#x27;base64&#x27;, &#x27;utf-8&#x27;) txt[&#x27;Content-Type&#x27;] = &#x27;text/plain&#x27; txt[&#x27;Content-Disposition&#x27;] = &#x27;attachment; filename=hello.txt&#x27; message.attach(txt) # 创建SMTP对象 smtper = SMTP_SSL(&#x27;smtp.qq.com&#x27;) # 开启安全连接 # smtper.starttls() sender = &#x27;703214452@qq.com&#x27; receivers = [&#x27;syxue@stu.suda.edu.cn&#x27;] # 登录到SMTP服务器 # 请注意此处不是使用密码而是邮件客户端授权码进行登录 # 对此有疑问的读者可以联系自己使用的邮件服务器客服 smtper.login(sender, &#x27;*****&#x27;) # 发送邮件 smtper.sendmail(sender, receivers, message.as_string()) # 与邮件服务器断开连接 smtper.quit() print(&#x27;发送完成!&#x27;)if __name__ == &#x27;__main__&#x27;: main() 应用构建模块 argparse 1234567891011121314151617181920212223242526272829303132333435import argparse# 声明# parents参数,合并其他解析器parser = argparse.ArgumentParser(description=&#x27;test&#x27;)# 位置参数,必填parser.add_argument(&quot;echo&quot;)# 可选参数,一个简称,一个全称,不给默认为Noneparser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;)&#x27;&#x27;&#x27;add_argument()参数action:默认是store,存储参数 store_const:表示只能赋值为const append:把参数存储成列表 append_const:把const的值存储为列表 count:统计参数出现的次数 store_true/store_false:保存布尔值,出现就是true or false default:默认值type:参数类型choice:只能从里面选required:可以省略 (仅针对可选参数)。help:打印的时候的帮助信息dest:解析后的参数名称nargs:表示后面要跟几个参数group=parser.add_mutually_exclusive_group()互斥选项,&#x27;&#x27;&#x27;# 解析,默认解析的sys.argv[1:]parser.parse_args() getopt 123import getopt# 命令行选项解析 readline getpass 1234import getpassp=getpass.getpass(prompt=&#x27;输入密码&#x27;)print(p,p) cmd 123import cmd# 面向行的命令处理器 shlex 12import shlex# 解析shell语法 configparser 12345678910111213141516171819202122232425262728293031323334353637383940import configparser&#x27;&#x27;&#x27;[DEFAULT]serveraliveinterval = 45compression = yescompressionlevel = 9[bitbucket]user = kk[topsecrect]port = 22&#x27;&#x27;&#x27;import configparserconfig = configparser.ConfigParser()# 不存在忽略,可以多个配置文件合并config.read(&#x27;example.ini&#x27;)# sections就是[]中的配置,has_section()# options是[]下面的选项,has_option()for section_name in config.sections(): print(&#x27;Section:&#x27;, section_name) print(&#x27; Options:&#x27;, config.options(section_name)) for name, value in config.items(section_name): print(&#x27; &#123;&#125; = &#123;&#125;&#x27;.format(name, value)) print() config.add_section(&#x27;bug_tracker&#x27;)config.set(&#x27;bug_tracker&#x27;, &#x27;url&#x27;, &#x27;http://localhost:8080/bugs&#x27;)config.set(&#x27;bug_tracker&#x27;, &#x27;username&#x27;, &#x27;dhellmann&#x27;)config.set(&#x27;bug_tracker&#x27;, &#x27;password&#x27;, &#x27;secret&#x27;)config.remove_option(&#x27;bug_tracker&#x27;, &#x27;password&#x27;)config.remove_section(&#x27;wiki&#x27;)# parser.write(f) logging 123456789101112import logginglogging.basicConfig(level=logging.WARNING)# 不同模块的日志logger1 = logging.getLogger(&#x27;package1.module1&#x27;)logger2 = logging.getLogger(&#x27;package2.module2&#x27;)logger1.warning(&#x27;This message comes from one module&#x27;)logger2.warning(&#x27;This comes from another module&#x27;) WARNING:package1.module1:This message comes from one module WARNING:package2.module2:This comes from another module 123456789101112131415161718192021222324252627282930import logging# 格式化# LOG_FILENAME = &#x27;logging_example.out&#x27;logging.basicConfig(format=&#x27;%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s&#x27;, level=logging.DEBUG, # filename=LOG_FILENAME, )logging.debug(&#x27;debug 信息&#x27;)logging.info(&#x27;info 信息&#x27;)logging.warning(&#x27;warning 信息&#x27;)logging.error(&#x27;error 信息&#x27;)logging.critical(&#x27;critial 信息&#x27;)&#x27;&#x27;&#x27;级别 数值CRITICAL 50ERROR 40WARNING 30INFO 20DEBUG 10NOTSET 0&#x27;&#x27;&#x27; 2023-03-28 21:44:07,434 - C:\\Users\\22627\\AppData\\Local\\Temp\\ipykernel_2380\\2094327826.py[line:8] - DEBUG: debug 信息 2023-03-28 21:44:07,436 - C:\\Users\\22627\\AppData\\Local\\Temp\\ipykernel_2380\\2094327826.py[line:9] - INFO: info 信息 2023-03-28 21:44:07,438 - C:\\Users\\22627\\AppData\\Local\\Temp\\ipykernel_2380\\2094327826.py[line:10] - WARNING: warning 信息 2023-03-28 21:44:07,440 - C:\\Users\\22627\\AppData\\Local\\Temp\\ipykernel_2380\\2094327826.py[line:11] - ERROR: error 信息 2023-03-28 21:44:07,443 - C:\\Users\\22627\\AppData\\Local\\Temp\\ipykernel_2380\\2094327826.py[line:12] - CRITICAL: critial 信息 1234567891011121314151617181920212223# 写不同文件import globimport loggingimport logging.handlersLOG_FILENAME = &#x27;logging_rotatingfile_example.out&#x27;my_logger = logging.getLogger(&#x27;MyLogger&#x27;)my_logger.setLevel(logging.DEBUG)handler = logging.handlers.RotatingFileHandler( LOG_FILENAME, maxBytes=20, backupCount=5,)my_logger.addHandler(handler)for i in range(20): my_logger.debug(&#x27;i = %d&#x27; % i)logfiles = glob.glob(&#x27;%s*&#x27; % LOG_FILENAME)for filename in sorted(logfiles): print(filename) fileinput 123import fileinput# 命令行过滤器框架 atexit 1234567891011121314151617181920import atexit# 程序关闭回调def my_cleanup(name): print(&#x27;my_cleanup(&#123;&#125;)&#x27;.format(name))atexit.register(my_cleanup, &#x27;first&#x27;)atexit.register(my_cleanup, &#x27;second&#x27;)atexit.register(my_cleanup, &#x27;third&#x27;)# 因为信号终止# os._exit()# 致命错误@atexit.registerdef all_done(): print(&#x27;all_done()&#x27;)print(&#x27;starting main program&#x27;) starting main program sched 123456789101112131415161718192021222324import sched# 在指定时刻运行任务import schedimport timescheduler = sched.scheduler(time.time, time.sleep)def long_event(name): print(&#x27;BEGIN EVENT :&#x27;, time.ctime(time.time()), name) time.sleep(2) print(&#x27;FINISH EVENT:&#x27;, time.ctime(time.time()), name)print(&#x27;START:&#x27;, time.ctime(time.time()))# 时间,优先级,函数,参数scheduler.enter(2, 1, long_event, (&#x27;first&#x27;,))# run是阻塞的,但是这个是到了就执行,要在不同线程内取消scheduler.enter(3, 1, long_event, (&#x27;second&#x27;,))scheduler.run() START: Tue Mar 28 21:57:03 2023 BEGIN EVENT : Tue Mar 28 21:57:05 2023 first FINISH EVENT: Tue Mar 28 21:57:07 2023 first BEGIN EVENT : Tue Mar 28 21:57:07 2023 second FINISH EVENT: Tue Mar 28 21:57:09 2023 second 123456789price=0age=int(input())if age&lt;12: price=0elif age&lt;=65: price=40elif age&gt;65: price=20print(f&#x27;Your price is &#123;price&#125; yuan&#x27;) Your price is 40 yuan 国际化和本地化 开发工具 pydoc 1234import pydocimport atexit# 运行时生成帮助文本pydoc.doc(atexit) doctest 123456789101112131415161718192021222324import doctest# 运行嵌入文档中的例子，验证是否生成期望的结果def my_function(a, b): &quot;&quot;&quot;Returns a * b. Works with numbers: &gt;&gt;&gt; my_function(2, 3) 6 and strings: &gt;&gt;&gt; my_function(&#x27;a&#x27;, 3) &#x27;aaa&#x27; # 忽略可能会变化的部分 &gt;&gt;&gt; unpredictable(MyClass()) #doctest: +ELLIPSIS [&lt;doctest_ellipsis.MyClass object at 0x...&gt;] &quot;&quot;&quot; return a * bif __name__==&quot;__main__&quot;: doctest.testmod()# !python3 -m doctest -v xxx.py unittest 123456789101112131415import unittest# 自动测试框架class SimplisticTest(unittest.TestCase): def test(self): a = &#x27;a&#x27; b = &#x27;a&#x27; self.assertEqual(a, b) self.assertFalse() self.assertTrue() self.assertNotEqual() self.assertNotEqual() # ... trace 12345678910111213141516171819import trace# 监视所执行的语句，生成报告，查看互相调用的函数之间的关系# 会生成函数之间的调用关系def recurse(level): print(&#x27;recurse(&#123;&#125;)&#x27;.format(level)) if level: recurse(level - 1)def not_called(): print(&#x27;This function is never called.&#x27;)def main(): print(&#x27;This is the main program.&#x27;) recurse(2)tracer = trace.Trace(count=False, trace=True)tracer.run(&#x27;recurse(2)&#x27;) traceback 12345import traceback# 调用栈来生成错误消息 cgitb 1234import cgitb# cgitb把sys.excepthook 换成一个函数,格式化输出，更详细 pdb 1234import pdb# 暂停程序，逐步监视执行# debug profile &amp; pstats 123456789101112131415161718192021222324252627import profileimport pstats# profile收集消耗处理器资源的统计信息def fib(n): if n == 0: return 0 elif n == 1: return 1 else: return fib(n - 1) + fib(n - 2)def fib_seq(n): seq = [] if n &gt; 0: seq.extend(fib_seq(n - 1)) seq.append(fib(n)) return seq# profile.run(&#x27;print(fib_seq(20)); print()&#x27;)profile.runctx( &#x27;print(fib_seq(n)); print()&#x27;, globals(), &#123;&#x27;n&#x27;: 20&#125;,)# pstats与profile结合 [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765] 57409 function calls (119 primitive calls) in 0.156 seconds Ordered by: standard name ncalls tottime percall cumtime percall filename:lineno(function) 21/1 0.000 0.000 0.156 0.156 1066040024.py:12(fib_seq) 57291/21 0.156 0.000 0.156 0.007 1066040024.py:4(fib) 4 0.000 0.000 0.000 0.000 :0(acquire) 25 0.000 0.000 0.000 0.000 :0(append) 1 0.000 0.000 0.156 0.156 :0(exec) 20 0.000 0.000 0.000 0.000 :0(extend) 3 0.000 0.000 0.000 0.000 :0(getpid) 3 0.000 0.000 0.000 0.000 :0(isinstance) 3 0.000 0.000 0.000 0.000 :0(len) 2 0.000 0.000 0.000 0.000 :0(print) 1 0.000 0.000 0.000 0.000 :0(setprofile) 1 0.000 0.000 0.156 0.156 &lt;string&gt;:1(&lt;module&gt;) 4 0.000 0.000 0.000 0.000 iostream.py:206(schedule) 3 0.000 0.000 0.000 0.000 iostream.py:418(_is_master_process) 3 0.000 0.000 0.000 0.000 iostream.py:437(_schedule_flush) 3 0.000 0.000 0.000 0.000 iostream.py:500(write) 4 0.000 0.000 0.000 0.000 iostream.py:96(_event_pipe) 1 0.000 0.000 0.156 0.156 profile:0(print(fib_seq(n)); print()) 0 0.000 0.000 profile:0(profiler) 4 0.000 0.000 0.000 0.000 socket.py:543(send) 4 0.000 0.000 0.000 0.000 threading.py:1066(_wait_for_tstate_lock) 4 0.000 0.000 0.000 0.000 threading.py:1133(is_alive) 4 0.000 0.000 0.000 0.000 threading.py:536(is_set) timeit 12345678910import timeit# 测量小代码时间t = timeit.Timer(&quot;print(&#x27;main statement&#x27;)&quot;, &quot;print(&#x27;setup&#x27;)&quot;)print(&#x27;TIMEIT:&#x27;)print(t.timeit(2))print(&#x27;REPEAT:&#x27;)print(t.repeat(3, 2)) TIMEIT: setup main statement main statement 1.2299999980314169e-05 REPEAT: setup main statement main statement setup main statement main statement setup main statement main statement [0.00017259999958696426, 2.790000007735216e-05, 1.540000039312872e-05] 123456789101112131415161718192021222324252627import contextlibimport time# Yolov5时间记录class Profile(contextlib.ContextDecorator): # YOLOv5 Profile class. Usage: @Profile() decorator or &#x27;with Profile():&#x27; context manager def __init__(self, t=0.0): self.t = t # self.cuda = torch.cuda.is_available() def __enter__(self): self.start = self.time() return self def __exit__(self, type, value, traceback): self.dt = self.time() - self.start # delta-time self.t += self.dt # accumulate dt def time(self): # if self.cuda: # torch.cuda.synchronize() return time.time() ttt=Profile()with ttt: [_ for _ in range(int(1e7))]print(ttt.t) 0.534808874130249 tabnanny 12import tabnanny# 缩进验证工具 compileall 1import compileall venv 12import venv# 创建虚拟环境 运行时特性 site 123import site# 站点特定的配置,导入路径 sys 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import sys# 系统特定配置print(&#x27;Version info:&#x27;)print()print(&#x27;sys.version =&#x27;, repr(sys.version))print(&#x27;sys.version_info =&#x27;, sys.version_info)print(&#x27;sys.hexversion =&#x27;, hex(sys.hexversion))print(&#x27;sys.api_version =&#x27;, sys.api_version)print(&#x27;This interpreter was built for:&#x27;, sys.platform)# 获取运行时参数print(&#x27;Arguments:&#x27;, sys.argv)# 退出# sys.exit(1)print(&#x27;Name:&#x27;, sys.implementation.name)print(&#x27;Version:&#x27;, sys.implementation.version)print(&#x27;Cache tag:&#x27;, sys.implementation.cache_tag)# print(&#x27;STATUS: Reading from stdin&#x27;)# data = sys.stdin.read()# print(&#x27;STATUS: Writing data to stdout&#x27;)# sys.stdout.write(data)# sys.stdout.flush()# print(&#x27;STATUS: Done&#x27;)# 参数的引用计数one = []print(&#x27;At start :&#x27;, sys.getrefcount(one))two = oneprint(&#x27;Second reference :&#x27;, sys.getrefcount(one))del twoprint(&#x27;After del :&#x27;, sys.getrefcount(one))# 参数大小class MyClass: passobjects = [ [], (), &#123;&#125;, &#x27;c&#x27;, &#x27;string&#x27;, b&#x27;bytes&#x27;, 1, 2.3, MyClass, MyClass(),]# 不统计类的属性大小for obj in objects: print(&#x27;&#123;:&gt;10&#125; : &#123;&#125;&#x27;.format(type(obj).__name__,sys.getsizeof(obj))) Version info: sys.version = '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]' sys.version_info = sys.version_info(major=3, minor=9, micro=13, releaselevel='final', serial=0) sys.hexversion = 0x3090df0 sys.api_version = 1013 This interpreter was built for: win32 Arguments: ['C:\\\\Users\\\\Ada\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\ipykernel_launcher.py', '--ip=127.0.0.1', '--stdin=9008', '--control=9006', '--hb=9005', '--Session.signature_scheme=&quot;hmac-sha256&quot;', '--Session.key=b&quot;fb322aac-cfd4-4a49-87ab-e11c0e6aea3e&quot;', '--shell=9007', '--transport=&quot;tcp&quot;', '--iopub=9009', '--f=c:\\\\Users\\\\Ada\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-100766YwHlokYHZ1d.json'] Name: cpython Version: sys.version_info(major=3, minor=9, micro=13, releaselevel='final', serial=0) Cache tag: cpython-39 At start : 2 Second reference : 3 After del : 2 list : 56 tuple : 40 dict : 64 str : 50 str : 55 bytes : 38 int : 28 float : 24 type : 1064 MyClass : 48 123456789101112131415161718192021222324class WithAttributes: def __init__(self): self.a = &#x27;a&#x27; self.b = &#x27;b&#x27; return def __sizeof__(self): return object.__sizeof__(self) + \\ sum(sys.getsizeof(v) for v in self.__dict__.values())# 统计带参数的类大小my_inst = WithAttributes()print(sys.getsizeof(my_inst))# getrecursionlimit() setrecursionlimit() 查看设置最大递归深度# getswitchinterval() setswitchinterval() 查看设置线程获取的cpu运行时间# 列表字典串的最大大小print(&#x27;maxsize :&#x27;, sys.maxsize)print(&#x27;maxunicode:&#x27;, sys.maxunicode)# 数的信息# sys.float_info# sys.int_info 148 maxsize : 9223372036854775807 maxunicode: 1114111 123456789101112131415# 处理错误信息def my_excepthook(type, value, traceback): print(&#x27;Unhandled error:&#x27;, type, value)sys.excepthook = my_excepthookprint(&#x27;Before exception&#x27;)raise RuntimeError(&#x27;This is the error message&#x27;)print(&#x27;After exception&#x27;)# Before exception# Unhandled error: &lt;class &#x27;RuntimeError&#x27;&gt; This is the error # message 12345678910111213141516171819202122232425262728293031323334import sysimport threadingimport timedef do_something_with_exception(): exc_type, exc_value = sys.exc_info()[:2] print(&#x27;Handling &#123;&#125; exception with message &quot;&#123;&#125;&quot; in &#123;&#125;&#x27;.format( exc_type.__name__, exc_value, threading.current_thread().name))def cause_exception(delay): time.sleep(delay) raise RuntimeError(&#x27;This is the error message&#x27;)def thread_target(delay): try: cause_exception(delay) except RuntimeError: do_something_with_exception()threads = [ threading.Thread(target=thread_target, args=(0.3,)), threading.Thread(target=thread_target, args=(0.1,)),]for t in threads: t.start()for t in threads: t.join() Handling RuntimeError exception with message &quot;This is the error message&quot; in Thread-7 Handling RuntimeError exception with message &quot;This is the error message&quot; in Thread-6 12345678910import sysnames = sorted(sys.modules.keys())name_text = &#x27;, &#x27;.join(names)# print(name_text)for d in sys.path: print(d)# sys.path 加入路径, d:\\BaiduSyncdisk\\Blog\\source\\_posts e:\\Anaconda3\\envs\\AAA\\python39.zip e:\\Anaconda3\\envs\\AAA\\DLLs e:\\Anaconda3\\envs\\AAA\\lib e:\\Anaconda3\\envs\\AAA C:\\Users\\Ada\\AppData\\Roaming\\Python\\Python39\\site-packages e:\\Anaconda3\\envs\\AAA\\lib\\site-packages e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\openea-1.0-py3.9.egg e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\python_levenshtein-0.20.7-py3.9.egg e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\gensim-4.2.0-py3.9-win-amd64.egg e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\matching-0.1.1-py3.9.egg e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\win32 e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\win32\\lib e:\\Anaconda3\\envs\\AAA\\lib\\site-packages\\Pythonwin C:\\Users\\Ada\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\extensions C:\\Users\\Ada\\.ipython os 12345678import osimport syssys.path.append(r&#x27;D:\\BaiduSyncdisk\\Blog\\source&#x27;)# os.listdir()root=&#x27;D:\\BaiduSyncdisk\\Blog\\source&#x27;for dir_name, sub_dirs, files in os.walk(root): print(dir_name,sub_dirs,files) 123456789101112131415161718192021222324for entry in os.scandir(root): if entry.is_dir(): typ = &#x27;dir&#x27; elif entry.is_file(): typ = &#x27;file&#x27; elif entry.is_symlink(): typ = &#x27;link&#x27; else: typ = &#x27;unknown&#x27; print(&#x27;&#123;name&#125; &#123;typ&#125;&#x27;.format( name=entry.name, typ=typ, ))# stat()查看详细信息# chmod()修改权限# access()测试进程权限# mkdir() 前面的路径必须存在# makedirs() 创建不存在的父路径# rmdir() 只会删除子目录# removedirs() 删除为空的所有父目录# replace() # rename()重命名# environ() 环境变量# getenv() 123456789# 当前工作目录print(os.getcwd())# 更改工作目录os.chdir(&#x27;d:\\\\BaiduSyncdisk\\\\Blog\\\\source&#x27;)print(os.getcwd())# 运行外部命令print(os.system(&#x27;pwd&#x27;))# 创建进程# os.fork() d:\\BaiduSyncdisk\\Blog\\source d:\\BaiduSyncdisk\\Blog\\source 1 platform 12345678910111213141516171819202122import platformprint(&#x27;uname:&#x27;, platform.uname())print()print(&#x27;system :&#x27;, platform.system())print(&#x27;node :&#x27;, platform.node())print(&#x27;release :&#x27;, platform.release())print(&#x27;version :&#x27;, platform.version())print(&#x27;machine :&#x27;, platform.machine())print(&#x27;processor:&#x27;, platform.processor())print(&#x27;interpreter:&#x27;, platform.architecture())print(&#x27;/bin/ls :&#x27;, platform.architecture(&#x27;/bin/ls&#x27;))print(&#x27;Normal :&#x27;, platform.platform())print(&#x27;Aliased:&#x27;, platform.platform(aliased=True))print(&#x27;Terse :&#x27;, platform.platform(terse=True))print(&#x27;Version :&#x27;, platform.python_version())print(&#x27;Version tuple:&#x27;, platform.python_version_tuple())print(&#x27;Compiler :&#x27;, platform.python_compiler())print(&#x27;Build :&#x27;, platform.python_build()) uname: uname_result(system='Windows', node='DESKTOP-SFFEKV7', release='10', version='10.0.19041', machine='AMD64') system : Windows node : DESKTOP-SFFEKV7 release : 10 version : 10.0.19041 machine : AMD64 processor: Intel64 Family 6 Model 158 Stepping 10, GenuineIntel interpreter: ('64bit', 'WindowsPE') /bin/ls : ('64bit', '') Normal : Windows-10-10.0.19041-SP0 Aliased: Windows-10-10.0.19041-SP0 Terse : Windows-10 Version : 3.9.13 Version tuple: ('3', '9', '13') Compiler : MSC v.1916 64 bit (AMD64) Build : ('main', 'Aug 25 2022 23:51:50') resource 12345678910111213141516171819import resource# 系统资源管理RESOURCES = [ (&#x27;ru_utime&#x27;, &#x27;User time&#x27;), (&#x27;ru_stime&#x27;, &#x27;System time&#x27;), (&#x27;ru_maxrss&#x27;, &#x27;Max. Resident Set Size&#x27;), (&#x27;ru_ixrss&#x27;, &#x27;Shared Memory Size&#x27;), (&#x27;ru_idrss&#x27;, &#x27;Unshared Memory Size&#x27;), (&#x27;ru_isrss&#x27;, &#x27;Stack Size&#x27;), (&#x27;ru_inblock&#x27;, &#x27;Block inputs&#x27;), (&#x27;ru_oublock&#x27;, &#x27;Block outputs&#x27;),]usage = resource.getrusage(resource.RUSAGE_SELF)for name, desc in RESOURCES: print(&#x27;&#123;:&lt;25&#125; (&#123;:&lt;10&#125;) = &#123;&#125;&#x27;.format( desc, name, getattr(usage, name))) gc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import gc# 垃圾回收&#x27;&#x27;&#x27;enable() --启用自动垃圾回收。disable() --禁用自动垃圾回收。isenabled() --如果启用了自动收集，则返回true。collect() --立即执行完全收集。get_count() --返回当前集合计数。get_stats() --返回包含每代统计信息的词典列表。set_debug() --设置调试标志。get_debug() --获取调试标志。set_threshold() --设置收集阈值。get_threshold() --返回集合阈值的当前值。get_objects() --返回收集器跟踪的所有对象的列表。is_tracked() --如果跟踪给定对象，则返回true。is_finalized() --如果给定对象已定稿，则返回true。get_referrers() --返回引用对象的对象列表。get_referents() --返回对象引用的对象列表。freeze() --冻结所有跟踪对象，并在将来的收集中忽略它们。unfreeze() --解冻永久生成中的所有对象。get_freeze_count() --返回永久生成中的对象数。&#x27;&#x27;&#x27;import sysclass Test(): def __init__(self): passt = Test()k = Test()t._self = t# 会多一个 因为gc会用一个print(sys.getrefcount(t)) #sys.getrefcount函数用来查看一个对象有几个引用print(sys.getrefcount(k))# del语句可以消除一个引用关系# 引用计数为主，标记-清除+分代回收为辅的回收策略# 专门用来处理这些循环引用# gc.collect()# gc.get_threshold()# python中默认把所有对象分成三代。# 第0代包含了最新的对象，第2代则是最早的一些对象。# 在一次垃圾回收中，所有未被回收的对象会被移到高一代的地方。# 这个方法返回的是(700,10,10)，这也是gc的默认值。# 这个值的意思是说，在第0代对象数量达到700个之前，不把未被回收的对象放入第一代；# 而在第一代对象数量达到10个之前也不把未被回收的对象移到第二代。# 可以是使用gc.set_threshold(threashold0,threshold1,threshold2)来手动设置这组阈值。 sysconfig 12import sysconfig# 解释器编译时配置 语言工具 warnings 123456789101112131415161718import warnings# 报告非致命条件或可修复错误# error把警告变成错误,simplefilter是filterwarnings简化版warnings.simplefilter(&#x27;ignore&#x27;, UserWarning)# 发出一个warningsprint(&#x27;Before the warning&#x27;)warnings.warn(&#x27;This is a warning message&#x27;)print(&#x27;After the warning&#x27;)# filterwarnings() 根据规则过滤信息warnings.filterwarnings(&#x27;ignore&#x27;, &#x27;.*do not.*&#x27;,)warnings.warn(&#x27;Show this message&#x27;)warnings.warn(&#x27;Do not show this message&#x27;) Before the warning After the warning 123456789101112131415import warningswarnings.simplefilter(&#x27;once&#x27;, UserWarning)def warning_on_one_line(message, category, filename, lineno, file=None, line=None): return &#x27;-&gt; &#123;&#125;:&#123;&#125;: &#123;&#125;:&#123;&#125;\\n&#x27;.format( filename, lineno, category.__name__, message)warnings.warn(&#x27;Warning message, before&#x27;)warnings.formatwarning = warning_on_one_linewarnings.warn(&#x27;Warning message, after&#x27;)warnings.warn(&#x27;This is a warning!&#x27;)warnings.warn(&#x27;This is a warning!&#x27;)warnings.warn(&#x27;This is a warning!&#x27;) C:\\Users\\Ada\\AppData\\Local\\Temp/ipykernel_9460/3571311107.py:9: UserWarning: Warning message, before warnings.warn('Warning message, before') -&gt; C:\\Users\\Ada\\AppData\\Local\\Temp/ipykernel_9460/3571311107.py:11: UserWarning:Warning message, after -&gt; C:\\Users\\Ada\\AppData\\Local\\Temp/ipykernel_9460/3571311107.py:13: UserWarning:This is a warning! abc dis 123456789101112131415import dis# 字节码反汇编工具def f(*args): nargs = len(args) print(nargs, args)if __name__ == &#x27;__main__&#x27;: import dis dis.dis(f) dis.show_code(f) 6 0 LOAD_GLOBAL 0 (len) 2 LOAD_FAST 0 (args) 4 CALL_FUNCTION 1 6 STORE_FAST 1 (nargs) 7 8 LOAD_GLOBAL 1 (print) 10 LOAD_FAST 1 (nargs) 12 LOAD_FAST 0 (args) 14 CALL_FUNCTION 2 16 POP_TOP 18 LOAD_CONST 0 (None) 20 RETURN_VALUE Name: f Filename: C:\\Users\\Ada\\AppData\\Local\\Temp/ipykernel_9460/3862671634.py Argument count: 0 Positional-only arguments: 0 Kw-only arguments: 0 Number of locals: 2 Stack size: 3 Flags: OPTIMIZED, NEWLOCALS, VARARGS, NOFREE Constants: 0: None Names: 0: len 1: print Variable names: 0: args 1: nargs inspect 12345678910111213import inspect# 检查现场对象,获取一个文件内的类,函数,示例,等等# getnumbers() 发现对象的成员属性,,example是py文件import examplefor name, data in inspect.getmembers(example): if name.startswith(&#x27;__&#x27;): continue print(&#x27;&#123;&#125; : &#123;!r&#125;&#x27;.format(name, data)) 模块和包 importlib 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import importlib# 运行时import&#x27;&#x27;&#x27;├── clazz│ ├── __init__.py│ ├── a.py│ └── b.py└── main.pya.pydef show(): print(&quot;show A&quot;)b.pydef show(): print(&quot;show B&quot;)&#x27;&#x27;&#x27;import osimport importlibdef get_modules(package=&quot;.&quot;): &quot;&quot;&quot; 获取包名下所有非__init__的模块名 &quot;&quot;&quot; modules = [] files = os.listdir(package) for file in files: if not file.startswith(&quot;__&quot;): name, ext = os.path.splitext(file) modules.append(&quot;.&quot; + name) return modulesif __name__ == &#x27;__main__&#x27;: package = &quot;clazz&quot; modules = get_modules(package) # 将包下的所有模块，逐个导入，并调用其中的函数 for module in modules: module = importlib.import_module(module, package) for attr in dir(module): if not attr.startswith(&quot;__&quot;): func = getattr(module, attr) func() &quot;&quot;&quot; show A show B &quot;&quot;&quot; pkgutil 12345678910111213import pkgutil# 包扩展工具# 一个.py文件就是一个python模块（module），如果一个目录下面有一个__init__.py文件，那么这个目录就是一个python包（package）# 实际上包是一种特殊的模块，而任何定义了__path__属性的模块都被当做包。iter_modules(path=None, prefix=&#x27;&#x27;)# path是包的目录路径，prefix是输出时，所有包的名字的前缀。用来获取该path下的子模块或子包。walk_packages(path=None, prefix=&#x27;&#x27;, onerror=None)# 同上，但是这个方法是递归获取路径下的所有模块。for _, name, ispkg in pkgutil.walk_packages(test.__path__, test.__name__ + &quot;.&quot;): print &quot;name: &#123;0:12&#125;, is_sub_package: &#123;1&#125;&quot;.format(name, ispkg) zipimport 123import zipimport# 从zip文档中导入包 1","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"python3 标准库","slug":"python3-标准库","permalink":"https://gladdduck.github.io/tags/python3-%E6%A0%87%E5%87%86%E5%BA%93/"}]},{"title":"python标准库-2","slug":"笔记-python3lib-2","date":"2023-03-30T05:59:49.971Z","updated":"2023-04-02T03:25:37.260Z","comments":true,"path":"2023/03/30/笔记-python3lib-2/","link":"","permalink":"https://gladdduck.github.io/2023/03/30/%E7%AC%94%E8%AE%B0-python3lib-2/","excerpt":"","text":"数学模块 decimal 1234import decimal# 精准的小数计算# 可以设置精度,取值等 fractions 123456789101112131415161718192021222324252627282930import fractions# 分数/有理数 加减乘除正常用# 创建 小数\\字符串\\整数 都行for v in [0.1, 0.5, 1.5, 2.0]: print(&#x27;&#123;&#125; = &#123;&#125;&#x27;.format(v, fractions.Fraction(v))) for s in [&#x27;1/2&#x27;, &#x27;2/4&#x27;, &#x27;3/6&#x27;]: f = fractions.Fraction(s) print(&#x27;&#123;&#125; = &#123;&#125;&#x27;.format(s, f)) for s in [&#x27;0.5&#x27;, &#x27;1.5&#x27;, &#x27;2.0&#x27;, &#x27;5e-1&#x27;]: f = fractions.Fraction(s) print(&#x27;&#123;0:&gt;4&#125; = &#123;1&#125;&#x27;.format(s, f))for n, d in [(1, 2), (2, 4), (3, 6)]: f = fractions.Fraction(n, d) print(&#x27;&#123;&#125;/&#123;&#125; = &#123;&#125;&#x27;.format(n, d, f)) # 精确度import fractionsimport mathprint(&#x27;PI =&#x27;, math.pi)f_pi = fractions.Fraction(str(math.pi))print(&#x27;No limit =&#x27;, f_pi)for i in [1, 6, 11, 60, 70, 90, 100]: limited = f_pi.limit_denominator(i) print(&#x27;&#123;0:8&#125; = &#123;1&#125;&#x27;.format(i, limited)) 0.1 = 3602879701896397/36028797018963968 0.5 = 1/2 1.5 = 3/2 2.0 = 2 1/2 = 1/2 2/4 = 1/2 3/6 = 1/2 0.5 = 1/2 1.5 = 3/2 2.0 = 2 5e-1 = 1/2 1/2 = 1/2 2/4 = 1/2 3/6 = 1/2 PI = 3.141592653589793 No limit = 3141592653589793/1000000000000000 1 = 3 6 = 19/6 11 = 22/7 60 = 179/57 70 = 201/64 90 = 267/85 100 = 311/99 random 1234567891011121314import random# r1=random.Random()# r2=random.Random()# r1r2互不影响# random 生成一个[0,1)的小数for i in range(5): print(&#x27;%04.3f&#x27; % random.random(), end=&#x27; &#x27;)print()# 指定区间的小数for i in range(5): print(&#x27;&#123;:04.3f&#125;&#x27;.format(random.uniform(1, 100)), end=&#x27; &#x27;)print() 0.413 0.516 0.783 0.878 0.469 50.379 1.563 83.167 90.209 54.711 123456# 固定种子，怎么运行都是相同的数random.seed(1)for i in range(5): print(&#x27;&#123;:04.3f&#125;&#x27;.format(random.random()), end=&#x27; &#x27;)print() 0.134 0.847 0.764 0.255 0.495 1234567891011# 随机整数print(&#x27;[1, 100]:&#x27;, end=&#x27; &#x27;)for i in range(3): print(random.randint(1, 100), end=&#x27; &#x27;)print(&#x27;\\n[-5, 5]:&#x27;, end=&#x27; &#x27;)for i in range(3): print(random.randint(-5, 5), end=&#x27; &#x27;)print() [1, 100]: 58 61 84 [-5, 5]: 1 -2 -4 123456789101112131415161718192021222324252627# 从序列中随机选择一个outcomes = &#123; &#x27;heads&#x27;: 0, &#x27;tails&#x27;: 0,&#125;sides = list(outcomes.keys())for i in range(10000): outcomes[random.choice(sides)] += 1print(&#x27;Heads:&#x27;, outcomes[&#x27;heads&#x27;])print(&#x27;Tails:&#x27;, outcomes[&#x27;tails&#x27;])# 打乱序列l=[i for i in range(10)]print(f&#x27;l :&#123;l&#125;&#x27;)random.shuffle(l)print(f&#x27;shuffled l:&#123;l&#125;&#x27;)# 采样samplelist=random.sample(l, 5)print(f&#x27;sample l:&#123;samplelist&#125;&#x27;) Heads: 4902 Tails: 5098 l :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] shuffled l:[9, 4, 8, 3, 6, 7, 0, 5, 2, 1] sample l:[4, 6, 9, 5, 3] 123# 非均匀分布# 高斯分布，正态分布random.gauss(mu=1,sigma=2) -0.21029077107544225 math 1234567891011121314151617181920212223242526272829303132import math# 常见常量print(&#x27; π: &#123;:.30f&#125;&#x27;.format(math.pi))print(&#x27; e: &#123;:.30f&#125;&#x27;.format(math.e))print(&#x27;nan: &#123;:.30f&#125;&#x27;.format(math.nan))print(&#x27;inf: &#123;:.30f&#125;&#x27;.format(math.inf))# 判断异常值print(math.isinf(10.0 ** 140))print(math.isinf((10.0 ** 200)*(10.0 ** 200))) # 比较,根据相对误差和绝对误差print(&#x27;=&#x27;*10)print(math.isclose(1000,900, rel_tol=0.1))print(math.isclose(1000,900, abs_tol=0.1))# 浮点数转整数# trunc() 直接截断 只留整数部分# floor() 不大于他的整数# ceil() 数轴左侧的最小整数import mathprint(&#x27;=&#x27;*10)HEADINGS = (&#x27;i&#x27;, &#x27;int&#x27;, &#x27;trunk&#x27;, &#x27;floor&#x27;, &#x27;ceil&#x27;)print(&#x27;&#123;:^5&#125; &#123;:^5&#125; &#123;:^5&#125; &#123;:^5&#125; &#123;:^5&#125;&#x27;.format(*HEADINGS))print(&#x27;&#123;:-^5&#125; &#123;:-^5&#125; &#123;:-^5&#125; &#123;:-^5&#125; &#123;:-^5&#125;&#x27;.format(&#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;,))fmt = &#x27;&#123;:5.1f&#125; &#123;:5.1f&#125; &#123;:5.1f&#125; &#123;:5.1f&#125; &#123;:5.1f&#125;&#x27;TEST_VALUES = [-1.5,-0.8,-0.5,-0.2,0,0.2,0.5,0.8,1,]for i in TEST_VALUES: print(fmt.format(i,int(i),math.trunc(i),math.floor(i),math.ceil(i),)) π: 3.141592653589793115997963468544 e: 2.718281828459045090795598298428 nan: nan inf: inf False True ========== True False ========== i int trunk floor ceil ----- ----- ----- ----- ----- -1.5 -1.0 -1.0 -2.0 -1.0 -0.8 0.0 0.0 -1.0 0.0 -0.5 0.0 0.0 -1.0 0.0 -0.2 0.0 0.0 -1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.2 0.0 0.0 0.0 1.0 0.5 0.0 0.0 0.0 1.0 0.8 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1234567891011121314151617181920# 划分整数和小数for i in range(6): print(&#x27;&#123;&#125;/2 = &#123;&#125;&#x27;.format(i, math.modf(i / 2.0)))# 排列组合数print(&#x27;&#123;:2.0f&#125; &#123;:6.0f&#125;&#x27;.format(10, math.factorial(10)))# 浮点数精确计算values = [0.1] * 10print(&#x27;for-loop : &#123;:.20f&#125;&#x27;.format(sum(values)))print(&#x27;math.fsum() : &#123;:.20f&#125;&#x27;.format(math.fsum(values)))# gcd 最大公约数print(math.gcd(10, 8))print(math.gcd(10, 0))print(math.gcd(50, 225))print(math.gcd(11, 9))print(math.gcd(0, 0))# 其他特殊函数 0/2 = (0.0, 0.0) 1/2 = (0.5, 0.0) 2/2 = (0.0, 1.0) 3/2 = (0.5, 1.0) 4/2 = (0.0, 2.0) 5/2 = (0.5, 2.0) 10 3628800 for-loop : 0.99999999999999988898 math.fsum() : 1.00000000000000000000 2 10 25 1 0 statistics 123456789101112131415161718from statistics import *data = [1, 2, 2, 5, 10, 12]# 均值print(&#x27;&#123;:0.2f&#125;&#x27;.format(mean(data)))# 中位数print(&#x27;median : &#123;:0.2f&#125;&#x27;.format(median(data)))print(&#x27;low : &#123;:0.2f&#125;&#x27;.format(median_low(data)))print(&#x27;high : &#123;:0.2f&#125;&#x27;.format(median_high(data)))# 众数print(mode(data))# 标准差,方差print(&#x27; pstdev : &#123;:6.2f&#125;&#x27;.format(pstdev(data)))print(&#x27; pvariance : &#123;:6.2f&#125;&#x27;.format(pvariance(data))) 5.33 median : 3.50 low : 2.00 high : 5.00 2 pstdev : 4.23 pvariance : 17.89 文件系统 os.path 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import osimport time# os.path 把路径当作字符串处理&#x27;&#x27;&#x27;# 相对路劲改为绝对路径abspath# 公共路径commonpath()# 公共前缀commonprefix()# 路径的最后一部分basename# 路径的前面的部分dirname# 文件是否存在exists# 字符串合并路径join()# 清除多余分隔符或者相对路径normpath# 把环境变量的指示符换成真正的值expandvars# 访问时间getatime# 修改时间getmtime# 创建时间getctime# 返回字节大小getsize&#x27;&#x27;&#x27;FILENAMES = [ # os.path.dirname(__file__), &#x27;D:\\BaiduSyncdisk\\Blog\\source&#x27;,]for file in FILENAMES: print(&#x27;File : &#123;!r&#125;&#x27;.format(file)) print(&#x27;Absolute :&#x27;, os.path.isabs(file)) print(&#x27;Is File? :&#x27;, os.path.isfile(file)) print(&#x27;Is Dir? :&#x27;, os.path.isdir(file)) print(&#x27;Is Link? :&#x27;, os.path.islink(file)) print(&#x27;Mountpoint? :&#x27;, os.path.ismount(file)) print(&#x27;Exists? :&#x27;, os.path.exists(file)) print(&#x27;Link Exists?:&#x27;, os.path.lexists(file)) print() File : 'D:\\\\BaiduSyncdisk\\\\Blog\\\\source' Absolute : True Is File? : False Is Dir? : True Is Link? : False Mountpoint? : False Exists? : True Link Exists?: True pathlib 1234567891011121314151617181920import pathlibfrom pathlib import *# 把路劲当作对象p = Path(r&#x27;./&#x27;)# iterdir目录种的每个生成一个对象print([x for x in p.iterdir() if x.is_dir()])# 模式查询所有文本print(list(p.glob(&#x27;python3lib*.ipynb&#x27;)))print(p.exists())print(p.is_dir())# p.mkdir()# p.rmdir() #空目录# p.unlink() #文件等其他# 直接用/拼接字符串q=p/&#x27;python3lib-1.ipynb&#x27;print(q)# 读文件with q.open() as f: print(f.readline()) [] [WindowsPath('python3lib-1.ipynb'), WindowsPath('python3lib-2.ipynb')] True True python3lib-1.ipynb &#123; 1234567891011121314151617181920212223242526272829# Check the file typesimport itertoolsp = Path(r&#x27;../&#x27;)to_scan = itertools.chain( p.iterdir(),)hfmt = &#x27;&#123;:18s&#125;&#x27; + (&#x27; &#123;:&gt;5&#125;&#x27; * 6)print(hfmt.format(&#x27;Name&#x27;, &#x27;File&#x27;, &#x27;Dir&#x27;, &#x27;Link&#x27;, &#x27;FIFO&#x27;, &#x27;Block&#x27;, &#x27;Character&#x27;))print()fmt = &#x27;&#123;:20s&#125; &#x27; + (&#x27;&#123;!r:&gt;5&#125; &#x27; * 6)for f in to_scan: print(fmt.format( str(f), f.is_file(), f.is_dir(), f.is_symlink(), f.is_fifo(), f.is_block_device(), f.is_char_device(), )) p = pathlib.Path(r&#x27;../_post&#x27;)print(&#x27;path : &#123;&#125;&#x27;.format(p))print(&#x27;name : &#123;&#125;&#x27;.format(p.name))print(&#x27;suffix: &#123;&#125;&#x27;.format(p.suffix))print(&#x27;stem : &#123;&#125;&#x27;.format(p.stem)) Name File Dir Link FIFO Block Character ..\\404 False True False False False False ..\\about False True False False False False ..\\books False True False False False False ..\\categories False True False False False False ..\\links False True False False False False ..\\repository False True False False False False ..\\tags False True False False False False ..\\_data False True False False False False ..\\_posts False True False False False False path : ..\\_post name : _post suffix: stem : _post 1234567891011121314p = pathlib.Path(r&#x27;./&#x27;)stat_info = p.stat()print(&#x27;&#123;&#125;:&#x27;.format(r&#x27;./&#x27;))print(&#x27; Size:&#x27;, stat_info.st_size)print(&#x27; Permissions:&#x27;, oct(stat_info.st_mode))print(&#x27; Owner:&#x27;, stat_info.st_uid)print(&#x27; Device:&#x27;, stat_info.st_dev)print(&#x27; Created :&#x27;, time.ctime(stat_info.st_ctime))print(&#x27; Last modified:&#x27;, time.ctime(stat_info.st_mtime))print(&#x27; Last accessed:&#x27;, time.ctime(stat_info.st_atime))# touch()创建一个文件或者更新修改时间# chmod()更改权限 ./: Size: 4096 Permissions: 0o40777 Owner: 0 Device: 3527538052 Created : Sat Oct 22 08:58:30 2022 Last modified: Thu Mar 16 13:20:36 2023 Last accessed: Thu Mar 16 13:36:45 2023 path : ..\\_post name : _post suffix: stem : _post glob 12345678910import glob# 查找匹配,类似正则# 只会匹配目中的所有路径,不会递归的搜索到子目录# *匹配多个 ?匹配一个for name in sorted(glob.glob(&#x27;./*.md&#x27;))[:5]: print(name) .\\LeetCode75.md .\\LeetCode剑指offer1.md .\\Linux常用命令.md .\\Neo4j.md .\\Neo4j安装.md fnmatch 12345678910111213141516171819import fnmatchimport osimport pprintpattern = &#x27;python*.ipynb&#x27;print(&#x27;Pattern :&#x27;, pattern)files = list(sorted(os.listdir(&#x27;.&#x27;)))print(&#x27;\\nFiles :&#x27;)pprint.pprint(files[:5])print(&#x27;\\nMatches :&#x27;)pprint.pprint(fnmatch.filter(files, pattern))# 返回是否匹配for name in sorted(files)[:3]: print(&#x27;Filename: &#123;:&lt;25&#125; &#123;&#125;&#x27;.format( name, fnmatch.fnmatchcase(name, pattern))) Pattern : python*.ipynb Files : ['LeetCode75.md', 'LeetCode剑指offer1.md', 'Linux常用命令.md', 'Neo4j.md', 'Neo4j安装.md'] Matches : ['python3lib-1.ipynb', 'python3lib-2.ipynb'] Filename: LeetCode75.md False Filename: LeetCode剑指offer1.md False Filename: Linux常用命令.md False linechache 123456789101112import linecache# 高效读取文本文件filename=r&#x27;D:\\BaiduSyncdisk\\Blog\\source\\_posts\\第一篇博客记录.md&#x27;# 超过回返回空字符穿print(&#x27;&#123;!r&#125;&#x27;.format(linecache.getline(filename, 2)))# 读取python源文件代码module_line = linecache.getline(&#x27;linecache.py&#x27;, 3)print(&#x27;MODULE:&#x27;)print(repr(module_line)) 'title: 第一篇博客记录\\n' MODULE: 'This is intended to read lines from modules imported -- hence if a filename\\n' tempfile 12345678910111213141516171819202122232425262728293031323334353637import tempfile# 临时文件对象import pathlibimport tempfile# 默认是在系统的临时文件区创建import tempfileprint(&#x27;gettempdir():&#x27;, tempfile.gettempdir())print(&#x27;gettempprefix():&#x27;, tempfile.gettempprefix())# 关闭文件回删除,默认句柄是w+b# TemporaryFile()没有文件名with tempfile.NamedTemporaryFile(mode=&#x27;w+t&#x27;, suffix=&#x27;_suffix&#x27;, prefix=&#x27;prefix_&#x27;, dir=&#x27;./&#x27;) as temp: temp.write(&#x27;Some data&#x27;) # 回滚到前面 temp.seek(0) print(temp.read()) print(&#x27;temp.name:&#x27;) print(&#x27; &#123;!r&#125;&#x27;.format(temp.name)) f = pathlib.Path(temp.name)print(&#x27;Exists after close:&#x27;, f.exists())# 临时目录with tempfile.TemporaryDirectory() as directory_name: the_dir = pathlib.Path(directory_name) print(the_dir) a_file = the_dir / &#x27;a_file.txt&#x27; a_file.write_text(&#x27;This file is deleted.&#x27;) print(a_file.read_text())print(&#x27;Directory exists after?&#x27;, the_dir.exists())print(&#x27;Contents after:&#x27;, list(the_dir.glob(&#x27;*&#x27;))) gettempdir(): C:\\Users\\Ada\\AppData\\Local\\Temp gettempprefix(): tmp Some data temp.name: 'd:\\\\BaiduSyncdisk\\\\Blog\\\\source\\\\_posts\\\\prefix_0iyyalif_suffix' Exists after close: False C:\\Users\\Ada\\AppData\\Local\\Temp\\tmpm9xfa5bw This file is deleted. Directory exists after? False Contents after: [] 1234567891011121314import tempfile# SpooledTemporaryFile 到一定阈值才写进去文件with tempfile.SpooledTemporaryFile(max_size=1000, mode=&#x27;w+t&#x27;, encoding=&#x27;utf-8&#x27;) as temp: print(&#x27;temp: &#123;!r&#125;&#x27;.format(temp.name)) for i in range(3): temp.write(&#x27;This line is repeated over and over.\\n&#x27;) print(temp._rolled, temp._file) print(&#x27;rolling over&#x27;) # 手动指定 temp.rollover() print(temp._rolled, temp._file) temp: None False &lt;_io.TextIOWrapper encoding='utf-8'&gt; False &lt;_io.TextIOWrapper encoding='utf-8'&gt; False &lt;_io.TextIOWrapper encoding='utf-8'&gt; rolling over True &lt;tempfile._TemporaryFileWrapper object at 0x000001E88C4ECE20&gt; shutil 12345678910111213141516171819202122232425# 高层文件操作import globimport shutilprint(&#x27;BEFORE:&#x27;, glob.glob(&#x27;./doing.*&#x27;))# 复制文件,底层函数copyfileobj()# shutil.copyfile(&#x27;./doing.ipynb&#x27;, &#x27;./doing.ipynb.copy&#x27;)print(&#x27;AFTER:&#x27;, glob.glob(&#x27;./doing.*&#x27;))# copy()如果指定目录,就会用源文件名,copy2会复制文件访问修改时间# shutil.copy(&#x27;doing.ipynb&#x27;, &#x27;example&#x27;)# 拷贝权限,和其他元素# shutil.copymode()# shutil.copystat()# 拷贝目录,可以过滤某些# shutil.copytree()# 删除目录# shutil.rmtree()# 移动,如果在同目录不一样的名字就是复制,否则移动# shutil.move()print(shutil.which(&#x27;virtualenv&#x27;))print(shutil.which(&#x27;（小区）13幢北侧垃圾亭周边袋装垃圾1处(3).jpg&#x27;))print(shutil.which(&#x27;no-such-program&#x27;)) BEFORE: ['.\\\\doing.ipynb'] AFTER: ['.\\\\doing.ipynb'] E:\\Anaconda3\\envs\\AAA\\Scripts\\virtualenv.EXE None None 1234567891011121314151617181920212223242526# # 压缩解压缩文件# import logging# import shutil# import sys# import tarfile# logging.basicConfig(# format=&#x27;%(message)s&#x27;,# stream=sys.stdout,# level=logging.DEBUG,# )# logger = logging.getLogger(&#x27;pymotw&#x27;)# print(&#x27;Creating archive:&#x27;)# shutil.make_archive(# &#x27;example&#x27;, &#x27;gztar&#x27;,# root_dir=&#x27;..&#x27;,# base_dir=&#x27;./&#x27;,# logger=logger,# )# print(&#x27;\\nArchive contents:&#x27;)# with tarfile.open(&#x27;example.tar.gz&#x27;, &#x27;r&#x27;) as t:# for n in t.getnames():# print(n) 12345# import shutil# # 解压缩文件# for format, exts, description in shutil.get_unpack_formats(&#x27;文件名&#x27;):# print(&#x27;&#123;:&lt;5&#125;: &#123;&#125;, names ending in &#123;&#125;&#x27;.format(# format, description, exts)) 1234567891011121314import shutil# 查看文件系统空间total_b, used_b, free_b = shutil.disk_usage(&#x27;.&#x27;)gib = 2 ** 30 # GiB == gibibytegb = 10 ** 9 # GB == gigabyteprint(&#x27;Total: &#123;:6.2f&#125; GB &#123;:6.2f&#125; GiB&#x27;.format( total_b / gb, total_b / gib))print(&#x27;Used : &#123;:6.2f&#125; GB &#123;:6.2f&#125; GiB&#x27;.format( used_b / gb, used_b / gib))print(&#x27;Free : &#123;:6.2f&#125; GB &#123;:6.2f&#125; GiB&#x27;.format( free_b / gb, free_b / gib)) Total: 209.72 GB 195.31 GiB Used : 67.00 GB 62.40 GiB Free : 142.72 GB 132.92 GiB filecmp 1234567import filecmp# shadow 是否比较文件内容filecmp.cmp(&#x27;&#x27;,&#x27;&#x27;,shallow=True)# 只比较当前目录,不比较内容filecmp.dircmp(&#x27;&#x27;,&#x27;&#x27;) mmap 123456789101112131415161718import mmap# 使用操作系统虚拟内存来访问数据with open(&#x27;./doing.ipynb&#x27;, &#x27;r&#x27;) as f: with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as m: # 指针向右移动10 print(&#x27;First 10 bytes via read :&#x27;, m.read(10)) # 分片操作符将指针移回起始位置,分片在向右移动10 print(&#x27;First 10 bytes via slice:&#x27;, m[:10]) # 再向右移动10 print(&#x27;2nd 10 bytes via read :&#x27;, m.read(10)) # m.flush() 修改 # 单独回滚 # m.seek(0) # rewind # f.seek(0) # rewind First 10 bytes via read : b'&#123;\\n &quot;cells&quot;' First 10 bytes via slice: b'&#123;\\n &quot;cells&quot;' 2nd 10 bytes via read : b': [\\n &#123;\\n ' codes 12345# 编码!# unicode# utf-8# assic# ... io 1234567891011121314import iooutput = io.StringIO()output.write(&#x27;This goes into the buffer. &#x27;)# 可以替换成文件print(&#x27;And so does this.&#x27;, file=output)# Retrieve the value writtenprint(output.getvalue())output.close() # discard buffer memory# Initialize a read bufferinput = io.StringIO(&#x27;Inital value for read buffer&#x27;)# Read from the bufferprint(input.read()) This goes into the buffer. And so does this. Inital value for read buffer 12345678910output = io.BytesIO()output.write(&#x27;This goes into the buffer. &#x27;.encode(&#x27;utf-8&#x27;))output.write(&#x27;ÁÇÊ&#x27;.encode(&#x27;utf-8&#x27;))# Retrieve the value writtenprint(output.getvalue())output.close() # discard buffer memory# Initialize a read bufferinput = io.BytesIO(b&#x27;Inital value for read buffer&#x27;)# Read from the bufferprint(input.read()) b'This goes into the buffer. \\xc3\\x81\\xc3\\x87\\xc3\\x8a' b'Inital value for read buffer' 数据持久存储与交换 pickle 123456789import pickle# 带s的是字符串# 不带s的是文件pickle.loads()pickle.load()pickle.dump()pickle.dumps() json 12345678910import json# 带s的是字符串# 不带s的是文件json.loads()json.load()json.dump()json.dumps() shelve,dbm 123import shelveimport dbm# 类似于字典,按键访问 sqlite3 123import sqlite3# 进程中的嵌入式关系数据库 xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152from xml.etree import ElementTree# 必须一次性遍历全部文档# 按顺序访问所有子节点iter()f=&#x27;&#x27;&#x27;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;PurchaseOrder PurchaseOrderNumber=&quot;99503&quot; OrderDate=&quot;1999-10-20&quot;&gt; &lt;Address Type=&quot;Shipping&quot;&gt; &lt;Name&gt;Ellen Adams&lt;/Name&gt; &lt;Street&gt;123 Maple Street&lt;/Street&gt; &lt;City&gt;Mill Valley&lt;/City&gt; &lt;State&gt;CA&lt;/State&gt; &lt;Zip&gt;10999&lt;/Zip&gt; &lt;Country&gt;USA&lt;/Country&gt; &lt;/Address&gt; &lt;Address Type=&quot;Billing&quot;&gt; &lt;Name&gt;Tai Yee&lt;/Name&gt; &lt;Street&gt;8 Oak Avenue&lt;/Street&gt; &lt;City&gt;Old Town&lt;/City&gt; &lt;State&gt;PA&lt;/State&gt; &lt;Zip&gt;95819&lt;/Zip&gt; &lt;Country&gt;USA&lt;/Country&gt; &lt;/Address&gt; &lt;DeliveryNotes&gt;Please leave packages in shed by driveway.&lt;/DeliveryNotes&gt; &lt;Items&gt; &lt;Item PartNumber=&quot;872-AA&quot;&gt; &lt;ProductName&gt;Lawnmower&lt;/ProductName&gt; &lt;Quantity&gt;1&lt;/Quantity&gt; &lt;USPrice&gt;148.95&lt;/USPrice&gt; &lt;Comment&gt;Confirm this is electric&lt;/Comment&gt; &lt;/Item&gt; &lt;Item PartNumber=&quot;926-AA&quot;&gt; &lt;ProductName&gt;Baby Monitor&lt;/ProductName&gt; &lt;Quantity&gt;2&lt;/Quantity&gt; &lt;USPrice&gt;39.98&lt;/USPrice&gt; &lt;ShipDate&gt;1999-05-21&lt;/ShipDate&gt; &lt;/Item&gt; &lt;/Items&gt;&lt;/PurchaseOrder&gt;&#x27;&#x27;&#x27;tree=ElementTree.fromstring(f)# for item in tree.iter(): print(item.tag) print(item.text) break# 使用attrib.get()获取属性for item in tree.iter(&#x27;PurchaseOrder&#x27;): print(item.attrib.get(&#x27;OrderDate&#x27;)) print(item.attrib.items())# findall获取所有节点for item in tree.findall(&#x27;./PurchaseOrder/Items/Item&#x27;): print(item.attrib.get(&#x27;PartNumber&#x27;)) PurchaseOrder 1999-10-20 dict_items([('PurchaseOrderNumber', '99503'), ('OrderDate', '1999-10-20')]) csv 数据压缩于归档 123456import zlibimport gzipimport bz2import tarfileimport zipfile 加密 1234567import hashlib# 可用加密算法print(&#x27;Guaranteed:\\n&#123;&#125;\\n&#x27;.format( &#x27;, &#x27;.join(sorted(hashlib.algorithms_guaranteed))))print(&#x27;Available:\\n&#123;&#125;&#x27;.format( &#x27;, &#x27;.join(sorted(hashlib.algorithms_available)))) Guaranteed: blake2b, blake2s, md5, sha1, sha224, sha256, sha384, sha3_224, sha3_256, sha3_384, sha3_512, sha512, shake_128, shake_256 Available: blake2b, blake2s, md4, md5, md5-sha1, mdc2, ripemd160, sha1, sha224, sha256, sha384, sha3_224, sha3_256, sha3_384, sha3_512, sha512, sha512_224, sha512_256, shake_128, shake_256, sm3, whirlpool 1import hmac 使用进程、线程和协程提供并发性 1 1 1 1 1 1","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"python3 标准库","slug":"python3-标准库","permalink":"https://gladdduck.github.io/tags/python3-%E6%A0%87%E5%87%86%E5%BA%93/"}]},{"title":"python标准库-1","slug":"笔记-python3lib-1","date":"2023-03-30T05:59:34.925Z","updated":"2023-04-02T03:25:27.941Z","comments":true,"path":"2023/03/30/笔记-python3lib-1/","link":"","permalink":"https://gladdduck.github.io/2023/03/30/%E7%AC%94%E8%AE%B0-python3lib-1/","excerpt":"","text":"12# help()函数查看# https://learnku.com/docs/pymotw/date-and-time/3380 文本处理 string 1234567891011121314151617181920212223import string# 文本常量,格式化,模板print(string.ascii_letters)print(string.printable )print(string.hexdigits)print(string.octdigits)print(&#x27;&#123;:&lt;30&#125;&#x27;.format(&#x27;left aligned&#x27;))print(&#x27;&#123;:0&gt;30&#125;&#x27;.format(&#x27;right aligned&#x27;))print(&#x27;&#123;:^30&#125;&#x27;.format(&#x27;centered&#x27;))print(&#x27;&#123;:*^30&#125;&#x27;.format(&#x27;centered&#x27;))print(f&#x27;&#123;&quot;centered&quot;:*^30&#125;&#x27;)print(&quot;int: &#123;0:d&#125;; hex: &#123;0:x&#125;; oct: &#123;0:o&#125;; bin: &#123;0:b&#125;&quot;.format(42))print(&quot;int: &#123;0:d&#125;; hex: &#123;0:#x&#125;; oct: &#123;0:#o&#125;; bin: &#123;0:#b&#125;&quot;.format(42))print(f&quot;int: &#123;42:d&#125;; hex: &#123;42:#x&#125;; oct: &#123;42:#o&#125;; bin: &#123;42:#b&#125;&quot;) # 总是显示它符号formatstr = &#x27;&#123;:+f&#125;; &#123;:+f&#125;&#x27;.format(3.14, -3.14) print(formatstr) # 正数前显示空格formatstr = &#x27;&#123;: f&#125;; &#123;: f&#125;&#x27;.format(3.14, -3.14) print(formatstr) # 只显示负号 同 &#x27;&#123;:f&#125;; &#123;:f&#125;&#x27;formatstr = &#x27;&#123;:-f&#125;; &#123;:-f&#125;&#x27;.format(3.14, -3.14) print(formatstr) abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!&quot;#$%&amp;'()*+,-./:;&lt;=&gt;?@[\\]^_`&#123;|&#125;~ 0123456789abcdefABCDEF 01234567 left aligned 00000000000000000right aligned centered ***********centered*********** ***********centered*********** int: 42; hex: 2a; oct: 52; bin: 101010 int: 42; hex: 0x2a; oct: 0o52; bin: 0b101010 int: 42; hex: 0x2a; oct: 0o52; bin: 0b101010 +3.140000; -3.140000 3.140000; -3.140000 3.140000; -3.140000 textwrap 1234567891011121314151617181920212223import textwrap# 多行文本处理,格式化文本段落(缩进)sample_text = &#x27;&#x27;&#x27; The textwrap module can be used to format text for output in situations where pretty-printing is desired. It offers programmatic functionality similar to the paragraph wrapping or filling features found in many text editors. &#x27;&#x27;&#x27;dedented_text = textwrap.dedent(sample_text).strip()print(dedented_text)print()for width in [45, 60]: print(&#x27;&#123;&#125; Columns:\\n&#x27;.format(width)) print(textwrap.fill(dedented_text, width=width)) print()dedented_text = textwrap.dedent(sample_text).strip()print(textwrap.fill(dedented_text, initial_indent=&#x27;&#x27;, subsequent_indent=&#x27; &#x27; * 4, width=50, )) The textwrap module can be used to format text for output in situations where pretty-printing is desired. It offers programmatic functionality similar to the paragraph wrapping or filling features found in many text editors. 45 Columns: The textwrap module can be used to format text for output in situations where pretty- printing is desired. It offers programmatic functionality similar to the paragraph wrapping or filling features found in many text editors. 60 Columns: The textwrap module can be used to format text for output in situations where pretty-printing is desired. It offers programmatic functionality similar to the paragraph wrapping or filling features found in many text editors. The textwrap module can be used to format text for output in situations where pretty-printing is desired. It offers programmatic functionality similar to the paragraph wrapping or filling features found in many text editors. re 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import re# **正则表达式**# 1.直接用re模块的函数搜索# 2.先用compile编译，然后用编译过的搜索# 匹配pattern = &#x27;this&#x27;text = &#x27;Does this text match the pattern?&#x27;match = re.search(pattern, text)s = match.start()e = match.end()print(&#x27;Found &quot;&#123;&#125;&quot;\\nin &quot;&#123;&#125;&quot;\\nfrom &#123;&#125; to &#123;&#125; (&quot;&#123;&#125;&quot;)&#x27;.format( match.re.pattern, match.string, s, e, text[s:e]))# 查询所有text = &#x27;abbaaabbbbaaaaa&#x27;pattern = &#x27;ab&#x27;for match in re.findall(pattern, text): print(&#x27;Found &#123;!r&#125;&#x27;.format(match)) text = &#x27;This is some text -- with punctuation.&#x27;print(text)print()# 组匹配patterns = [ (r&#x27;^(\\w+)&#x27;, &#x27;word at start of string&#x27;), (r&#x27;(\\w+)\\S*$&#x27;, &#x27;word at end, with optional punctuation&#x27;), (r&#x27;(\\bt\\w+)\\W+(\\w+)&#x27;, &#x27;word starting with t, another word&#x27;), (r&#x27;(\\w+t)\\b&#x27;, &#x27;word ending with t&#x27;),]for pattern, desc in patterns: regex = re.compile(pattern) match = regex.search(text) print(&quot;&#x27;&#123;&#125;&#x27; (&#123;&#125;)\\n&quot;.format(pattern, desc)) print(&#x27; &#x27;, match.groups()) print() # 替换re.sub()# 拆分re.split() Found &quot;this&quot; in &quot;Does this text match the pattern?&quot; from 5 to 9 (&quot;this&quot;) Found 'ab' Found 'ab' This is some text -- with punctuation. '^(\\w+)' (word at start of string) ('This',) '(\\w+)\\S*$' (word at end, with optional punctuation) ('punctuation',) '(\\bt\\w+)\\W+(\\w+)' (word starting with t, another word) ('text', 'with') '(\\w+t)\\b' (word ending with t) ('text',) 123456789101112131415161718&#x27;&#x27;&#x27;*:0次或多次+:一次或多次?:零次或一次&#123;a,b&#125;:指定出现次数?:在重复指令后面,取消贪心模式[ab]:匹配a或b[^ab]:不匹配a和b.:任意单个字符\\d:数字\\D:非数字\\s:空白符(制表符,空格,换行)\\S:非空白符\\w:字母数字\\W:非字母数字(?&lt;=pattern):匹配pattern开头的 (?&lt;=exp2)exp1:查找 exp2 后面的 exp1。(?&lt;!pattern):不匹配pattern开头的 (?&lt;!exp2)exp1:查找前面不是 exp2 的 exp1。&#x27;&#x27;&#x27; difflib 12345678910111213141516171819202122232425262728293031323334353637383940import difflib# 字符串比较序列text1 = &quot;&quot;&quot;Lorem ipsum dolor sit amet, consectetuer adipiscingelit. Integer eu lacus accumsan arcu fermentum euismod. Donecpulvinar porttitor tellus. Aliquam venenatis. Donec facilisispharetra tortor. In nec mauris eget magna consequatconvalis. Nam sed sem vitae odio pellentesque interdum. Sedconsequat viverra nisl. Suspendisse arcu metus, blandit quis,rhoncus ac, pharetra eget, velit. Mauris urna. Morbi nonummymolestie orci. Praesent nisi elit, fringilla ac, suscipit non,tristique vel, mauris. Curabitur vel lorem id nisl portaadipiscing. Suspendisse eu lectus. In nunc. Duis vulputatetristique enim. Donec quis lectus a justo imperdiet tempus.&quot;&quot;&quot;text1_lines = text1.splitlines()text2 = &quot;&quot;&quot;Lorem ipsum dolor sit amet, consectetuer adipiscingelit. Integer eu lacus accumsan arcu fermentum euismod. Donecpulvinar, porttitor tellus. Aliquam venenatis. Donec facilisispharetra tortor. In nec mauris eget magna consequatconvalis. Nam cras vitae mi vitae odio pellentesque interdum. Sedconsequat viverra nisl. Suspendisse arcu metus, blandit quis,rhoncus ac, pharetra eget, velit. Mauris urna. Morbi nonummymolestie orci. Praesent nisi elit, fringilla ac, suscipit non,tristique vel, mauris. Curabitur vel lorem id nisl portaadipiscing. Duis vulputate tristique enim. Donec quis lectus ajusto imperdiet tempus. Suspendisse eu lectus. In nunc.&quot;&quot;&quot;text2_lines = text2.splitlines()d = difflib.Differ()diff = d.compare(text1_lines, text2_lines)print(&#x27;\\n&#x27;.join(diff))&#x27;&#x27;&#x27;- 只在第一个文件有+ 只在第二个文件有 两个文件中都有? 没有出现在两个文件中&#x27;&#x27;&#x27; Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Integer eu lacus accumsan arcu fermentum euismod. Donec - pulvinar porttitor tellus. Aliquam venenatis. Donec facilisis + pulvinar, porttitor tellus. Aliquam venenatis. Donec facilisis ? + - pharetra tortor. In nec mauris eget magna consequat ? - + pharetra tortor. In nec mauris eget magna consequat - convalis. Nam sed sem vitae odio pellentesque interdum. Sed ? - -- + convalis. Nam cras vitae mi vitae odio pellentesque interdum. Sed ? +++ +++++ + consequat viverra nisl. Suspendisse arcu metus, blandit quis, rhoncus ac, pharetra eget, velit. Mauris urna. Morbi nonummy molestie orci. Praesent nisi elit, fringilla ac, suscipit non, tristique vel, mauris. Curabitur vel lorem id nisl porta - adipiscing. Suspendisse eu lectus. In nunc. Duis vulputate - tristique enim. Donec quis lectus a justo imperdiet tempus. + adipiscing. Duis vulputate tristique enim. Donec quis lectus a + justo imperdiet tempus. Suspendisse eu lectus. In nunc. 数据结构 enum 12345678910111213141516171819202122232425262728293031323334353637import enum# IntEnum支持大小比较class BugStatus(enum.Enum): new = 7 incomplete = 6 invalid = 5 wont_fix = 4 in_progress = 3 fix_committed = 2 fix_released = 1 by_design = 4 closed = 1# 每个东西都有一个name一个valuefor status in BugStatus: print(&#x27;&#123;:15&#125; = &#123;&#125;&#x27;.format(status.name, status.value))# 如果存在多个值，下面出现的就是别名，不想出现多个值，使用@uniqueprint(&#x27;\\nSame: by_design is wont_fix: &#x27;, BugStatus.by_design is BugStatus.wont_fix)print(&#x27;Same: closed is fix_released: &#x27;, BugStatus.closed is BugStatus.fix_released)# 空格分开，从1开始，也可以使用元组列表BugStatus = enum.Enum( value=&#x27;BugStatus&#x27;, names=(&#x27;fix_released fix_committed in_progress &#x27; &#x27;wont_fix invalid incomplete new&#x27;),)print(&#x27;Member: &#123;&#125;&#x27;.format(BugStatus.new))print(&#x27;\\nAll members:&#x27;)for status in BugStatus: print(&#x27;&#123;:15&#125; = &#123;&#125;&#x27;.format(status.name, status.value)) new = 7 incomplete = 6 invalid = 5 wont_fix = 4 in_progress = 3 fix_committed = 2 fix_released = 1 Same: by_design is wont_fix: True Same: closed is fix_released: True 1234567891011121314151617181920212223242526# 用元组作为值class BugStatus(enum.Enum): new = (7, [&#x27;incomplete&#x27;, &#x27;invalid&#x27;, &#x27;wont_fix&#x27;, &#x27;in_progress&#x27;]) incomplete = (6, [&#x27;new&#x27;, &#x27;wont_fix&#x27;]) invalid = (5, [&#x27;new&#x27;]) wont_fix = (4, [&#x27;new&#x27;]) in_progress = (3, [&#x27;new&#x27;, &#x27;fix_committed&#x27;]) fix_committed = (2, [&#x27;in_progress&#x27;, &#x27;fix_released&#x27;]) fix_released = (1, [&#x27;new&#x27;]) def __init__(self, num, transitions): self.num = num self.transitions = transitions def can_transition(self, new_state): return new_state.name in self.transitionsprint(&#x27;Name:&#x27;, BugStatus.in_progress)print(&#x27;Value:&#x27;, BugStatus.in_progress.value)print(&#x27;Custom attribute:&#x27;, BugStatus.in_progress.transitions)print(&#x27;Using attribute:&#x27;, BugStatus.in_progress.can_transition(BugStatus.new)) Name: BugStatus.in_progress Value: (3, ['new', 'fix_committed']) Custom attribute: ['new', 'fix_committed'] Using attribute: True collection ChainMap 123456789101112131415161718192021222324# ChainMapimport collections# 相当于把几个字典装入一个列表，会按照进入列表的顺序覆盖相同值# 修改任一个，会修改到原来的数据a = &#123;&#x27;a&#x27;: &#x27;A&#x27;, &#x27;c&#x27;: &#x27;C&#x27;&#125;b = &#123;&#x27;b&#x27;: &#x27;B&#x27;, &#x27;c&#x27;: &#x27;D&#x27;&#125;# 合并多个字典m = collections.ChainMap(a, b)print(m.maps)#当多个字典中有相同的key值是，默认取第一个key对应的valueprint(&#x27;Before: &#123;&#125;&#x27;.format(m[&#x27;c&#x27;]))a[&#x27;c&#x27;] = &#x27;E&#x27;print(&#x27;After : &#123;&#125;&#x27;.format(m[&#x27;c&#x27;]))print(&#x27;a:&#x27;, a)# reverse the listm.maps = list(reversed(m.maps))print(m.maps)print(&#x27;c = &#123;&#125;&#x27;.format(m[&#x27;c&#x27;])) [&#123;'a': 'A', 'c': 'C'&#125;, &#123;'b': 'B', 'c': 'D'&#125;] Before: C After : E a: &#123;'a': 'A', 'c': 'E'&#125; [&#123;'b': 'B', 'c': 'D'&#125;, &#123;'a': 'A', 'c': 'E'&#125;] c = D 12345678910111213# 搜索查询底层映射，直到一个键被找到。不同的是，写，更新和删除只操作第一个映射。dict1= &#123;&quot;a&quot;:&quot;zhangsan&quot;,&quot;b&quot;:&quot;lisi&quot;&#125;dict2= &#123;&quot;c&quot;:&quot;wangwu&quot;&#125;new_dict = collections.ChainMap(dict1,dict2)print(new_dict)new_dict1 = new_dict.new_child()print(new_dict1)new_dict1[&quot;x&quot;]=0new_dict1[&quot;y&quot;] = 100.0new_dict1[&quot;a&quot;] = 666print(new_dict1) ChainMap(&#123;'a': 'zhangsan', 'b': 'lisi'&#125;, &#123;'c': 'wangwu'&#125;) ChainMap(&#123;&#125;, &#123;'a': 'zhangsan', 'b': 'lisi'&#125;, &#123;'c': 'wangwu'&#125;) ChainMap(&#123;'x': 0, 'y': 100.0, 'a': 666&#125;, &#123;'a': 'zhangsan', 'b': 'lisi'&#125;, &#123;'c': 'wangwu'&#125;) Counter 1234567891011121314151617181920212223242526272829303132333435363738394041424344import collections# 三种构建方式1.一个元素序列，一个键值字典，关键字传参import collectionsprint(collections.Counter([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;b&#x27;]))print(collections.Counter(&#123;&#x27;a&#x27;: 2, &#x27;b&#x27;: 3, &#x27;c&#x27;: 1&#125;))print(collections.Counter(a=2, b=3, c=1))# 计数只会根据新数据增加，替换数据不会改变计数c = collections.Counter()print(&#x27;Initial :&#x27;, c)c.update(&#x27;abcdaab&#x27;)print(&#x27;Sequence:&#x27;, c)c.update(&#123;&#x27;a&#x27;: 1, &#x27;d&#x27;: 5&#125;)print(&#x27;Dict :&#x27;, c)# 可以用字典API获取值,如果没有返回0print(c[&#x27;a&#x27;],c[&#x27;666&#x27;])# elements返回所有元素,most_common()返回前n个最多的# 算数操作c1 = collections.Counter([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;b&#x27;])c2 = collections.Counter(&#x27;alphabet&#x27;)print(&#x27;C1:&#x27;, c1)print(&#x27;C2:&#x27;, c2)# 计数相加print(&#x27;\\nCombined counts:&#x27;)print(c1 + c2)# 计数相减,小于0自动删除print(&#x27;\\nSubtraction:&#x27;)print(c1 - c2)# 取最小值print(&#x27;\\nIntersection (taking positive minimums):&#x27;)print(c1 &amp; c2)# 取最大值print(&#x27;\\nUnion (taking maximums):&#x27;)print(c1 | c2) Counter(&#123;'b': 3, 'a': 2, 'c': 1&#125;) Counter(&#123;'b': 3, 'a': 2, 'c': 1&#125;) Counter(&#123;'b': 3, 'a': 2, 'c': 1&#125;) Initial : Counter() Sequence: Counter(&#123;'a': 3, 'b': 2, 'c': 1, 'd': 1&#125;) Dict : Counter(&#123;'d': 6, 'a': 4, 'b': 2, 'c': 1&#125;) 4 0 C1: Counter(&#123;'b': 3, 'a': 2, 'c': 1&#125;) C2: Counter(&#123;'a': 2, 'l': 1, 'p': 1, 'h': 1, 'b': 1, 'e': 1, 't': 1&#125;) Combined counts: Counter(&#123;'a': 4, 'b': 4, 'c': 1, 'l': 1, 'p': 1, 'h': 1, 'e': 1, 't': 1&#125;) Subtraction: Counter(&#123;'b': 2, 'c': 1&#125;) Intersection (taking positive minimums): Counter(&#123;'a': 2, 'b': 1&#125;) Union (taking maximums): Counter(&#123;'b': 3, 'a': 2, 'c': 1, 'l': 1, 'p': 1, 'h': 1, 'e': 1, 't': 1&#125;) defaultdict 123456789# 没有键时,返回函数默认值def default_factory(): return &#x27;default value&#x27;d = collections.defaultdict(default_factory, foo=&#x27;bar&#x27;)print(&#x27;d:&#x27;, d)print(&#x27;foo =&gt;&#x27;, d[&#x27;foo&#x27;])print(&#x27;bar =&gt;&#x27;, d[&#x27;bar&#x27;]) d: defaultdict(&lt;function default_factory at 0x000001AA941D3DC0&gt;, &#123;'foo': 'bar'&#125;) foo =&gt; bar bar =&gt; default value deque 1234567891011121314151617181920212223242526272829import collectionsimport random# 双端队列# list常用函数+线程安全# append(),appendleft(),pop(),popleft()# 可以设置最大长度,队列达到指定长度时会删除之前(队头)的元素d1 = collections.deque(maxlen=3)d2 = collections.deque(maxlen=3)for i in range(5): n = random.randint(0, 100) print(&#x27;n =&#x27;, n) d1.append(n) d2.appendleft(n) print(&#x27;D1:&#x27;, d1) print(&#x27;D2:&#x27;, d2)# 旋转d = collections.deque(range(10))print(&#x27;Normal :&#x27;, d)d = collections.deque(range(10))d.rotate(2)print(&#x27;Right rotation:&#x27;, d)d = collections.deque(range(10))d.rotate(-2)print(&#x27;Left rotation :&#x27;, d) n = 7 D1: deque([7], maxlen=3) D2: deque([7], maxlen=3) n = 73 D1: deque([7, 73], maxlen=3) D2: deque([73, 7], maxlen=3) n = 34 D1: deque([7, 73, 34], maxlen=3) D2: deque([34, 73, 7], maxlen=3) n = 56 D1: deque([73, 34, 56], maxlen=3) D2: deque([56, 34, 73], maxlen=3) n = 79 D1: deque([34, 56, 79], maxlen=3) D2: deque([79, 56, 34], maxlen=3) Normal : deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) Right rotation: deque([8, 9, 0, 1, 2, 3, 4, 5, 6, 7]) Left rotation : deque([2, 3, 4, 5, 6, 7, 8, 9, 0, 1]) namedtuple 12345678910111213141516import collections# 带有名字的元组,会返回一个有指定属性的类# 属性名字不能是关键字,属性不能修改Person = collections.namedtuple(&#x27;Person&#x27;, &#x27;name age&#x27;)bob = Person(name=&#x27;Bob&#x27;, age=30)print(&#x27;Representation:&#x27;, bob)# 转为OrderedDictprint(&#x27;As Dictionary:&#x27;, bob._asdict())print(&#x27;\\nBefore:&#x27;, bob)bob2 = bob._replace(name=&#x27;Robert&#x27;)print(&#x27;After:&#x27;, bob2)# 不是同一个实例print(&#x27;Same?:&#x27;, bob is bob2) Representation: Person(name='Bob', age=30) As Dictionary: &#123;'name': 'Bob', 'age': 30&#125; Before: Person(name='Bob', age=30) After: Person(name='Robert', age=30) Same?: False OrderedDict 12345678910111213141516171819202122import collections# 会记住往字典里添加的顺序import collections# 进行比较时,不仅比较值是否相同,也比较加入顺序d = collections.OrderedDict( [(&#x27;a&#x27;, &#x27;A&#x27;), (&#x27;b&#x27;, &#x27;B&#x27;), (&#x27;c&#x27;, &#x27;C&#x27;)])print(&#x27;Before:&#x27;)for k, v in d.items(): print(k, v)d.move_to_end(&#x27;b&#x27;)print(&#x27;\\nmove_to_end():&#x27;)for k, v in d.items(): print(k, v)d.move_to_end(&#x27;b&#x27;, last=False)print(&#x27;\\nmove_to_end(last=False):&#x27;)for k, v in d.items(): print(k, v) Before: a A b B c C move_to_end(): a A c C b B move_to_end(last=False): b B a A c C collections.abc array数组 1234567891011121314151617import arrayimport binascii# 返回二进制数据 data 的十六进制表示形式。 data 的每个字节都被转换为相应的2位十六进制表示形式。a = array.array(&#x27;i&#x27;, range(3))print(&#x27;Initial :&#x27;, a)s = b&#x27;This is the array.&#x27;a = array.array(&#x27;b&#x27;, s)print(&#x27;As byte string:&#x27;, s)print(&#x27;As array :&#x27;, a)print(&#x27;As hex :&#x27;, binascii.hexlify(a))# 与序列类似的函数print(chr(a[0])) Initial : array('i', [0, 1, 2]) As byte string: b'This is the array.' As array : array('b', [84, 104, 105, 115, 32, 105, 115, 32, 116, 104, 101, 32, 97, 114, 114, 97, 121, 46]) As hex : b'54686973206973207468652061727261792e' T 1234567891011121314# 二进制转换import arrayimport binasciia = array.array(&#x27;i&#x27;, range(5))print(&#x27;A1:&#x27;, a)as_bytes = a.tobytes()print(f&#x27;Byets: &#123;as_bytes&#125;&#x27;)print(&#x27;Bytes:&#x27;, binascii.hexlify(as_bytes))a2 = array.array(&#x27;i&#x27;)a2.frombytes(as_bytes)print(&#x27;A2:&#x27;, a2) A1: array('i', [0, 1, 2, 3, 4]) Byets: b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00' Bytes: b'0000000001000000020000000300000004000000' A2: array('i', [0, 1, 2, 3, 4]) 1234567891011121314151617181920212223# array文件转换import arrayimport binasciiimport tempfilea = array.array(&#x27;i&#x27;, range(5))print(&#x27;A1:&#x27;, a)# Write the array of numbers to a temporary fileoutput = tempfile.NamedTemporaryFile()a.tofile(output.file) # must pass an *actual* fileoutput.flush()# Read the raw datawith open(output.name, &#x27;rb&#x27;) as input: raw_data = input.read() print(&#x27;Raw Contents:&#x27;, binascii.hexlify(raw_data)) # Read the data into an array input.seek(0) a2 = array.array(&#x27;i&#x27;) a2.fromfile(input, len(a)) print(&#x27;A2:&#x27;, a2) heapq 123456789101112131415161718192021import heapq# 堆排序,只有小项堆# 用数组的形式表示堆,N的子元素位于2*N+1和2*N+2data=[19, 9, 4, 10, 11]print(f&#x27;original data: &#123;data&#125;&#x27;)# 把原数组转为堆结构数组# 可以之间转换堆,也可以一个个往里面添加元素heappushheapq.heapify(data)print(f&#x27;heapify data: &#123;data&#125;&#x27;)# heapreplace 删除最小元素并加入一个for n in [0, 13]: smallest = heapq.heapreplace(data, n) print(&#x27;replace &#123;:&gt;2&#125; with &#123;:&gt;2&#125;:&#x27;.format(smallest, n))print(f&#x27;replaced data: &#123;data&#125;&#x27;)# nlargest nsmallest返回前几个大/小的# heapq.merge()合并几个有序列表 original data: [19, 9, 4, 10, 11] heapify data: [4, 9, 19, 10, 11] replace 4 with 0: replace 0 with 13: replaced data: [9, 10, 19, 13, 11] bisect 123456789101112131415import bisectvalues = [14, 85, 77, 26, 50, 45, 66, 79, 10, 3, 84, 77, 1]print(&#x27;--- --- --------&#x27;)l = []for i in values: # 默认右插 position = bisect.bisect(l, i) bisect.insort(l, i) # position = bisect.bisect_left(l, i) # bisect.insort_left(l, i) print(&#x27;&#123;:3&#125; &#123;:3&#125;&#x27;.format(i, position), l) --- --- -------- 14 0 [14] 85 1 [14, 85] 77 1 [14, 77, 85] 26 1 [14, 26, 77, 85] 50 2 [14, 26, 50, 77, 85] 45 2 [14, 26, 45, 50, 77, 85] 66 4 [14, 26, 45, 50, 66, 77, 85] 79 6 [14, 26, 45, 50, 66, 77, 79, 85] 10 0 [10, 14, 26, 45, 50, 66, 77, 79, 85] 3 0 [3, 10, 14, 26, 45, 50, 66, 77, 79, 85] 84 9 [3, 10, 14, 26, 45, 50, 66, 77, 79, 84, 85] 77 8 [3, 10, 14, 26, 45, 50, 66, 77, 77, 79, 84, 85] 1 0 [1, 3, 10, 14, 26, 45, 50, 66, 77, 77, 79, 84, 85] queue 123456789101112131415161718192021222324import queue# 线程安全的队列# maxsize 是个整数，用于设置可以放入队列中的项目数的上限。# 当达到这个大小的时候，插入操作将阻塞至队列中的项目被消费掉# FIFO队列,普通队列queue.Queue()# LIFO栈queue.LifoQueue()# 优先队列queue.PriorityQueue()q = queue.PriorityQueue()# 队列的变体，按优先级顺序（最低优先）检索打开的条目。# 条目通常是以下格式的元组：# 插入格式：q.put((priority number, data))# 自定义类,实现比较方法,__eq__,__lt__q=queue.PriorityQueue()q.put((2, &quot;Lisa&quot;))q.put((1, &quot;Lucy&quot;))q.put((0, &quot;Tom&quot;))while not q.empty(): print(q.get()) (0, 'Tom') (1, 'Lucy') (2, 'Lisa') struct:二进制数据结构 123456789import struct# 将字节串解读为打包的二进制数据# struct的pack函数把任意数据类型变成bytesp=struct.pack(&#x27;&gt;I&#x27;, 66666)print(f&#x27;type-&gt;bytes:&#123;p&#125;&#x27;)# unpack把bytes变成相应的数据类型p=struct.unpack(&quot;&gt;I&quot;, b&quot;\\x00\\x01\\x04j&quot;)print(f&#x27;bytes-&gt;type:&#123;p&#125;&#x27;) type-&gt;bytes:b'\\x00\\x01\\x04j' bytes-&gt;type:(66666,) weakref:对象的非永久引用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import weakref# 弱引用不会增加对象的引用数量。因此，弱引用不会妨碍所指对象被当作垃圾回收。class ExpensiveObject: def __del__(self): print(&#x27;(Deleting &#123;&#125;)&#x27;.format(self)) def __str__(self) -&gt; str: return &#x27;ExpensiveObject&#x27;def callback(reference): &quot;&quot;&quot;Invoked when referenced object is deleted&quot;&quot;&quot; print(&#x27;callback(&#123;!r&#125;)&#x27;.format(reference))obj = ExpensiveObject()r = weakref.ref(obj, callback)# 会在finalize中提供一个对象的引用,永远不会被回收# f = weakref.finalize(obj, on_finalize, obj)print(&#x27;obj:&#x27;, obj)print(&#x27;ref:&#x27;, r)print(&#x27;r():&#x27;, r())print(&#x27;deleting obj&#x27;)del objprint(&#x27;r():&#x27;, r())# WeakValueDictionary： 实现的是一种可变映射，里面的值是对象的弱引用。# 被引用的对象在程序中的其他地方被当作垃圾回收后，对应的键会自动从 WeakValueDictionary 中删除。因此，WeakValueDictionary 经常用于缓存。# WeakValueDictionary 示例：# WeakValueDictionary 示例：class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return &#x27;Cheese(%r)&#x27; % self.kind # 执行： stock = weakref.WeakValueDictionary() # 创建弱引用字典实例。 catalog = [Cheese(&#x27;Read Leicester&#x27;), Cheese(&#x27;Tilsit&#x27;),Cheese(&#x27;Brie&#x27;), Cheese(&#x27;Parmesan&#x27;)] for cheese in catalog: stock[cheese.kind] = cheese # 名称映射到实例. [弱引用]print(sorted(stock.keys())) del catalog print(sorted(stock.keys()) ) # 为什么还剩一个？ 因为临时变量。 del cheese print(sorted(stock.keys()) ) # 临时变量删除后，为空.import weakrefclass C: # 这里新建一个类，因为WeakValueDictionary() def __init__(self, value): # 要求value是一个obj self.value = valuedef test_weak_value_dict(): d= weakref.WeakValueDictionary() #如果d是普通字典,那么还是会print(test1) k1 = &#x27;test1&#x27; v1 = C(1) # 这时候C(1)是有一个强引用的：v1 d[k1] = v1 # 这个语句也就是字典赋值，但是由于我们用的 print(d[k1]) # WeakValueDictionary()，所以字典里的是弱引用 del v1 # 这时候删除了C(1)唯一的强引用 v1，因此 print(d[k1]) # 会报错 instance ExpensiveObject obj: ExpensiveObject ref: &lt;weakref at 0x000001AA94201360; to 'ExpensiveObject' at 0x000001AA94117AF0&gt; r(): ExpensiveObject deleting obj r(): ExpensiveObject ['Brie', 'Parmesan', 'Read Leicester', 'Tilsit'] ['Parmesan'] [] copy 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 浅拷贝深拷贝import copyimport functools# 当重载比较运算符时，可以只实现其中一两种，其他的会自动生成@functools.total_orderingclass MyClass: def __init__(self, name): self.name = name def __eq__(self, other): return self.name == other.name def __gt__(self, other): return self.name &gt; other.namea = MyClass(&#x27;a&#x27;)my_list = [a]dup = copy.copy(my_list)print(&#x27; my_list:&#x27;, my_list)print(&#x27; dup:&#x27;, dup)print(&#x27; dup is my_list:&#x27;, (dup is my_list))print(&#x27; dup == my_list:&#x27;, (dup == my_list))print(&#x27;dup[0] is my_list[0]:&#x27;, (dup[0] is my_list[0]))print(&#x27;dup[0] == my_list[0]:&#x27;, (dup[0] == my_list[0]))a = MyClass(&#x27;a&#x27;)my_list = [a]dup = copy.deepcopy(my_list)print(&#x27; my_list:&#x27;, my_list)print(&#x27; dup:&#x27;, dup)print(&#x27; dup is my_list:&#x27;, (dup is my_list))print(&#x27; dup == my_list:&#x27;, (dup == my_list))print(&#x27;dup[0] is my_list[0]:&#x27;, (dup[0] is my_list[0]))print(&#x27;dup[0] == my_list[0]:&#x27;, (dup[0] == my_list[0]))# 类实现,控制建立副本# __copy()__# __deepcopy()__ my_list: [&lt;__main__.MyClass object at 0x000001AA940FF340&gt;] dup: [&lt;__main__.MyClass object at 0x000001AA940FF340&gt;] dup is my_list: False dup == my_list: True dup[0] is my_list[0]: True dup[0] == my_list[0]: True my_list: [&lt;__main__.MyClass object at 0x000001AA94208A90&gt;] dup: [&lt;__main__.MyClass object at 0x000001AA941FFFD0&gt;] dup is my_list: False dup == my_list: True dup[0] is my_list[0]: False dup[0] == my_list[0]: True 123456789101112131415161718192021222324252627282930313233343536373839404142class Graph: def __init__(self, name, connections): self.name = name self.connections = connections def add_connection(self, other): self.connections.append(other) def __repr__(self): return &#x27;Graph(name=&#123;&#125;, id=&#123;&#125;)&#x27;.format( self.name, id(self)) def __deepcopy__(self, memo): print(&#x27;\\nCalling __deepcopy__ for &#123;!r&#125;&#x27;.format(self)) if self in memo: existing = memo.get(self) print(&#x27; Already copied to &#123;!r&#125;&#x27;.format(existing)) return existing print(&#x27; Memo dictionary:&#x27;) if memo: for k, v in memo.items(): print(&#x27; &#123;&#125;: &#123;&#125;&#x27;.format(k, v)) else: print(&#x27; (empty)&#x27;) dup = Graph(copy.deepcopy(self.name, memo), []) print(&#x27; Copying to new object &#123;&#125;&#x27;.format(dup)) memo[self] = dup for c in self.connections: dup.add_connection(copy.deepcopy(c, memo)) return dup# memo字典跟踪已复制的对象避免递归root = Graph(&#x27;root&#x27;, [])a = Graph(&#x27;a&#x27;, [root])b = Graph(&#x27;b&#x27;, [a, root])root.add_connection(a)root.add_connection(b)dup = copy.deepcopy(root) pprint 1234567891011121314import pprint# 美观打印data = [ (1, &#123;&#x27;a&#x27;: &#x27;A&#x27;, &#x27;b&#x27;: &#x27;B&#x27;, &#x27;c&#x27;: &#x27;C&#x27;, &#x27;d&#x27;: &#x27;D&#x27;&#125;), (2, &#123;&#x27;e&#x27;: &#x27;E&#x27;, &#x27;f&#x27;: &#x27;F&#x27;, &#x27;g&#x27;: &#x27;G&#x27;, &#x27;h&#x27;: &#x27;H&#x27;, &#x27;i&#x27;: &#x27;I&#x27;, &#x27;j&#x27;: &#x27;J&#x27;, &#x27;k&#x27;: &#x27;K&#x27;, &#x27;l&#x27;: &#x27;L&#x27;&#125;), (3, [&#x27;m&#x27;, &#x27;n&#x27;]), (4, [&#x27;o&#x27;, &#x27;p&#x27;, &#x27;q&#x27;]), (5, [&#x27;r&#x27;, &#x27;s&#x27;, &#x27;t&#x27;&#x27;u&#x27;, &#x27;v&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;]),]print(data)# depth可以控制打印深度,width控制打印宽度,compact会尝试更加紧凑pprint.pprint(data,compact=True) [(1, &#123;'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D'&#125;), (2, &#123;'e': 'E', 'f': 'F', 'g': 'G', 'h': 'H', 'i': 'I', 'j': 'J', 'k': 'K', 'l': 'L'&#125;), (3, ['m', 'n']), (4, ['o', 'p', 'q']), (5, ['r', 's', 'tu', 'v', 'x', 'y', 'z'])] [(1, &#123;'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D'&#125;), (2, &#123;'e': 'E', 'f': 'F', 'g': 'G', 'h': 'H', 'i': 'I', 'j': 'J', 'k': 'K', 'l': 'L'&#125;), (3, ['m', 'n']), (4, ['o', 'p', 'q']), (5, ['r', 's', 'tu', 'v', 'x', 'y', 'z'])] 12345678910111213141516171819202122import loggingfrom pprint import pformatlogging.basicConfig( level=logging.DEBUG, format=&#x27;%(levelname)-8s %(message)s&#x27;,)logging.debug(&#x27;Logging pformatted data&#x27;)# 格式化转成字符串formatted = pformat(data)for line in formatted.splitlines(): logging.debug(line.rstrip()) # print(line.rstrip())# 递归打印local_data = [&#x27;a&#x27;, &#x27;b&#x27;, 1, 2]local_data.append(local_data)print(&#x27;id(local_data) =&gt;&#x27;, id(local_data))pprint.pprint(local_data)print(local_data) DEBUG Logging pformatted data DEBUG [(1, &#123;'a': 'A', 'b': 'B', 'c': 'C', 'd': 'D'&#125;), DEBUG (2, DEBUG &#123;'e': 'E', DEBUG 'f': 'F', DEBUG 'g': 'G', DEBUG 'h': 'H', DEBUG 'i': 'I', DEBUG 'j': 'J', DEBUG 'k': 'K', DEBUG 'l': 'L'&#125;), DEBUG (3, ['m', 'n']), DEBUG (4, ['o', 'p', 'q']), DEBUG (5, ['r', 's', 'tu', 'v', 'x', 'y', 'z'])] id(local_data) =&gt; 1832127417216 ['a', 'b', 1, 2, &lt;Recursion on list with id=1832127417216&gt;] ['a', 'b', 1, 2, [...]] 算法 functools:管理函数的工具 partial 123456789101112131415161718192021222324from functools import partial# 将一个函数的部分参数预先绑定为某些值，从而得到一个新的具有较少可变参数的函数# 普通函数def add(a,b,*args, **kwargs): print(f&#x27;a:&#123;a&#125;, b:&#123;b&#125;&#x27;) # 打印位置参数 for n in args: print(n) print(&quot;-&quot;*20) # 打印关键字参数 for k, v in kwargs.items(): print(&#x27;%s:%s&#x27; % (k, v)) print(&quot;-&quot;*20)# 普通调用add(1, 2, 3, v1=10, v2=20)# partial的参数会先占用函数前面的参数,后面传的会依次当作后面的形参add_partial = partial(add, 10, k1=10, k2=20)add_partial(1, 2, 3, k3=20)add_partial(1, 2, 3, k1=20) a:1, b:2 3 -------------------- v1:10 v2:20 -------------------- a:10, b:1 2 3 -------------------- k1:10 k2:20 k3:20 -------------------- a:10, b:1 2 3 -------------------- k1:20 k2:20 -------------------- 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# partialmethod和partial实现相同的功能，只是 partial在类方法中使用会报错，而此函数用在类方法中；from functools import partialmethodclass Cell(object): def __init__(self): self._alive = False @property def alive(self): return self._alive def set_state(self, state): self._alive = bool(state) set_alive = partialmethod(set_state, True) set_dead = partialmethod(set_state, False) c = Cell()c.alive # 结果为:False c.set_alive()c.alive # 结果为:Truedef standalone(self, a=1, b=2): print(&#x27; called standalone with:&#x27;, (self, a, b)) if self is not None: print(&#x27; self.attr =&#x27;, self.attr)class MyClass: def __init__(self): self.attr = &#x27;instance attribute&#x27; method1 = partialmethod(standalone) method2 = partial(standalone)o = MyClass()print(&#x27;standalone&#x27;)standalone(None)print()# 可以把对象传进去print(&#x27;method1 as partialmethod&#x27;)o.method1()print()# 穿不进去对象print(&#x27;method2 as partial&#x27;)try: o.method2()except TypeError as err: print(&#x27;ERROR: &#123;&#125;&#x27;.format(err)) standalone called standalone with: (None, 1, 2) method1 as partialmethod called standalone with: (&lt;__main__.MyClass object at 0x0000021B97BA8B80&gt;, 1, 2) self.attr = instance attribute method2 as partial ERROR: standalone() missing 1 required positional argument: 'self' 富比较 1234567891011121314151617181920212223242526272829303132333435363738394041424344import functoolsimport inspectfrom pprint import pprint&#x27;&#x27;&#x27;大于 &gt; __gt__()大于等于 &gt;= __ge__()等于 == __eq__()小于 &lt; __lt__()小于等于 &lt;= __le__()不等于 != __ne()__&#x27;&#x27;&#x27;@functools.total_orderingclass MyObject: def __init__(self, val): self.val = val def __eq__(self, other): print(&#x27; testing __eq__(&#123;&#125;, &#123;&#125;)&#x27;.format( self.val, other.val)) return self.val == other.val def __gt__(self, other): print(&#x27; testing __gt__(&#123;&#125;, &#123;&#125;)&#x27;.format( self.val, other.val)) return self.val &gt; other.valprint(&#x27;Methods:\\n&#x27;)pprint(inspect.getmembers(MyObject, inspect.isfunction))a = MyObject(1)b = MyObject(2)print(&#x27;\\nComparisons:&#x27;)for expr in [&#x27;a &lt; b&#x27;, &#x27;a &lt;= b&#x27;, &#x27;a == b&#x27;, &#x27;a &gt;= b&#x27;, &#x27;a &gt; b&#x27;]: print(&#x27;\\n&#123;:&lt;6&#125;:&#x27;.format(expr)) result = eval(expr) print(&#x27; result of &#123;&#125;: &#123;&#125;&#x27;.format(expr, result)) Methods: [('__eq__', &lt;function MyObject.__eq__ at 0x0000021B998A7940&gt;), ('__ge__', &lt;function _ge_from_gt at 0x0000021B932024C0&gt;), ('__gt__', &lt;function MyObject.__gt__ at 0x0000021B998A70D0&gt;), ('__init__', &lt;function MyObject.__init__ at 0x0000021B998A79D0&gt;), ('__le__', &lt;function _le_from_gt at 0x0000021B93202550&gt;), ('__lt__', &lt;function _lt_from_gt at 0x0000021B93202430&gt;)] Comparisons: a &lt; b : testing __gt__(1, 2) testing __eq__(1, 2) result of a &lt; b: True a &lt;= b: testing __gt__(1, 2) result of a &lt;= b: True a == b: testing __eq__(1, 2) result of a == b: False a &gt;= b: testing __gt__(1, 2) testing __eq__(1, 2) result of a &gt;= b: False a &gt; b : testing __gt__(1, 2) result of a &gt; b: False 1234567891011121314151617181920212223242526# cmp_to_key将 Python 2 程序转换至新版的转换工具，以保持对比较函数的兼容。&#x27;&#x27;&#x27;key 参数：Python 3 支持，接受的函数（入参为每个元素）返回值（对这个元素的计算），表示此元素的权值，sorted 将按照权值大小进行排序cmp 参数：Python 2 支持，接受的函数是元素中的所有需要对比的两个元素，这个函数定义大于（一般返回1）、小于（-1）、等于逻辑（1），最后根据这些比较逻辑排序&#x27;&#x27;&#x27;from functools import cmp_to_keydef mycmp(a, b): # 提取字符中的数字 a = int(&#x27;&#x27;.join([i for i in a if i.isdigit()])) b = int(&#x27;&#x27;.join([i for i in b if i.isdigit()])) if a &gt; b: print(a, &quot;vs&quot;, b, &#x27;=&#x27; , 1) return 1 elif a &lt; b: print(a, &quot;vs&quot;, b, &#x27;=&#x27; , -1) return -1 else: print(a, &quot;vs&quot;, b, &#x27;=&#x27; , 0) return 0print(sorted([&#x27;b29s&#x27;, &#x27;c2s20&#x27;, &#x27;a1-1&#x27;, &#x27;88d&#x27;], key=cmp_to_key(mycmp)))print(sorted([&#x27;b29s&#x27;, &#x27;c2s20&#x27;, &#x27;a1-1&#x27;, &#x27;88d&#x27;], key=lambda x: int(&#x27;&#x27;.join([i for i in x if i.isdigit()])))) 220 vs 29 = 1 11 vs 220 = -1 11 vs 220 = -1 11 vs 29 = -1 88 vs 29 = 1 88 vs 220 = -1 ['a1-1', 'b29s', '88d', 'c2s20'] ['a1-1', 'b29s', '88d', 'c2s20'] 缓存 123456789101112131415161718192021222324252627282930313233import functools# maxsize 设置最大缓存量# 最近最少使用@functools.lru_cache()# @functools.cache()# cache不需要移出旧值，缓存大小没有限制# return lru_cache(maxsize=None)(user_function)def expensive(a, b): # 参数必须是可散列的 print(&#x27;expensive(&#123;&#125;, &#123;&#125;)&#x27;.format(a, b)) return a * bMAX = 2print(&#x27;First set of calls:&#x27;)for i in range(MAX): for j in range(MAX): expensive(i, j)print(expensive.cache_info())print(&#x27;\\nSecond set of calls:&#x27;)for i in range(MAX + 1): for j in range(MAX + 1): expensive(i, j)print(expensive.cache_info())print(&#x27;\\nClearing cache:&#x27;)expensive.cache_clear()print(expensive.cache_info())print(&#x27;\\nThird set of calls:&#x27;)for i in range(MAX): for j in range(MAX): expensive(i, j)print(expensive.cache_info()) First set of calls: expensive(0, 0) expensive(0, 1) expensive(1, 0) expensive(1, 1) CacheInfo(hits=0, misses=4, maxsize=128, currsize=4) Second set of calls: expensive(0, 2) expensive(1, 2) expensive(2, 0) expensive(2, 1) expensive(2, 2) CacheInfo(hits=4, misses=9, maxsize=128, currsize=9) Clearing cache: CacheInfo(hits=0, misses=0, maxsize=128, currsize=0) Third set of calls: expensive(0, 0) expensive(0, 1) expensive(1, 0) expensive(1, 1) CacheInfo(hits=0, misses=4, maxsize=128, currsize=4) 缩减 12345678910111213141516171819202122232425import functoolsfrom functools import reduce# def reduce(function, iterable, initializer=None):# it = iter(iterable)# if initializer is None:# value = next(it)# else:# value = initializer# for element in it:# value = function(value, element)# return value# 是计算 ((((1+2)+3)+4)+5) 的值,前缀和print(reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) )# 默认参数放第一个initializerdef do_reduce(a, b): print(&#x27;do_reduce(&#123;&#125;, &#123;&#125;)&#x27;.format(a, b)) return a + bdata = range(1, 5)print(data)result = functools.reduce(do_reduce, data, 999)print(&#x27;result: &#123;&#125;&#x27;.format(result)) 15 range(1, 5) do_reduce(999, 1) do_reduce(1000, 2) do_reduce(1002, 3) do_reduce(1005, 4) result: 1009 泛型函数 1234567891011121314151617181920212223242526272829import functools# 不同的类型进不同的函数,根据参数的第一个参数切换函数@functools.singledispatchdef myfunc(arg): print(&#x27;default myfunc(&#123;!r&#125;)&#x27;.format(arg))@myfunc.register(int)def myfunc_int(arg): print(&#x27;myfunc_int(&#123;&#125;)&#x27;.format(arg))@myfunc.register(list)def myfunc_list(arg): print(&#x27;myfunc_list()&#x27;) for item in arg: print(&#x27; &#123;&#125;&#x27;.format(item))@myfunc.registerdef myfunc_list(arg: float): print(&#x27;myfunc_float(&#123;&#125;)&#x27;.format(arg))# 找不到匹配的类型会计算继承顺序,匹配最近的父类myfunc(&#x27;string argument&#x27;)myfunc(1)myfunc(2.3)myfunc([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]) default myfunc('string argument') myfunc_int(1) myfunc_float(2.3) myfunc_list() a b c itertools:迭代器函数 chain 12345678910111213141516# 在消费数据之前不从迭代器生成数据from itertools import chainfor i in chain([1, 2, 3], [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]): print(i, end=&#x27; &#x27;)print()def make_iterables_to_chain(): yield [1, 2, 3] yield [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]for i in chain.from_iterable(make_iterables_to_chain()): print(i, end=&#x27; &#x27;)print() 1 2 3 a b c 1 2 3 a b c zip_longest 123456789101112131415from itertools import zip_longestr1 = range(3)r2 = range(2)print(&#x27;zip stops early:&#x27;)print(list(zip(r1, r2)))r1 = range(3)r2 = range(2)print(&#x27;\\nzip_longest processes all of the values:&#x27;)print(list(zip_longest(r1, r2)))print(list(zip_longest(r1, r2,fillvalue=6666))) zip stops early: [(0, 0), (1, 1)] zip_longest processes all of the values: [(0, 0), (1, 1), (2, None)] [(0, 0), (1, 1), (2, 6666)] islice 123456789101112131415from itertools import isliceprint(&#x27;Stop at 5:&#x27;)for i in islice(range(100), 5): print(i, end=&#x27; &#x27;)print(&#x27;\\n&#x27;)print(&#x27;Start at 5, Stop at 10:&#x27;)for i in islice(range(100), 5, 10): print(i, end=&#x27; &#x27;)print(&#x27;\\n&#x27;)print(&#x27;By tens to 100:&#x27;)for i in islice(range(100), 0, 100, 10): print(i, end=&#x27; &#x27;)print(&#x27;\\n&#x27;) Stop at 5: 0 1 2 3 4 Start at 5, Stop at 10: 5 6 7 8 9 By tens to 100: 0 10 20 30 40 50 60 70 80 90 tee map,starmap 123456789101112131415161718192021222324252627282930def times_two(x): return 2 * xdef multiply(x, y): return (x, y, x * y)print(&#x27;Doubles:&#x27;)for i in map(times_two, range(5)): print(i,end=&#x27; &#x27;)print(&#x27;\\nMultiples:&#x27;)r1 = range(5)r2 = range(5, 10)for i in map(multiply, r1, r2): print(&#x27;&#123;:d&#125; * &#123;:d&#125; = &#123;:d&#125;&#x27;.format(*i))# 只运行完最短的print(&#x27;\\nStopping:&#x27;)r1 = range(5)r2 = range(2)for i in map(multiply, r1, r2): print(i)from itertools import starmap# map 传入的函数为f(x,y) starmap传入的函数为f(*x)values = [(0, 5), (1, 6), (2, 7), (3, 8), (4, 9)]for i in starmap(lambda x,y: (x*y,x,y), values): print(&#x27;&#123;&#125; * &#123;&#125; = &#123;&#125;&#x27;.format(*i)) Doubles: 0 2 4 6 8 Multiples: 0 * 5 = 0 1 * 6 = 6 2 * 7 = 14 3 * 8 = 24 4 * 9 = 36 Stopping: (0, 0, 0) (1, 1, 1) 0 * 0 = 5 6 * 1 = 6 14 * 2 = 7 24 * 3 = 8 36 * 4 = 9 count,cycle,repear 1234567891011121314151617181920from itertools import count,repeat,cycle# count无限产生值for i in zip(count(start=1, step=10), [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]): print(&#x27;&#123;&#125;: &#123;&#125;&#x27;.format(*i))# cycle无限重复值 for i in zip(range(7), cycle([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])): print(i)# repear重复n次值,不提供就是无限 for i in repeat([1,2,3,4], 5): print(i) # 组合for i, s in zip(count(), repeat(&#x27;over-and-over&#x27;, 5)): print(i, s) for i in map(lambda x, y: (x, y, x * y), repeat(2), range(5)): print(&#x27;&#123;:d&#125; * &#123;:d&#125; = &#123;:d&#125;&#x27;.format(*i)) 1: a 11: b 21: c (0, 'a') (1, 'b') (2, 'c') (3, 'a') (4, 'b') (5, 'c') (6, 'a') [1, 2, 3, 4] [1, 2, 3, 4] [1, 2, 3, 4] [1, 2, 3, 4] [1, 2, 3, 4] 0 over-and-over 1 over-and-over 2 over-and-over 3 over-and-over 4 over-and-over 2 * 0 = 0 2 * 1 = 2 2 * 2 = 4 2 * 3 = 6 2 * 4 = 8 dropwhile,takewhile,filter,filterfalse,compress 12345678910111213141516171819202122232425262728293031323334353637383940414243from itertools import dropwhile,takewhile,filterfalse,compressdef should_drop(x): print(&#x27;Testing:&#x27;, x) return x &lt; 1# 第一次为false之后的元素都会返回for i in dropwhile(should_drop, [-1, 0, 1, 2, -2]): print(&#x27;Yielding:&#x27;, i)print(&#x27;------------------------&#x27;)def should_take(x): print(&#x27;Testing:&#x27;, x) return x &lt; 2# 第一次为false之前的元素都会返回,遇见false就不返回了for i in takewhile(should_take, [-1, 0, 1, 2, -2]): print(&#x27;Yielding:&#x27;, i)print(&#x27;------------------------&#x27;)# 只返回true的元素,每一个都会计算def check_item(x): print(&#x27;Testing:&#x27;, x) return x &lt; 1for i in filter(check_item, [-1, 0, 1, 2, -2]): print(&#x27;Yielding:&#x27;, i)print(&#x27;------------------------&#x27;)# 相反def check_item(x): print(&#x27;Testing:&#x27;, x) return x &lt; 1for i in filterfalse(check_item, [-1, 0, 1, 2, -2]): print(&#x27;Yielding:&#x27;, i)print(&#x27;------------------------&#x27;)# 根据true和false选择数据every_third = cycle([False, False, True])data = range(1, 10)for i in compress(data, every_third): print(i, end=&#x27; &#x27;)print() Testing: -1 Testing: 0 Testing: 1 Yielding: 1 Yielding: 2 Yielding: -2 ------------------------ Testing: -1 Yielding: -1 Testing: 0 Yielding: 0 Testing: 1 Yielding: 1 Testing: 2 ------------------------ Testing: -1 Yielding: -1 Testing: 0 Yielding: 0 Testing: 1 Testing: 2 Testing: -2 Yielding: -2 ------------------------ Testing: -1 Testing: 0 Testing: 1 Yielding: 1 Testing: 2 Yielding: 2 Testing: -2 ------------------------ 3 6 9 groupby 1234567from itertools import groupbyd = dict(a=1, b=2, c=1, d=2, e=1, f=2, g=3)d = [(1,2),(2,3),(3,4),(4,2)]di = sorted(d, key=lambda x:x[1])for k, g in groupby(di, key=lambda x:x[1]): print(k, list(map(lambda x:x[1], g))) 2 [2, 2] 3 [3] 4 [4] accumulate 1234567891011from itertools import accumulate# 计算累计和print(list(accumulate(range(5))))print(list(accumulate(&#x27;abcde&#x27;)))def f(a, b): print(a, b) return b + a + bprint(list(accumulate(&#x27;abcde&#x27;, f))) [0, 1, 3, 6, 10] ['a', 'ab', 'abc', 'abcd', 'abcde'] a b bab c cbabc d dcbabcd e ['a', 'bab', 'cbabc', 'dcbabcd', 'edcbabcde'] product 12345678910111213141516171819202122232425262728293031323334from itertools import product# 笛卡尔积FACE_CARDS = (&#x27;J&#x27;, &#x27;Q&#x27;, &#x27;K&#x27;, &#x27;A&#x27;)SUITS = (&#x27;H&#x27;, &#x27;D&#x27;, &#x27;C&#x27;, &#x27;S&#x27;)# 顺序由输入顺序决定DECK = list( product( chain(range(2, 11), FACE_CARDS), SUITS, ))for card in DECK: print(&#x27;&#123;:&gt;2&#125;&#123;&#125;&#x27;.format(*card), end=&#x27; &#x27;) if card[1] == SUITS[-1]: print() # repear控制几个自身def show(iterable): for i, item in enumerate(iterable, 1): print(item, end=&#x27; &#x27;) if (i % 3) == 0: print() print()print(&#x27;Repeat 2:\\n&#x27;)show(list(product(range(3), repeat=2)))print(&#x27;Repeat 3:\\n&#x27;)show(list(product(range(3), repeat=3))) 2H 2D 2C 2S 3H 3D 3C 3S 4H 4D 4C 4S 5H 5D 5C 5S 6H 6D 6C 6S 7H 7D 7C 7S 8H 8D 8C 8S 9H 9D 9C 9S 10H 10D 10C 10S JH JD JC JS QH QD QC QS KH KD KC KS AH AD AC AS Repeat 2: (0, 0) (0, 1) (0, 2) (1, 0) (1, 1) (1, 2) (2, 0) (2, 1) (2, 2) Repeat 3: (0, 0, 0) (0, 0, 1) (0, 0, 2) (0, 1, 0) (0, 1, 1) (0, 1, 2) (0, 2, 0) (0, 2, 1) (0, 2, 2) (1, 0, 0) (1, 0, 1) (1, 0, 2) (1, 1, 0) (1, 1, 1) (1, 1, 2) (1, 2, 0) (1, 2, 1) (1, 2, 2) (2, 0, 0) (2, 0, 1) (2, 0, 2) (2, 1, 0) (2, 1, 1) (2, 1, 2) (2, 2, 0) (2, 2, 1) (2, 2, 2) permutations,combinations 123456789101112131415161718192021222324from itertools import permutations,combinations,combinations_with_replacementdef show(iterable): first = None for i, item in enumerate(iterable, 1): if first != item[0]: if first is not None: print() first = item[0] print(&#x27;&#x27;.join(item), end=&#x27; &#x27;) print()# 排列print(&#x27;All permutations:\\n&#x27;)show(permutations(&#x27;abcd&#x27;))print(&#x27;\\nPairs:\\n&#x27;)show(permutations(&#x27;abcd&#x27;, r=2))# 组合print(&#x27;\\nUnique pairs:\\n&#x27;)show(combinations(&#x27;abcd&#x27;, r=2))# 包含自身print(&#x27;\\nUnique pairs:\\n&#x27;)show(combinations_with_replacement(&#x27;abcd&#x27;, r=2)) All permutations: abcd abdc acbd acdb adbc adcb bacd badc bcad bcda bdac bdca cabd cadb cbad cbda cdab cdba dabc dacb dbac dbca dcab dcba Pairs: ab ac ad ba bc bd ca cb cd da db dc Unique pairs: ab ac ad bc bd cd Unique pairs: aa ab ac ad bb bc bd cc cd dd operator:内置操作符的函数结构 1234567891011121314151617from operator import *# 关键字的函数实现a = -1b = 5print(&#x27;a =&#x27;, a)print(&#x27;b =&#x27;, b)print()print(&#x27;not_(a) :&#x27;, not_(a))print(&#x27;truth(a) :&#x27;, truth(a))print(&#x27;is_(a, b) :&#x27;, is_(a, b))print(&#x27;is_not(a, b):&#x27;, is_not(a, b))for func in (lt, le, eq, ne, ge, gt): print(&#x27;&#123;&#125;(a, b): &#123;&#125;&#x27;.format(func.__name__, func(a, b))) a = -1 b = 5 not_(a) : False truth(a) : True is_(a, b) : False is_not(a, b): True lt(a, b): True le(a, b): True eq(a, b): False ne(a, b): True ge(a, b): False gt(a, b): False 1234567891011121314151617181920212223class MyObj: &quot;&quot;&quot;example class for attrgetter&quot;&quot;&quot; def __init__(self, arg): super().__init__() self.arg = arg def __repr__(self): return &#x27;MyObj(&#123;&#125;)&#x27;.format(self.arg)l = [MyObj(i) for i in range(5)]print(&#x27;objects :&#x27;, l)# Extract the &#x27;arg&#x27; value from each objectg = attrgetter(&#x27;arg&#x27;)vals = [g(i) for i in l]print(&#x27;arg values:&#x27;, vals)# Sort using argl.reverse()print(&#x27;reversed :&#x27;, l)print(&#x27;sorted :&#x27;, sorted(l, key=g)) objects : [MyObj(0), MyObj(1), MyObj(2), MyObj(3), MyObj(4)] arg values: [0, 1, 2, 3, 4] reversed : [MyObj(4), MyObj(3), MyObj(2), MyObj(1), MyObj(0)] sorted : [MyObj(0), MyObj(1), MyObj(2), MyObj(3), MyObj(4)] contextlib:上下文管理器工具 123456789101112131415161718192021222324252627282930313233343536class WithinContext: def __init__(self, context): print(&#x27;WithinContext.__init__(&#123;&#125;)&#x27;.format(context)) def do_something(self): print(&#x27;WithinContext.do_something()&#x27;) def __del__(self): print(&#x27;WithinContext.__del__&#x27;)class Context: def __init__(self, handle_error): print(&#x27;__init__(&#123;&#125;)&#x27;.format(handle_error)) self.handle_error = handle_error def __enter__(self): print(&#x27;Context.__enter__()&#x27;) # 此处返回作为as使用 return WithinContext(self) def __exit__(self, exc_type, exc_val, exc_tb): print(&#x27;__exit__()&#x27;) print(&#x27; exc_type =&#x27;, exc_type) print(&#x27; exc_val =&#x27;, exc_val) print(&#x27; exc_tb =&#x27;, exc_tb) # 返回true就不继续传递,返回false继续传递 return self.handle_errorwith Context(False) as c: c.do_something()print(&#x27;---------------&#x27;)with Context(True): raise RuntimeError(&#x27;error message handled&#x27;) __init__(False) Context.__enter__() WithinContext.__init__(&lt;__main__.Context object at 0x0000021B997DA3D0&gt;) WithinContext.__del__ WithinContext.do_something() __exit__() exc_type = None exc_val = None exc_tb = None --------------- __init__(True) Context.__enter__() WithinContext.__init__(&lt;__main__.Context object at 0x0000021B997DA3D0&gt;) WithinContext.__del__ __exit__() exc_type = &lt;class 'RuntimeError'&gt; exc_val = error message handled exc_tb = &lt;traceback object at 0x0000021B998C7D80&gt; 1234567891011121314151617181920import timefrom contextlib import contextmanager@contextmanagerdef timethis(label): start = time.time() # yield 之前的代码会在上下文管理器中作为 __enter__() 方法执行 # 所有在 yield 之后的代码会作为 __exit__() 方法执行 # 如果出现了异常，异常会在yield语句那里抛出。 try: yield finally: end = time.time() print(&#x27;&#123;&#125;: &#123;&#125;&#x27;.format(label, end - start))# Example usewith timethis(&#x27;counting&#x27;): n = 10000000 while n &gt; 0: n -= 1 counting: 0.678372859954834 日期和时间 time 12345678910111213141516171819202122232425262728293031323334353637import time# 报告系统挂钟时间,返回某一时刻的秒数print(time.time())# monotonic()递增函数,time可能因为系统时间后退# monotonic的起始时间无意义,主要是差值print(time.monotonic())# perf_counter高分辨率时钟print(time.perf_counter())# process_time处理器处理时间print(time.process_time())# ctime 返回人能看懂的时间字符串,默认返回当前时间print(time.ctime())print(time.ctime(time.time()+20))# 返回当前时间的结构化时间print(time.localtime())# 返回UTC时区的结构化时间print(time.gmtime())# 把结构化时间转化为浮点秒数print(time.mktime(time.localtime()))# 处理时区问题# 字符串时间转为结构化时间print(time.strptime(time.ctime()))# 结构化时间转化为指定格式print(time.strftime(r&quot;%Y-%m-%d %H:%M:%S&quot;,time.localtime())) 1678199761.7579758 951660.75 644.1160248 3.59375 Tue Mar 7 22:36:01 2023 Tue Mar 7 22:36:21 2023 time.struct_time(tm_year=2023, tm_mon=3, tm_mday=7, tm_hour=22, tm_min=36, tm_sec=1, tm_wday=1, tm_yday=66, tm_isdst=0) time.struct_time(tm_year=2023, tm_mon=3, tm_mday=7, tm_hour=14, tm_min=36, tm_sec=1, tm_wday=1, tm_yday=66, tm_isdst=0) 1678199761.0 time.struct_time(tm_year=2023, tm_mon=3, tm_mday=7, tm_hour=22, tm_min=36, tm_sec=1, tm_wday=1, tm_yday=66, tm_isdst=-1) 2023-03-07 22:36:01 1234567891011121314151617181920212223import textwrapimport timeavailable_clocks = [ (&#x27;monotonic&#x27;, time.monotonic), (&#x27;perf_counter&#x27;, time.perf_counter), (&#x27;process_time&#x27;, time.process_time), (&#x27;time&#x27;, time.time),]for clock_name, func in available_clocks: print(textwrap.dedent(&#x27;&#x27;&#x27;\\ &#123;name&#125;: adjustable : &#123;info.adjustable&#125; implementation: &#123;info.implementation&#125; monotonic : &#123;info.monotonic&#125; resolution : &#123;info.resolution&#125; current : &#123;current&#125; &#x27;&#x27;&#x27;).format( name=clock_name, info=time.get_clock_info(clock_name), current=func()) ) monotonic: adjustable : False implementation: GetTickCount64() monotonic : True resolution : 0.015625 current : 951073.281 perf_counter: adjustable : False implementation: QueryPerformanceCounter() monotonic : True resolution : 1e-07 current : 56.6460748 process_time: adjustable : False implementation: GetProcessTimes() monotonic : True resolution : 1e-07 current : 2.59375 time: adjustable : True implementation: GetSystemTimeAsFileTime() monotonic : False resolution : 0.015625 current : 1678199174.288961 datetime 12345678910111213141516171819import datetime# 获取年月日等today = datetime.date.today()print(today)print(&#x27;ctime :&#x27;, today.ctime())tt = today.timetuple()print(&#x27;tuple : tm_year =&#x27;, tt.tm_year)print(&#x27; tm_mon =&#x27;, tt.tm_mon)print(&#x27; tm_mday =&#x27;, tt.tm_mday)print(&#x27; tm_hour =&#x27;, tt.tm_hour)print(&#x27; tm_min =&#x27;, tt.tm_min)print(&#x27; tm_sec =&#x27;, tt.tm_sec)print(&#x27; tm_wday =&#x27;, tt.tm_wday)print(&#x27; tm_yday =&#x27;, tt.tm_yday)print(&#x27; tm_isdst =&#x27;, tt.tm_isdst)print(&#x27;ordinal:&#x27;, today.toordinal())print(&#x27;Year :&#x27;, today.year)print(&#x27;Mon :&#x27;, today.month)print(&#x27;Day :&#x27;, today.day) 2023-03-07 ctime : Tue Mar 7 00:00:00 2023 tuple : tm_year = 2023 tm_mon = 3 tm_mday = 7 tm_hour = 0 tm_min = 0 tm_sec = 0 tm_wday = 1 tm_yday = 66 tm_isdst = -1 ordinal: 738586 Year : 2023 Mon : 3 Day : 7 12345678910import datetimeimport time# 根据天数返回日期o = 733114print(&#x27;o :&#x27;, o)print(&#x27;fromordinal(o) :&#x27;, datetime.date.fromordinal(o))t = time.time()print(&#x27;t :&#x27;, t)print(&#x27;fromtimestamp(t):&#x27;, datetime.date.fromtimestamp(t)) o : 733114 fromordinal(o) : 2008-03-13 t : 1678199846.9677696 fromtimestamp(t): 2023-03-07 1234567891011121314import datetime# 获取时间对应秒数for delta in [datetime.timedelta(microseconds=1), datetime.timedelta(milliseconds=1), datetime.timedelta(seconds=1), datetime.timedelta(minutes=1), datetime.timedelta(hours=1), datetime.timedelta(days=1), datetime.timedelta(weeks=1), ]: print(&#x27;&#123;:15&#125; = &#123;:8&#125; seconds&#x27;.format( str(delta), delta.total_seconds()) ) 0:00:00.000001 = 1e-06 seconds 0:00:00.001000 = 0.001 seconds 0:00:01 = 1.0 seconds 0:01:00 = 60.0 seconds 1:00:00 = 3600.0 seconds 1 day, 0:00:00 = 86400.0 seconds 7 days, 0:00:00 = 604800.0 seconds 1234567891011121314151617import datetime# 时间的计算today = datetime.date.today()print(&#x27;Today :&#x27;, today)one_day = datetime.timedelta(days=1)print(&#x27;One day :&#x27;, one_day)yesterday = today - one_dayprint(&#x27;Yesterday:&#x27;, yesterday)tomorrow = today + one_dayprint(&#x27;Tomorrow :&#x27;, tomorrow)print()print(&#x27;tomorrow - yesterday:&#x27;, tomorrow - yesterday)print(&#x27;yesterday - tomorrow:&#x27;, yesterday - tomorrow) 1234567891011121314151617import datetimeimport time# 时间比较print(&#x27;Times:&#x27;)t1 = datetime.time(12, 55, 0)print(&#x27; t1:&#x27;, t1)t2 = datetime.time(13, 5, 0)print(&#x27; t2:&#x27;, t2)print(&#x27; t1 &lt; t2:&#x27;, t1 &lt; t2)print()print(&#x27;Dates:&#x27;)d1 = datetime.date.today()print(&#x27; d1:&#x27;, d1)d2 = datetime.date.today() + datetime.timedelta(days=1)print(&#x27; d2:&#x27;, d2)print(&#x27; d1 &gt; d2:&#x27;, d1 &gt; d2) 12345678910111213141516import datetime# 时间和日期组合在一起print(&#x27;Now :&#x27;, datetime.datetime.now())print(&#x27;Today :&#x27;, datetime.datetime.today())print(&#x27;UTC Now:&#x27;, datetime.datetime.utcnow())print()FIELDS = [ &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;hour&#x27;, &#x27;minute&#x27;, &#x27;second&#x27;, &#x27;microsecond&#x27;,]d = datetime.datetime.now()for attr in FIELDS: print(&#x27;&#123;:15&#125;: &#123;&#125;&#x27;.format(attr, getattr(d, attr))) Now : 2023-03-07 22:41:14.718075 Today : 2023-03-07 22:41:14.718076 UTC Now: 2023-03-07 14:41:14.718075 year : 2023 month : 3 day : 7 hour : 22 minute : 41 second : 14 microsecond : 719073 123456789101112import datetime# 日期格式化format = &quot;%a %b %d %H:%M:%S %Y&quot;today = datetime.datetime.today()print(&#x27;ISO :&#x27;, today)s = today.strftime(format)print(&#x27;strftime:&#x27;, s)d = datetime.datetime.strptime(s, format)print(&#x27;strptime:&#x27;, d.strftime(format)) ISO : 2023-03-07 22:40:31.254463 strftime: Tue Mar 07 22:40:31 2023 strptime: Tue Mar 07 22:40:31 2023 日期操作 1234import calendar# 设置星期一是第一天还是星期天是第一天c = calendar.TextCalendar(calendar.MONDAY)c.prmonth(2023, 3) March 2023 Mo Tu We Th Fr Sa Su 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1234import calendarimport pprintpprint.pprint(calendar.monthcalendar(2023, 3)) [[0, 0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 19], [20, 21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 0, 0]] 12# jupyter nbconvert --to markdown ***.ipynb# ipynb-&gt;markdown","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"python3 标准库","slug":"python3-标准库","permalink":"https://gladdduck.github.io/tags/python3-%E6%A0%87%E5%87%86%E5%BA%93/"}]},{"title":"更换,配置腾讯云服务器","slug":"配置-配置腾讯云服务器","date":"2023-03-30T04:30:51.203Z","updated":"2023-11-26T05:17:18.231Z","comments":true,"path":"2023/03/30/配置-配置腾讯云服务器/","link":"","permalink":"https://gladdduck.github.io/2023/03/30/%E9%85%8D%E7%BD%AE-%E9%85%8D%E7%BD%AE%E8%85%BE%E8%AE%AF%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"阿里服务器到期了,续费too expensive,改用腾讯与的新用户,188一年2核4G 服务器相关(买完服务器之后步骤) 1.改用root连接 在腾讯云服务器控制台中,修改实例密码 用ssh连接 1234ssh ubuntu@ip 输入你的密码 ssh连接上之后 123456sudo passwd root输入root密码重复一遍sudo vi /etc/ssh/sshd_config把PermitRootLogin 改为 yes(按i 进入Insert模式 然后修改 按ese退出编辑模型 :wq 退出) 然后就可以用ssh root@ip进行连接了 2.安装nginx(方面后面设置访问的根目录) 安装 123sudo apt updatesudo apt install nginxsudo systemctl status nginx 修改配置文件 123456789101112131415161718/etc/nginx/sites-enabled/default修改配置文件server &#123; # 端口 listen 80; listen [::]:80; # 域名 server_name 域名; # 这个域名访问的路径 location / &#123; root index.html的完整路径; index index.html; &#125;&#125;3. 重启nginxservice nginx restart 3.安装conda(不用python可以跳过) 官网下载conda安装包 ssh传到服务器(vscode直接拖进去) 进入到自己的文件夹(合理有序创建文件夹) bash 安装包名字 配置环境变量 1234567# 两种方式,上面一种对我没用,下面有用1. /home/../.bashrcexport PATH=..../bin:$PATHsource ~/.bashrc2. /etc/profilesource /etc/profile conda -V 不是command not found就行 4.运行python文件 123456789101112131415161718192021222324252627281. nohup python appcopy.py &gt;appcopy.log 2&gt;&amp;1 &amp;解释:2&gt;&amp;1 &amp;0 代表STDIN_FILENO 标准输入（一般是键盘），1 代表STDOUT_FILENO 标准输出（一般是显示屏，准确的说是用户终端控制台），2 三代表STDERR_FILENO (标准错误（出错信息输出）。&gt; 直接把内容生成到指定文件，会覆盖原来文件中的内容[ls &gt; test.txt],&gt;&gt; 尾部追加，不会覆盖原有内容 [ls &gt;&gt; test.txt],&lt; 将指定文件的内容作为前面命令的参数[cat &lt; text.sh]2&gt;&amp;1就是用来将标准错误2重定向到标准输出1中的。此处1前面的&amp;就是为了让bash将1解释成标准输出而不是文件1。至于最后一个&amp;，则是让bash在后台执行。2. 第一步会给一个进程ipps aux 查看所有进程3. 查看输出内容cat appcopy.log 4.关闭进程kill -9 进程编号kill -KILL 进程编号 域名相关(更换域名与之前ip的绑定) 在腾讯云域名解析页面 把之前域名绑定的ip换成现在的ip即可 但是现在的服务器要有相应的网页","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"搭建博客","slug":"搭建博客","permalink":"https://gladdduck.github.io/tags/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"}]},{"title":"LeecCode剑指offer1","slug":"算法-LeetCode剑指offer1","date":"2023-03-16T01:35:17.779Z","updated":"2023-03-30T05:57:32.307Z","comments":true,"path":"2023/03/16/算法-LeetCode剑指offer1/","link":"","permalink":"https://gladdduck.github.io/2023/03/16/%E7%AE%97%E6%B3%95-LeetCode%E5%89%91%E6%8C%87offer1/","excerpt":"","text":"LeecCode剑指offer1刷题记录 第一天 剑指 Offer 09. 用两个栈实现队列 思路:一个栈1用于进,一个栈2用于出,当2空了,就把1里面的元素全部放进2,如果此时1也空了,那就是都空了 12345678910111213141516class CQueue: def __init__(self): self.stack_in=[] self.stack_out=[] def appendTail(self, value: int) -&gt; None: self.stack_in.append(value) def deleteHead(self) -&gt; int: if len(self.stack_out): return self.stack_out.pop() else: if len(self.stack_in): while len(self.stack_in): self.stack_out.append(self.stack_in.pop()) return self.stack_out.pop() else: return -1 剑指 Offer 30. 包含min函数的栈 思路:一个单独的栈x存最小值,如果进栈的元素小于等于x最顶元素就进x,如果出栈元素等于x顶层元素,x出栈 123456789101112131415161718class MinStack: def __init__(self): self.stack=[] self.minnums=[] def push(self, x: int) -&gt; None: self.stack.append(x) if not len(self.minnums) or x&lt;=self.minnums[-1]: self.minnums.append(x) def pop(self) -&gt; None: if self.stack[-1]==self.minnums[-1]: self.stack.pop() self.minnums.pop() else: self.stack.pop() def top(self) -&gt; int: return self.stack[-1] def min(self) -&gt; int: return self.minnums[-1] 第二天 剑指 Offer 06. 从尾到头打印链表 思路:1.遍历一遍链表,用数组存每个元素,然后返回数组的逆序 2.递归 12345678class Solution: def reversePrint(self, head: ListNode) -&gt; List[int]: ans=[] while head: ans.append(head.val) head=head.next return ans[::-1] # return self.reversePrint(head.next) + [head.val] if head else [] 剑指 Offer 24. 反转链表 思路:1.三个指针,模拟列表断开向后连接的情景,2.把链表元素都存在数组里,当作一个个单独的节点,反过来连接 12345678910111213141516171819class Solution: def reverseList(self, head: ListNode) -&gt; ListNode: if head is None:return head re=[] while head: re.append(head) temp=head.next head.next=None head=temp re.reverse() print(re) ret=None for i in range(len(re)): if ret is None: ret=re[i] else: ret.next=re[i] ret=ret.next return re[0] 剑指 Offer 35. 复杂链表的复制 错误思路:不能像普通链表一样遍历重新连接,因为random指针的节点可能还没遍历到 思路:1.递归 2.把A-B-C的链表 改造成A-A’-B-B’-C-C’,然后模仿原指针的下一个位置,主要各个边界条件的判断 12345678910111213141516171819202122232425# 拼接+拆分class Solution: def copyRandomList(self, head: &#x27;Node&#x27;) -&gt; &#x27;Node&#x27;: if head is None :return None temphead=head while head: temp=Node(head.val) temp.next=head.next head.next=temp head=head.next.next head=temphead while head: if head.random: head.next.random=head.random.next head=head.next.next orighead=head=temphead.next ans=head while head: if head.next is None: break temp=orighead.next.next head.next=orighead.next.next head=head.next orighead=temp return ans 123456789101112131415161718// Hash表+递归class Solution &#123;public: unordered_map&lt;Node*, Node*&gt; cachedNode; Node* copyRandomList(Node* head) &#123; if (head == nullptr) &#123; return nullptr; &#125; if (!cachedNode.count(head)) &#123; Node* headNew = new Node(head-&gt;val); cachedNode[head] = headNew; headNew-&gt;next = copyRandomList(head-&gt;next); headNew-&gt;random = copyRandomList(head-&gt;random); &#125; return cachedNode[head]; &#125;&#125;; 第三天 剑指 Offer 05. 替换空格 思路:先用数组比直接返回str.replace时间空间上都要快不少 1234567class Solution: def replaceSpace(self, s: str) -&gt; str: res = [] for c in s: if c == &#x27; &#x27;: res.append(&quot;%20&quot;) else: res.append(c) return &quot;&quot;.join(res) 剑指 Offer 58 - II. 左旋转字符串 思路:. 123class Solution: def reverseLeftWords(self, s: str, n: int) -&gt; str: return s[n:]+s[:n] 第四天 剑指 Offer 03. 数组中重复的数字 思路:1.字典存 2.排序 3.一直交换到已有 12345678910111213141516171819class Solution: def findRepeatNumber(self, nums: List[int]) -&gt; int: m=dict() for i in nums: if i in m: return i m[i]=1class Solution: def findRepeatNumber(self, nums: [int]) -&gt; int: i = 0 while i &lt; len(nums): if nums[i] == i: i += 1 continue if nums[nums[i]] == nums[i]: return nums[i] nums[nums[i]], nums[i] = nums[i], nums[nums[i]] return -1 剑指 Offer 53 - I. 在排序数组中查找数字 I 思路:二分,然后下标加到不是这个数 123456789class Solution: def search(self, nums: List[int], target: int) -&gt; int: index=bisect_left(nums,target) length=len(nums) ans=0 while index&lt;length and nums[index]==target: ans+=1 index+=1 return ans 剑指 Offer 53 - II. 0～n-1中缺失的数字 思路:1.直接遍历 2.hash 3.位运算 4.应该的和-实际的和=差的数字 5.二分 12345678910111213141516# 后面加n个数 一起异或,缺的数只会出现一次,相同的数异或两次为-class Solution: def missingNumber(self, nums: List[int]) -&gt; int: # ans=0 # for index,num in enumerate(nums): # ans^=index # ans^=num # return ans^len(nums) left,right=0,len(nums)-1 while left&lt;=right: mid=(left+right)&gt;&gt;1 if nums[mid]==mid: left=mid+1 else: right=mid-1 return left 第五天 剑指 Offer 11. 旋转数组的最小数字 思路:根据凹的性质一次遍历,如果找不到那么就是递增的,直接返回numbers[0] 123456class Solution: def minArray(self, numbers: List[int]) -&gt; int: for i in range(1,len(numbers)): if numbers[i]&lt;numbers[i-1]: return numbers[i] return numbers[0] 剑指 Offer 50. 第一个只出现一次的字符 思路:1.OrderedDict 2.Counter 123456789101112131415class Solution: def firstUniqChar(self, s: str) -&gt; str: m=OrderedDict() for i in s: m[i]=m.get(i,0)+1 for k,v in m.items(): if v==1: return k return &#x27; &#x27; # frequency = collections.Counter(s) # for i, ch in enumerate(s): # if frequency[ch] == 1: # return ch # return &#x27; &#x27; 剑指 Offer 04. 二维数组中的查找 思路:1.对每一行二分O(N∗log(N))O(N*log(N))O(N∗log(N)) 2.把矩阵向左旋转90度就是一个搜索树,从底向上搜索, 每次可消去一行或者一列 O(N+M)O(N+M)O(N+M) 1234567891011121314class Solution: def findNumberIn2DArray(self, matrix: List[List[int]], target: int) -&gt; bool: if len(matrix)==0:return False m=len(matrix[0]) n=len(matrix) i,j=n-1,0 while i&gt;=0 and j&lt;m: if matrix[i][j]&gt;target: i-=1 elif matrix[i][j]&lt;target: j+=1 else: return True return False 第六天 剑指 Offer 32 - I. 从上到下打印二叉树 思路:广搜 1234567891011121314class Solution: def levelOrder(self, root: TreeNode) -&gt; List[int]: if not root:return [] stack=collections.deque([root]) ans=[] while len(stack): cur=stack.popleft() ans.append(cur.val) if cur.left: stack.append(cur.left) if cur.right: stack.append(cur.right) return ans 剑指 Offer 32 - II. 从上到下打印二叉树 II 思路:1.广搜存节点的时候新增一个layer表示在第几层 2.每一次遍历完队列中的所有节点 3.记录每一层的最后一个节点 1234567891011121314151617181920212223242526272829303132333435class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root:return [] stack=collections.deque([(root,1)]) ans=[] temp=[root.val] lastlayer=-1 while len(stack): (cur,layer)=stack.popleft() if layer!=lastlayer: ans.append(temp) temp=[] if cur.left: stack.append((cur.left,layer+1)) temp.append(cur.left.val) if cur.right: stack.append((cur.right,layer+1)) temp.append(cur.right.val) lastlayer=layer return ansclass Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root: return [] res, queue = [], collections.deque() queue.append(root) while queue: tmp = [] for _ in range(len(queue)): node = queue.popleft() tmp.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) res.append(tmp) return res 剑指 Offer 32 - III. 从上到下打印二叉树 III 思路:在上面一题的基础上,在新增每一层的时候,用一个标志,奇数正加,偶数反加 1234567891011121314151617181920212223class Solution: def levelOrder(self, root: TreeNode) -&gt; List[List[int]]: if not root:return [] stack=collections.deque([(root,1)]) ans=[] temp=[root.val] lastlayer=0 while len(stack): (cur,layer)=stack.popleft() if layer!=lastlayer: if layer&amp;1: ans.append(temp) else: ans.append(temp[::-1]) temp=[] if cur.left: stack.append((cur.left,layer+1)) temp.append(cur.left.val) if cur.right: stack.append((cur.right,layer+1)) temp.append(cur.right.val) lastlayer=layer return ans 第七天 剑指 Offer 26. 树的子结构 思路:1. 先找到子树的根节点,然后对比剩下的部分是否一样,判断条件比较多 2.三种情况,一个是从当前节点比,一个是左子树的子树,一个是右子树的子树 12345678class Solution: def isSubStructure(self, A: TreeNode, B: TreeNode) -&gt; bool: def recur(A, B): if not B: return True if not A or A.val != B.val: return False return recur(A.left, B.left) and recur(A.right, B.right) return bool(A and B) and (recur(A, B) or self.isSubStructure(A.left, B) or self.isSubStructure(A.right, B)) 剑指 Offer 27. 二叉树的镜像 思路:递归交换左右子树 12345678910class Solution: def mirrorTree(self, root: TreeNode) -&gt; TreeNode: if root is None:return None l,r=None,None if root.left: r=self.mirrorTree(root.left) if root.right: l=self.mirrorTree(root.right) root.right,root.left=r,l return root 剑指 Offer 28. 对称的二叉树 错误思路:只比较了左右子树,没有从全局对比 题解:1.两个指针,反过来比(一个从左往右走,一个从右往左走) 2.交换左右子树再递归查询 1234567891011121314class Solution: def isSymmetric(self, root: TreeNode) -&gt; bool: def check(a,b): if a is None and b is None: return True if a is None and b : return False if b is None and a: return False if a.val != b.val: return False return check(a.left,b.right) and check(a.right,b.left) return check(root,root) 第八天 剑指 Offer 10- I. 斐波那契数列 剑指 Offer 10- II. 青蛙跳台阶问题 思路:1.递归 2.记忆递归 3.动态规划 4.空间优化的动态规划 12345678910class Solution: def fib(self, n: int) -&gt; int: if n==0:return 0 a=0 b=1 for i in range(2,n+1): a,b=b,a+b a%=1e9+7 b%=1e9+7 return int(b) 剑指 Offer 63. 股票的最大利润 思路:保存最小的价格 一次遍历,比较答案和今天减去最小价格,更新最小价格 12345678910111213141516171819202122class Solution: def maxProfit(self, prices: List[int]) -&gt; int: # if len(prices)==0: # return 0 # ans=0 # leftprofit=0 # buyprice=prices[0] # for index in range(1,len(prices)): # if prices[index]-prices[index-1]+leftprofit&gt;=0: # leftprofit=prices[index]-prices[index-1]+leftprofit # ans=max(ans,leftprofit) # else: # buyprice=prices[index] # leftprofit=0 # return ans inf = int(1e9) minprice = inf maxprofit = 0 for price in prices: maxprofit = max(price - minprice, maxprofit) minprice = min(price, minprice) return maxprofit 第九天 剑指 Offer 42. 连续子数组的最大和 思路:如果之前的加上当前的是负数,那就把当前的当作开始 1234567891011class Solution: def maxSubArray(self, nums: List[int]) -&gt; int: # for i in range(1, len(nums)): # nums[i] += max(nums[i - 1], 0) # return max(nums) pre = 0 maxAns = nums[0] for x in nums: pre = max(pre + x, x) maxAns = max(maxAns, pre) return maxAns 剑指 Offer 47. 礼物的最大价值 思路:二维DP基础 1234567891011121314151617181920212223class Solution: def maxValue(self, grid: List[List[int]]) -&gt; int: # n=len(grid) # m=len(grid[0]) # dp=[[0]*m for _ in range(n)] # dp[0][0]=grid[0][0] # for i in range(1,n): # dp[i][0]=dp[i-1][0]+grid[i][0] # for i in range(1,m): # dp[0][i]=dp[0][i-1]+grid[0][i] # for i in range(1,n): # for j in range(1,m): # dp[i][j]=max(dp[i-1][j],dp[i][j-1])+grid[i][j] # return dp[n-1][m-1] m, n = len(grid), len(grid[0]) for j in range(1, n): # 初始化第一行 grid[0][j] += grid[0][j - 1] for i in range(1, m): # 初始化第一列 grid[i][0] += grid[i - 1][0] for i in range(1, m): for j in range(1, n): grid[i][j] += max(grid[i][j - 1], grid[i - 1][j]) return grid[-1][-1] 第十天 剑指 Offer 46. 把数字翻译成字符串 思路:如果和当前的数和前面的数组合小于26,当前的情况就可以由前一个数的情况加上前两个数的情况得到,如果大于25,那就只是能前面的情况 12345678910111213141516171819202122232425262728class Solution: def translateNum(self, num: int) -&gt; int: num=str(num) length=len(num) if length==1: return 1 a=1 b=0 if int(num[0])*10+int(num[1])&lt;=25 and int(num[0])*10!=0: b=2 else: b=1 for index,item in enumerate(num[2:],2): if int(num[index-1])*10+int(num[index])&lt;=25 and int(num[index-1])*10!=0: b,a=a+b,b else: b,a=b,b return b &#x27;&#x27;&#x27; s = str(num) a = b = 1 for i in range(2, len(s) + 1): tmp = s[i - 2:i] c = a + b if &quot;10&quot; &lt;= tmp &lt;= &quot;25&quot; else a b = a a = c return a &#x27;&#x27;&#x27; 剑指 Offer 48. 最长不含重复字符的子字符串 思路:双指针维护当前不含重复字符的区间,用字典存区间里的字符,如果当前区间新增了一个不重复的,就更新答案,如果加了一个重复的,左指针一直移到不重复的点 12345678910111213141516class Solution: def lengthOfLongestSubstring(self, s: str) -&gt; int: left,right=0,0 length=len(s) ans=0 count=dict() while right&lt;length: if count.get(s[right],-1)==-1: count[s[right]]=1 right+=1 ans=max(ans,right-left) else: count[s[left]]=-1 left+=1 return ans 第十一天 剑指 Offer 22. 链表中倒数第k个节点 思路:遍历一遍得到长度,然后找到length-k的节点 剑指 Offer 18. 删除链表的节点 思路:存好前一个节点 第十二天 剑指 Offer 25. 合并两个排序的链表 思路:归并排序的合并 1234567891011121314class Solution: def mergeTwoLists(self, l1: ListNode, l2: ListNode) -&gt; ListNode: ans=ListNode(-1) pre=ans while l1 and l2: if l1.val&lt;l2.val: pre.next=l1 l1=l1.next else: pre.next=l2 l2=l2.next pre=pre.next pre.next=l1 if l1 else l2 return ans.next 剑指 Offer 52. 两个链表的第一个公共节点 思路:A链表一个指针A,B链表一个指针B,如果A指针遍历完A了,就指向B链表,B同理,这两相当于把两个链表拼接了,AB-BA,这样解决了长度不一致的问题 123456789101112131415class Solution: def getIntersectionNode(self, headA: ListNode, headB: ListNode) -&gt; ListNode: pA,pB=headA,headB while pA or pB: if pA==pB: return pA if pA: pA=pA.next else: pA=headB if pB: pB=pB.next else: pB=headA return None 第十三天 剑指 Offer 21. 调整数组顺序使奇数位于偶数前面 思路:双指针,类似快排 123456789101112131415161718class Solution: def exchange(self, nums: List[int]) -&gt; List[int]: length=len(nums) left,right=0,length-1 while left&lt;right: flag=False while left&lt;length and nums[left]&amp;1: left+=1 flag=True while right&gt;=0 and nums[right]&amp;1==0: right-=1 flag=True if left&gt;right: return nums nums[left],nums[right]=nums[right],nums[left] left+=1 right-=1 return nums 剑指 Offer 57. 和为s的两个数字 思路:双指针,一个从左一个从右,根据当前和的大小,移动指针 123456789101112class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: length=len(nums) left,right=0,length-1 while left&lt;right: if nums[left]+nums[right]&gt;target: right-=1 elif nums[left]+nums[right]&lt;target: left+=1 else: return [nums[left],nums[right]] return None 剑指 Offer 58 - I. 翻转单词顺序 思路:分词转置,用队列手动实现 1234class Solution: def reverseWords(self, s: str) -&gt; str: word=s.split() return &quot; &quot;.join(word[::-1]) 十四天 剑指 Offer 12. 矩阵中的路径 思路:从每一个格子dfs搜索 1234567891011121314151617181920212223242526272829class Solution: def exist(self, board: List[List[str]], word: str) -&gt; bool: length=len(word) n=len(board) m=len(board[0]) visited=[[0]*m for _ in range(n)] def dfs(cur,x,y): if board[x][y]!=word[cur]: return False if cur==length-1: return True for i,j in [(1,0),(-1,0),(0,1),(0,-1)]: x_,y_=x+i,y+j if 0&lt;=x_&lt;n and 0&lt;=y_&lt;m and not visited[x_][y_]: visited[x_][y_]=1 if dfs(cur+1,x_,y_): return True visited[x_][y_]=0 return False for i in range(n): for j in range(m): if board[i][j]==word[0]: visited[i][j]=1 if dfs(0,i,j): return True visited[i][j]=0 return False 面试题13. 机器人的运动范围 思路:1.dfs搜索 2.两个for循环遍历,用字典存已访问 123456789101112131415161718192021222324252627282930313233class Solution: def movingCount(self, m: int, n: int, k: int) -&gt; int: def check(a,b): t=0 for num in chain(str(a),str(b)): t+=int(num) if t&lt;=k: return True return False # visited=&#123;&#125; # ans=0 # def dfs(x,y): # for i,j in [(1,0),(-1,0),(0,1),(0,-1)]: # x_,y_=x+i,y+j # if 0&lt;=x_&lt;n and 0&lt;=y_&lt;m and (x_,y_) not in visited: # visited[(x_,y_)]=1 # if check(x_,y_): # nonlocal ans # ans+=1 # dfs(x_,y_) # if k&gt;=0: # ans+=1 # visited[(0,0)]=1 # dfs(0,0) # return ans visited=&#123;&#125; visited[(0,0)]=1 for i in range(n): for j in range(m): if ((i-1,j) in visited or (i,j-1) in visited) : if check(i,j): visited[(i,j)]=1 return len(visited) 第十五天 剑指 Offer 34. 二叉树中和为某一值的路径 思路:dfs搜索并存储路径 题解:广搜,存节点的父节点,找到和之后反着找路径 1234567891011121314151617181920class Solution: def pathSum(self, root: TreeNode, target: int) -&gt; List[List[int]]: if not root:return [] ans=[] def dfs(curnode,cursum,path): # s起点，e终点 if not curnode.left and not curnode.right: if cursum == target: nonlocal ans ans.append(path[:]) return if curnode.left: path.append(curnode.left.val) dfs(curnode.left,cursum+curnode.left.val,path) path.pop() if curnode.right: path.append(curnode.right.val) dfs(curnode.right,cursum+curnode.right.val,path) path.pop() dfs(root,root.val,[root.val]) return ans 剑指 Offer 36. 二叉搜索树与双向链表 思路:类似线索二叉树的构造,一个指针存上一个节点,注意的是第一个节点和最后一个节点的处理 1234567891011121314151617class Solution: def treeToDoublyList(self, root: &#x27;Node&#x27;) -&gt; &#x27;Node&#x27;: if not root:return root self.pre=None def dfs(cur): if not cur: return dfs(cur.left) if not self.pre: self.head=cur else: self.pre.right,cur.left=cur,self.pre self.pre=cur dfs(cur.right) dfs(root) self.head.left=self.pre self.pre.right=self.head return self.head 剑指 Offer 54. 二叉搜索树的第k大节点 思路:1.中序遍历,输出数组的k大节点 2.在遍历二叉树的时候,先搜右子树,再搜左子树,记录当前节点是第几大 123456789101112131415161718class Solution: def kthLargest(self, root: TreeNode, k: int) -&gt; int: cnt=0 ans=-1 def dfs(curnode): # s起点，e终点 nonlocal cnt if cnt&gt;k:return if curnode.right: dfs(curnode.right) if cnt+1==k: nonlocal ans ans=curnode.val cnt+=1 if cnt&gt;k:return if curnode.left: dfs(curnode.left) dfs(root) return ans 第十六天 面试题45. 把数组排成最小的数 思路:根据数字排序,具体的,A,B两个数, 转为字符串拼接成AB和BA,逐个比较两个的大小,小的放前面,为什么转为AB,不同的数字不影响,比如123,124,主要防止这种情况1230和123,或者123和1234 ,这两个数字应该是在答案中挨在一起的,组合成AB,BA就是答案需要的最小数 12345678910111213141516171819class Solution: def minNumber(self, nums: List[int]) -&gt; str: def cmp(a,b): a=str(a) b=str(b) tempa=a a+=b b+=tempa for i,j in zip(a,b): if i&lt;j: return -1 if i&gt;j: return 1 return 0 nums.sort(key=functools.cmp_to_key(cmp)) print(nums) return &quot;&quot;.join(map(str,nums)) 面试题61. 扑克牌中的顺子 思路：没读懂题目 题解: 就是判断五个数是不是连着的,但是大小王可以当作任何数. 判断不能有重复且最大值-最小值+大小王的数量应该小于5 1234567891011class Solution: def isStraight(self, nums: List[int]) -&gt; bool: repeat = set() ma, mi = 0, 14 for num in nums: if num == 0: continue # 跳过大小王 ma = max(ma, num) # 最大牌 mi = min(mi, num) # 最小牌 if num in repeat: return False # 若有重复，提前返回 false repeat.add(num) # 添加牌至 Set return ma - mi &lt; 5 # 最大牌 - 最小牌 &lt; 5 则可构成顺子 第十七天 剑指 Offer 40. 最小的k个数 思路:1.排序 2.堆排序 3.快速排序:如果当前作为基数的这个值下标正好是k,那么他左边的就是前k小的数,否则分开排序左右两边 12345678910111213141516171819202122232425class Solution: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: # if k==0:return [] # a=[-arr[i] for i in range(k)] # heapq.heapify(a) # for item in arr[k:]: # if -item &gt; a[0]: # heapq.heappushpop(a,-item) # return list(map(lambda x:-x,a)) if k==0:return [] if k&gt;=len(arr):return arr def quick_sort(l,r): i,j=l,r while i&lt;j: while i&lt;j and arr[j]&gt;=arr[l]:j-=1 while i&lt;j and arr[i]&lt;=arr[l]:i+=1 arr[i],arr[j]=arr[j],arr[i] arr[i],arr[l]=arr[l],arr[i] if k&lt;i:return quick_sort(l,i-1) if k&gt;i:return quick_sort(i+1,r) return arr[:k] return quick_sort(0,len(arr)-1) 剑指 Offer 41. 数据流中的中位数 思路:1.二分查找插入位置,保持数组有序 2.两个优先队列,一个存左半部分一个存右半部分,固定一个是奇数,或者两个都是偶数,这样取值的时候固定取一个一个队列或者两个一起取,存值的时候,也要注意奇偶数 12345678910111213141516171819202122232425262728293031from heapq import *class MedianFinder: def __init__(self): # self.list=[] # self.length=0 # 存小 /大项堆 self.A=[] # 存大 /小项堆 self.B=[] def addNum(self, num: int) -&gt; None: # if self.length==0: # self.list.append(num) # else: # index=bisect.bisect_left(self.list,num) # self.list.insert(index,num) # self.length+=1 if (len(self.A)+len(self.B))&amp;1: heappush(self.A,-heappushpop(self.B,num)) else: heappush(self.B,-heappushpop(self.A,-num)) def findMedian(self) -&gt; float: # if self.length&amp;1: # return self.list[self.length//2] # else: # return (self.list[self.length//2-1]+self.list[self.length//2])/2 if (len(self.A)+len(self.B))&amp;1: return self.B[0] return (self.B[0]-self.A[0])/2 第十八天 剑指 Offer 55 - I. 二叉树的深度 思路:广搜的层次遍历,深搜也行 1234567891011121314151617181920from collections import dequeclass Solution: def maxDepth(self, root: TreeNode) -&gt; int: if not root:return 0 ans=0 que=deque() que.append(root) while que: length=len(que) for i in range(length): cur=que.popleft() if cur.left: que.append(cur.left) if cur.right: que.append(cur.right) ans+=1 return ans 剑指 Offer 55 - II. 平衡二叉树 思路:和上面一题同理,都是计算树的深度,这题递归求比较方便 123456789101112131415class Solution: ans=True def isBalanced(self, root: TreeNode) -&gt; bool: def aaa(cur): if not cur:return 0 if not cur.left and not cur.right: return 1 left=self.isBalanced(cur.left) right=self.isBalanced(cur.right) if abs(left-right)&gt;1: print(left,right) self.ans=False return max(left,right)+1 aaa(root) return self.ans 第十九天 剑指 Offer 64. 求1+2+…+n 思路:无, 题解:利用逻辑运算的短路性质当作if判断,n&gt;1的时候 执行递归,否则就是直接短路了 1234567class Solution: def __init__(self): self.res = 0 def sumNums(self, n: int) -&gt; int: n &gt; 1 and self.sumNums(n - 1) self.res += n return self.res 剑指 Offer 68 - I. 二叉搜索树的最近公共祖先 思路:如果两个值都小于当前节点,则递归搜索左子树,如果都大于当前节点,递归搜索右子树,否则当前节点就是公共祖先 1234567891011121314class Solution: def __init__(self): self.ans=None def lowestCommonAncestor(self, root: &#x27;TreeNode&#x27;, p: &#x27;TreeNode&#x27;, q: &#x27;TreeNode&#x27;) -&gt; &#x27;TreeNode&#x27;: if not root:return root def do(cur): if p.val&lt;cur.val and q.val&lt;cur.val: do(cur.left) elif p.val&gt;cur.val and q.val &gt; cur.val: do(cur.right) else: self.ans=cur do(root) return self.ans 剑指 Offer 68 - II. 二叉树的最近公共祖先 思路:1.dfs搜索一遍存父节点 然后用字典存一个节点的父节点,搜另一个节点时,如果父节点存在就是祖先 2.在深搜的时候,分条件,如果 节点分别在左右子树 或者 一个节点在子树,另一个节点就是当前节点,那么就是答案 12345678910111213141516171819202122232425262728293031class Solution: ans=None def lowestCommonAncestor(self, root: TreeNode, p: TreeNode, q: TreeNode) -&gt; TreeNode: # def dfs(cur): # if not cur :return False # left=dfs(cur.left) # right=dfs(cur.right) # if (left and right) or ((left or right) and (cur==p or cur == q)): # self.ans=cur # return left or right or cur==p or cur == q # dfs(root) # return self.ans fa=&#123;&#125; def dfs(cur): if cur.left: fa[cur.left.val]=cur dfs(cur.left) if cur.right: fa[cur.right.val]=cur dfs(cur.right) fa[root.val]=None dfs(root) vis=&#123;&#125; while p: vis[p]=1 p=fa[p.val] while q: if q in vis: return q q=fa[q.val] return None 第二十天 剑指 Offer 07. 重建二叉树 思路:根据两个遍历顺序,画图分析一下,递归的建树就行 123456789101112class Solution: def buildTree(self, preorder: List[int], inorder: List[int]) -&gt; TreeNode: def build(pre,ino): if len(pre)==0: return None root=TreeNode(pre[0]) root_index=ino.index(pre[0]) root.left=build(pre[1:1+root_index],ino[:root_index]) root.right=build(pre[1+root_index:],ino[root_index+1:]) return root return build(preorder,inorder) 剑指 Offer 33. 二叉搜索树的后序遍历序列 思路:二叉搜索树,中序遍历是顺序的,有了后序遍历,排序一下就得到了中序遍历,看看这两个序列能不能建成一个树,能建成就是正确的后续遍历,否则就不是,用了一下上一题的代码 12345678910111213141516171819class Solution: def verifyPostorder(self, postorder: List[int]) -&gt; bool: inorder=sorted(postorder) flag=True def build(pre,ino): if len(pre)==0: return None root=TreeNode(pre[-1]) try: root_index=ino.index(pre[-1]) root.left=build(pre[:root_index],ino[:root_index]) root.right=build(pre[root_index:-1],ino[root_index+1:]) except: nonlocal flag flag=False return root a=build(postorder,inorder) print(a) return flag 剑指 Offer 16. 数值的整数次方 思路:快速幂,但是要注意的是n的正负数,奇数就单独乘一次x,偶数就乘x的平方 1234567891011121314151617class Solution: def myPow(self, x: float, n: int) -&gt; float: res = 1 if n&gt;0: while n &gt; 0: if n &amp; 1: res *= x x *= x n &gt;&gt;= 1 else: n=abs(n) while n &gt; 0: if n &amp; 1: res /= x x *= x n &gt;&gt;= 1 return res 第二十一天 剑指 Offer 15. 二进制中1的个数 思路:位移与1 123456789class Solution: def hammingWeight(self, n: int) -&gt; int: ans=0 while n: if n&amp;1: ans+=1 n&gt;&gt;=1 return ans 剑指 Offer 65. 不用加减乘除做加法 思路:位运算,我选择不做 12345678910111213141516MASK1 = 4294967296 # 2^32MASK2 = 2147483648 # 2^31MASK3 = 2147483647 # 2^31-1class Solution: def add(self, a: int, b: int) -&gt; int: a %= MASK1 b %= MASK1 while b != 0: carry = ((a &amp; b) &lt;&lt; 1) % MASK1 a = (a ^ b) % MASK1 b = carry if a &amp; MASK2: # 负数 return ~((a ^ MASK2) ^ MASK3) else: # 正数 return a 第二十二天 剑指 Offer 56 - I. 数组中数字出现的次数 思路:两个相同的数异或为0,但是数据里面有两个只出现一次的数,把数据全部异或一遍之后,结果就是这两个数异或的结果,从后往前遍历这个结果,遇见的第一个1,就是这两个数不同的位置,然后根据这个位置把数组分成两份,这两份里面的数字异或完就剩下只出现一次的数字 1234567891011121314class Solution: def singleNumbers(self, nums: List[int]) -&gt; List[int]: n,x,y,m=0,0,0,1 for item in nums: n^=item while n&amp;m==0: m&lt;&lt;=1 for item in nums: if item&amp;m: x^=item else: y^=item return [x,y] 剑指 Offer 56 - II. 数组中数字出现的次数 II 思路:统计每一位上1出现的次数,然后对3取余,剩下位置上的1组成的数字就是只出现一次的 1234567891011121314class Solution: def singleNumber(self, nums: List[int]) -&gt; int: counts = [0] * 32 for num in nums: for j in range(32): counts[j] += num &amp; 1 num &gt;&gt;= 1 counts=list(map(lambda x:x%3,counts)) ans=0 for j in range(32): if counts[j]: temp=1&lt;&lt;j ans^=temp return ans 第二十三天 剑指 Offer 39. 数组中出现次数超过一半的数字 思路:1.常规排序或者计数 2.使用投票,随机选取一个数字,如果后面的数字等于他,票数加1,否则票数-1,如果票数为0,就重新换一个数字选择 123456789101112class Solution: def majorityElement(self, nums: List[int]) -&gt; int: votes = 0 for num in nums: if votes == 0: x = num votes += 1 if num == x else -1 # 验证 x 是否为众数 # for num in nums: # if num == x: count += 1 # return x if count &gt; len(nums) // 2 else 0 # 当无众数时返回 0 return x 剑指 Offer 66. 构建乘积数组 思路:正过来乘一遍,乘上之前的数,反过来乘一遍,乘上之后的数 12345678910111213class Solution: def constructArr(self, a: List[int]) -&gt; List[int]: length=len(a) ans=[] temp=1 for index,item in enumerate(a): ans.append(temp) temp*=item temp=1 for index in range(length-1,-1,-1): ans[index]*=temp temp*=a[index] return ans 第二十四天 剑指 Offer 57 - II. 和为s的连续正数序列 思路:双指针维护一个区间 123456789101112131415161718class Solution: def findContinuousSequence(self, target: int) -&gt; List[List[int]]: ans=[] cursum=0 left,right=1,1 while left&lt;target: if cursum&gt;target: cursum-=left left+=1 elif cursum&lt;target: cursum+=right right+=1 else: ans.append(list(range(left,right))) cursum-=left left+=1 return ans 剑指 Offer 14- I. 剪绳子 思路:dp,当前的数字,可以由比他小的任意两个数的乘积得到,这两个数同样可以由比他们小的乘积得到 123456789101112131415class Solution: def cuttingRope(self, n: int) -&gt; int: if n==2:return 1 if n==3:return 2 dp=[0]*(n+1) dp[2]=2 dp[3]=3 dp[4]=4 for i in range(5,n+1): for j in range(2,i): dp[i]=max(dp[i],dp[i-j]*dp[j]) return dp[n] # 只考虑2,3就行,证明略 # dp[i] = max(2 * (i - 2), 2 * dp[i - 2], 3 * (i - 3), 3 * dp[i - 3]) # 只考虑分成2,3 剑指 Offer 62. 圆圈中最后剩下的数字 思路:模拟会超时,每次删除一个数字,就相当于把后面的数字挪到前面了,根据这个性质,逆着推,在前面加上m个数,然后对当前的数据量取余,就得到了这个数字的原始位置 1234567891011121314class Solution: def lastRemaining(self, n: int, m: int) -&gt; int: # nums=list(range(n)) # start=0 # while len(nums)!=1: # length=len(nums) # num=nums[(start+m-1)%length] # nums.remove(num) # start=(start+m-1)%length # return nums[0] x=0 for i in range(1,n+1): x=(x+m)%i return x 第二十五天 剑指 Offer 29. 顺时针打印矩阵 思路:一圈圈的模拟,从左往右,从上往下,从右往左,从下往上,坐标在左上角和右下角,每次走完一行都修改边界 123456789101112131415161718class Solution: def spiralOrder(self, matrix:[[int]]) -&gt; [int]: if not matrix: return [] l, r, t, b, res = 0, len(matrix[0]) - 1, 0, len(matrix) - 1, [] while True: for i in range(l, r + 1): res.append(matrix[t][i]) # left to right t += 1 if t &gt; b: break for i in range(t, b + 1): res.append(matrix[i][r]) # top to bottom r -= 1 if l &gt; r: break for i in range(r, l - 1, -1): res.append(matrix[b][i]) # right to left b -= 1 if t &gt; b: break for i in range(b, t - 1, -1): res.append(matrix[i][l]) # bottom to top l += 1 if l &gt; r: break return res 剑指 Offer 31. 栈的压入、弹出序列 思路:如果是正确的顺序,那么一进一出,肯定是正好的,两个队列一起操作,遇到出栈顺序的数字就出栈,模拟,不正确的顺序栈内最后会剩下元素 123456789class Solution: def validateStackSequences(self, pushed: List[int], popped: List[int]) -&gt; bool: st, j = [], 0 for x in pushed: st.append(x) while st and st[-1] == popped[j]: st.pop() j += 1 return len(st) == 0 第二十六天 剑指 Offer 20. 表示数值的字符串 思路:根据题目要求分别实现判断是不是小数,是不是整数,是不是科学计数(根据e分开,然后利用前两个函数),然后一起判断 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution: def isNumber(self, s: str) -&gt; bool: s=s.strip() def isint(a): if len(a)==0: return False if a[0]==&#x27;-&#x27; or a[0]==&#x27;+&#x27;: a=a[1:] if len(a)==0: return False for item in a: if not item.isdecimal(): return False return True def isfloat(a): if len(a)==0: return False if a[0]==&#x27;-&#x27; or a[0]==&#x27;+&#x27;: a=a[1:] if len(a)==0: return False if a==&#x27;.&#x27;: return False flag=True for index,item in enumerate(a): if not item.isdecimal(): if item ==&#x27;.&#x27; and flag: flag=False continue return False return True def isnum(a): if len(a)==0: return False if a[0]==&#x27;-&#x27; or a[0]==&#x27;+&#x27;: a=a[1:] if len(a)==0: return False index=0 if &#x27;e&#x27; in a: index=a.index(&#x27;e&#x27;) elif &#x27;E&#x27; in a: index=a.index(&#x27;E&#x27;) else: return False front=a[:index] end=a[index+1:] return (isfloat(front) or isint(front)) and isint(end) return isint(s) or isfloat(s) or isnum(s) 面试题67. 把字符串转换成整数 思路:一个个字符遍历转为int,要判断是否越界了 123456789101112131415161718192021222324252627class Solution: def strToInt(self, s: str) -&gt; int: s=s.strip() if len(s)==0: return 0 flag=1 if s[0]==&#x27;-&#x27;: s=s[1:] flag=-1 elif s[0]==&#x27;+&#x27;: s=s[1:] if len(s)==0: return 0 if s[0].isalpha(): return 0 index=0 ans=0 while index&lt;len(s) and s[index].isdecimal() : ans=ans*10+int(s[index]) index+=1 INT_MAX=(1&lt;&lt;31)-1 INT_MIN=-(1&lt;&lt;31) if ans*flag&gt;INT_MAX: return INT_MAX if ans*flag&lt;INT_MIN: return INT_MIN return ans*flag 第二十七天 面试题59 - II. 队列的最大值 思路:利用一个单调栈(递减栈)记录队列里的最大值,出栈的时候判断是不是单调栈的第一个元素,进栈的时候判断一下和栈顶元素的大小关系,把小于他的都弹出来(因为只要他在,前面的数的最大值都是他) 12345678910111213141516171819202122import queueclass MaxQueue: def __init__(self): self.queue = queue.Queue() self.maxqueue = queue.deque() def max_value(self) -&gt; int: if len(self.maxqueue)==0: return -1 return self.maxqueue[0] def push_back(self, x: int) -&gt; None: self.queue.put(x) while self.maxqueue and x&gt;self.maxqueue[-1]: self.maxqueue.pop() self.maxqueue.append(x) def pop_front(self) -&gt; int: if not self.maxqueue: return -1 temp=self.queue.get() if temp==self.maxqueue[0]: self.maxqueue.popleft() return temp 剑指 Offer 59 - I. 滑动窗口的最大值 思路:可以直接用上一题的代码,维护一个区间,队列的长度就是区间的长度,每次进一个就弹出一个,获取队列,里面的最大值 题解:单调队列实现 12345678910111213class Solution: def maxSlidingWindow(self, nums: List[int], k: int) -&gt; List[int]: deq=MaxQueue() for item in nums[:k-1]: deq.push_back(item) ans=[] for item in nums[k-1:]: deq.push_back(item) ans.append(deq.max_value()) deq.pop_front() return ans 第二十八天 剑指 Offer 38. 字符串的排列 思路:深搜,全排列,但是不能重复,用位运算来表示访问标识符 123456789101112131415161718class Solution: def permutation(self, s: str) -&gt; List[str]: length=len(s) visited=0 ans=set() def dfs(index,cur): if index==length: ans.add(&quot;&quot;.join(cur)) return for i in range(length): nonlocal visited if not (1&lt;&lt;i)&amp;visited: visited|=(1&lt;&lt;i) dfs(index+1,cur+[s[i]]) visited^=(1&lt;&lt;i) dfs(0,[]) return list(ans) 剑指 Offer 37. 序列化二叉树 思路:就是用某种方式存树,然后再把存的树还原成原本的树 题解:层次遍历(深搜的三种遍历树不唯一),把一层的所有节点都存起来,包括空节点 1234567891011121314151617181920212223242526272829303132333435363738import collectionsclass Codec: def serialize(self, root): if not root: return &quot;[]&quot; queue = collections.deque() queue.append(root) res = [] while queue: cur=queue.popleft() if cur: res.append(str(cur.val)) queue.append(cur.left) queue.append(cur.right) else: res.append(&#x27;null&#x27;) return &#x27;[&#x27;+&quot;,&quot;.join(res)+&#x27;]&#x27; def deserialize(self, data): if data==&#x27;[]&#x27;:return vals, i = data[1:-1].split(&#x27;,&#x27;), 1 root = TreeNode(int(vals[0])) queue = collections.deque() queue.append(root) while queue: cur=queue.popleft() if vals[i]!=&#x27;null&#x27;: temp = TreeNode(int(vals[i])) cur.left=temp queue.append(temp) i+=1 if vals[i]!=&#x27;null&#x27;: temp = TreeNode(int(vals[i])) cur.right=temp queue.append(temp) i+=1 return root *第二十九天 剑指 Offer 19. 正则表达式匹配 思路:类似字符串最短编辑距离,$dp[i][j] $代表 s[:i]s[:i]s[:i] 与 p[:j]p[:j]p[:j] 是否可以匹配。s是字符串,p是模式串 当p[j]=='*'时: dp[i][j-2]:不记这个字符,当作他出现0次 s=‘’ p=“c*” dp[i-1][j] and s[i]==p[j-1]: *前面的字符和s这个位置上的字符一样 dp[i-1][j] and ‘*’==p[j-1]: *前面的字符是.,随意匹配 (这两种情况可以视作,当前的p和s已经匹配了,s又加入了一个新字符,看这个新字符和p的最后一个是不是一样) 当p[j]!='*'时: dp[i-1][j-1] and s[i-1]==p[j-1]:前面的都能匹配,看当前位置的两个字符是不是一样 dp[i-1][j-1] and ‘.’==p[j-1]: .随意匹配 实现的时候注意,dp的下标是从1开始,但是s,p的下标是从0开始,公式里面的sp下标要多减个1 12345678910111213141516171819class Solution: def isMatch(self, s: str, p: str) -&gt; bool: m, n = len(s) + 1, len(p) + 1 dp = [[False] * n for _ in range(m)] dp[0][0] = True for j in range(2, n, 2): dp[0][j] = dp[0][j - 2] and p[j - 1] == &#x27;*&#x27; for i in range(1,m): for j in range(1,n): if p[j-1]==&#x27;*&#x27;: if dp[i][j-2] or ( s[i-1]==p[j-2] and dp[i-1][j]) or ( p[j-2]==&#x27;.&#x27; and dp[i-1][j]): dp[i][j]=True else: if ( p[j-1]==&#x27;.&#x27; and dp[i-1][j-1]) or (( p[j-1]==s[i-1] and dp[i-1][j-1])): dp[i][j]=True return dp[m-1][n-1] 剑指 Offer 49. 丑数 思路:当前的数位x,下一个数一定是(a∗2,b∗3,c∗5)(a*2,b*3,c*5)(a∗2,b∗3,c∗5)之中最小的一个,而且(a,b,c)(a,b,c)(a,b,c)一定是之前的某个丑数:用三个指针,如果下一个是当前的指针指的数,这个指针加1指向下一个数,刚开始都指向1 12345678910111213141516class Solution: def nthUglyNumber(self, n: int) -&gt; int: # 最小堆 dp=[0]*n dp[0]=1 a,b,c=0,0,0 for i in range(1,n): dp[i]=min(dp[a]*2,dp[b]*3,dp[c]*5) if dp[i]==dp[a]*2: a+=1 if dp[i]==dp[b]*3: b+=1 if dp[i]==dp[c]*5: c+=1 return dp[n-1] 剑指 Offer 60. n个骰子的点数 思路:首先要知道,n个筛子可以扔出多少个点:[n,6n],共5*n+1个点,每个点,可以从少一个筛子的情况下得到,f(n,x)表示n个筛子得到x点 f(n,x)=f(n−1,x)+f(n−1,x−2)+,..,f(n−1,x−6)f(n,x)=f(n-1,x)+f(n-1,x-2)+,..,f(n-1,x-6)f(n,x)=f(n−1,x)+f(n−1,x−2)+,..,f(n−1,x−6)得到,但是这样会越界 上一层的x,可以贡献给这一层的6个数字 f(n,x+k)=f(n−1,x),k∈[1,2,3,4,5,6]f(n,x+k)=f(n-1,x),k \\in [1,2,3,4,5,6]f(n,x+k)=f(n−1,x),k∈[1,2,3,4,5,6] 1234567891011class Solution: def dicesProbability(self, n: int) -&gt; List[float]: dp=[[0]*(5*(n+1)+1) for _ in range(n+1)] for k in range(6): dp[1][k]=1/6 for i in range(2,n+1): for j in range(5*i+1): for k in range(6): dp[i][j+k]+=(dp[i-1][j])/6 print(dp) return dp[n][:5*n+1] 第三十天 剑指 Offer 17. 打印从1到最大的n位数 思路:一行代码,但是考虑大整数的情况下,可以用深搜 1234class Solution: def printNumbers(self, n: int) -&gt; List[int]: right=pow(10,n) return [i for i in range(1,right)] 剑指 Offer 51. 数组中的逆序对 思路:快排,统计逆序对,用之前的代码 1234567891011121314151617181920212223242526272829303132333435363738class Solution: def reversePairs(self, nums: List[int]) -&gt; int: ans=0 def mergesort(seq): &quot;&quot;&quot;归并排序&quot;&quot;&quot; if len(seq) &lt;= 1: return seq mid = len(seq) // 2 # 将列表分成更小的两个列表 # 分别对左右两个列表进行处理，分别返回两个排序好的列表 left = mergesort(seq[:mid]) right = mergesort(seq[mid:]) # 对排序好的两个列表合并，产生一个新的排序好的列表 return merge(left, right) def merge(left, right): &quot;&quot;&quot;合并两个已排序好的列表，产生一个新的已排序好的列表&quot;&quot;&quot; result = [] # 新的已排序好的列表 i = 0 # 下标 j = 0 # 对两个列表中的元素 两两对比。 # 将最小的元素，放到result中，并对当前列表下标加1 while i &lt; len(left) and j &lt; len(right): # 左边的小,正常 if left[i] &lt;= right[j]: result.append(left[i]) i += 1 # 右边的小 ,是逆序,并且左边的往后也构成逆序 else: result.append(right[j]) j += 1 nonlocal ans ans+=len(left)-i result += left[i:] result += right[j:] return result mergesort(nums) return ans 第三十一天 剑指 Offer 14- II. 剪绳子 II 题解思路:根据证明,把n长的划分为长度为3的段时,乘积最大,利用剪绳子1的方法不行,因为max(dp[i],dp[i−j]∗dp[j])max(dp[i],dp[i-j]*dp[j])max(dp[i],dp[i−j]∗dp[j]),取模之后没法用,不取模又不准 12345678910111213class Solution: def cuttingRope(self, n: int) -&gt; int: if n==2:return 1 if n==3:return 2 if n==4:return 4 MOD=1e9+7 ans=1 while n&gt;4: ans*=3 n-=3 ans%=MOD return int((ans*n)%MOD) 剑指 Offer 43. 1～n 整数中 1 出现的次数 题解思路:主要是数学推到,对于123456这个数字,假设当前的位是百位他的前面一定就有123*100次1出现,但是他的后面要分情况,456还是会出现100次1,156只出现了56次,056不出现1.后面三种情况可以总结位min(max(n−100+1,0),100)min(max(n-100+1,0),100)min(max(n−100+1,0),100),循环遍历每一位数字就行 123456789101112131415161718class Solution: def countDigitOne(self, n: int) -&gt; int: k=0 ans=0 # ppp=pow(10,k) ppp=1 while n&gt;=ppp: temp=0 front=n//(ppp*10) temp+=(front*ppp) back=n%(ppp*10) temp+=min(max(back-ppp+1,0),ppp) ans+=temp k+=1 ppp*=10 return ans 剑指 Offer 44. 数字序列中某一位的数字 思路:根据规律,前面是1位数长度是10个,2位数长度是2∗10∗92*10*92∗10∗9,三位数是3∗100∗93*100*93∗100∗9,…,根据这个规律,可以找到n应该是在几位数上,然后除以位数的长度,就找到了在哪个数字上,在对长度取余就是这个数字的第几位 123456789101112131415161718192021class Solution: def findNthDigit(self, n: int) -&gt; int: if n&lt;10:return n # 10 # 20*9 # 300*9 # 4000*9 n-=10 index=2 while n: temp=index*pow(10,index-1)*9 if n&lt;temp: break n-=temp index+=1 a=n//index b=n%index # 找到所在的数字 num=pow(10,index-1)+a return int(str(num)[b]) 总结","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"python100天31-40","slug":"笔记-python100天31-40","date":"2023-03-07T10:33:08.243Z","updated":"2024-03-18T13:27:33.436Z","comments":true,"path":"2023/03/07/笔记-python100天31-40/","link":"","permalink":"https://gladdduck.github.io/2023/03/07/%E7%AC%94%E8%AE%B0-python100%E5%A4%A931-40/","excerpt":"","text":"12345678910111213141516171819202122# 01-15python基础# 16-20python进阶# 21-30前端概述# 31-35Linux# 36-40MySQL# 41-55Django# 56-60FaskAPI# 61-65爬虫与并发编程# 66-80numpy&amp;pandas# 81-90机器学习&amp;pytorch# 91-100项目 Python100天学习31-35 Linux 资料连接 Python100天学习36-40 MySQL 资料连接 关系数据库产品 Oracle - 目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系数据库，它是一个完备关系的产品；作为分布式数据库，它实现了分布式处理的功能。在 Oracle 最新的 12c 版本中，还引入了多承租方架构，使用该架构可轻松部署和管理数据库云。 DB2 - IBM 公司开发的、主要运行于 Unix（包括 IBM 自家的 AIX）、Linux、以及 Windows 服务器版等系统的关系数据库产品。DB2 历史悠久且被认为是最早使用 SQL 的数据库产品，它拥有较为强大的商业智能功能。 SQL Server - 由 Microsoft 开发和推广的关系型数据库产品，最初适用于中小企业的数据管理，但是近年来它的应用范围有所扩展，部分大企业甚至是跨国公司也开始基于它来构建自己的数据管理系统。 MySQL - MySQL 是开放源代码的，任何人都可以在 GPL（General Public License）的许可下下载并根据个性化的需要对其进行修改。MySQL 因为其速度、可靠性和适应性而备受关注。 PostgreSQL - 在 BSD 许可证下发行的开放源代码的关系数据库产品。 安装教程 windows linux macos MySQL基本命令 查看命令 查看所有数据库 1show databases; 查看所有字符集 1show character set; 查看所有的排序规则 1show collation; 查看所有的引擎 1show engines; 查看所有日志文件 1show binary logs; 查看数据库下所有表 1show tables; 获取帮助 在 MySQL 命令行工具中，可以使用 help命令或 ?来获取帮助，如下所示。 查看 show命令的帮助。 1? show 查看有哪些帮助内容。 1? contents 获取函数的帮助。 1? functions 获取数据类型的帮助。 1? data types SQL语句 数据库的基本操作 SQL 包含以下 4 部分： 数据定义语言（Data Definition Language，DDL） 用来创建或删除数据库以及表等对象，主要包含以下几种命令： DROP：删除数据库和表等对象 CREATE：创建数据库和表等对象 ALTER：修改数据库和表等对象的结构 数据操作语言（Data Manipulation Language，DML） 用来变更表中的记录，主要包含以下几种命令： SELECT：查询表中的数据 INSERT：向表中插入新数据 UPDATE：更新表中的数据 DELETE：删除表中的数据 数据查询语言（Data Query Language，DQL） 用来查询表中的记录，主要包含 SELECT 命令，来查询表中的数据。 数据控制语言（Data Control Language，DCL） 用来确认或者取消对数据库中的数据进行的变更。除此之外，还可以对数据库中的用户设定权限。主要包含以下几种命令： GRANT：赋予用户操作权限 REVOKE：取消用户的操作权限 COMMIT：确认对数据库中的数据进行的变更 ROLLBACK：取消对数据库中的数据进行的变更 基本语法 SQL 语句不区分大小写 SQL 语句中含有字符串的时候，需要像 ‘abc’ 这样，使用英文单引号’将字符串括起来，用来标识这是一个字符串。 SQL 语句中含有日期的时候，同样需要使用英文单引号将其括起来。日期的格式有很多种（‘26 Jan 2010’ 或者’10/01/26’ 等），统一使用 ‘2020-01-26’ 这种’年-月-日’的格式。 在 SQL 语句中书写数字的时候，不需要使用任何符号标识，直接写成 1000 这样的数字即可。 SQL 语句要以分号;结尾.在 RDBMS （关系型数据库）当中，SQL 语句是逐条执行的，一条 SQL 语句代表着数据库的一个操作。 C语言中文网SQL教程 基本操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152-- 查看数据库 ,LIKE可选,不写就是查看全部 SHOW DATABASES [LIKE &#x27;数据库名&#x27;];-- 安装 MySQL 时系统自动创建的6个数据库，其各自功能如下：-- information_schema：主要存储了系统中的一些数据库对象信息，比如用户表信息、列信息、权限信息、字符集信息和分区信息等。-- mysql：MySQL 的核心数据库，类似于 SQL Server 中的 master 表，主要负责存储数据库用户、用户访问权限等 MySQL 自己需要使用的控制和管理信息。常用的比如在 mysql 数据库的 user 表中修改 root 用户密码。-- performance_schema：主要用于收集数据库服务器性能参数。-- sakila：MySQL 提供的样例数据库，该数据库共有 16 张表，这些数据表都是比较常见的，在设计数据库时，可以参照这些样例数据表来快速完成所需的数据表。-- sys：MySQL 5.7 安装完成后会多一个 sys 数据库。sys 数据库主要提供了一些视图，数据都来自于 performation_schema，主要是让开发者和使用者更方便地查看性能问题。-- world：world 数据库是 MySQL 自动创建的数据库，该数据库中只包括 3 张数据表，分别保存城市，国家和国家使用的语言等内容。-- 创建数据库-- 字符集是用来定义 MySQL 存储字符串的方式，校对规则定义了比较字符串的方式。CREATE DATABASE [IF NOT EXISTS] &lt;数据库名&gt;[[DEFAULT] CHARACTER SET &lt;字符集名&gt;] [[DEFAULT] COLLATE &lt;校对规则名&gt;];-- 查看数据库的定义声明SHOW CREATE DATABASE test_db;-- 使用 ALTER DATABASE 来修改已经被创建或者存在的数据库的相关参数ALTER DATABASE [数据库名] &#123; [ DEFAULT ] CHARACTER SET &lt;字符集名&gt; |[ DEFAULT ] COLLATE &lt;校对规则名&gt;&#125;-- ALTER DATABASE 用于更改数据库的全局特性。-- 使用 ALTER DATABASE 需要获得数据库 ALTER 权限。-- 数据库名称可以忽略，此时语句对应于默认数据库。-- CHARACTER SET 子句用于更改默认的数据库字符集。-- 删除数据库DROP DATABASE [ IF EXISTS ] &lt;数据库名&gt;-- MySQL 安装后，系统会自动创建名为 information_schema 和 mysql 的两个系统数据库，系统数据库存放一些和数据库相关的信息，如果删除了这两个数据库，MySQL 将不能正常工作。-- USE 语句用来完成一个数据库到另一个数据库的跳转-- 创建数据库之后，该数据库不会自动成为当前数据库USE &lt;数据库名&gt;-- 单行注释# 单行注释/* 多行注释*/-- 查看帮助命令,查询内容是关键字,可以用LIKEHELP &#x27;查询内容&#x27; SQL语句的大小写规则 MySQL 用服务器主机的底层文件系统所包含的目录和文件来表示数据库和表。因此，数据库名和表名的默认大小写取决于服务器主机的操作系统在命名方面的规定。 常见错误 121 开头 服务器错误2 开头 客户端错误 数据库设计 数据库设计三个范式 12345671.第一范式： 要求任何一张表必须有主键，每一个字段原子性不可再分。2.第二范式： 建立在第一范式的基础之上，要求所有非主键字段完全依赖主键，不要产生部分依赖。(学术编号+教师编号,学生姓名,教师姓名)-&gt;(学生编号,教师编号)(学生编号,学生姓名)(教师编号,教师姓名)3.第三范式： 建立在第二范式的基础之上，要求所有非主键字段直接依赖主键，不要产生传递依赖。(学生编号,学生姓名,班级编号,班级名称)-&gt;(学生编号,学生姓名,班级编号)(班级编号,班级名称) MySQL数据类型 1234567891011整型:TINYINT(1字节,255) SMALLINT(2字节,65535) MEDIUMINT(3字节,16777214) INT(4字节,4294967295) BIGINT(8字节,)浮点型:FLOAT(4字节) DOUBLE(8字符) DECIMAL(M+2字节,指定精度)日期型:YEAR(yyyy,1字节) TIME(HH:MM:SS,3字节) DATE(YYYY-MM-DD,三字节) DATETIME(YYYY-MM-DD HH:MM:SS,8字节)字符串类型:CHAR(M字节,定长) VARCHAR(L+1字节,L实际长度) TINYTEXT(L字节,2**8) TEXT(L+2字节,2**16) MEDIUMTEXT(L+3字节,2**24) LONGTEXT(L+3字节,2**32) ENUM() SET()二进制类型:BIT() BINARY() VARBINARY() BLOB()转义符: 用\\ 系统变量 123456-- MySQL 中的系统变量以两个“@”开头。SHOW GLOBAL VARIABLES; SHOW SESSION VARIABLES;-- 设置SET @@global.innodb_file_per_table=default; MySQL存储引擎 存储引擎就是指表的类型。数据库的存储引擎决定了表在计算机中的存储方式。 1234SHOW ENGINES;SET default_storage_engine=&lt; 存储引擎名 &gt; InnoDB 1.支持事务,实现了4个隔离级别 2.灾难恢复性好,commit rollback crash-recovery 3.行级锁 4.缓存处理 5.支持外键 使用InnoDB时，MySQL会在数据目录(Data )下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件。 InnoDB存储引擎和MyISAM不太一样，虽然也有.frm文件来存放表结构定义相关的元数据，但是表数据和索引数据是存放在一起的.至于是每个表单独存放还是所有表存放在一起，用户可以自己设置。 物理存储结构 数据文件(表数据和索引数据) 数据文件用来存放数据表中的数据和所有的索引数据，包括主键和其他普通索引。 InnoDB存储的数据采用表空间(Tablepace)进行存放设计。表空间是用来存放MySQL系统相关信息的一个特殊共享表空间。 InnoDB的表空间分为以下两种形式∶ 共享表空间，表数据和索引都存放在同一个表空间。默认的表空间文件就是上面所提到的MySQL初始化路径下的 ibdata1文件。 独立表空间，每个表的数据和索引被存放在一个单独的.ibd文件中。 日志文件 默认情况下，InnoDB存储引擎的数据目录下会有两个名为ib_logfile0和ib_Jogfile1的文件。在MySQL官方手册中将其称为InnoDB存储引擎的重做日志文件( redo log file )。 重做日志文件对InnoDB存储擎至关重要。InnoDB可以通过重做日志将数据库宕机时已经完成但还没有来得及将数据写入磁盘的事务恢复，也能将所有部分完成并已经写入磁盘的末完成事务回滚，并且将数据还原，以此来保证数据的完整性。 每个InnoDB存储引擎至少有1个重做日志文件组 ( group )，每个文件组下至少有2个重做日志文件，如默认的ib_Jogfile0和ib_logfile1。 MyISAM 优 占用空间小 访问速度快，对事务完整性没有要求或以SELECT、INSERT为主的应用基本上都可以使用这个 引擎来创建表可以配合锁，实现操作系统下的复制备份 支持全文检索(InnoDB在MySQL 5.6版本以后也支持全文检索)数据紧凑存储，因此可获得更 小的索引和更快的全表扫描性能。 MyISAM对整张表加锁，而不是针对行。读取时会对需要读到的所有表加共享锁，写入时对表加排他锁。但是在表有读取查询的同时也可以往表中插入新的记录（这被称为并发插入)。 三种索引:B-Tree,R-Tree,Full-Text 缺 不支持事务的完整性和并发性 不支持行级锁，使用表级锁，并发性差 主机宕机后，MyISAM表易损坏，灾难恢复性不佳数据库崩溃后无法安全恢复 只缓存索引，数据的缓存是利用操作系统缓冲区来实现的，可能会引发过多的系统调用，且效率不佳 物理存储 MyISAM存储引擎的表在数据库中被存储成3个物理文件，文件名与表名相同。扩展名为frm、MYD和MYI。其中: frm为扩展名的文件存储表的结构; MYD为扩展名的文件存储数据，其是MYData的缩写; MYI为扩展名的文件存储索引，其是MYIndex的缩写。不管表有多少索引，都是存放在同一个.MYT文件中. 不同存储引擎存储的方式 MySQL中的每一个数据表在磁盘上至少被表示为一个文件，即存放着该数据表结构定义的.frm 文件。不同的存储引擎还有其它用来存放数据和索引信息的文件。 从MySQL 8.0版本开始，frm 表结构定义文件被取消，MySQL把表结构信息都写到了系统表空间。 数据表的基本操作","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python学习笔记","slug":"Python学习笔记","permalink":"https://gladdduck.github.io/tags/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"python100天1-15","slug":"笔记-python100天1-15","date":"2023-02-27T08:33:05.380Z","updated":"2023-02-27T09:08:35.281Z","comments":true,"path":"2023/02/27/笔记-python100天1-15/","link":"","permalink":"https://gladdduck.github.io/2023/02/27/%E7%AC%94%E8%AE%B0-python100%E5%A4%A91-15/","excerpt":"","text":"12345678910111213141516171819202122# 01-15python基础# 16-20python进阶# 21-30前端概述# 31-35Linux# 36-40MySQL# 41-55Django# 56-60FaskAPI# 61-65爬虫与并发编程# 66-80numpy&amp;pandas# 81-90机器学习&amp;pytorch# 91-100项目 Python100天学习1-15 资料连接 第一天-初识python 12345678910# 1. python历史# 2. python优缺点# 3. python安装# 4. print的简单使用# print函数可以输出多个值，多个值之间可以用 , 进行分隔，输出的内容之间默认以空格分开。print(&#x27;你好&#x27;, &#x27;世界&#x27;)print(&#x27;hello&#x27;, &#x27;world&#x27;, sep=&#x27;, &#x27;, end=&#x27;!&#x27;)print(&#x27;goodbye, world&#x27;, end=&#x27;!\\n&#x27;)# 5.turtle画国旗和佩奇 第二天-语言元素 12345678910# 1. 程序,变量和类型# 2. 变量命名原则# 3. 类型转换- chr()：将整数转换成该编码对应的字符串（一个字符）。- ord()：将字符串（一个字符）转换成对应的编码（整数）。- int(): 将字符串表示的n进制数字转换为十进制表示- bin(), oct(), hex(): 将十进制数字转为2/8/16进制字符串表示# 4. 运算符及其优先级 # 3. 类型转换 # 4. 运算符及其优先级 运算符 描述 [] [:] 下标，切片 ** 指数 ~ + - 按位取反, 正负号 * / % // 乘，除，模，整除 + - 加，减 &gt;&gt; &lt;&lt; 右移，左移 &amp; 按位与 ^ | 按位异或，按位或 &lt;= &lt; &gt; &gt;= 小于等于，小于，大于，大于等于 == != 等于，不等于 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 = += -= *= /= %= //= **= &amp;= ` =^=&gt;&gt;=&lt;&lt;=` 说明： 在实际开发中，如果搞不清楚运算符的优先级，可以使用括号来确保运算的执行顺序。 第三天-分支结构 – 第四天-循环结构 – 第五天-构造程序逻辑 – 第六天-函数和模块的使用 1234567891011121314151617181920212223242526# 1.可变参数可变参数允许传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个tuple。# 2.关键字参数关键字参数允许传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict。# 3.导入模块如果导入的模块除了定义函数之外还有可以执行代码，那么Python解释器在导入这个模块时就会执行这些代码# 4.变量作用域if __name__ == &#x27;__main__&#x27;: # 这里声明的变量属于全局作用域def a(): def b(): # 这里修改全局变量需要声明global # 这里修改a函数里面的变量需要声明nonlocal # 仅仅使用不需要声明 # 如果没有全局变量但是声明了,会新建一个全局变量 # 如果没有nonlocal但是声明了，会报错 第七天-字符串和常用数据结构 字符串函数 可以使用*复制字符串 因此a=[[0] * 3]*5 a里面的list都是同一个地址,修改一个就会修改全部 但是[0] * 3 数字是直接存的对象 修改这个就是直接换了个对象 不糊修改对象的内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647str1 = &#x27;hello, world!&#x27;# 通过内置函数len计算字符串的长度# len() 复杂度为O(1) 调用__len__print(len(str1)) # 13# 获得字符串首字母大写的拷贝print(str1.capitalize()) # Hello, world!# 获得字符串每个单词首字母大写的拷贝print(str1.title()) # Hello, World!# 获得字符串变大写后的拷贝print(str1.upper()) # HELLO, WORLD!# 从字符串中查找子串所在位置,rfind 最后一次出现的位置print(str1.find(&#x27;or&#x27;)) # 8print(str1.find(&#x27;shit&#x27;)) # -1# 与find类似但找不到子串时会引发异常 rindex最后一次出现的位置# print(str1.index(&#x27;or&#x27;))# print(str1.index(&#x27;shit&#x27;))# 检查字符串是否以指定的字符串开头print(str1.startswith(&#x27;He&#x27;)) # Falseprint(str1.startswith(&#x27;hel&#x27;)) # True# 检查字符串是否以指定的字符串结尾print(str1.endswith(&#x27;!&#x27;)) # True# 将字符串以指定的宽度居中并在两侧填充指定的字符print(str1.center(50, &#x27;*&#x27;))# 将字符串以指定的宽度靠右(左:ljust)放置左侧填充指定的字符print(str1.rjust(50, &#x27; &#x27;))str2 = &#x27;abc123456&#x27;# 检查字符串是否由数字构成print(str2.isdigit()) # Falseprint(str2.isdecimal()) # Falseprint(str2.isnumeric()) # False# 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。print(str2.istitle())# 检测字符串是否只由空格组成。print(str2.isspace())# 检查字符串是否以字母构成print(str2.isalpha()) # False# 检查字符串是否以数字和字母构成print(str2.isalnum()) # Truestr3 = &#x27; jackfrued@126.com &#x27;print(str3)# 获得字符串修剪左右(lstrip,rstrip)两侧空格之后的拷贝print(str3.strip())# 根据指定的分隔符将字符串进行分割。# 如果字符串包含指定的分隔符，则返回一个3元的元组，第一个为分隔符左边的子串，第二个为分隔符本身，第三个为分隔符右边的子串。 rpartition 最右边一个print(str3.partition(&#x27;@&#x27;)) #(&#x27; jackfrued&#x27;, &#x27;@&#x27;, &#x27;126.com &#x27;)# 大小写字符的转换print(str3.swapcase()) 字符串格式化 1234567891011# 1.a, b = 5, 10print(&#x27;%d * %d = %d&#x27; % (a, b, a * b))# 2.a, b = 5, 10print(&#x27;&#123;&#125; * &#123;&#125; = &#123;&#125;&#x27;.format(a, b, a * b))print(&#x27;&#123;0&#125; * &#123;1&#125; = &#123;2&#125;&#x27;.format(a, b, a * b))print(&#x27;&#123;aaa&#125; * &#123;bbb&#125; = &#123;ccc&#125;&#x27;.format(aaa=a, bbb=b, ccc=a * b))# 3.a, b = 5, 10print(f&#x27;&#123;a&#125; * &#123;b&#125; = &#123;a * b&#125;&#x27;) 列表 列表容器中并没有保存真正的对象，它保存的仅仅是对象的引用(堆中的地址)。 12345678910111213141516171819202122232425list1 = [1, 3, 5, 7, 100]# 添加元素list1.append(200)list1.insert(1, 400)# 合并两个列表list1.extend([1000, 2000])list1 += [1000, 2000]# 根据值删除元素 删除第一个list1.remove(1234)# 根据下标删除元素list1.pop(0)# 切片返回的是拷贝，修改新数组，原数组不动# https://pythontutor.com/python-debugger.html#mode=editfruits = [ [66666,77777777], &#x27;apple&#x27;, &#x27;strawberry&#x27;, &#x27;waxberry&#x27;]fruits3 = fruits[:4]print(fruits3) # 数组里面存的是列表的地址，拷贝的也是列表的地址，修改还是到列表的地址去修改，所以会变fruits3[0][0]=000fruits3[2]=&#x27;aaaaaaaaa&#x27;print(fruits3)print(fruits)# [[66666, 77777777], &#x27;apple&#x27;, &#x27;strawberry&#x27;, &#x27;waxberry&#x27;]# [[0, 77777777], &#x27;apple&#x27;, &#x27;aaaaaaaaa&#x27;, &#x27;waxberry&#x27;]# [[0, 77777777], &#x27;apple&#x27;, &#x27;strawberry&#x27;, &#x27;waxberry&#x27;] 什么时候不用数组 123# array 类似C的数组# 必须指定类型 生成器 1234567891011121314import sys# 用列表的生成表达式语法创建列表容器# 用这种语法创建列表之后元素已经准备就绪所以需要耗费较多的内存空间f = [x ** 2 for x in range(1, 1000)]print(sys.getsizeof(f)) # 查看对象占用内存的字节数# 请注意下面的代码创建的不是一个列表而是一个生成器对象# 通过生成器可以获取到数据但它不占用额外的空间存储数据# 每次需要数据的时候就通过内部的运算得到数据(需要花费额外的时间)f = (x ** 2 for x in range(1, 1000))print(sys.getsizeof(f)) # 相比生成式生成器不占用存储数据的空间for val in f: print(val)yield：生成函数 元组 元组在创建时间和占用的空间上面都优于列表 集合 字典 序列的抽象基类 MutavleSequence:可变序列抽象基类(setitem,delitem) Sequence:不可变序列抽象基类 +,+=,extend区别 1234567891011121314151617181920212223# +=实际上是调用了extend方法# +=返回的本身,在原地址上修改# a=a+ 会返回一个新对象# append会把参数当成一个对象加进去# extend参数必须是可迭代对象,一个个加进去a=[1,2]print(id(a))a.extend((777,))a+=[666]# 报错# a+=(777)print(id(a))a=a+[666]print(id(a))a.append([666,777])print(id(a))# 2358526812672# 2358526812672# 2358526332032# 2358526332032 可切片对象 12345678910alist[len(alist):]=[9]# 末尾追加元素alist[:0]=[1,2]# 开头追加元素alist[3:3]=[1,2]# 索引位置追加元素# 结束位置大于长度会返回长度# 开始位置大于长度会返回空列表# 切片赋值长度必须相等 第八天-面向对象编程基础 python三个知识点:is和==,嵌套列表,类的私有属性 123456789101112131415161718192021222324252627282930# 1.类的私有属性可以在属性名前面加两个下划线# __len__不是私有成员,因为后面也有__class Test: def __init__(self, foo): self.__foo = foo def __bar(self): print(self.__foo) print(&#x27;__bar&#x27;)def main(): test = Test(&#x27;hello&#x27;) # AttributeError: &#x27;Test&#x27; object has no attribute &#x27;__bar&#x27; test.__bar() # AttributeError: &#x27;Test&#x27; object has no attribute &#x27;__foo&#x27; print(test.__foo) test = Test(&#x27;hello&#x27;) test._Test__bar() print(test._Test__foo)if __name__ == &quot;__main__&quot;: main()# 2.Python并没有从语法上严格保证私有属性或方法的私密性，它只是给私有的属性和方法换了一个名字来妨碍对它们的访问,更换名字的规则仍然可以访问到它们 第九天-面向对象进阶 class用于声明一个类,用type创建类 object是所有类的父类，所有类是type的实例 类的属性 12345678910111213141516171819202122232425262728293031323334353637383940# 1.@property装饰器class Person(object): def __init__(self, name, age): self._name = name self._age = age # 访问器 - getter方法 @property def name(self): return self._name # 访问器 - getter方法 @property def age(self): return self._age # 修改器 - setter方法 @age.setter def age(self, age): self._age = age # 属性名字和@property修饰的方法名字不能一样,不然会死循环# 把一个getter方法变成属性，只需要加上@property就可以了# @property本身又创建了另一个装饰器@score.setter，负责把一个setter方法变成属性赋值# 上面name是只读属性,age是读写属性# 2.__slots__魔法 ,只有slots内的属性才能被添加,对子类没有用,如果子类有,就是父类和子类的并集class Person(object): # 限定Person对象只能绑定_name, _age和_gender属性 __slots__ = (&#x27;_name&#x27;, &#x27;_age&#x27;, &#x27;_gender&#x27;) def __init__(self, name, age): self._name = name self._age = age # 会报错 # self.hhhh=666Person._gender = &#x27;男&#x27;# 这样能绑定?Person.sex = &#x27;?&#x27;person = Person(&#x27;王大锤&#x27;, 22)# 这样会报错,但是加上Person._sex = &#x27;?&#x27; 就变成了只读,不能修改person.sex=66 类的方法 123456789101112# 1.静态方法# @staticmethod修饰,不用self,和C++类似# 2.类方法# @classmethod修饰,默认传递了cls参数,调用类本身,@classmethoddef now(cls): print(cls)# 3.实例方法# self 就是实例本身 继承和多态 12345678910111213# 子类在继承了父类的方法后，可以对父类已有的方法给出新的实现版本，这个动作称之为方法重写（override）。通过方法重写我们可以让父类的同一个行为在子类中拥有不同的实现版本，当我们调用这个经过子类重写的方法时，不同的子类对象会表现出不同的行为，这个就是多态# 抽象类from abc import ABCMeta, abstractmethodclass Pet(object, metaclass=ABCMeta): def __init__(self, nickname): self._nickname = nickname @abstractmethod def make_voice(self): pass 定制类-魔法函数(不是继承,python自带) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# __str__打印输出变成自定义字符串# __repr__ 直接调用类时打印(jupyter)def __str__(self): return &#x27;6666&#x27;__repr__ = __str__# __iter__可用for循环迭代# __next__去下一个对象class Fib(object): def __init__(self): self.a, self.b = 0, 1 # 初始化两个计数器a，b def __iter__(self): return self # 实例本身就是迭代对象，故返回自己 def __next__(self): self.a, self.b = self.b, self.a + self.b # 计算下一个值 if self.a &gt; 100000: # 退出循环的条件 raise StopIteration() return self.a # 返回下一个值# __getitem__像列表一样取值 也可以改成字典形式 也可以用for循环if isinstance(n, int): # n是索引if isinstance(n, slice): # n是切片# 如果这个对象被for时，会首先调用__iter__方法返回一个iterator,然后再对这个iterator循环调用__next__方法，直到碰到StopIteration时则停止退出。# 如果for的对象没有__iter__方法，则无法获得一个迭代器，那么就会报错，但是，如果这个类实现了__getitem__方法，会从0开始依次读取相应的下标，直到发生IndexError为止# __iter__是优先读取的# __getattr__获取类的属性,已经定义的属性不会调用,使用没有定义的属性才会调用# __call__ 可以直接对实例进行调用# __bases__查看父类# __enter__ with进入# __exit__with退出class Sample: def __enter__(self): print( &quot;enter&quot;) return self def __exit__(self, exc_type,exc_val,exc_tb): print ( &quot;exit&quot;) def do_something(self): print ( &quot;doing something&quot; )with Sample() as sample: sample.do_something()# @contextlib.contextmanger # __dict__与dir()的区别：# dir()是一个函数，返回的是list；# __dict__是一个字典，键为属性名，值为属性值(类和实例不一样,可以通过修改这个增加属性)；# dir()用来寻找一个对象的所有属性，包括__dict__中的属性，__dict__是dir()的子集； 如果要获得一个对象的所有属性和方法，可以使用dir()函数 dir('abc') 第十天-图形用户界面和游戏开发 – 第十一天-文件和异常 – 1234567891011121314151617181920212223242526272829# 1.jsonimport json# 字符串处理data = &#123; &#x27;name&#x27; : &#x27;ACME&#x27;, &#x27;shares&#x27; : 100, &#x27;price&#x27; : 542.23&#125;json_str = json.dumps(data)data = json.loads(json_str)# 文件处理# Writing JSON datawith open(&#x27;data.json&#x27;, &#x27;w&#x27;) as f: json.dump(data, f)# Reading data backwith open(&#x27;data.json&#x27;, &#x27;r&#x27;) as f: data = json.load(f)# 2.异常# 1.except语句不是必须的，finally语句也不是必须的，但是二者必须要有一个，否则就没有try的意义了。# 2.except语句可以有多个，Python会按except语句的顺序依次匹配你指定的异常，如果异常已经处理就不会再进入后面的except语句。# 3.except语句可以以元组形式同时指定多个异常，参见实例代码。# 4.except语句后面如果不指定异常类型，则默认捕获所有异常，你可以通过logging或者sys模块获取当前异常。# 5.如果要捕获异常后要重复抛出，请使用raise，后面不要带任何参数或信息。# 6.不建议捕获并抛出同一个异常，请考虑重构你的代码。# 7.不建议在不清楚逻辑的情况下捕获所有异常，有可能你隐藏了很严重的问题。# 8.尽量使用内置的异常处理语句来替换try/except语句，比如with语句，getattr()方法。 第十二天-字符串和正则表达式 正则表达式练习 正则表达式规则 123456# re模块处理# pattern:r&#x27;自己写的表达式&#x27;# str:待匹配字符串 函数 说明 compile(pattern, flags=0) 编译正则表达式返回正则表达式对象 match(pattern, string, flags=0) 用正则表达式匹配字符串 成功返回匹配对象 否则返回None search(pattern, string, flags=0) 搜索字符串中第一次出现正则表达式的模式 成功返回匹配对象 否则返回None split(pattern, string, maxsplit=0, flags=0) 用正则表达式指定的模式分隔符拆分字符串 返回列表 sub(pattern, repl, string, count=0, flags=0) 用指定的字符串替换原字符串中与正则表达式匹配的模式 可以用count指定替换的次数 fullmatch(pattern, string, flags=0) match函数的完全匹配（从字符串开头到结尾）版本 findall(pattern, string, flags=0) 查找字符串所有与正则表达式匹配的模式 返回字符串的列表 finditer(pattern, string, flags=0) 查找字符串所有与正则表达式匹配的模式 返回一个迭代器 purge() 清除隐式编译的正则表达式的缓存 re.I / re.IGNORECASE 忽略大小写匹配标记 re.M / re.MULTILINE 多行匹配标记 第十三天-进程和线程 进程线程知识参考操作系统 多进程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# Unix和Linux操作系统上提供了 `fork()`系统调用来创建进程，调用 `fork()`函数的是父进程，创建出的是子进程# Windows没有fork调用from multiprocessing import Processfrom os import getpidfrom random import randintfrom time import time, sleepdef download_task(filename): print(&#x27;启动下载进程，进程号[%d].&#x27; % getpid()) print(&#x27;开始下载%s...&#x27; % filename) time_to_download = randint(5, 10) sleep(time_to_download) print(&#x27;%s下载完成! 耗费了%d秒&#x27; % (filename, time_to_download))def main(): start = time() p1 = Process(target=download_task, args=(&#x27;Python从入门到住院.pdf&#x27;, )) p1.start() p2 = Process(target=download_task, args=(&#x27;Peking Hot.avi&#x27;, )) p2.start() p1.join() p2.join() end = time() print(&#x27;总共耗费了%.2f秒.&#x27; % (end - start))if __name__ == &#x27;__main__&#x27;: main()# 进程池def main(): start = time() p = Pool(4) # 这里进程池有四个进程但是用了五个任务 # task 0，1，2，3是立刻执行的，而task 4要等待前面某个task完成后才执行 for i in range(5): p.apply_async(download_task, args=(i,)) p.close() p.join() print(&#x27;总共耗费了%.2f秒.&#x27; % (end - start))# 进程通信from multiprocessing import Process, Queueimport os, time, random# 写数据进程执行的代码:def write(q): print(&#x27;Process to write: %s&#x27; % os.getpid()) for value in [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]: print(&#x27;Put %s to queue...&#x27; % value) q.put(value) time.sleep(random.random())# 读数据进程执行的代码:def read(q): print(&#x27;Process to read: %s&#x27; % os.getpid()) while True: value = q.get(True) print(&#x27;Get %s from queue.&#x27; % value)if __name__==&#x27;__main__&#x27;: # 父进程创建Queue，并传给各个子进程： q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) # 启动子进程pw，写入: pw.start() # 启动子进程pr，读取: pr.start() # 等待pw结束: pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止: pr.terminate()&#x27;&#x27;&#x27;Process to write: 50563Put A to queue...Process to read: 50564Get A from queue.Put B to queue...Get B from queue.Put C to queue...Get C from queue.&#x27;&#x27;&#x27; 多线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105from random import randint# 在Python早期的版本中就引入了thread模块（现在名为_thread）来实现多线程编程，然而该模块过于底层，而且很多功能都没有提供# 因此目前的多线程开发我们推荐使用threading模块，该模块对多线程编程提供了更好的面向对象的封装。from threading import Threadfrom time import time, sleepdef download(filename): print(&#x27;开始下载%s...&#x27; % filename) time_to_download = randint(5, 10) sleep(time_to_download) print(&#x27;%s下载完成! 耗费了%d秒&#x27; % (filename, time_to_download))def main(): start = time() t1 = Thread(target=download, args=(&#x27;Python从入门到住院.pdf&#x27;,)) t1.start() t2 = Thread(target=download, args=(&#x27;Peking Hot.avi&#x27;,)) t2.start() t1.join() t2.join() end = time() print(&#x27;总共耗费了%.3f秒&#x27; % (end - start))if __name__ == &#x27;__main__&#x27;: main()# 继承 `Thread`类的方式来创建自定义的线程类from random import randintfrom threading import Threadfrom time import time, sleepclass DownloadTask(Thread): def __init__(self, filename): # 可以穿name给线程命名 super().__init__() self._filename = filename def run(self): print(&#x27;开始下载%s...&#x27; % self._filename) time_to_download = randint(5, 10) sleep(time_to_download) print(&#x27;%s下载完成! 耗费了%d秒&#x27; % (self._filename, time_to_download))def main(): start = time() t1 = DownloadTask(&#x27;Python从入门到住院.pdf&#x27;) t1.start() t2 = DownloadTask(&#x27;Peking Hot.avi&#x27;) t2.start() t1.join() t2.join() end = time() print(&#x27;总共耗费了%.2f秒.&#x27; % (end - start))if __name__ == &#x27;__main__&#x27;: main()# 线程上锁from time import sleepfrom threading import Thread, Lock# RLock 可重用锁,同一线程中可以多次调用acquire,但是release要调用一样的次数class Account(object): def __init__(self): self._balance = 0 self._lock = Lock() def deposit(self, money): # 先获取锁才能执行后续的代码 self._lock.acquire() try: new_balance = self._balance + money sleep(0.01) self._balance = new_balance finally: # 在finally中执行释放锁的操作保证正常异常锁都能释放 self._lock.release() @property def balance(self): return self._balanceclass AddMoneyThread(Thread): def __init__(self, account, money): super().__init__() self._account = account self._money = money def run(self): self._account.deposit(self._money)def main(): account = Account() threads = [] for _ in range(100): t = AddMoneyThread(account, 1) threads.append(t) t.start() for t in threads: t.join() print(&#x27;账户余额为: ￥%d元&#x27; % account.balance)if __name__ == &#x27;__main__&#x27;: main()# 线程通信from queue import Queue# queue.Queue：这是一个线程安全的队列，可以被用来在线程之间传递数据。# queue.LifoQueue：这是一个线程安全的栈，可以被用来在线程之间传递数据。# queue.PriorityQueue：这是一个线程安全的优先队列，可以被用来在线程之间传递数据。# collections.deque：这是一个线程安全的双端队列，可以被用来在线程之间传递数据。# multiprocessing.Queue：这是一个线程安全的队列，可以被用来在进程之间传递数据。 第十四天-网络编程入门和网络应用开发 计算机网络基础知识补充 发邮件 发短信 网络服务 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 多线程网络服务# 服务器端from socket import socket, SOCK_STREAM, AF_INETfrom base64 import b64encodefrom json import dumpsfrom threading import Threaddef main(): # 自定义线程类 class FileTransferHandler(Thread): def __init__(self, cclient): super().__init__() self.cclient = cclient def run(self): my_dict = &#123;&#125; my_dict[&#x27;filename&#x27;] = &#x27;guido.jpg&#x27; # JSON是纯文本不能携带二进制数据 # 所以图片的二进制数据要处理成base64编码 my_dict[&#x27;filedata&#x27;] = data # 通过dumps函数将字典处理成JSON字符串 json_str = dumps(my_dict) # 发送JSON字符串 self.cclient.send(json_str.encode(&#x27;utf-8&#x27;)) self.cclient.close() # 1.创建套接字对象并指定使用哪种传输服务 server = socket() # 2.绑定IP地址和端口(区分不同的服务) server.bind((&#x27;192.168.1.2&#x27;, 5566)) # 3.开启监听 - 监听客户端连接到服务器 server.listen(512) print(&#x27;服务器启动开始监听...&#x27;) with open(&#x27;guido.jpg&#x27;, &#x27;rb&#x27;) as f: # 将二进制数据处理成base64再解码成字符串 data = b64encode(f.read()).decode(&#x27;utf-8&#x27;) while True: client, addr = server.accept() # 启动一个线程来处理客户端的请求 FileTransferHandler(client).start()if __name__ == &#x27;__main__&#x27;: main()# 客户端from socket import socketfrom json import loadsfrom base64 import b64decodedef main(): client = socket() client.connect((&#x27;192.168.1.2&#x27;, 5566)) # 定义一个保存二进制数据的对象 in_data = bytes() # 由于不知道服务器发送的数据有多大每次接收1024字节 data = client.recv(1024) while data: # 将收到的数据拼接起来 in_data += data data = client.recv(1024) # 将收到的二进制数据解码成JSON字符串并转换成字典 # loads函数的作用就是将JSON字符串转成字典对象 my_dict = loads(in_data.decode(&#x27;utf-8&#x27;)) filename = my_dict[&#x27;filename&#x27;] filedata = my_dict[&#x27;filedata&#x27;].encode(&#x27;utf-8&#x27;) with open(&#x27;/Users/Hao/&#x27; + filename, &#x27;wb&#x27;) as f: # 将base64格式的数据解码成二进制数据并写入文件 f.write(b64decode(filedata)) print(&#x27;图片已保存.&#x27;)if __name__ == &#x27;__main__&#x27;: main() 第十五天-图像和办公文档处理 图像 12345678910111213141516171819202122232425262728293031323334353637383940&gt;&gt;&gt; from PIL import Image&gt;&gt;&gt;&gt;&gt;&gt; image = Image.open(&#x27;./res/guido.jpg&#x27;)&gt;&gt;&gt; image.format, image.size, image.mode(&#x27;JPEG&#x27;, (500, 750), &#x27;RGB&#x27;)&gt;&gt;&gt; image.show()# 裁剪图像&gt;&gt;&gt; image = Image.open(&#x27;./res/guido.jpg&#x27;)&gt;&gt;&gt; rect = 80, 20, 310, 360&gt;&gt;&gt; image.crop(rect).show()# 略缩图&gt;&gt;&gt; image = Image.open(&#x27;./res/guido.jpg&#x27;)&gt;&gt;&gt; size = 128, 128&gt;&gt;&gt; image.thumbnail(size)&gt;&gt;&gt; image.show()# 缩放粘贴图像&gt;&gt;&gt; image1 = Image.open(&#x27;./res/luohao.png&#x27;)&gt;&gt;&gt; image2 = Image.open(&#x27;./res/guido.jpg&#x27;)&gt;&gt;&gt; rect = 80, 20, 310, 360&gt;&gt;&gt; guido_head = image2.crop(rect)&gt;&gt;&gt; width, height = guido_head.size&gt;&gt;&gt; image1.paste(guido_head.resize((int(width / 1.5), int(height / 1.5))), (172, 40))# 旋转和反转&gt;&gt;&gt; image = Image.open(&#x27;./res/guido.png&#x27;)&gt;&gt;&gt; image.rotate(180).show()&gt;&gt;&gt; image.transpose(Image.FLIP_LEFT_RIGHT).show()# 操作像素&gt;&gt;&gt; image = Image.open(&#x27;./res/guido.jpg&#x27;)&gt;&gt;&gt; for x in range(80, 310):... for y in range(20, 360):... image.putpixel((x, y), (128, 128, 128))... &gt;&gt;&gt; image.show()# 滤镜&gt;&gt;&gt; from PIL import Image, ImageFilter&gt;&gt;&gt;&gt;&gt;&gt; image = Image.open(&#x27;./res/guido.jpg&#x27;)&gt;&gt;&gt; image.filter(ImageFilter.CONTOUR).show() Excel Word B站视频总结 元类编程 元类:创建类的类 1.动态属性 12345678910#get@property修饰#set@aaa.setter#查找不到进入__getattr__#先进入这个__getattribute__getattr(类,属性)==类.属性 2.属性描述符 1234567891011121314151617# 数据描述符class IntField: def __get__( self, instance，owner): return self.value def __set__(self, instance, value): if not isinstance(value, numbers.Integral): raise ValueError( &quot;int value need&quot;) if value &lt; 0: raise ValueError( &quot;positive value need&quot;) self.value = value def __delete__(self, instance): passclass User: # 自定义类型检测 age = IntField() 3.类属性取值过程 如果user是某个类的实例，那么user.age（以及等价的getattr(user, ‘age’))首先调用__getattribute__。如果类定义了_getattr_方法， 那么在_getattribute__抛出 AttributeError的时候就会调用到_getattr_,而对于描述符(get)的调用，则是发生在__getattribute__内部的。 user = User()，那么user.age顺序如下: (1) 如果&quot;age”是出现在user或其基类的__dict__中，且age是data descriptor，那么调用其__get__方法 ,否则 (2) 如果&quot;age&quot;出现在obj的__dict__中，那么直接返回 obj.dict[ ‘age’]，否则 (3) 如果&quot;age&quot;出现在User或其基类的__dict__中 (3.1) 如果age是non-data descriptor，那么调用其__get__方法，否则 (3.2) 返回__dict__[ ‘age’] (4) 如果User有__getattr__方法，调用__getattr__方法，否则 (5) 抛出AttributeError 4.__new__和__init__区别 new传的类本身 init传的对象实例 先进new后进init new不返回对象,不会进init 5.type动态创建类 type(“类名”,(父类),{属性,函数}) 控制类的创建过程 class user(metaclass=自定义元类) 元类编程-&gt;封装 6.可迭代,迭代器,生成器 迭代器和迭代序列分离 iter 可迭代 next 迭代器 1234567891011121314151617class company(object): def _init_(self, employee_list): self.employee = employee_list def _iter_( self): return MyIterator( self.employee)class MyIterator(Iterator ) : def _init_(self, employee_list): self.iter_list = employee_listself.index = 0 def inext_(self): #真正返回迭代值的逻辑 try: word = self.iter_list[ self.index] except IndexError: raise stopIteration self.index +=1 return word 生成器 1234567891011121314def gen_fib(index): n,a,b = 0,0,1 while n&lt;index: yie1d b a,b = b,a+b n += 1for data in gen_fib(10): print (data)IPyGenObjectgi_framegi_code会保存上一次执行的位置和代码 大文件读取 12345678910111213141516def myreadlines(f, newline) :buf = &quot;&quot;while True: while newline in buf: pos = buf.index( newline) yield buf[:pos] buf = buf[pos + len(newline) : ] chunk = f.read(4096*10) if not chunk : # 文件结尾 yield buf break buf += chunkwith open(&quot;input.txt&quot; ) as f: for line in myreadlines(f，&quot;&#123;&quot;): print (line) 7.socket编程 见网络编程 8.多线程 1.GIL 全局解释器锁 python中一个线程对应c语言的一个线程 gil使得同一时刻只有一个线程运行在一个cpu上运行字节码 不能把多个线程映射到多个cpu上 gil会根据执行的字节码行数及时间片释放gil 遇见io操作也会主动释放(适合io频繁) 2.线程同步,通信 多线程实现 使用线程传递函数 继承多线程类,实现run 线程通信 共享变量:不好 Queue:还有其他线程安全的数据结构 线程同步 Lock,RLock Lock:获取两次就会死锁 RLock:允许多线程环境下多次acquire,但是release要一样的数量 condition:wait()和notify() 等待和唤醒 先等待才能唤醒 把waiter的锁放入一个双端队列 notify把队列弹一个出来释放 with condition 就是获取锁释放锁(默认RLock) with之后才能wait和notify,wait把condition的锁释放掉 con’t wait on a un-acquire lock Semaphore:用于控制进入数量的锁 threading.Semaphore(3) 3.线程池&amp;进程池 from concurrent import futures 12345678910111213141516171819202122232425262728executor = ThreadPoo1Executor(max_workers=1)#通过submit函数提交执行的函数到线程池中,submit是立即返回task1 = executor. submit(get_htm1,(3))task2 = executor. submit(get_htm1,(2))# done用于判断是否完成task1.done()# result获取函数返回结果task1.result()#要获取已经成功的task的返回urls = [3,2,4]all_task = [executor. submit(get_html,(url)) for url in urls]# yield已经完成的线程for future in as_completed(all_task): data = future.result() print( &quot;get ipage success&quot;.format(data))#通过executor获取已经完成的task返回值,返回顺序一致for data in executor.map(get_html, urls): print( &quot;get &#123;fpage&quot;.format(data))# 阻塞主线程,等全部还是等一个wait() 进程适合计算密集 线程适合io密集 父进程和子进程各有数据 子进程会把创建进程下面的代码单独运行一遍 ProcessPoolExecutor用的multiprocessing 不能用queue.Queue 不能用共享变量 from queue import Queue from multiprocessing import Queue from multiprocessing.Manager import Queue #Manager 有很多数据结构 pipe只能用于两个进程 性能高于Queue 9.IO复用 并发 并发是指一个时间段内有几个程序在同一个cpu运行，但是任意时刻只有一个程序在cpu上运行 并行 并行是指任意时刻点上，有多个程序同时运行在多个cpu 同步 同步是指代码调用IO操作时必须等待IO操作完成才返 回的调用方式。 异步 异步是指代码调用IO操作时，不必等IO操作完成就返回的调用方式。 阻塞 阻塞是指调用函数时候当前线程被挂起。 非阻塞 非阻塞是指调用函数时候当前线程不会被挂起，而是立即返回。 10.回调协程 11.asynch await 12.事件循环","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python学习笔记","slug":"Python学习笔记","permalink":"https://gladdduck.github.io/tags/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"LeetCode75","slug":"算法-LeetCode75","date":"2023-02-25T02:15:22.077Z","updated":"2023-11-26T05:21:12.210Z","comments":true,"path":"2023/02/25/算法-LeetCode75/","link":"","permalink":"https://gladdduck.github.io/2023/02/25/%E7%AE%97%E6%B3%95-LeetCode75/","excerpt":"","text":"LeetCode75学习计划 第一天 1480.一维数组的动态和 思路:前缀和 12345678# python的内置数据方法# https://docs.python.org/3/library/itertools.html# accumulate([1,2,3,4,5]) --&gt; 1 3 6 10 15class Solution: def runningSum(self, nums: List[int]) -&gt; List[int]: return list(accumulate(nums)) 724.寻找数组的中心下标 思路: 先求前缀和,然后遍历下标,利用前缀和计算下标两边的和,左右两端的位置需要判断一下 1234567891011121314class Solution: def pivotIndex(self, nums: List[int]) -&gt; int: pre_sum=list(accumulate(nums)) length=len(nums) if pre_sum[length-1]-pre_sum[0]==0: return 0 for index in range(1,length-1): if pre_sum[index-1]==pre_sum[length-1]-pre_sum[index]: return index # 返回最左边下标,防止有x,x,x,x,..0,0,0,0的情况 if pre_sum[length-2]==0: return length-1 return -1 第二天 205. 同构字符串 思路:每个字符串对应位置的字母是一一对应的,用字典. 两个方向,一个是s对t的字母是一一对应,一个是t对s的字母是一一对应 1234567891011121314151617181920212223242526272829class Solution: def isIsomorphic1(self, s: str, t: str) -&gt; bool: dic=defaultdict(str) for index,item in enumerate(s): # 检查s对t if item not in dic: # 检擦t对s if t[index] not in dic.values(): dic[item]=t[index] else: return False else: if dic[item]!=t[index]: return False return True def isIsomorphic(self, s: str, t: str) -&gt; bool: def check(s,t): dic=defaultdict(str) for index,item in enumerate(s): if item not in dic: dic[item]=t[index] else: if dic[item]!=t[index]: return False return True return check(s,t) and check(t,s) 392. 判断子序列 思路:判断子序列,两个字符串不同位置的比较,双指针,ab指针,如果对应字符一样,都前进,如果不一样,指向母字符串的前进 1234567891011class Solution: def isSubsequence(self, s: str, t: str) -&gt; bool: length=len(s) if length==0:return True index=0 for item in t: if item==s[index]: index+=1 if index==length: return True return False 332周赛 6355. 统计公平数对的数目 思路:对数组排序,对每一个数,用二分找到大小在lower和upper之间的下标,如果这个数也在下标中就-1,最后结果除2,(i,j)(j,i)都算了 bilibili:两个数的和,枚举一个数,用其他方法处理另一个数 6356. 子字符串异或查询 思路:对每一个查询,a^b=c =&gt; a=c^b,然后把a转换成二进制字符串,剩下的就是在字符串中找子字符串在起始位置 bilibili:预处理s中的二进制,把子字符串转换成数字存进dict,直接找a 6357. 最少得分子序列 没做出来思路:计算最长公共子序列,统计不在最长公共子序列中的下标,就是要删除的下标(可能错在需要找到最左边的最长子序列) bilibili: 1.删除[left,right]中间的几个和删除全部是一样的 2.枚举s,把s从中间划分,前面匹配t的前部分,后面匹配t的后部分 3.中间就是可以删掉的部分,找到最小的 4.实现的时候,先从后往前匹配s和t(全部匹配),然后从前往后,找到相应的答案 第三天 21. 合并两个有序链表 思路:双指针比较交替,问题就是开头的细节,一种是用一个空链表头,一种就是先比较ab的大小直接赋值ab的头 12345678910111213141516171819202122# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextclass Solution: def mergeTwoLists(self, a: Optional[ListNode], b: Optional[ListNode]) -&gt; Optional[ListNode]: if not a:return b if not b:return a # 空表头 prehead=ListNode(0) pre=prehead while a and b: if a.val&gt;b.val: pre.next=b b=b.next else: pre.next=a a=a.next pre=pre.next pre.next=a if a else b return prehead.next 206. 反转链表 思路:反转链表需要标记连续的三个节点,a,b,c 把b指向a,然后a,b,c依次向后移动一个,注意边界情况 123456789101112131415161718192021# Definition for singly-linked list.# class ListNode:# def __init__(self, val=0, next=None):# self.val = val# self.next = nextclass Solution: def reverseList(self, a: Optional[ListNode]) -&gt; Optional[ListNode]: if not a:return a if not a.next:return a b=a.next c=a.next.next # 这个地方不断掉会死循环 a.next=None while b: b.next=a if not c:break a=b b=c c=c.next return b 第四天 876. 链表的中间结点 思路:把链表存成数组,找数组长度一半的节点 12345678class Solution: def middleNode(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: nums=[] while head: nums.append(head) head=head.next length=len(nums) return nums[length//2] 其他解法:1.第一次计算长度,第二次找节点 2.快慢指针 142. 环形链表 II 自己错误思路:快慢指针,只能检查是否有环,找不到入口 思路:1.字典存已经走过的 2.快慢指针经过数学推导计算 12345678910class Solution: def detectCycle(self, head: Optional[ListNode]) -&gt; Optional[ListNode]: nums=dict() while head: if head in nums.keys(): return head else: nums[head]=1 head=head.next return head 第五天 121. 买卖股票的最佳时机 思路:如果今天减去昨天的利润,加上之前的利润小于0,说明今天是巨亏的,不如之前的不买,买今天的,如果今天减去昨天的利润,加上之前的利润仍然大于0,记录一下,继续往后加,说不定会涨 1234567891011class Solution: def maxProfit(self, prices: List[int]) -&gt; int: ans=0 profit=0 for index in range(1,len(prices)): if prices[index]-prices[index-1]+profit&lt;0: profit=0 else: profit+=prices[index]-prices[index-1] ans=max(ans,profit) return ans 409. 最长回文串 思路:统计字符的数量,注意加上一个奇数就行 12345678910111213class Solution: def longestPalindrome(self, s: str) -&gt; int: m=defaultdict(int) for item in s: m[item]+=1 ans=0 flag=0 for k,v in m.items(): if v&amp;1: flag=1 v-=1 ans+=v return ans+flag 第六天 589. N 叉树的前序遍历 思路:二叉树的深搜,变成了多叉树的深搜 1234567891011class Solution: def preorder(self, a: &#x27;Node&#x27;) -&gt; List[int]: ans=[] def dfs(root): if not root:return ans ans.append(root.val) for chi in root.children: dfs(chi) dfs(a) return ans 102. 二叉树的层序遍历 思路:广搜,用一个额外的层数变量标记当前节点在第几层 其他思路:记录当前栈内有几个节点,然后遍历完这些节点,这些节点之后的就是下一层的节点 123456789101112131415161718192021class Solution: def levelOrder(self, root: Optional[TreeNode]) -&gt; List[List[int]]: ans=[] deq=[] if not root:return [] deq.insert(0,(root,0)) last=0 curlayer=[] while len(deq): (temp,layer)=deq.pop() if layer!=last: ans.append(curlayer) last=layer curlayer=[] curlayer.append(temp.val) if temp.left: deq.insert(0,(temp.left,layer+1)) if temp.right: deq.insert(0,(temp.right,layer+1)) ans.append(curlayer) return ans 第七天 704. 二分查找 思路:正常二分,right要到能遍历到的边界 二分的细节&amp;边界 12345678910111213class Solution: def search(self, nums: List[int], target: int) -&gt; int: left,right=0,len(nums)-1 while left&lt;=right: mid=(left+right)&gt;&gt;1 if nums[mid]&lt;target: left=mid+1 elif nums[mid]&gt;target: right=mid-1 else: return mid return -1 if nums[mid]!=target else mid 278. 第一个错误的版本 思路:二分查找的变换版,区别在于要记录mid量,纯二分是找到mid直接返回,这个找到的可能不是需要的 123456789101112class Solution: def firstBadVersion(self, n: int) -&gt; int: left,right=1,n ans=1 while left&lt;=right: mid=(left+right)&gt;&gt;1 if isBadVersion(mid): right=mid-1 ans=mid else: left=mid+1 return ans 第八天 98. 验证二叉搜索树 错误思路:不能判断当前节点之后,然后再去分别判断左右子树 正确×思路: 每棵左右子树节点的大小范围应该都是low-up,初始low=-inf,up=inf,左子树的范围是(low,root.val) 右子树是(root.val,up) 官方题解也是错的 其他:二叉搜素树中序遍历一定是升序的 树的几种遍历 123456789101112class Solution: def firstBadVersion(self, n: int) -&gt; int: left,right=1,n ans=1 while left&lt;=right: mid=(left+right)&gt;&gt;1 if isBadVersion(mid): right=mid-1 ans=mid else: left=mid+1 return ans 235. 二叉搜索树的最近公共祖先 思路:1.寻找祖先路径,找到第一个不同的位置 2.一次遍历,如果都小就都找左边,如果都大就都找右边,如果有小有大就找到了分界点 123456789class Solution: def lowestCommonAncestor(self, r: &#x27;TreeNode&#x27;, p: &#x27;TreeNode&#x27;, q: &#x27;TreeNode&#x27;) -&gt; &#x27;TreeNode&#x27;: while True: if r.val&gt;p.val and r.val&gt;q.val: r=r.left elif r.val&lt;p.val and r.val &lt; q.val: r=r.right else: return r 第九天 733. 图像渲染 思路:广搜/深搜找同颜色的,上下左右判断边界,访问数组 1234567891011121314151617181920class Solution: def floodFill(self, image: List[List[int]], sr: int, sc: int, color: int) -&gt; List[List[int]]: n=len(image) m=len(image[0]) visited=[[0]*m for _ in range(n)] dq=deque() dq.append((sr,sc)) oldcolor=image[sr][sc] while dq: x,y=dq.popleft() image[x][y]=color visited[x][y]=1 for x_,y_ in [(0,1),(0,-1),(-1,0),(1,0)]: if x_+x&gt;=0 and x_+x&lt;n and y_+y&gt;=0 and y_+y&lt;m: if visited[x_+x][y_+y]: continue if image[x_+x][y_+y]==oldcolor: dq.append((x_+x,y_+y)) return image 200. 岛屿数量 思路:深搜/广搜,从某点开始把连在一起的都访问一次,记录一共从几个点开始,这些点都是不同的岛屿 12345678910111213141516171819202122class Solution: def numIslands(self, grid: List[List[str]]) -&gt; int: n=len(grid) m=len(grid[0]) visited=[[0 if grid[i][j]==&#x27;1&#x27; else 1 for j in range(m)] for i in range(n)] ans=0 for i in range(n): for j in range(m): if not visited[i][j]: ans+=1 dq=deque() dq.append((i,j)) while dq: x,y=dq.popleft() visited[x][y]=1 for x_,y_ in [(0,1),(0,-1),(-1,0),(1,0)]: if x_+x&gt;=0 and x_+x&lt;n and y_+y&gt;=0 and y_+y&lt;m: if not visited[x_+x][y_+y]: visited[x_+x][y_+y]=1 dq.append((x_+x,y_+y)) return ans 333周赛 6365. 将整数减少到零需要的最少操作数 思路1:刚开始以为要转成二进制的01传,看0多还是1多,如果0多直接返回1的数量,但是668错了 思路2:打表100000之内2的次方,然后二分查找n在那两个数中间,找距离近的这个数的插值,然后+1递归下去,54-&gt;64-54=10-&gt;10-8=2-&gt;0 bilibili:找到最低为的1,考虑这个1 是直接减掉还是加上同位置的1 ,枚举这两种可能. 判断一个数是不是2的幂:(x &amp; ( x-1 ))==0 找到最低位的1:lowbit: x &amp; -x ☆6364. 无平方子集计数 没思路:题型重灾区,应该是用dp做,但是毫无思路 bilibili:对不起,等我学有所成再来看,什么jb玩意那么难 6363. 找出对应 LCP 矩阵的字符串 没思路 第十天 509. 斐波那契数 思路:. 1234# 1.自顶向下,记忆化搜索# 2.自底向上,dp数组# 3.用a,b两个变量,空间复杂度降到O(1)# 4.矩阵快速幂,时间复杂度降到O(logn) 70. 爬楼梯 思路:. 1# 斐波那契数列模板题 第十一天 746. 使用最小花费爬楼梯 思路:爬到今天的费用只能有两个来源,前一个和前两个,但是顶楼数组里没有,所以追加一个0,第一层第二层的费用就是本身,第二层为什么不是min(第一层,第二层)呢,因为如果是从第一层上到的第二层,第二层还要继续向上上,那么还得加上第二层的费用,就变成了(第一层+第二层)的费用了 1234567891011121314class Solution: def minCostClimbingStairs(self, cost: List[int]) -&gt; int: cost.append(0) n=len(cost) # dp=[99999]*(n) a=cost[0] b=cost[1] c=b for i in range(2,n): c=min(a,b)+cost[i] a,b=b,c # dp[i]=min(dp[i-1],dp[i-2])+cost[i] return c 62. 不同路径 思路:深搜和广搜的复杂度应该是O(2n)O(2^n)O(2n),会超时,还是dp,当前位置只能从左边或者上边来到,就把左边和上边的方案数加起来就行,第一行第一列的方案数都是1 1234567891011121314151617181920212223242526272829class Solution: def uniquePaths(self, m: int, n: int) -&gt; int: a=[1 for j in range(n) ] b=[1 for j in range(n) ] for i in range(1,m): for j in range(1,n): b[j]=a[j]+b[j-1] a=b[:] return b[-1] # dp=[[0 for j in range(n) ] for i in range(m)] # for i in range(m): # for j in range(n): # if i==0 or j==0: # dp[i][j]=1 # else: # dp[i][j]=dp[i][j-1]+dp[i-1][j] # return dp[m-1][n-1] # dq=deque([(0,0)]) # ans=0 # while dq: # x,y=dq.pop() # if x==m-1 and y==n-1: # ans+=1 # for x_,y_ in [(x+1,y),(x,y+1)]: # if x_&gt;=0 and x_&lt;m and y_&gt;=0 and y_&lt;n: # dq.append((x_,y_)) # return ans 第十二天 438. 找到字符串中所有字母异位词 思路:双指针维护长度为第二个字符串的区间,对区间内的数字统计数量,数量一致答案加1,右移的时候,右侧字符加1,左侧字符减1 12345678910111213141516171819202122232425class Solution: def findAnagrams(self, s: str, p: str) -&gt; List[int]: def val(a,b): for i,j in zip(a,b): if i!=j: return False return True pnums=[0]*26 snums=[0]*26 constant=ord(&#x27;a&#x27;) for item in p: pnums[ord(item)-constant]+=1 left=right=0 lengths=len(s) lengthp=len(p) ans=[] while right&lt;lengths: snums[ord(s[right])-constant]+=1 if val(snums,pnums): ans.append(left) right+=1 if right&gt;=lengthp: snums[ord(s[left])-constant]-=1 left+=1 return ans 424. 替换后的最长重复字符 思路:没有思路,考虑到了应该是用双指针 题解:双指针加一个maxhistory记录最多的相同字符个数,如果当前区间长度大于了k+maxhistory,说明不可能变成一样的,左边右移1,否则说明当前区间不是最大长度,还可增加新元素 123456789101112131415161718192021222324class Solution: def characterReplacement(self, s: str, k: int) -&gt; int: constant=ord(&#x27;A&#x27;) length=len(s) # 左右指针 left=right=0 # 用于记录left-right区间每个字母的个数 nums=[0]*26 # 用于记录区间内出现的 最多的相同字符的个数 historymax=0 while right&lt;length: # 新加的字符个数加1 nums[ord(s[right])-constant]+=1 # 更新一下区间内最长的字符个数 historymax=max(historymax,nums[ord(s[right])-constant]) # historymax+k 是目前可以达到的最长长度,已经包含了右节点了 # 小于说明现在这个区间长度还小于最大长度 # 大于说明把其它不是最多出现的字符替换以后，都不能填满这个滑动的窗口，说明此时 k 不够用 # 这个时候须要考虑左边界向右移动 if right-left+1&gt;historymax+k: nums[ord(s[left])-constant]-=1 left+=1 right+=1 return right-left 第十三天 1. 两数之和 思路:数组排序,然后对每个数字,二分查找target减去她的值 题解:用字典存储每个target-num的值,如果当前数字在字典中存在,找到答案,否则把target减他存进去 123456789101112131415161718class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: # nums=[(i,n) for i,n in enumerate(nums)] # nums=sorted(nums,key=lambda x:x[1]) # length=len(nums) # for i in range(length): # ttt=target-nums[i][1] # index=bisect_left(nums,ttt,key=lambda x:x[1]) # if index==i:continue # if index&lt;0 or index&gt;=length:continue # if nums[index][1]==ttt: # return [nums[i][0],nums[index][0]] hashtable = dict() for i, num in enumerate(nums): if target - num in hashtable: return [hashtable[target - num], i] hashtable[nums[i]] = i return [] 299. 猜数字游戏 思路:A数字好统计,对于B数字,分别存A,B中数字出现的个数,加入对他们重新排序,一定是只能匹配个数少的,所以直接取每个数字二者中的最小值,求和就是B. 123456789101112131415class Solution: def getHint(self, secret: str, guess: str) -&gt; str: hasA=[0]*10 hasB=[0]*10 A=0 for i,j in zip(secret,guess): if i==j: A+=1 else: hasA[int(j)]+=1 hasB[int(i)]+=1 ans=sum([min(a,b) for a,b in zip(hasA,hasB)]) return f&#x27;&#123;A&#125;A&#123;ans&#125;B&#x27; 第十四天 844. 比较含退格的字符串 思路:忘记用栈了，从后往前遍历数组，cnt记录当前#的数量，然后跳过cnt个字母。 题解:用栈，遇见#退一个字符 12345678910111213141516class Solution: def backspaceCompare(self, s: str, t: str) -&gt; bool: def check(a): length=len(a) ans=[] cnt=0 for i in range(length-1,-1,-1): if a[i]==&#x27;#&#x27;: cnt+=1 else: if cnt==0: ans.append(a[i]) else: cnt-=1 return ans return check(s)==check(t) 394. 字符串解码 思路:栈操作，一个数组存数字，一个栈用来弹字符，遇见]一直弹，直到弹出[。然后复制数字数组的最后一个数字便，在加入栈中，数字的处理有一点点麻烦 12345678910111213141516171819202122232425262728class Solution: def decodeString(self, s: str) -&gt; str: stack=[] nums=[] length=len(s) i=0 while i&lt;length: if s[i]==&#x27;]&#x27;: temp=[] while stack[-1]!=&#x27;[&#x27;: temp.append(stack.pop()) stack.pop() temp=&quot;&quot;.join(temp[::-1]) stack.append(temp*nums[-1]) nums.pop() i+=1 elif s[i].isnumeric(): n=0 while i&lt;length and s[i].isnumeric(): n*=10 n+=int(s[i]) i+=1 nums.append(n) else: stack.append(s[i]) i+=1 return &quot;&quot;.join(stack) 第十五天 1046. 最后一块石头的重量 思路:大项堆，但是python的heapq只能实现小项堆，大项堆的实现要加负号 123456789101112131415class Solution: def lastStoneWeight(self, x: List[int]) -&gt; int: x=list(map(lambda x:-x,x)) # 这一步的作用不是很明确 # 注意heapify(包括heapq封装的其他操作)都不会更改数据结构(仍为list)，只会以堆的操作规范对其进行处理。 # 虽然类型仍为list，但元素的顺序已经满足了堆的规范，所以从线性的角度看结果列表并非是有序的(是[1, 3, 7, 9, 5]而非[1, 3, 5, 7, 9]) heapq.heapify(x) while len(x)&gt;1: a=heapq.heappop(x) b=heapq.heappop(x) if a!=b: newstore=abs(max(a,b)-min(a,b)) heapq.heappush(x,-newstore) return -x[0] if len(x) else 0 692. 前K个高频单词 思路:Counter统计单词数量，然后按照数量降序，字典序升序排列，返回k个 题解：优先队列，元组（单词，词频） 知识点：1.Counter的most_common()在计数相同的情况下是按出现顺序返回 2.python多关键字排序： 1234arr=[(1,4,3),(1,3,3),(2,1,4),(3,5,1)]arr.sort(key=lambda s:(s[0],-s[1])) #两个关键字排序,在需要倒序排列的关键字前加`-`号 123456class Solution: def topKFrequent(self, words: List[str], k: int) -&gt; List[str]: c = Counter(words).items() c = sorted(c,key=lambda x:(-x[1],x[0])) return list(map(lambda x:x[0],c[:k])) # return sorted((cnt := Counter(words)).keys(), key=lambda key: (-cnt[key], key))[:k] 总结","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"}]},{"title":"python100天16-30","slug":"笔记-python100天16-30","date":"2023-02-18T08:22:29.557Z","updated":"2023-02-21T10:23:48.298Z","comments":true,"path":"2023/02/18/笔记-python100天16-30/","link":"","permalink":"https://gladdduck.github.io/2023/02/18/%E7%AC%94%E8%AE%B0-python100%E5%A4%A916-30/","excerpt":"","text":"12345678910111213141516171819202122# 01-15python基础# 16-20python进阶# 21-30前端概述# 31-35Linux# 36-40MySQL# 41-55Django# 56-60FaskAPI# 61-65爬虫与并发编程# 66-80numpy&amp;pandas# 81-90机器学习&amp;pytorch# 91-100项目 Python100天学习16-20 Python语言进阶 资料连接 重要知识点 1.生成式,推导式 2.嵌套列表 3.heapq模块(堆排序) 1234567891011121314151617181920&quot;&quot;&quot;从列表中找出最大的或最小的N个元素堆结构(大根堆/小根堆)&quot;&quot;&quot;import heapqlist1 = [34, 25, 12, 99, 87, 63, 58, 78, 88, 92]list2 = [ &#123;&#x27;name&#x27;: &#x27;IBM&#x27;, &#x27;shares&#x27;: 100, &#x27;price&#x27;: 91.1&#125;, &#123;&#x27;name&#x27;: &#x27;AAPL&#x27;, &#x27;shares&#x27;: 50, &#x27;price&#x27;: 543.22&#125;, &#123;&#x27;name&#x27;: &#x27;FB&#x27;, &#x27;shares&#x27;: 200, &#x27;price&#x27;: 21.09&#125;, &#123;&#x27;name&#x27;: &#x27;HPQ&#x27;, &#x27;shares&#x27;: 35, &#x27;price&#x27;: 31.75&#125;, &#123;&#x27;name&#x27;: &#x27;YHOO&#x27;, &#x27;shares&#x27;: 45, &#x27;price&#x27;: 16.35&#125;, &#123;&#x27;name&#x27;: &#x27;ACME&#x27;, &#x27;shares&#x27;: 75, &#x27;price&#x27;: 115.65&#125;]print(heapq.nlargest(3, list1))print(heapq.nsmallest(3, list1))print(heapq.nlargest(2, list2, key=lambda x: x[&#x27;price&#x27;]))print(heapq.nlargest(2, list2, key=lambda x: x[&#x27;shares&#x27;])) 4.itertools模块 1234567891011121314&quot;&quot;&quot;迭代工具模块&quot;&quot;&quot;import itertools# 产生ABCD的全排列itertools.permutations(&#x27;ABCD&#x27;)# 产生ABCDE的五选三组合itertools.combinations(&#x27;ABCDE&#x27;, 3)# 产生ABCD和123的笛卡尔积itertools.product(&#x27;ABCD&#x27;, &#x27;123&#x27;)# 产生ABC的无限循环序列itertools.cycle((&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;)) 5.collections模块 namedtuple：命令元组，它是一个类工厂，接受类型的名称和属性列表来创建一个类。 deque：双端队列，是列表的替代实现。Python中的列表底层是基于数组来实现的，而deque底层是双向链表，因此当你需要在头尾添加和删除元素时，deque会表现出更好的性能，渐近时间复杂度为O(1)O(1)O(1)。 Counter：dict的子类，键是元素，值是元素的计数，它的most_common()方法可以帮助我们获取出现频率最高的元素。 OrderedDict：dict的子类，它记录了键值对插入的顺序，看起来既有字典的行为，也有链表的行为。 defaultdict：类似于字典类型，但是可以通过默认的工厂函数来获得键对应的默认值，相比字典中的setdefault()方法，这种做法更加高效。 数据结构和算法 选择排序 12345678910def select_sort(items, comp=lambda x, y: x &lt; y): &quot;&quot;&quot;简单选择排序&quot;&quot;&quot; items = items[:] for i in range(len(items) - 1): min_index = i for j in range(i + 1, len(items)): if comp(items[j], items[min_index]): min_index = j items[i], items[min_index] = items[min_index], items[i] return items 冒泡排序 123456789101112def bubble_sort(items, comp=lambda x, y: x &gt; y): &quot;&quot;&quot;冒泡排序&quot;&quot;&quot; items = items[:] for i in range(len(items) - 1): swapped = False for j in range(len(items) - 1 - i): if comp(items[j], items[j + 1]): items[j], items[j + 1] = items[j + 1], items[j] swapped = True if not swapped: break return items 归并排序 12345678910111213141516171819202122232425262728def merge(items1, items2, comp=lambda x, y: x &lt; y): &quot;&quot;&quot;合并(将两个有序的列表合并成一个有序的列表)&quot;&quot;&quot; items = [] index1, index2 = 0, 0 while index1 &lt; len(items1) and index2 &lt; len(items2): if comp(items1[index1], items2[index2]): items.append(items1[index1]) index1 += 1 else: items.append(items2[index2]) index2 += 1 items += items1[index1:] items += items2[index2:] return itemsdef merge_sort(items, comp=lambda x, y: x &lt; y): return _merge_sort(list(items), comp)def _merge_sort(items, comp): &quot;&quot;&quot;归并排序&quot;&quot;&quot; if len(items) &lt; 2: return items mid = len(items) // 2 left = _merge_sort(items[:mid], comp) right = _merge_sort(items[mid:], comp) return merge(left, right, comp) 快速排序 12345678910111213141516171819202122232425&quot;&quot;&quot;快速排序 - 选择枢轴对元素进行划分，左边都比枢轴小右边都比枢轴大&quot;&quot;&quot;def quick_sort(items, comp=lambda x, y: x &lt;= y): items = list(items)[:] _quick_sort(items, 0, len(items) - 1, comp) return itemsdef _quick_sort(items, start, end, comp): if start &lt; end: pos = _partition(items, start, end, comp) _quick_sort(items, start, pos - 1, comp) _quick_sort(items, pos + 1, end, comp)def _partition(items, start, end, comp): pivot = items[end] i = start - 1 for j in range(start, end): if comp(items[j], pivot): i += 1 items[i], items[j] = items[j], items[i] items[i + 1], items[end] = items[end], items[i + 1] return i + 1 选择排序 1234567891011def select_sort(items, comp=lambda x, y: x &lt; y): &quot;&quot;&quot;简单选择排序&quot;&quot;&quot; items = items[:] for i in range(len(items) - 1): min_index = i for j in range(i + 1, len(items)): if comp(items[j], items[min_index]): min_index = j items[i], items[min_index] = items[min_index], items[i] return items 二分查找 123456789101112def bin_search(items, key): &quot;&quot;&quot;折半查找&quot;&quot;&quot; start, end = 0, len(items) - 1 while start &lt;= end: mid = (start + end) // 2 if key &gt; items[mid]: start = mid + 1 elif key &lt; items[mid]: end = mid - 1 else: return mid return -1 穷举 贪心 动态规划 分治 回溯 函数的使用方式 map``filter 123items1 = list(map(lambda x: x ** 2, filter(lambda x: x % 2, range(1, 10))))items2 = [x ** 2 for x in range(1, 10) if x % 2] 位置参数、可变参数、关键字参数、命名关键字参数 Local &gt;&gt;&gt; Embedded &gt;&gt;&gt; Global &gt;&gt;&gt; Built-in 装饰器 面向对象相关知识 导致引用计数+1的情况： 对象被创建，例如a = 23 对象被引用，例如b = a 对象被作为参数，传入到一个函数中，例如f(a) 对象作为一个元素，存储在容器中，例如list1 = [a, a] 导致引用计数-1的情况： 对象的别名被显式销毁，例如del a 对象的别名被赋予新的对象，例如a = 24 一个对象离开它的作用域，例如f函数执行完毕时，f函数中的局部变量（全局变量不会） 对象所在的容器被销毁，或从容器中删除对象 引用计数可能会导致循环引用问题，而循环引用会导致内存泄露，如下面的代码所示。为了解决这个问题，Python中引入了“标记-清除”和“分代收集”。在创建一个对象的时候，对象被放在第一代中，如果在第一代的垃圾检查中对象存活了下来，该对象就会被放到第二代中，同理在第二代的垃圾检查中对象存活下来，该对象就会被放到第三代中。 1234567# 循环引用会导致内存泄露 - Python除了引用技术还引入了标记清理和分代回收# 在Python 3.6以前如果重写__del__魔术方法会导致循环引用处理失效# 如果不想造成循环引用可以使用弱引用list1 = []list2 = [] list1.append(list2)list2.append(list1) 以下情况会导致垃圾回收： 调用gc.collect() gc模块的计数器达到阀值 程序退出 面向对象的设计原则 几种设计模式 迭代器和生成器 并发编程 Python中有GIL来防止多个线程同时执行本地字节码，这个锁对于CPython是必须的，因为CPython的内存管理并不是线程安全的，因为GIL的存在多线程并不能发挥CPU的多核特性。 Python100天学习21-30 Web前端概述 资料连接 第二十一天-第三十天 HTML5 标签 CSS3语法 JavaScript语法 JQuery概述 Ajax Vue、vue-cli：渐进式框架 Element：UI框架 Echarts：报表框架 Bulma:基于弹性盒子的CSS框架 Bootstrap:响应式布局框架","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python学习笔记","slug":"Python学习笔记","permalink":"https://gladdduck.github.io/tags/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"知识图谱表示学习综述","slug":"学术-知识图谱表示学习综述,","date":"2022-12-02T02:19:08.766Z","updated":"2023-11-26T05:18:44.453Z","comments":true,"path":"2022/12/02/学术-知识图谱表示学习综述,/","link":"","permalink":"https://gladdduck.github.io/2022/12/02/%E5%AD%A6%E6%9C%AF-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0,/","excerpt":"","text":"copy from 本文分享一篇知识图谱表示学习汇报ppt，将知识图谱表示学习方法粗略分为四大类，涉及将近30篇优秀论文，只简单介绍其核心思想，完整汇报ppt获取请关注公众号(AI机器学习与知识图谱)回复关键字：知识图谱表示学习 翻译距离模型：包括TransH、TransR、TransD、TranSparse、TransM、MianfoldE、TransF、TransA、KG2E、TransG、UM、SE模型等； 语义匹配模型：包括RESCAL、DistMult、HoLE、ComplEx、ANALOGY、SNE、NTN、MLP、NAM模型等； 随机游走模型：包括DeepWalk、LINE、node2vec模型等； 子图汇聚模型：包括GCN、GAT、GraphSage模型等。 一、Motivation 知识图谱是由实体（节点）和关系（不同类型的边）组成的多关系图，每条边连接头尾两个实体，通常用SPO三元组进行表示（subject,predicate, object），被称为一个事实。虽然知识图谱在表示结构化数据方面很有效，但这类三元组的潜在符号特性通常使得KGs很难操作。 因此知识图谱表示学习便成为了一个热门的研究方向，知识图谱嵌入的关键思想是将图谱中的实体entity和关系relation转化为连续的向量，在保留KG原有结构的同时使得操作方便。于是便可将entityembedding和relationembedding用到下游各种任务中，例如图谱补全，关系抽取，实体分类，实体链接及实体融合等 知识图谱嵌入技术经典三个步骤： 知识图谱嵌入技术经典三个步骤： 1、representing entities and relations 2、defininga scoring function 3、learning entity and relation representations（最大化所有观测事实的置信度plausibility） 根据scoring function区别分为distance-based scoring functions和similarity-based scoring functions 二、翻译距离模型 基础三大模型：TransE，TransH，TransR 三大模型图 后续改进模型 后后续改进模型 高斯嵌入 小结： 三、语义匹配模型 语义匹配基本模型： 模型图 看不懂的模型 基于神经网络的匹配 模型图 小结 四、基于随机游走的模型 DeepWalk： Line： node2vec： 五、子图汇聚模型 GCN图卷积： GAT图注意力： GraphSage：","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"知识图谱表示","slug":"知识图谱表示","permalink":"https://gladdduck.github.io/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A8%E7%A4%BA/"}]},{"title":"快速傅里叶变换(FFT)求多项式乘法","slug":"笔记-快速傅里叶变换(FFT)求多项式乘法","date":"2022-11-18T03:11:17.939Z","updated":"2023-11-26T04:43:40.721Z","comments":true,"path":"2022/11/18/笔记-快速傅里叶变换(FFT)求多项式乘法/","link":"","permalink":"https://gladdduck.github.io/2022/11/18/%E7%AC%94%E8%AE%B0-%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2(FFT)%E6%B1%82%E5%A4%9A%E9%A1%B9%E5%BC%8F%E4%B9%98%E6%B3%95/","excerpt":"","text":"[toc] 推荐一篇写的很好的课件 多项式的表示与乘法 系数表示法 多项式A(x)=∑i=0naixiA(x)=\\sum_{i=0}^{n} a_ix^iA(x)=∑i=0n​ai​xi的系数表示就是 a=(a0,a1,...,an)Ta=(a_0,a_1,...,a_n)^Ta=(a0​,a1​,...,an​)T 如果用系数表示,多项式乘法的复杂度是O(n2)O(n^2)O(n2),就是和平时手算过程一样 点值表示法 n+1个不同的点能唯一确定n次多项式系数 对于多项式A(x),B(x)A(x),B(x)A(x),B(x) A(x):{(x0,y0),(x1,y1),(x2,y2),…,(xn,yn)},A(x):\\left\\{\\left(x_{0}, y_{0}\\right),\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\ldots,\\left(x_{n}, y_{n}\\right)\\right\\},A(x):{(x0​,y0​),(x1​,y1​),(x2​,y2​),…,(xn​,yn​)}, B(x):{(x0,y0′),(x1,y1′),(x2,y2′),…,(xn,yn′)}B(x):\\left\\{\\left(x_{0}, y_{0}^{\\prime}\\right),\\left(x_{1}, y_{1}^{\\prime}\\right),\\left(x_{2}, y_{2}^{\\prime}\\right), \\ldots,\\left(x_{n}, y_{n}^{\\prime}\\right)\\right\\}B(x):{(x0​,y0′​),(x1​,y1′​),(x2​,y2′​),…,(xn​,yn′​)} 设 C(x)=A(x)B(x)C(x) = A(x) B(x)C(x)=A(x)B(x),因为C(x)C(x)C(x)的系数是2n,所以要在A(x)和B(x)A(x)和B(x)A(x)和B(x)上取2n个不同的点才行,C(x)C(x)C(x)的点值表示为 {(x0,y0y0′),(x1,y1y1′),(x2,y2y2′),…,(x2n,y2ny2n′)}\\left\\{\\left(x_{0}, y_{0} y_{0}^{\\prime}\\right),\\left(x_{1}, y_{1} y_{1}^{\\prime}\\right),\\left(x_{2}, y_{2} y_{2}^{\\prime}\\right), \\ldots,\\left(x_{2 n}, y_{2 n} y_{2 n}^{\\prime}\\right)\\right\\}{(x0​,y0​y0′​),(x1​,y1​y1′​),(x2​,y2​y2′​),…,(x2n​,y2n​y2n′​)} 点值表示的多项式乘法复杂度为O(n)O(n)O(n) 系数表示法与点值表示法的转换 系数到点(也叫求值):Xa=yXa=yXa=y 因为系数矩阵行列式不为0,所以可逆. 点到系数(也叫插值):a=X−1ya=X^{-1}ya=X−1y 单位复数根 n次单位复数根满足wn=1w^n=1wn=1,n次单位复数根敲好有n个 复杂证明略过,n次单位根的所有根,作为计算点值的xxx 离散傅里叶变换 对于 n 次多项式 A(x)=∑i=0naixiA(x)=\\sum_{i=0}^{n} a_{i} x^{i}A(x)=∑i=0n​ai​xi , 其系数形式为 a=(a0,a1,…,an)Ta=\\left(a_{0}, a_{1}, \\ldots, a_{n}\\right)^{T}a=(a0​,a1​,…,an​)T . 设 $ y_{k}=A\\left(\\omega_{n}{k}\\right)=\\sum_{i=0}{n} a_{i} \\omega_{n+1}^{k i}, 0 \\leq k \\leq n, k \\in N $, 则向量 $ y=\\left(y_{0}, y_{1}, \\ldots, y_{n}\\right)^{T} $ 就是系数向量 $ a=\\left(a_{0}, a_{1}, \\ldots, a_{n}\\right)^{T} $ 的离散傅里叶变换. 但是离散傅里叶变换的复杂度仍是O(n2)O(n^2)O(n2) 快速傅里叶变换(FFT) FFT 将A(x)A(x)A(x)拆分为奇数下标与偶数下标的系数 A[0](x)=a0+a2x+a4x2+⋯+an−1xn−12,A^{[0]}(x)=a_{0}+a_{2} x+a_{4} x^{2}+\\cdots+a_{n-1} x^{\\frac{n-1}{2}},A[0](x)=a0​+a2​x+a4​x2+⋯+an−1​x2n−1​, A[1](x)=a1+a3x+a5x2+⋯+anxn−12.A^{[1]}(x)=a_{1}+a_{3} x+a_{5} x^{2}+\\cdots+a_{n} x^{\\frac{n-1}{2}} .A[1](x)=a1​+a3​x+a5​x2+⋯+an​x2n−1​. A[0](x)A^{[0]}(x)A[0](x) 包含 A 所有偶数下标的系数, $ A^{[1]}(x)$ 数下标的系数, 于是有: A(x)=A[0](x2)+xA[1](x2).A(x)=A^{[0]}\\left(x^{2}\\right)+x A^{[1]}\\left(x^{2}\\right) .A(x)=A[0](x2)+xA[1](x2). 所以, 求 $ A(x)$ 在 ωn+10,ωn+11,…,ωn+1n\\omega_{n+1}^{0}, \\omega_{n+1}^{1}, \\ldots, \\omega_{n+1}^{n}ωn+10​,ωn+11​,…,ωn+1n​ 处的值的问题转化为: a. 求次数为 $ \\frac{n}{2}$ 的多项式 $ A^{[0]}(x), A^{[1]}(x) $ 在点 (ωn+10)2,(ωn+11)2,…,(ωn+1n)2\\left(\\omega_{n+1}^{0}\\right)^{2},\\left(\\omega_{n+1}^{1}\\right)^{2}, \\ldots,\\left(\\omega_{n+1}^{n}\\right)^{2}(ωn+10​)2,(ωn+11​)2,…,(ωn+1n​)2 处的取值. 递归即可得到结果. 复杂度 T(n)=2T(n2)+Θ(n)T(n)=2 T\\left(\\frac{n}{2}\\right)+\\Theta(n)T(n)=2T(2n​)+Θ(n) 然后进行点值乘法,得到点值的结果,再利用逆变换为系数表达. 具体流程 加倍多项式次数 通过加入 nnn 个系数为 0 的高阶项, 把多项式 $ A(x) 和 B(x)$ 变为次数为 2n2 n2n 的 多项式, 并构造其系数表达. 求值 通过应用 $ 2(n+1) $ 阶的 $FFT $计算出 $A(x) 和 B(x) $ 长度为 $ 2(n+1) $ 的点值表达. 这些点值表达中包含了两个多项式在 $ 2(n+1) $ 次单位根处的取值. 逐点相乘 把 $A(x) 的值与 B(x) $的值逐点相乘, 可以计算出 $C(x)=A(x) B(x) $ 的点值表 达, 这个表示中包含了 $ C(x) 在每个 2(n+1) $ 次单位根处的值. 揷值 通过对 $2(n+1) $ 个点值应用 FFT, 计算其逆 DFT, 就可以构造出多项式C(x)C(x)C(x)的系数表达 由于 $ 1 、 3 $ 的时间复杂度为 $ \\Theta(n)$, $2 、 4 $ 的时间复杂度为 Θ(nlog⁡2n)\\Theta\\left(n \\log _{2} n\\right)Θ(nlog2​n) , 因此整个算法的时间复杂度为 $ \\Theta\\left(n \\log _{2} n\\right)$ . python 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132import math# 定义ΠPI = 3.1415926# 定义复数class complex: def __init__(self,real=0,virtual=0) -&gt; None: self.real=real self.virtual=virtual def __str__(self) -&gt; str: return f&#x27;real:&#123;self.real&#125; virtual:&#123;self.virtual&#125;\\n&#x27; # 复数的乘法加法减法def complex_mut(a,b): ret=complex() ret.real = a.real * b.real - a.virtual * b.virtual ret.virtual = a.real * b.virtual + a.virtual * b.real return ret def complex_add(a,b): ret=complex() ret.real = a.real + b.real ret.virtual = a.virtual + b.virtual return retdef complex_sub(a,b): ret=complex() ret.real = a.real - b.real ret.virtual = a.virtual - b.virtual return ret # 获取i次n复根def get_w(n,k,inverse): w=complex() # 根据欧拉函数获得w accy=round(PI*2*k/n,6) # 逆傅里叶变换sin前面要有- if inverse: w.real=round(math.cos(accy),6) w.virtual=round(-math.sin(accy),6) else: w.real=round(math.cos(accy),6) w.virtual=round(math.sin(accy),6) return w# 快速傅里叶变换def FFT(coefficient,n,inverse): # 如果n==1了直接返回系数 if n==1: return coefficient # 用于存放奇偶次项 odd,even=[],[] for index in range(n): if index&amp;1: odd.append(coefficient[index]) else: even.append(coefficient[index]) # 对奇偶次项分别计算快速傅里叶变换 e_k=FFT(even,n//2,inverse) d_k=FFT(odd,n//2,inverse) # 计算第k个点和第k+n//2个点的y坐标 y_k,y_k_2=[],[] for i in range(n//2): w=get_w(n,i,inverse) y_k.append(complex_add(e_k[i],complex_mut(w,d_k[i]))) y_k_2.append(complex_sub(e_k[i],complex_mut(w,d_k[i]))) # 返回n个点的y坐标 return y_k+y_k_2 def polynomial_mul(coefficient_a,coefficient_b): # 本来是坐标代表高位 # 现在反过来,左边代表地位,索引就是x的项数 coefficient_a=coefficient_a[::-1] coefficient_b=coefficient_b[::-1] # 计算乘积的最高次项是多少 length=len(coefficient_a)-1+len(coefficient_b)-1 # 取乘积的此项大的 2的n次方 方便后面FFT计算 digitnum = 1 while length&gt;0: length&gt;&gt;=1 digitnum+=1 length = 1 while digitnum&gt;0: length&lt;&lt;=1 digitnum-=1 # 把系数变为复数,方便后面和n复根计算 a,b=[complex() for _ in range(length+1)],[complex() for _ in range(length+1)] for index,item in enumerate(coefficient_a): a[index].real=item for index,item in enumerate(coefficient_b): b[index].real=item # 对系数a,b进行快速傅里叶变换 FFT_a=FFT(a,length,inverse=False) FFT_b=FFT(b,length,inverse=False) c=[] # 对变换得到的y坐标进行点值乘法 for index in range(length): c.append(complex_mut(FFT_a[index],FFT_b[index])) # 对c进行逆傅里叶变换 FFT_c=FFT(c,length,inverse=True) # 取c的实部才是结果 ans=[] for item in FFT_c: # 控制精度,因为float计算会有误差 if item.real/length&gt;0.05 or item.real/length&lt;-0.05: # 小数点后保留2位 # 得到的结果还需要除以n ans.append(round(item.real/length,2)) else: ans.append(0) return ans# (x2+x+1)^2# x4+x3+x2+x3+x2+x+x2+x+1# x4+2*x3+3*x2+2*x+1# 0 0 0 1 2 3 2 1if __name__==&#x27;__main__&#x27;: # 左边代表高次项,右边代表低次项 a=[0,3,2] b=[2,1,1] # O(nlogn)的多项式乘法 c=polynomial_mul(a,b) # 打印 astr=&#x27; + &#x27;.join([f&#x27;&#123;item&#125;*x^&#123;index&#125; &#x27; for index,item in enumerate(a[::-1])][::-1]) bstr=&#x27; + &#x27;.join([f&#x27;&#123;item&#125;*x^&#123;index&#125; &#x27; for index,item in enumerate(b[::-1])][::-1]) print(f&quot; &#123;astr&#125;&quot;) print(f&quot;* &#123;bstr&#125;&quot;) cstr=&#x27; + &#x27;.join([f&#x27;&#123;item&#125;*x^&#123;index&#125; &#x27; for index,item in enumerate(c) if item !=0 ][::-1] ) print(f&quot;= &#123;cstr&#125;&quot;) C++代码 来自知乎 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;iomanip&gt;#include&lt;math.h&gt;using namespace std;const double PI = 3.1415926;struct _complex&#123; double x; double y;&#125;;//手动封装的复数结构体，x为实部，y为虚部_complex a[4096], b[4096];//用于存储两个多项式的系数bool is_output[4096];//后面会用到的用于判断是否输出的一串变量_complex omega(const int&amp; n, const int&amp; k,bool inverse)&#123; _complex r; if (!inverse) &#123; r.x = cos(PI * 2 * k / n); r.y = sin(PI * 2 * k / n); &#125; else &#123; r.x = cos(PI * 2 * k / n); r.y = -sin(PI * 2 * k / n); &#125; return r;&#125;//用于插复根inline _complex operator*(_complex a, _complex b)&#123; _complex r; r.x = a.x * b.x - a.y * b.y; r.y = a.x * b.y + a.y * b.x; return r;&#125;inline _complex operator+(_complex a, _complex b)&#123; _complex r; r.x = a.x + b.x; r.y = a.y + b.y; return r;&#125;inline _complex operator-(_complex a, _complex b)&#123; _complex r; r.x = a.x - b.x; r.y = a.y - b.y; return r;&#125;//因为没有用到除法，这里我就没有重载除的函数void Real_DFT(_complex* a, bool inverse, int anum)//这个inverse表示是否为反变换，false为否，true表示是&#123; if (anum == 1) return; vector&lt;_complex&gt; buf1, buf2;//buf1和buf2为两个缓冲数组，用于暂存变换中各项系数 for (int i = 0; i &lt; anum ; i++) &#123; if (i &amp; 1) &#123; buf2.push_back(a[i]);//奇数项 &#125; else &#123; buf1.push_back(a[i]);//偶数项 &#125; &#125; for (int i = 0; i &lt; anum / 2; i++) &#123; a[i] = buf1[i]; a[i + anum / 2] = buf2[i]; &#125;//拆分排序后重新赋值回a，为下一步排序准备 Real_DFT(a, inverse, anum / 2); Real_DFT(a + anum / 2, inverse, anum / 2);//奇偶数项拆开后迭代继续拆分 int armlength = anum / 2; for (int i = 0; i &lt; armlength; i++) &#123; _complex t = omega(anum, i, inverse); buf1[i] = a[i] + t * a[i + anum / 2];//低次复根走这边插 buf2[i] = a[i] - t * a[i + anum / 2];//高次复根走这边插 &#125;//这里继续用到了buf数组只是为了暂存，没有别的意思 for (int i = 0; i &lt; anum / 2; i++) &#123; a[i] = buf1[i]; a[i + anum / 2] = buf2[i]; &#125;//重新赋值回去 return;&#125;int main()&#123;//inport data int numa = 0, numb = 0;//numa是a多项式的项数，numb同理 cin &gt;&gt; numa; int ptr0 = 0, maxa = 0, sum = 0, ptr1 = 0,maxb=0;//maxa存储a多项式中的最高次幂，maxb同理 for (int i = 0; i&lt;numa; i++) &#123; int id = 0; cin &gt;&gt; id; maxa = maxa &gt; id ? maxa : id; cin &gt;&gt; a[id].x; &#125; cin &gt;&gt; numb; for (int i = 0; i &lt; numb; i++) &#123; int id = 0; cin &gt;&gt; id; maxb = maxb &gt; id ? maxb : id; cin &gt;&gt; b[id].x; &#125; sum = maxa + maxb;//decide complete num int digitnum = 1; for (; sum &gt; 0; sum &gt;&gt;= 1, digitnum++); sum = 1; for (; digitnum &gt; 0; sum &lt;&lt;= 1, digitnum--);//由于傅里叶变换要求插值数为2的整数次幂//这里首先确定多项式相乘后最多的项数也就是sum然后找到第一个比sum大的2的整数次幂的数，将sum重置为这个2的整数次幂//Fast Fourier Transform Real_DFT(a, false, sum); Real_DFT(b, false, sum); for (int i = 0; i &lt; sum; i++) a[i] = a[i] * b[i];//这一步就是上文没有细讲的点值表达式相乘，还是挺好搞的 Real_DFT(a, true, sum);//export data int num=0; for (int i = 0; i &lt;= sum; i++) &#123; if (a[i].x / sum &gt; 0.05||a[i].x/sum&lt;-0.05)//遍历得到的结果，如果这个数的绝对值大于0.05（题目要求的0.1精度，根据四舍五入原则判断），则准备输出 &#123; num++; is_output[i] = 1; &#125; &#125; cout &lt;&lt; num; for (int i = sum; i &gt;=0; i--) &#123; if(is_output[i]==1) cout &lt;&lt; &quot; &quot; &lt;&lt;i&lt;&lt;&quot; &quot;&lt;&lt; std::fixed &lt;&lt; setprecision(1) &lt;&lt; (a[i].x / sum); &#125; return 0;&#125;输入2 1 2.4 0 3.22 2 1.5 1 0.5输出3 3 3.6 2 6.0 1 1.6","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"快速傅里叶变换","slug":"快速傅里叶变换","permalink":"https://gladdduck.github.io/tags/%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"}]},{"title":"Linux的一些常用命令记录","slug":"实习-Linux常用命令","date":"2022-11-17T09:35:08.623Z","updated":"2024-03-13T13:14:19.223Z","comments":true,"path":"2022/11/17/实习-Linux常用命令/","link":"","permalink":"https://gladdduck.github.io/2022/11/17/%E5%AE%9E%E4%B9%A0-Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334# 查看cpu型号cat /proc/cpuinfo | grep &#x27;model name&#x27;# 查看系统uname -a# 查看显卡lshw -C display# 如果显卡是Nvidianvidia-smi# 后台运行程序nohup ***** &amp; # 查看所有进程ps -aux# 根据进程号杀死进程kill -9 进程号# 远程复制文件scp -r 路径 用户名@ip:路径# 远程同步文件rsync -avz 路径 用户名@ip:路径# 修改文件权限# 第一个数字（7）表示所有者（Owner）的权限，即文件的所有者可以读（4）、写（2）、执行（1）。# 第二个数字（7）表示与文件所有者同组的用户的权限，同组用户也可以读（4）、写（2）、执行（1）。# 第三个数字（7）表示其他用户的权限，即除了文件所有者和同组用户之外的所有用户的权限，也可以读（4）、写（2）、执行（1）。# 因此，chmod 777允许所有用户都拥有对该文件的读、写和执行权限。chmod 777 文件名","categories":[{"name":"快捷命令","slug":"快捷命令","permalink":"https://gladdduck.github.io/categories/%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"Linux快捷命令","slug":"Linux快捷命令","permalink":"https://gladdduck.github.io/tags/Linux%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}]},{"title":"多个排序算法复杂度","slug":"算法-排序复杂度","date":"2022-11-12T13:53:00.287Z","updated":"2023-11-26T04:45:12.730Z","comments":true,"path":"2022/11/12/算法-排序复杂度/","link":"","permalink":"https://gladdduck.github.io/2022/11/12/%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%E5%A4%8D%E6%9D%82%E5%BA%A6/","excerpt":"","text":"算法 稳定性 空间复杂度 时间复杂度 分类 插入排序 ★稳定 O(1)O(1)O(1) $O(n^2) $ 插入类 希尔排序 不稳定 O(1)O(1)O(1) $O(n{1.3}-n2) $ 插入类 冒泡排序 ★稳定 O(1)O(1)O(1) O(n2)O(n^2)O(n2) 交换类 快速排序 不稳定 O(log2(n))O(log_2(n))O(log2​(n)) O(nlog2(n)−n2)O(nlog_2(n)-n^2)O(nlog2​(n)−n2) 交换类 选择排序 不稳定 O(1)O(1)O(1) O(n2)O(n^2)O(n2) 选择类 堆排序 不稳定 O(1)O(1)O(1) O(nlog2(n))O(nlog_2(n))O(nlog2​(n)) 选择类 堆排序 建堆 O(n)O(n)O(n) 调整 O(log2(n))O(log_2(n))O(log2​(n)) 归并排序 ★稳定 O(n)O(n)O(n) O(nlog2(n))O(nlog_2(n))O(nlog2​(n)) 基数排序 ★稳定 O(r)O(r)O(r) O(d(n+r))O(d(n+r))O(d(n+r)) 12后面慢慢补充每个算法的代码","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://gladdduck.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"git Time out error解决","slug":"配置-githuberror处理","date":"2022-11-09T11:06:17.746Z","updated":"2023-11-26T05:21:03.870Z","comments":true,"path":"2022/11/09/配置-githuberror处理/","link":"","permalink":"https://gladdduck.github.io/2022/11/09/%E9%85%8D%E7%BD%AE-githuberror%E5%A4%84%E7%90%86/","excerpt":"","text":"错误信息: 1234567891011fatal: unable to access &#x27;https://github.com/gladdduck/gladdduck.github.io.git/&#x27;:Failed to connect to github.com port 443 after 21048 ms: Timed outFATAL &#123; err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (D:\\BaiduSyncdisk\\Blog\\node_modules\\hexo-util\\lib\\spawn.js:51:21) at ChildProcess.emit (node:events:513:28) at ChildProcess.cp.emit (D:\\BaiduSyncdisk\\Blog\\node_modules\\cross-spawn\\lib\\enoent.js:34:29) at Process.ChildProcess._handle.onexit (node:internal/child_process:293:12) &#123; code: 128 &#125;&#125; Something&#x27;s wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html 解决: git中输入 123git config --global --unset http.proxy git config --global --unset https.proxy cmd 中输入 1ipconfig /flushdns 刷新 dns缓存 然后再执行相应命令. 成功","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"git Time out","slug":"git-Time-out","permalink":"https://gladdduck.github.io/tags/git-Time-out/"}]},{"title":"详解PyTorch中加载数据的方法--Dataset、Dataloader、Sampler、collate-fn","slug":"笔记-Pytorch数据集加载","date":"2022-11-09T10:38:42.428Z","updated":"2022-11-09T11:28:39.538Z","comments":true,"path":"2022/11/09/笔记-Pytorch数据集加载/","link":"","permalink":"https://gladdduck.github.io/2022/11/09/%E7%AC%94%E8%AE%B0-Pytorch%E6%95%B0%E6%8D%AE%E9%9B%86%E5%8A%A0%E8%BD%BD/","excerpt":"","text":"转载 作者pytorch其他笔记 数据读取是所有训练模型任务中最基础最重要的一步，PyTorch为数据集的读取、加载和使用提供了很好的机制，使得数据加载的工作变得异常简单而且具有非常高的定制性。 Dataset、Dataloader、Sampler的关系 PyTorch中对于数据集的处理有三个非常重要的类：Dataset、Dataloader、Sampler，它们均是 torch.utils.data 包下的模块（类）。它们的关系可以这样理解： Dataset是数据集的类，主要用于定义数据集 Sampler是采样器的类，用于定义从数据集中选出数据的规则，比如是随机取数据还是按照顺序取等等 Dataloader是数据的加载类，它是对于 Dataset和 Sampler的进一步包装，即其实 Dataset和 Sampler会作为参数传递给 Dataloader，用于实际读取数据，可以理解为它是这个工作的真正实践者，而 Dataset和 Sampler则负责定义。我们训练、测试所获得的数据也是 Dataloader直接给我们的。 总的来说，Dataset定义了整个数据集，Sampler提供了取数据的机制，最后由 Dataloader取完成取数据的任务。 本篇以一个最简单的例子为例，比如有一个文件夹（data-folder）中存储训练的数据（一共30张图片：0.png 到 29.png），他们对应的标签被写在了一个 labels.txt文件中，第n行对应n-1.png的标签，是一个三分类问题，即0、1和2三种标签（虚构的数据集，不具有任何意义）。目录结构如下： 12345678|--- Project |--- main.py |--- labels.txt |--- data-folder |--- 0.png |--- 1.png |--- …… |--- 29.png Dataset Dataset 位于 torch.utils.data 下，我们通过定义继承自这个类的子类来自定义数据集。它有两个最重要的方法需要重写，实际上它们都是类的特殊方法： __getitem__(self, index)：传入参数 index为下标，返回数据集中对应下标的数据组（数据和标签） __len__(self)：返回数据集的大小 简单说，重写了这两个方法的继承自 Dataset 的类都可以作为数据集的定义类使用，即一个 Dataset类的必要结构： 123456789class Dataset(torch.utils.data.Dataset): def __init__(self, filepath=None,dataLen=None): pass def __getitem__(self, index): pass def __len__(self): pass 如下就是我们的例子的加载实例，其中的 image2tensor 使用了 torchvision.transforms 完成了一个简单的从 PIL.Image 格式的图片到 tensor 的转换，可以先不必在意，后面会详细地讲到 transforms 这个超级重要的工具： 12345678910111213141516171819202122232425262728293031323334353637from torch.utils.data import Datasetfrom PIL import Imageimport osfrom torchvision import transformsclass MyDataset(Dataset): def __init__(self, images_folder_path, labels_file_path): self.images_folder_path = images_folder_path with open(labels_file_path, &#x27;r&#x27;) as file: self.labels = list(map(int, file.read().splitlines())) def __getitem__(self, item): image = Image.open(os.path.join(self.images_folder_path, &quot;&#123;&#125;.png&quot;.format(item))) image = self.image2tensor(image) label = self.labels[item] return (image, label) def __len__(self): return len(self.labels) def image2tensor(self, image): &quot;&quot;&quot; transform PIL.Image to tensor :param image: image in PIL.Image format :return: image in tensor format &quot;&quot;&quot; transform = transforms.Compose([ transforms.ToTensor() ]) image = image.convert(&#x27;RGB&#x27;) return transform(image)myDataset = MyDataset(&quot;./data-folder/&quot;, &quot;./labels.txt&quot;) Dataloader Dataloader对 Dataset（和 Sampler等）打包，完成最后对数据的读取的执行工作，一般不需要自己定义或者重写一个 Dataloader的类（或子类），直接使用即可，通过传入参数定制 Dataloader，定制化的功能应该在 Dataset（和 Sampler等）中完成了。 Dataloader的完整签名： https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader Dataloader的一些常用参数 Dataloader的一些重要的参数如下，除了第一个 dataset参数外，其他均为可选参数： dataset（第一个参数，必须的参数）：一个 Dataset的实例，即传入的数据集（或者其他可迭代对象） batch_size：整数值，每个 batch的样本数量，即 batch大小，默认为1 shuffle：bool值，如果设置为 True，则在每个 epoch开始的时候，会对数据集的数据进行重新排序，默认 False sampler：传入一个自定义的 Sampler实例，定义从数据集中取样本的策略，Sampler每次返回一个索引，默认为 None batch_sampler：也是传入一个自定义的 Sampler实例，但是与 sampler参数不同的是，它接收的 Sampler是一次返回一个 batch的索引，默认为 None num_workers：整数值，定义有几个进程来处理数据。0意味着所有的数据都会被加载进主进程，默认0 collate_fn：传入一个函数，它的作用是将一个 batch的样本打包成一个大的 tensor，tensor的第一维就是这些样本，如果没有特殊需求可以保持默认即可（后边会详细介绍） pin_memory：bool值，如果为 True，那么将加载的数据拷贝到 CUDA中的固定内存中。 drop_last：bool值，如果为 True，则对最后的一个 batch来说，如果不足 batch_size个样本了就舍弃，如果为 False，也会继续正常执行，只是最后的一个 batch可能会小一点（剩多少算多少），默认 False timeout：如果是正数，表明等待从加载一个 batch等待的时间，若超出设定的时间还没有加载完，就放弃这个 batch，如果是0，表示不设置限制时间。默认为0 Dataloader参数之间的互斥 值得注意的是，Dataloader的参数之间存在互斥的情况，主要针对自己定义的采样器： sampler：如果自行指定了 sampler参数，则 shuffle必须保持默认值，即 False batch_sampler：如果自行指定了 batch_sampler参数，则 batch_size、shuffle、sampler、drop_last 都必须保持默认值 如果没有指定自己是采样器，那么默认的情况下（即 sampler和 batch_sampler均为 None的情况下），Dataloader的采样策略是如何的呢： sampler： shuffle = True：sampler采用 RandomSampler，即随机采样 shuffle = Flase：sampler采用 SequentialSampler，即按照顺序采样 batch_sampler：采用 BatchSampler，即根据 batch_size 进行 batch采样 上面提到的 RandomSampler、SequentialSampler和 BatchSampler都是 PyTorch自己实现的，且它们都是 Sampler的子类，后边会详述。 Dataloader的实例 下面我们继续我们的例子，定义 Dataloader的实例，从我们定义的 myDataset 数据集中加载数据，每一个 batch大小为8。并且我们使用了一个循环来验证其工作的情况： 12345678910from torch.utils.data import DataLoadermyDataloader = DataLoader(myDataset, batch_size=8)for epoch in range(2): for data in myDataloader: images, labels = data[0], data[1] print(len(images)) print(labels) # train your module 123456789101112131415168tensor([0, 1, 1, 1, 2, 0, 1, 2])8tensor([0, 2, 1, 1, 1, 1, 2, 0])8tensor([1, 0, 0, 0, 0, 1, 1, 0])6tensor([2, 0, 1, 1, 1, 2])8tensor([0, 1, 1, 1, 2, 0, 1, 2])8tensor([0, 2, 1, 1, 1, 1, 2, 0])8tensor([1, 0, 0, 0, 0, 1, 1, 0])6tensor([2, 0, 1, 1, 1, 2]) Sampler Sampler类是一个很抽象的父类，其主要用于设置从一个序列中返回样本的规则，即采样的规则。Sampler是一个可迭代对象，使用 step方法可以返回下一个迭代后的结果，因此其主要的类方法就是 __iter__ 方法，定义了迭代后返回的内容。其父类的代码如下（PyTorch 1.7）： 1234567class Sampler(Generic[T_co]): def __init__(self, data_source: Optional[Sized]) -&gt; None: pass def __iter__(self) -&gt; Iterator[T_co]: raise NotImplementedError 从上述代码可见，其实 Sampler父类并没有给出 __iter__ 的具体定义，因此，如果我们要定义自己的采样器，就要编写继承自 Sampler的子类，并且重写 __iter__ 方法给出迭代返回样本的逻辑。 但是，正如上文提到的，Dataloader中的 sampler和 batch_sampler参数默认情况下使用的那些采样器（RandomSampler、SequentialSampler和 BatchSampler）一样，PyTorch自己实现了很多 Sampler的子类，这些采样器其实可以完成大部分功能，所以本节主要关注一些 Sampler的子类以及他们的用法，而不过多地讨论如何自己实现一个 Sampler。 SequentialSampler SequentialSampler就是一个按照顺序进行采样的采样器，接收一个数据集做参数（实际上任何可迭代对象都可），按照顺序对其进行采样： 1234567from torch.utils.data import SequentialSamplerpseudo_dataset = list(range(10))for data in SequentialSampler(pseudo_dataset): print(data, end=&quot; &quot;)0 1 2 3 4 5 6 7 8 9 RandmSampler RandomSampler 即一个随机采样器，返回随机采样的值，第一个参数依然是一个数据集（或可迭代对象）。还有一组参数如下： replacement：bool值，默认是 False，设置为 True时表示可以采出重复的样本 num_samples：只有在 replacement设置为 True的时候才能设置此参数，表示要采出样本的个数，默认为数据集的总长度。有时候由于 replacement置 True的原因导致重复数据被采样，导致有些数据被采不到，所以往往会设置一个比较大的值 1234567891011121314151617181920from torch.utils.data import RandomSamplerpseudo_dataset = list(range(10))randomSampler1 = RandomSampler(pseudo_dataset)randomSampler2 = RandomSampler(pseudo_dataset, replacement=True, num_samples=20)print(&quot;for random sampler #1: &quot;)for data in randomSampler1: print(data, end=&quot; &quot;)print(&quot;\\n\\nfor random sampler #2: &quot;)for data in randomSampler2: print(data, end=&quot; &quot;)for random sampler #1: 4 5 2 9 3 0 6 8 7 1 for random sampler #2: 4 9 0 6 9 3 1 6 1 8 5 0 2 7 2 8 6 4 0 6 SubsetRandomSampler SubsetRandomSampler 可以设置子集的随机采样，多用于将数据集分成多个集合，比如训练集和验证集的时候使用： 12345678910111213141516171819from torch.utils.data import SubsetRandomSamplerpseudo_dataset = list(range(10))subRandomSampler1 = SubsetRandomSampler(pseudo_dataset[:7])subRandomSampler2 = SubsetRandomSampler(pseudo_dataset[7:])print(&quot;for subset random sampler #1: &quot;)for data in subRandomSampler1: print(data, end=&quot; &quot;)print(&quot;\\n\\nfor subset random sampler #2: &quot;)for data in subRandomSampler2: print(data, end=&quot; &quot;)for subset random sampler #1: 0 4 6 5 3 2 1 for subset random sampler #2: 7 8 9 WeightedRandomSampler WeightedRandomSampler和 RandomSampler的参数一致，但是不在传入一个 dataset，第一个参数变成了 weights，只接收一个一定长度的 list作为 weights 参数，表示采样的权重，采样时会根据权重随机从 list(range(len(weights))) 中采样，即 WeightedRandomSampler并不需要传入样本集，而是只在一个根据 weights长度创建的数组中采样，所以采样的结果可能需要进一步处理才能使用。weights的所有元素之和不需要为1。 12345678910from torch.utils.data import WeightedRandomSamplerpseudo_dataset = list(range(10))weights = [1,1,1,1,1,10,10,10,10,10]weightedRandomSampler = WeightedRandomSampler(weights, replacement=True, num_samples=20)for data in weightedRandomSampler: print(data, end=&quot; &quot;)7 8 7 7 9 7 8 9 8 7 5 5 9 9 6 5 8 9 6 5 BatchSampler 以上的四个 Sampler在每次迭代都只返回一个索引，而 BatchSampler的作用是对上述这类返回一个索引的采样器进行包装，按照设定的 batch_size返回一组索引，因其他的参数和上述的有些不同： sampler：一个 Sampler对象（或者一个可迭代对象） batch_size：batch的大小 drop_last：是否丢弃最后一个可能不足 batch_size大小的数据 123456789101112131415161718from torch.utils.data import BatchSamplerpseudo_dataset = list(range(10))batchSampler1 = BatchSampler(pseudo_dataset, batch_size=3, drop_last=False)batchSampler2 = BatchSampler(pseudo_dataset, batch_size=3, drop_last=True)print(&quot;for batch sampler #1: &quot;)for data in batchSampler1: print(data, end=&quot; &quot;)print(&quot;\\n\\nfor batch sampler #2: &quot;)for data in batchSampler2: print(data, end=&quot; &quot;)for batch sampler #1: [0, 1, 2] [3, 4, 5] [6, 7, 8] [9] for batch sampler #2: [0, 1, 2] [3, 4, 5] [6, 7, 8] collate_fn Dataloader其实还有一个比较重要的参数是 collate_fn，它接收一个 callable对象，比如一个函数，它的作用是将每次迭代出来的数据打包成 batch。 举个例子，如果我们在 Dataloader中设置了 batch_size为8，实际上，从 Dataloader所读取的数据集Dataset中取出数据时得到的是单独的数据，比如我们的例子中，每次采样得到一个 tuple：(image, label)，因此 collate_fn 的作用就有了，它负责包装 batch，即每从数据集中抽出8个这样的 tuple，它负责把8个 (image, label)包装成一个 list: [images, labels]，这个 list有两个元素，每一个是一个 tensor，比如第一个元素，实际上是一个 8×size(image) 的tensor，即给原来的数据增加了一维，也就是最前边的 batch的维度，labels也同理。 有时候我们可能会需要实现自己的包装逻辑，所以需要自定义一个函数来完成定制化的如上的内容，只要将该函数名传递给 collate_fn参数即可。 PyTorch集成的数据集 实际上，PyTorch提供了很多常用数据集的接口，如果使用这些数据集的话，可以直接使用对应的包加载，会方便很多，比如： torchvision.datasets 就提供了很多视觉方向的数据集：https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=torchvision datasets torchtext 则提供了很多文本处理方向的数据集 torchaudio 提供了很多音频处理方向的数据集 当然 PyTorch也可以配合其他包来获得数据以及对数据进行处理，比如： 对于视觉方面，配合 Pillow、OpenCV等 对于音频处理方面，配合 scipy、librosa等 对于文本处理方面，配合 Cython、NLTK、SpaCy等","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Dataset","slug":"Dataset","permalink":"https://gladdduck.github.io/tags/Dataset/"},{"name":"Dataloader","slug":"Dataloader","permalink":"https://gladdduck.github.io/tags/Dataloader/"},{"name":"Sampler","slug":"Sampler","permalink":"https://gladdduck.github.io/tags/Sampler/"},{"name":"collate_fn","slug":"collate-fn","permalink":"https://gladdduck.github.io/tags/collate-fn/"}]},{"title":"Cypher语言学习笔记","slug":"笔记-cypther学习笔记","date":"2022-11-05T09:16:38.119Z","updated":"2023-11-26T05:20:22.661Z","comments":true,"path":"2022/11/05/笔记-cypther学习笔记/","link":"","permalink":"https://gladdduck.github.io/2022/11/05/%E7%AC%94%E8%AE%B0-cypther%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1# CQL:C-ypher Q-uery L-nguage 123# 中文:http://neo4j.com.cn/public/cypher/default.html# ★英文:https://neo4j.com/docs/cypher-manual/current/introduction/# 中文:https://www.w3cschool.cn/neo4j/ 表达式 123456789%%cypherMATCH (n:Person)RETURNCASE WHEN n.born&gt;1980 THEN 1 WHEN n.born&lt;1980 THEN 2 ELSE 3END AS resultlimit 5 [&#123;'result': 2&#125;, &#123;'result': 2&#125;, &#123;'result': 2&#125;, &#123;'result': 2&#125;, &#123;'result': 2&#125;] list 123%%cypherRETURN range(0, 10)[0..-5]//[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]左闭右开 [&#123;'range(0, 10)': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&#125;] 12%%cypherRETURN [x IN range(0,10) WHERE x % 2 = 0 ] AS result 12%%cypherRETURN [x IN range(0,10) | x^3 ] AS result 123%%cypherMATCH (a:Person &#123;name: &#x27;Keanu Reeves&#x27;&#125;)RETURN [(a)--&gt;(b:Movie) WHERE b.title CONTAINS &#x27;Matrix&#x27; | b.released] AS years [&#123;'years': [1999, 2003, 2003]&#125;] 123456%%cypherMATCH (a:Person &#123;name: &#x27;Keanu Reeves&#x27;&#125;)WITH [(a)--&gt;(b:Movie) | b.released] AS yearsUNWIND years AS yearWITH year ORDER BY yearRETURN COLLECT(year) AS sorted_years [&#123;'sorted_years': [1995, 1997, 1999, 2000, 2003, 2003, 2003]&#125;] map 12345%%cypherMATCH (actor:Person)-[:ACTED_IN]-&gt;(movie:Movie)WITH actor, count(movie) AS nbrOfMoviesRETURN actor&#123;.name, nbrOfMovies&#125;limit 5 [&#123;'actor': &#123;'nbrOfMovies': 1, 'name': 'Emil Eifrem'&#125;&#125;, &#123;'actor': &#123;'nbrOfMovies': 7, 'name': 'Keanu Reeves'&#125;&#125;, &#123;'actor': &#123;'nbrOfMovies': 3, 'name': 'Laurence Fishburne'&#125;&#125;, &#123;'actor': &#123;'nbrOfMovies': 5, 'name': 'Hugo Weaving'&#125;&#125;, &#123;'actor': &#123;'nbrOfMovies': 3, 'name': 'Carrie-Anne Moss'&#125;&#125;] null 基础语法 官网 命令 作用 CREATE 创建节点\\关系\\属性 MATCH 检索节点\\关系\\属性 RETURN 返回查询结果 WHERE 提供过滤条件 DELETE 删除节点\\关系 REMOVE 删除节点\\关系的属性\\标签 ORDER BY 排序检索数据 SET 添加或更新标签 12%load_ext icypher%cypher http://neo4j:111222@localhost:7474/db/data CREATE 创建没有属性的节点 使用属性创建节点 在没有属性的节点之间创建关系 使用属性创建节点之间的关系 为节点或关系创建单个或多个标签 123%%cypherCREATE (dept:Dept &#123; deptno:10,dname:&#x27;Accounting&#x27;,location:&#x27;苏州&#x27;,isperson:true &#125;)//一个节点多个属性一个标签 [] 123%%cyphercreate (m:MOVIE:Cinema:Film:Picture&#123;labels:true&#125;)//一个节点多个标签 [] 1234%%cyphermatch (n:MOVIE:Cinema)return n//区分大小写 [&#123;'n': Node('Cinema', 'Film', 'MOVIE', 'Picture')&#125;, &#123;'n': Node('Cinema', 'Film', 'MOVIE', 'Picture', labels=True)&#125;] 12345678910111213# 配合json使用# &#123;# &#x27;props&#x27; : [ &#123;# &#x27;name&#x27; : &#x27;Andy&#x27;,# &#x27;position&#x27; : &#x27;Developer&#x27;# &#125;, &#123;# &#x27;name&#x27; : &#x27;Michael&#x27;,# &#x27;position&#x27; : &#x27;Developer&#x27;# &#125; ]# &#125;# UNWIND $props AS map# CREATE (n)# SET n = map MATCH 从数据库获取有关节点和属性的数据 从数据库获取有关节点，关系和属性的数据 需要和别的语句搭配使用 123%%cypherMATCH (p:Dept &#123;location:&#x27;苏州&#x27;&#125;) RETURN p.location//这是注释 不能放上面 [&#123;'p.location': '苏州'&#125;] 12345%%cypherMATCH (p:Dept)WHERE p.location = &#x27;苏州&#x27;RETURN p//等价上面的 [&#123;'p': Node('Dept', deptno=10, dname='Accounting', isperson=True, location='苏州')&#125;] 12345%%cypherMATCH (director:Movie)--(movie)RETURN movielimit 5//--表示关系 不考虑方向(--&gt;)和属性 [&#123;'movie': Node('Person', born=1978, name='Emil Eifrem')&#125;, &#123;'movie': Node('Person', born=1952, name='Joel Silver')&#125;, &#123;'movie': Node('Person', born=1965, name='Lana Wachowski')&#125;, &#123;'movie': Node('Person', born=1967, name='Lilly Wachowski')&#125;, &#123;'movie': Node('Person', born=1960, name='Hugo Weaving')&#125;] 12345678%%cypherMATCH (wallstreet &#123;title: &#x27;Joe Versus the Volcano&#x27;&#125;)&lt;-[:ACTED_IN|DIRECTED]-(person)RETURN person.namelimit 5//查询多个关系//如果关系名字里面有空格 用反引号``//[:TYPE*minHops..maxHops] 代表关系的长度//shortestPath((martin)-[*..15]-(oliver)) 最短路径,最大长度为15 [&#123;'person.name': 'Meg Ryan'&#125;, &#123;'person.name': 'Tom Hanks'&#125;, &#123;'person.name': 'John Patrick Stanley'&#125;, &#123;'person.name': 'Nathan Lane'&#125;, &#123;'person.name': 'Meg Ryan'&#125;] 1234%%cypherMATCH (charlie &#123;name: &#x27;Tom Hanks&#x27;&#125;)-[:ACTED_IN]-&gt;(movie)&lt;-[:DIRECTED]-(director)RETURN movie.title, director.namelimit 5 [&#123;'movie.title': &quot;You've Got Mail&quot;, 'director.name': 'Nora Ephron'&#125;, &#123;'movie.title': 'Sleepless in Seattle', 'director.name': 'Nora Ephron'&#125;, &#123;'movie.title': 'Joe Versus the Volcano', 'director.name': 'John Patrick Stanley'&#125;, &#123;'movie.title': 'That Thing You Do', 'director.name': 'Tom Hanks'&#125;, &#123;'movie.title': 'Cloud Atlas', 'director.name': 'Tom Tykwer'&#125;] 12# OPTIONAL MATCH # using nulls for missing parts RETURN 检索节点的某些属性 检索节点的所有属性 检索节点和关联关系的某些属性 检索节点和关联关系的所有属性 需要和别的语句搭配使用 1# return * return 所有出现过的变量 12345%%cypherMATCH (`This isn\\&#x27;t a common variable`)WHERE `This isn\\&#x27;t a common variable`.name = &#x27;Kiefer Sutherland&#x27;RETURN `This isn\\&#x27;t a common variable`.born as othername//DISTINCT 返回不重复的值 [&#123;'othername': 1966&#125;, &#123;'othername': 1966&#125;] CREATE+MATCH+RETURN 12%%cypherCREATE (e:Customer&#123;id:&#x27;1001&#x27;,name:&#x27;Abc&#x27;,dob:&#x27;01/10/1982&#x27;&#125;) [] 12%%cypherCREATE (cc:CreditCard&#123;id:&#x27;5001&#x27;,number:&#x27;1234567890&#x27;,cvv:&#x27;888&#x27;,expiredate:&#x27;20/17&#x27;&#125;) [] 1# 1. 使用现有节点创建没有属性的关系 1234567%%cyphermatch (e:Customer),(cc:CreditCard)create (e)-[r:DO_SHOPPING_WITH]-&gt;(cc)RETURN r//不加return 也可以//只能创建有向关系,查询的时候可以查双向关系 [&#123;'r': DO_SHOPPING_WITH(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890'))&#125;] 123%%cypherMATCH (e:Customer)-[r ]-&gt;(cc) RETURN r [&#123;'r': second_relation(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890'))&#125;, &#123;'r': DO_SHOPPING_WITH(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890'))&#125;] 1234%%cypherMATCH whole=(e)-[r ]-&gt;(cc:Movie) RETURN wholelimit 5 [&#123;'whole': Path(Node('Person', born=1978, name='Emil Eifrem'), ACTED_IN(Node('Person', born=1978, name='Emil Eifrem'), Node('Movie', released=1999, tagline='Welcome to the Real World', title='The Matrix')))&#125;, &#123;'whole': Path(Node('Person', born=1952, name='Joel Silver'), PRODUCED(Node('Person', born=1952, name='Joel Silver'), Node('Movie', released=1999, tagline='Welcome to the Real World', title='The Matrix')))&#125;, &#123;'whole': Path(Node('Person', born=1965, name='Lana Wachowski'), DIRECTED(Node('Person', born=1965, name='Lana Wachowski'), Node('Movie', released=1999, tagline='Welcome to the Real World', title='The Matrix')))&#125;, &#123;'whole': Path(Node('Person', born=1967, name='Lilly Wachowski'), DIRECTED(Node('Person', born=1967, name='Lilly Wachowski'), Node('Movie', released=1999, tagline='Welcome to the Real World', title='The Matrix')))&#125;, &#123;'whole': Path(Node('Person', born=1960, name='Hugo Weaving'), ACTED_IN(Node('Person', born=1960, name='Hugo Weaving'), Node('Movie', released=1999, tagline='Welcome to the Real World', title='The Matrix')))&#125;] 1# 2. 使用现有节点创建有属性的关系 1234%%cyphermatch (e:Customer),(cc:CreditCard)create (e)-[r:DO_SHOPPING_WITH&#123;shopdata:&#x27;12/12/2014&#x27;,price:5500&#125;]-&gt;(cc)RETURN r [&#123;'r': DO_SHOPPING_WITH(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890'), price=5500, shopdata='12/12/2014')&#125;] 12# 3.使用新节点创建有/无属性的关系# 和1.2.的区别是 1.2.需要先match 123%%cyphercreate (fb1:FaceBookProfile)-[like:LIKES]-&gt;(fb2:FaceBookProfile)//创建了两个新节点喝一个新关系 [] 1234%%cyphercreate (video1:YoutubeVideo&#123;title:&#x27;Action Movie1&#x27;,update_by:&#x27;Abc&#x27;,uploaded_data:&#x27;10/10/2010&#x27;&#125;)-[movie:ACTION_MOVIES&#123;rating:1&#125;]-&gt;(video2:YoutubeVideo&#123;title:&#x27;Action Movie2&#x27;,update_by:&#x27;Xyz&#x27;,uploaded_data:&#x27;12/12/2012&#x27;&#125;) [] 123%%cyphermatch (cust)-[r:DO_SHOPPING_WITH]-&gt;(cc)return cust,r,cc [&#123;'cust': Node('Customer', dob='01/10/1982', id='1001', name='Abc'), 'r': DO_SHOPPING_WITH(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890')), 'cc': Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890')&#125;, &#123;'cust': Node('Customer', dob='01/10/1982', id='1001', name='Abc'), 'r': DO_SHOPPING_WITH(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890')), 'cc': Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890')&#125;, &#123;'cust': Node('Customer', dob='01/10/1982', id='1001', name='Abc'), 'r': DO_SHOPPING_WITH(Node('Customer', dob='01/10/1982', id='1001', name='Abc'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890'), price=5500, shopdata='12/12/2014'), 'cc': Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890')&#125;] WHERE 1234WHERE &lt;condition&gt; &lt;boolean-operator&gt; &lt;condition&gt; &lt;condition&gt;: &lt;property-name&gt; &lt;comparison-operator&gt; &lt;value&gt; &lt;comparison-operator&gt;: =/&lt;&gt;/&lt;/&gt;/&lt;=/&gt;=/=~(正则)&lt;boolean-operator&gt;: AND/OR/NOT/XOR 12345%%cypherMATCH (emp:YoutubeVideo) WHERE emp.aaaaa = &#x27;Xyz&#x27;RETURN id(emp)//没有的属性认为False [] 12345%%cypherMATCH (emp:YoutubeVideo) WHERE emp.update_by = &#x27;Abc&#x27; OR emp.update_by = &#x27;Xyz&#x27;RETURN id(emp)//查询 [&#123;'id(emp)': 231&#125;, &#123;'id(emp)': 232&#125;] 1234567%%cyphermatch (n:Dept),(c:CreditCard)where n.location=&#x27;苏州&#x27; and c.cvv=&#x27;888&#x27;create (n)-[r:no_relations&#123;prop:&#x27;随机创建的&#x27;&#125;]-&gt;(c)return r//创建 数字也要用&#x27;&#x27;,直接888查不到,创建的时候用&#x27;&#x27;了 [&#123;'r': no_relations(Node('Dept', deptno=10, dname='Accounting', isperson=True, location='苏州'), Node('CreditCard', cvv='888', expiredate='20/17', id='5001', number='1234567890'), prop='随机创建的')&#125;] 12345678%%cypherMATCH (n:Person)WHERE n[&#x27;born&#x27;] &gt; 1980RETURN n.name, n.bornlimit 5//n.name CONTAINS &#x27;ete&#x27;//n.name ENDS WITH &#x27;ter&#x27;//WHERE n.name STARTS WITH &#x27;Pet&#x27; [&#123;'n.name': 'Jonathan Lipnicki', 'n.born': 1996&#125;, &#123;'n.name': 'Natalie Portman', 'n.born': 1981&#125;, &#123;'n.name': 'Emile Hirsch', 'n.born': 1985&#125;, &#123;'n.name': 'Rain', 'n.born': 1982&#125;, &#123;'n.name': 'Jonathan Lipnicki', 'n.born': 1996&#125;] 123456%%cypherMATCH (n:Person)-[r]-&gt;()WHERE n.name=&#x27;Angela Scope&#x27; AND type(r) =~ &#x27;F.*&#x27;RETURN type(r), rlimit 5//A开头的关系 [&#123;'type(r)': 'FOLLOWS', 'r': FOLLOWS(Node('Person', name='Angela Scope'), Node('Person', name='Jessica Thompson'))&#125;, &#123;'type(r)': 'FOLLOWS', 'r': FOLLOWS(Node('Person', name='Angela Scope'), Node('Person', name='Jessica Thompson'))&#125;] 12345678%%cypherMATCH (person:Person),(f:Person)WHERE EXISTS &#123; MATCH (person)-[:FOLLOWS]-&gt;(f) WHERE person.name = &#x27;Paul Blythe&#x27; &#125;RETURN f.name AS name//嵌套查询 内层可用外层变量 [&#123;'name': 'Angela Scope'&#125;, &#123;'name': 'Angela Scope'&#125;] DELETE 删除节点 删除关系 12%%cypherMATCH (e:Film) delete e [] 123%%cyphermatch (n:Customer)-[r]-(c:CreditCard) delete n,c,r//删除节点时必要保证节点没有其他的关系相连 [] 1234%%cypherMATCH (n:Movie)DETACH DELETE n//删除节点和相连的关系 [] 12%%cyphermatch (n)-[r]-(c:Dept) return r [] REMOVW 删除节点或关系的标签 删除节点或关系的属性 keys(n) 查看n的所有属性 labels(n) 查看n的所有标签 1234%%cyphercreate (book:Book &#123;id:122,title:&#x27;Neo4j TUtorial&#x27;,pages:333,price:250&#125;)return book [&#123;'book': Node('Book', id=122, pages=333, price=250, title='Neo4j TUtorial')&#125;] 12345%%cyphermatch (book:Book&#123;id:122&#125;)remove book.noattrreturn book//没有这个属性也可以 [&#123;'book': Node('Book', id=122, pages=333, title='Neo4j TUtorial')&#125;] 1234%%cyphermatch (n:label1)remove n:label1return n [&#123;'n': Node('label2', 'label3', 'label4', labels=True)&#125;] SET 向现有节点或关系添加新属性 添加或更新属性值 12345%%cyphermatch (n:Dept)set n.dname=&#x27;帅哥&#x27; ,n.type=&#x27;666&#x27;return n//有就修改 没有添加 [&#123;'n': Node('Dept', deptno=10, dname='帅哥', location='Hyderabad', type='666')&#125;, &#123;'n': Node('Dept', deptno=10, dname='帅哥', isperson=True, location='苏州', type='666')&#125;] 12345%%cypherMATCH (book:Book&#123;&#125;) SET book+=&#123;title:&#x27;neo4j tutorial&#x27;&#125;return book//book=&#123;offline:True&#125;会把原有是属性值全部删掉 book+=&#123;offline:True&#125; 不会删除原有属性 新增一个属性 [&#123;'book': Node('Book', offline=True, title='neo4j tutorial')&#125;] 123%%cypherMATCH (book:Book&#123;&#125;) SET book:Knowledge RETURN book//新增一个标签 [&#123;'book': Node('Book', 'Knowledge', offline=True, title='neo4j tutorial')&#125;] 12345%%cypherMATCH (book:Book&#123;&#125;) SET book.addtitle=book.titleremove book.titlereturn book [&#123;'book': Node('Book', 'Knowledge', addtitle='neo4j tutorial', offline=True)&#125;, &#123;'book': Node('Book')&#125;, &#123;'book': Node('Book', addtitle='neo4j start', offline=True)&#125;, &#123;'book': Node('Book', addtitle='neo4j end', offline=False)&#125;] 12345%%cypherMATCH (n &#123;dname: &#x27;帅哥&#x27;&#125;)SET (CASE WHEN n.type = 666 THEN n END).worksIn = &#x27;Malmo&#x27;RETURN n//只有n.type = 666 才设置 [&#123;'n': Node('Dept', deptno=10, dname='帅哥', location='Hyderabad', type='666')&#125;, &#123;'n': Node('Dept', deptno=10, dname='帅哥', isperson=True, location='苏州', type='666')&#125;] 123456789# &#123;# &#x27;props&#x27; : &#123;# &#x27;name&#x27; : &#x27;Andy&#x27;,# &#x27;position&#x27; : &#x27;Developer&#x27;# &#125;# &#125;# MATCH (n &#123;name: &#x27;Andy&#x27;&#125;)# SET n = $props# RETURN n.name, n.position, n.age, n.hungry ORDER BY 默认是升序排列 DESC改为降序 123456%%cyphermatch (movie:Movie)return movie.released,movie.titleorder by movie.released DESC , movie.titlelimit 15//多个属性排列 [&#123;'movie.released': None, 'movie.title': 'The Matrix'&#125;, &#123;'movie.released': None, 'movie.title': 'The Matrix'&#125;, &#123;'movie.released': None, 'movie.title': 'The Matrix Reloaded'&#125;, &#123;'movie.released': None, 'movie.title': 'The Matrix Reloaded'&#125;, &#123;'movie.released': None, 'movie.title': 'The Matrix Revolutions'&#125;, &#123;'movie.released': None, 'movie.title': 'The Matrix Revolutions'&#125;] UNION [ALL] 将两个不同的结果合并 123456%%cyphercreate (n:CreditCard&#123;id:1,name:&#x27;ABX XYZ&#x27;,number:&#x27;1234567890&#x27;,cvv:1230,valid_from:&#x27;6/14&#x27;,valid_to:&#x27;6/24&#x27;&#125;),(n1:CreditCard&#123;id:2,name:&#x27;ABX1 XYZ1&#x27;,number:&#x27;1234567891&#x27;,cvv:1231,valid_from:&#x27;6/141&#x27;,valid_to:&#x27;6/241&#x27;&#125;),(n2:CreditCard&#123;id:3,name:&#x27;ABX2 XYZ2&#x27;,number:&#x27;1234567892&#x27;,cvv:1232,valid_from:&#x27;6/142&#x27;,valid_to:&#x27;6/242&#x27;&#125;),(n3:CreditCard&#123;id:4,name:&#x27;ABX3 XYZ3&#x27;,number:&#x27;1234567893&#x27;,cvv:1233,valid_from:&#x27;6/143&#x27;,valid_to:&#x27;6/243&#x27;&#125;),(n4:CreditCard&#123;id:5,name:&#x27;ABX XYZ&#x27;,number:&#x27;1234567890&#x27;,cvv:123,valid_from:&#x27;6/14&#x27;,valid_to:&#x27;6/24&#x27;&#125;) 123456%%cyphercreate (n:DebitCard&#123;id:1,name:&#x27;ABX XYZ&#x27;,number:&#x27;1234567890&#x27;,cvv:1230,valid_from:&#x27;6/14&#x27;,valid_to:&#x27;6/24&#x27;&#125;),(n1:CreditCard&#123;id:11,name:&#x27;ABX1 XYZ1&#x27;,number:&#x27;1234567891&#x27;,cvv:1231,valid_from:&#x27;6/141&#x27;,valid_to:&#x27;6/241&#x27;&#125;),(n2:CreditCard&#123;id:12,name:&#x27;ABX2 XYZ2&#x27;,number:&#x27;1234567892&#x27;,cvv:1232,valid_from:&#x27;6/142&#x27;,valid_to:&#x27;6/242&#x27;&#125;),(n3:CreditCard&#123;id:13,name:&#x27;ABX3 XYZ3&#x27;,number:&#x27;1234567893&#x27;,cvv:1233,valid_from:&#x27;6/143&#x27;,valid_to:&#x27;6/243&#x27;&#125;),(n4:CreditCard&#123;id:14,name:&#x27;ABX XYZ&#x27;,number:&#x27;1234567890&#x27;,cvv:123,valid_from:&#x27;6/14&#x27;,valid_to:&#x27;6/24&#x27;&#125;) 1234567%%cyphermatch (cc:CreditCard) return cc.id as id ,cc.number as numberUNION match (dc:DebitCard) return dc.id as id ,dc.number as number//自动去掉重复从行 不用as//这里既有信用卡式和借记卡具有相同的属性名：身份证和号码，但他们有不同的节点名称前缀。//这就是为什么UNION命令显示此错误消息。为了避免这种错误，Neo4j的CQL提供“AS”子句。 [&#123;'id': '5001', 'number': '1234567890'&#125;, &#123;'id': 1, 'number': '1234567890'&#125;, &#123;'id': 2, 'number': '1234567891'&#125;, &#123;'id': 3, 'number': '1234567892'&#125;, &#123;'id': 4, 'number': '1234567893'&#125;, &#123;'id': 5, 'number': '1234567890'&#125;, &#123;'id': 11, 'number': '1234567891'&#125;, &#123;'id': 12, 'number': '1234567892'&#125;, &#123;'id': 13, 'number': '1234567893'&#125;, &#123;'id': 14, 'number': '1234567890'&#125;] 12345%%cyphermatch (cc:CreditCard) return cc.id as id ,cc.number as numberUNION ALLmatch (dc:DebitCard) return dc.id as id ,dc.number as number//显示所有的行 [&#123;'id': '5001', 'number': '1234567890'&#125;, &#123;'id': 1, 'number': '1234567890'&#125;, &#123;'id': 2, 'number': '1234567891'&#125;, &#123;'id': 3, 'number': '1234567892'&#125;, &#123;'id': 4, 'number': '1234567893'&#125;, &#123;'id': 5, 'number': '1234567890'&#125;, &#123;'id': 11, 'number': '1234567891'&#125;, &#123;'id': 12, 'number': '1234567892'&#125;, &#123;'id': 13, 'number': '1234567893'&#125;, &#123;'id': 14, 'number': '1234567890'&#125;, &#123;'id': 1, 'number': '1234567890'&#125;] LIMIT &amp; SKIP limit n 只取结果的前n行 skip n 跳过结果的前n行 可以放在一起用 limit/skip 1 + toInteger(3 * rand()) MERGE MERGE命令在图中搜索给定模式 如果存在，则返回结果 如果它不存在于图中，则它创建新的节点/关系并返回结果。 123%%cyphermatch (gp:GoogleProfile&#123; Id: 201402,Name:&#x27;Nokia&#x27;&#125;)return id(gp) [] 123%%cypherMERGE (gp:GoogleProfile&#123; Id: 201402,Name:&#x27;Nokia&#x27;&#125;)return id(gp) [&#123;'id(gp)': 248&#125;] 123%%cyphermerge (gp:GoogleProfile&#123;Id:201402,Name:&#x27;Nokia&#x27;&#125;)return id(gp) [&#123;'id(gp)': 248&#125;] 123456%%cypherMERGE (keanu:Person &#123;name: &#x27;mergecreated&#x27;&#125;)ON CREATE SET keanu.created = timestamp()RETURN keanu.name, keanu.created//如果没有就会创建 并添加一个timestamp [&#123;'keanu.name': 'mergecreated', 'keanu.created': 1667637911668&#125;] 1234567%%cypherMERGE (person:Person&#123;name: &#x27;mergecreatedfound&#x27;&#125;)ON MATCH SET person.found = trueRETURN person.name, person.foundlimit 5//如果找到了就添加 没找到就不添加found [&#123;'person.name': 'mergecreatedfound', 'person.found': True&#125;] 12345678%%cypherMERGE (keanu:Person &#123;name: &#x27;Keanu Reeves&#x27;&#125;)ON CREATE SET keanu.created = timestamp()ON MATCH SET keanu.lastSeen = timestamp()RETURN keanu.name, keanu.created, keanu.lastSeen//有就是lastSeen,没有就是created [&#123;'keanu.name': 'Keanu Reeves', 'keanu.created': None, 'keanu.lastSeen': 1667638041825&#125;] 12345%%cypherMATCH (person:Person)MERGE (city:City &#123;name: person.bornIn&#125;)MERGE (person)-[r:BORN_IN]-&gt;(city)RETURN person.name, person.bornIn, city 1234567# CREATE CONSTRAINT ON (n:Person) ASSERT n.name IS UNIQUE;# CREATE CONSTRAINT ON (n:Person) ASSERT n.role IS UNIQUE;# For example, given two unique constraints on :Person(id) and :Person(ssn), # a query such as MERGE (n:Person &#123;id: 12, ssn: 437&#125;) will fail, # if there are two different nodes (one with id 12 and one with ssn 437) # or if there is only one node with only one of the properties. # In other words, there must be exactly one node that matches the pattern, or no matching nodes. NULL值 12%%cyphercreate (n:Book) [] 1234%%cypherMATCH (e:Book) RETURN e.offline,e.title,e.sal// None 就是NULL [&#123;'e.offline': True, 'e.title': 'neo4j tutorial', 'e.sal': None&#125;, &#123;'e.offline': None, 'e.title': None, 'e.sal': None&#125;] 12345%%cyphermatch (book:Book)where book.offline is not nullreturn book//where book.offline is null [&#123;'book': Node('Book', 'Knowledge', offline=True, title='neo4j tutorial')&#125;] IN 同 python IN 1234%%cypherMATCH (e:Book) WHERE e.offline IN [true]RETURN e [&#123;'e': Node('Book', 'Knowledge', offline=True, title='neo4j tutorial')&#125;, &#123;'e': Node('Book', offline=True, title='neo4j start')&#125;] CQL函数 官网 12%%cypherreturn datetime() [&#123;'datetime()': '2022-11-04T07:36:17.068Z'&#125;] 123%%cypherSHOW FUNCTIONS yield name,category,descriptionlimit 5 1234%%cypherMATCH (a)-[movie:ACTED_IN]-&gt;(b) RETURN STARTNODE(movie),ENDNODE(movie)limit 5 [&#123;'STARTNODE(movie)': Node('Person', born=1964, name='Keanu Reeves'), 'ENDNODE(movie)': Node('Movie', released=2003, title=&quot;Something's Gotta Give&quot;)&#125;, &#123;'STARTNODE(movie)': Node('Person', born=1964, name='Keanu Reeves'), 'ENDNODE(movie)': Node('Movie', released=2000, tagline='Pain heals, Chicks dig scars... Glory lasts forever', title='The Replacements')&#125;, &#123;'STARTNODE(movie)': Node('Person', born=1964, name='Keanu Reeves'), 'ENDNODE(movie)': Node('Movie', released=1995, tagline='The hottest data on earth. In the coolest head in town', title='Johnny Mnemonic')&#125;, &#123;'STARTNODE(movie)': Node('Person', born=1964, name='Keanu Reeves'), 'ENDNODE(movie)': Node('Movie', released=1997, tagline='Evil has its winning ways', title=&quot;The Devil's Advocate&quot;)&#125;, &#123;'STARTNODE(movie)': Node('Person', born=1964, name='Keanu Reeves'), 'ENDNODE(movie)': Node('Movie', released=2003, tagline='Everything that has a beginning has an end', title='The Matrix Revolutions')&#125;] 12345%%cypherMATCH (a)-[movie:ACTED_IN]-&gt;(b) RETURN ID(movie),TYPE(movie)limit 5//type 只能看relation [&#123;'ID(movie)': 221, 'TYPE(movie)': 'ACTED_IN'&#125;, &#123;'ID(movie)': 114, 'TYPE(movie)': 'ACTED_IN'&#125;, &#123;'ID(movie)': 132, 'TYPE(movie)': 'ACTED_IN'&#125;, &#123;'ID(movie)': 22, 'TYPE(movie)': 'ACTED_IN'&#125;, &#123;'ID(movie)': 15, 'TYPE(movie)': 'ACTED_IN'&#125;] 创建索引 12%%cypherCREATE INDEX ON :Movie (title) [] 12%%cypherDROP INDEX ON :Movie (title) [] 创建约束 1234%%cypherMATCH (cc:CreditCard) RETURN cc.id,cc.number,cc.name,cc.expiredate,cc.cvvlimit 5 1234%%cypherCREATE CONSTRAINT ON (cc:CreditCard)ASSERT cc.id IS UNIQUE//如果已经存在重复的就不能创建,把重复的删除 [] 123%%cyphercreate (cc:CreditCard&#123;id:666&#125;)//Node(246) already exists with label `CreditCard` and property `id` = 14 [] 123%%cypherDROP CONSTRAINT ON (cc:CreditCard)ASSERT cc.id IS UNIQUE [] 12%%cyphercreate (cc:CreditCard&#123;id:666&#125;) [] 补充 WITH allows query parts to be chained together 12345%%cypherMATCH (david &#123;name: &#x27;Jessica Thompson&#x27;&#125;)--(otherPerson)--()WITH otherPerson, count(*) AS foafWHERE foaf &gt; 0RETURN otherPerson.name [&#123;'otherPerson.name': 'Angela Scope'&#125;, &#123;'otherPerson.name': 'Angela Scope'&#125;] UNWIND expands a list into a sequence of rows. 123%%cypherUNWIND [1, 2, 3, null] AS xRETURN x, &#x27;val&#x27; AS y [&#123;'x': 1, 'y': 'val'&#125;, &#123;'x': 2, 'y': 'val'&#125;, &#123;'x': 3, 'y': 'val'&#125;, &#123;'x': None, 'y': 'val'&#125;] 123456%%cypherWITH [1, 1, 2, 2] AS collUNWIND coll AS xWITH DISTINCT xRETURN collect(x) AS setOfVals//列表去重 [&#123;'setOfVals': [1, 2]&#125;] 123456%%cypherWITH [1, 2] AS a, [3, 4] AS bUNWIND (a + b) AS xRETURN x [&#123;'x': 1&#125;, &#123;'x': 2&#125;, &#123;'x': 3&#125;, &#123;'x': 4&#125;] 123456%%cypherWITH [[1, 2], [3, 4], 5] AS nestedUNWIND nested AS xUNWIND x AS yRETURN y//两重循环 [&#123;'y': 1&#125;, &#123;'y': 2&#125;, &#123;'y': 3&#125;, &#123;'y': 4&#125;, &#123;'y': 5&#125;] 123456789%%cypherWITH [] AS listUNWIND CASE WHEN list = [] THEN [null] ELSE list END AS emptylistRETURN emptylist//避免列表为空 [&#123;'emptylist': None&#125;] FOREACH 1234%%cypherMATCH p=(start)-[*]-&gt;(finish)WHERE start.name = &#x27;Tom Hanks&#x27; AND finish.title starts with &#x27;C&#x27;FOREACH (n IN nodes(p) | SET n.marked = true) 1234%%cypherMATCH (a &#123;name: &#x27;Tom Hanks&#x27; &#125;)FOREACH (name IN [&#x27;Mike&#x27;, &#x27;Carl&#x27;, &#x27;Bruce&#x27;] |CREATE (a)-[:FRIEND]-&gt;(:Person &#123;name: name&#125;)) [] CALL CALL {} CALL procedure 1234567%%cypherUNWIND [0, 1, 2] AS xCALL &#123; WITH x RETURN x * 10 AS y&#125;RETURN x, y [&#123;'x': 0, 'y': 0&#125;, &#123;'x': 1, 'y': 10&#125;, &#123;'x': 2, 'y': 20&#125;] LOAD CSV LOAD CSV FROM ‘file:///artists.csv’ AS line -正常数据 USING PERIODIC COMMIT 1000 LOAD CSV FROM ‘file:///artists.csv’ AS line -大数据,1000提交一次事物 12# SHOW PROCEDURES YIELD *.# SHOW FUNCTIONS YIELD *.","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Cypher","slug":"Cypher","permalink":"https://gladdduck.github.io/tags/Cypher/"}]},{"title":"Neo4j浏览器端快捷键","slug":"杂谈-Neo4j浏览器端快捷键","date":"2022-11-04T09:24:08.889Z","updated":"2023-11-26T05:21:56.934Z","comments":true,"path":"2022/11/04/杂谈-Neo4j浏览器端快捷键/","link":"","permalink":"https://gladdduck.github.io/2022/11/04/%E6%9D%82%E8%B0%88-Neo4j%E6%B5%8F%E8%A7%88%E5%99%A8%E7%AB%AF%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"1、 执行当前命令： ctrl+enter 2、 历史上一个命令：ctrl+向上箭头 3、 切换到多行编辑：shift+enter 4、 将焦点转移到编辑器： / 5、 切换到全屏编辑： esc","categories":[{"name":"快捷命令","slug":"快捷命令","permalink":"https://gladdduck.github.io/categories/%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"Neo4j快捷命令","slug":"Neo4j快捷命令","permalink":"https://gladdduck.github.io/tags/Neo4j%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}]},{"title":"Neo4j&JDK安装踩坑","slug":"配置-Neo4j安装","date":"2022-11-03T09:31:04.917Z","updated":"2022-11-03T10:35:37.710Z","comments":true,"path":"2022/11/03/配置-Neo4j安装/","link":"","permalink":"https://gladdduck.github.io/2022/11/03/%E9%85%8D%E7%BD%AE-Neo4j%E5%AE%89%E8%A3%85/","excerpt":"","text":"前言 最近要开始打工了 😟 😟 😟 😟 创建一个知识图谱(可视化)嵌入到一个系统里面,当作子系统. 期待的效果是百度百科影视图谱,任务太艰巨了. 😔 😔 😔 😔 如果你看到了这篇博客,有好的解决方案都可以帮帮我. 😘 😘 😘 😘 正文 踩坑 😭😭😭😭 问题: 123想创建多个数据库用,刚开始默认有两个,一个neo4j,一个system.希望创建别的数据库.比如: 网上搜索了很多办法,最坑的一个: 12创建:create database name删除:drop database name 看着挺好,试了很多遍报错 看了文档才知道,这是企业版专属命令,社区版用不了… 解决: neo4j官网 新建数据库 在 neo4j\\conf\\neo4j.conf中, 找到 dbms.default_database=defaultdatabase 修改后面的名字 如果数据库不存在,就会创建一个新的 如果存在,启动之后就会设为默认的数据库 但是有一个弊端: 这种方式还是切换不了数据库 cypher命令 use databasename也不能用 上面两种方法都会报错 因为社区版只能开启一个用户数据库… 如果想切换数据库只能修改配置文件,然后重启(neo4j restart)或者开一个新的进程(neo4j start). 删除数据库 把 neo4j\\data\\文件夹下面的 对应的数据库名字删除,即可. 配置前须知 neo4j现在已经到5.x了, neo4j 3.x版本需要jdk8 neo4j 4.x版本需要jdk11 安装之前需要把jdk安装好,我用的neo4j4.3.19, jdk11.2 JDK安装 jdk有很多资料,建议找一个时间最近的,不要找好几年前的. 下载jdk安装包 官网下载需要注册,可以用其他镜像 如果需要,更改路径,但是要记住 (没图了,网上找的图) 一路next之后,如果jdk目录里没有jre 命令: bin\\jlink.exe --module-path jmods --add-modules java desktop --output jre 就多了一个jre文件夹 配置环境变量 12%JAVA_HOME%\\bin%JAVA_HOME%\\jre\\bin 1.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar 解释每个变量的作用 123456789101112131415161718192021222324252627282930JAVA_HOME 变量名：JAVA_HOME 变量值：C:\\develop\\Java\\jdk1.8.0_191 用途：定义一个变量，供其他地方使用Path 变量名：Path 变量值：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin; 用途：让系统在任何路径下都可以识别java、javac、javap等命令CLASSPATH 变量名：CLASSPATH 变量值：.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar 用途：告诉jvm要使用或执行的class放在什么路径上，便于JVM加载class文件，.;表示当前路径，tools.jar和dt.jar为类库路径CLASSPATH详解 - tools.jar 工具类库(编译和运行等)，它跟我们程序中用到的基础类库没有关系。我们注意到在Path中变量值bin目录下的各个exe工具的大小都很小，一般都在27KB左右，这是因为它们实际上仅仅相当于是一层代码的包装，这些工具的实现所要用到的类库都在tools.jar中，用压缩软件打开tools.jar，你会发现有很多文件是和bin目录下的exe工具相对性的。当然，如果tools.jar的功能只有这些的话，那么我们根本不用把它加入到CLASSPATH变量中，因为bin目录下的工具自己可以完成对这些类库的调用，因此tools.jar应该还有其他的功能。在里面还可以看到有Applet和RMI等相关的文件，因此tools.jar应该还是远程调用等必须的jar包。tools.jar的其他作用可以查看其他资料。 - dt.jar 运行环境类库，主要是Swing包，这一点通过用压缩软件打开dt.jar也可以看到。如果在开发时候没有用到Swing包，那么可以不用将dt.jar添加到CLASSPATH变量中。 CLASSPATH中的类库是由Application ClassLoader或者我们自定义的类加载器来加载的，这里当然不能包括基础类库，如果包括基础类库的话，并用两个不同的自定义类加载器去加载该基础类，那它得到的该基础类就不是唯一的了，这样便不能保证Java类的安全性。 - 基本类库和扩展类库rt.jar 基本类库是所有的 import java.* 开头的类，在 %JAVA_HOME%\\jre\\lib 目录下（如其中的 rt.jar、resource.jar ），类加载机制提到，该目录下的类会由 Bootstrap ClassLoader 自动加载，并通过亲委派模型保证了基础类库只会被Bootstrap ClassLoader加载，这也就保证了基础类的唯一性。 - 扩展类库是所有的 import javax.* 开头的类，在 %JAVA_HOME%\\jre\\lib\\ext 目录下，该目录下的类是由Extension ClassLoader 自动加载，不需要我们指定。 - rt.jar 默认就在根ClassLoader的加载路径里面，放在CLASSPATH也是多此一举。 验证 123cmd里输入:java -versionjavac -version neo4j安装 1234neo4j有三个版本一个是社区版:和桌面版基本上没区别,桌面版就是一个应用程序,社区版需要用命令行启动一个是企业版:收费,没用过,功能很多,上面有体会一个是桌面版:有可以操作的页面,方便,但是会有点慢 官网下载,找对应的安装zip(社区版) 下载解压 配置环境变量 cmd中输入:neo4j start 就可以启动了,浏览器输入访问 1http://localhost:7474/browser/ 默认用户名密码都是neo4j","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"neo4j安装","slug":"neo4j安装","permalink":"https://gladdduck.github.io/tags/neo4j%E5%AE%89%E8%A3%85/"}]},{"title":"多个域名访问同一个服务器","slug":"配置-一个服务器使用多个域名","date":"2022-10-26T07:22:34.389Z","updated":"2023-11-26T05:18:09.953Z","comments":true,"path":"2022/10/26/配置-一个服务器使用多个域名/","link":"","permalink":"https://gladdduck.github.io/2022/10/26/%E9%85%8D%E7%BD%AE-%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AA%E5%9F%9F%E5%90%8D/","excerpt":"","text":"需求 有时候服务器少，但是项目多，好几个项目部署到一个服务器上。 或者不同的项目有不同的端口。 但是只有一个域名，是不是只能用一个项目呢？ NONONO 🙅🙅🙅🙅🙅 比如 我有三个域名(A,B,C)(怎么把一个域名变成三个域名，在有办法)，三个项目在服务器上(a,b,c) 研究一下怎么把A-a，B-b，C-c 首先，把一个域名变成多个 比如，我在腾讯云上申请了一个yayan.xyz的域名(其他云没搞过，但是同理)。 打开腾讯云的控制台，域名解析，点进要解析的域名 讲解一下重要的字段 1234主机记录：就是我们想要的域名，比如主机记录填&quot;aaa&quot;,那么就有一个新的域名aaa.yayan.xyz记录类型:用的不多，选A就行，有CHAME(加速?)，TXT(验证?),NS(DNS)?记录值:如果是A就是自己域名绑定的ip，其他的要根据你干啥填TTL:路由跳转的最大跳数，不重要吧? 点击新增字段，输入自己想要的域名，确定之后，几分钟就行了 然后，服务器配置 服务器下个nginx(之前觉得麻烦，没想到这么好用) 这个网上很多，一个命令就行了，忘了是啥了，可以搜搜 修改nginx配置文件 我的是： 1/etc/nginx/sites-available/default vscode连接服务器的在前一篇 修改监听端口对应的域名 我用的http所以是80， https应该是443 一个例子 1234567891011121314151617server &#123; listen 80; listen [::]:80; server_name unsplash.yayan.xyz; location / &#123; proxy_pass http://服务器ip:6666; &#125;&#125;server &#123; listen 80; listen [::]:80; server_name www.yayan.xyz; location / &#123; root /anaconda/pythoncode/ChargingMonitor; index index.html index.php index.jsp; &#125;&#125; 重启nginx服务 1service nginx restart 现在： 访问unsplash.yayan.xyz 就会跳转到6666端口对应的服务，比如gradio或者flask搭的项目接口 访问 www.yayan.xyz 就会跳转到/anaconda/pythoncode/ChargingMonitor文件夹下对应的index.html或者其他 💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪💪","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"多个域名访问同一个服务器","slug":"多个域名访问同一个服务器","permalink":"https://gladdduck.github.io/tags/%E5%A4%9A%E4%B8%AA%E5%9F%9F%E5%90%8D%E8%AE%BF%E9%97%AE%E5%90%8C%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Vscode连接阿里云服务器","slug":"配置-Vscode连接阿里云","date":"2022-10-26T06:43:08.377Z","updated":"2023-11-20T04:45:41.465Z","comments":true,"path":"2022/10/26/配置-Vscode连接阿里云/","link":"","permalink":"https://gladdduck.github.io/2022/10/26/%E9%85%8D%E7%BD%AE-Vscode%E8%BF%9E%E6%8E%A5%E9%98%BF%E9%87%8C%E4%BA%91/","excerpt":"","text":"有个阿里云ECS服务器，之前一直用宝塔面板连接，方便时方便，但是有时候太占内容了。 本来服务器就小，一个宝塔占的差不多了。 后期改成Vscode。 其他能远程连接的软件很多，但是vscode是个神器，很推荐。 方法1：密钥对 用密钥对个人觉得有点，类似hexo博客搭建里面连接github. 在阿里云控制台，找到密钥对，点进去创建密钥对 创建一个新的，名字随便起 绑定到实例中，然后重启 绑定完会自动下载一个.pem文件，尽量存到C:\\user\\username里面的一个问价夹 如果直接放桌面或者公共文件夹，后期会报一个too open的错误 打开vscode，下载remote-ssh插件，打开ssh的配置文件 应该是C:\\Users\\username\\.ssh\\config 在配置文件中添加 1234Host 起个名字 HostName 服务器的ip(192.168.1.1) IdentityFile pem的路径\\xxx.pem User 用户名(root) 或者点击”+“号，输入命令： 1ssh -i &quot;pem路径&quot; root@服务器ip 配置完成，打开就行了,后面会选操作系统，选个continue，忘记要不要输密码了 目前单台云服务器只支持绑定单个密钥对。若您选择已经绑定过其他密钥对的云服务器，新绑定的密钥对将会覆盖以前绑定的密钥对。绑定/解绑密钥对需要在控制台重启ECS实例才能生效 太麻烦了，而且我自己用的时候很多次显示Permission denied (publickey).无解， 强烈推荐下面一种方式 方法2：用户名密码连接 先贴一个阿里云官网文档，通过密码或密钥认证登录Linux实例-为Linux实例开启root用户远程登录 先用VNC连接一下，修改配置文件 输入用户名密码。 如果密码忘了，在菜单栏的实例中，修改密码 终端中，输入 123vi /etc/ssh/sshd_config# 如果不是root，就输入sudo vi /etc/ssh/sshd_config 往下翻，基本上在最后 123456# PermitRootLogin no修改为PermitRootLogin yes。# PasswordAuthentication no修改为PasswordAuthentication yes。# 修改方法：# 1. 找到要修改的位置，点击&quot;i&quot;,就进入编辑模式了# 2. 修改改完之后按Esc键，输入:wq保存修改。# 如果不是root，输入:wq!保存 重启sshd服务 1service sshd restart 在vscode的远程连接中，修改配置文件或者直接输入 1234Host 起个名字 HostName 服务器的ip(192.168.1.1) User 用户名(root)# 或者输入 ssh root@服务器ip 输入实例密码就连接成功了！ 👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍","categories":[{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"Vscode 阿里云","slug":"Vscode-阿里云","permalink":"https://gladdduck.github.io/tags/Vscode-%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"","slug":"杂谈-markdown快捷键","date":"2022-10-22T00:58:32.349Z","updated":"2022-10-20T06:17:32.000Z","comments":true,"path":"2022/10/22/杂谈-markdown快捷键/","link":"","permalink":"https://gladdduck.github.io/2022/10/22/%E6%9D%82%E8%B0%88-markdown%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"1title:markdown记录 准备记录以下markdown在vscode中的一些快捷操作。","categories":[],"tags":[]},{"title":"第一篇博客记录","slug":"杂谈-第一篇博客记录","date":"2022-10-22T00:58:32.349Z","updated":"2023-11-26T04:43:28.513Z","comments":true,"path":"2022/10/22/杂谈-第一篇博客记录/","link":"","permalink":"https://gladdduck.github.io/2022/10/22/%E6%9D%82%E8%B0%88-%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/","excerpt":"","text":"😍😍😍 第一篇博客，费尽了千辛万苦。 还有很多没完善的地方，先用着，后续再改。 因为自己写代码的过程中遇见了很多重复的错误，每次改bug都要浪费时间。 索性没见一个都给他记录下来。 这篇博客是用Github+hexo，用的pure主题。搭建过程中也遇到了很多问题。后续都会写出来。 😆😆😆 先记录一下：vscode写markdown加入表情 Markdown Emoji ， 还有这， 还有这 😏😏😏 😴😴😴 结束，睡大觉去咯。 😠😠😠 ！！！！ 一定一定 不要用git的shell执行npm或者hexo npm在cmd安装的包和在gitshell安装的包是独立的！！！ 如果打开页面connot get，看看public里有没有html文件，没有就安装一些包。 比如，不比如了(hello-hexo文章里有详细说明)，有时候在cmd里执行命令会出现报错，还得滚回gitshell里用， 模模糊糊也不知道为啥，可能是安装的时候使用-g 和–save命令的区别 有时间查查这两个参数搞清楚 💢💢💢💢 睡大觉去了 🐷🐷🐷🐷 markdown还能用点啥好玩的呢 表情已经满足不了我的使用了 🤣🤣🤣 发现了 windows下，中文输入法输一个i，里面的表情也都能用i ，选表情截不了图。 👀👀👀 123456789101112# google colab!pip install kaggleimport jsontoken = &#123;&quot;username&quot;:&quot;coderduck&quot;,&quot;key&quot;:&quot;xxx&quot;&#125;with open(&#x27;/content/kaggle.json&#x27;, &#x27;w&#x27;) as file: json.dump(token, file)!mkdir -p ~/.kaggle!cp /content/kaggle.json ~/.kaggle/!chmod 600 ~/.kaggle/kaggle.json!kaggle config set -n path -v /content!kaggle competitions download -c dogs-vs-cats","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E8%B0%88/"}],"tags":[{"name":"搭建博客","slug":"搭建博客","permalink":"https://gladdduck.github.io/tags/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"}]},{"title":"print(Hello gitalk)","slug":"配置-hello-gitalk配置","date":"2022-10-22T00:58:32.349Z","updated":"2022-10-22T02:40:50.609Z","comments":true,"path":"2022/10/22/配置-hello-gitalk配置/","link":"","permalink":"https://gladdduck.github.io/2022/10/22/%E9%85%8D%E7%BD%AE-hello-gitalk%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Github上配置 xxx.github.io仓库内，找到issues-labels 2. 新建一个label 名字一定是gitalk 用来存放提交的评论 新建一个application授权 打开右上角头像，【Settings】-&gt;【Developer settings】-&gt;【OAuth Apps】-&gt;【New OAuth App】 Homepage URL和Authorization callback URL 一定是xxxx.github.io ,其他的随便填。 复制下来生成的Client ID和Client secrets 主题中配置 配置文件_config.yml中的设置 123456789101112131415comment: type: gitalk # 启用哪种评论系统 gitalk: enable: true 开启gitalk评论，不需要配置 owner: github用户名 admin: github用户名 repo: 博客的仓库名称(注意不是地址) ClientID: 上面生成的Client ID ClientSecret: 上面生成的Client Secret labels: &#x27;gitalk&#x27; github issue 对应的issue标签（上面新建的） distractionFreeMode: true 无干扰模式，不需要更改 language: zh-CN # proxy 如果设置之后gitalk加载不出来就设置，具体错误是什么忘记了 proxy: &#x27;https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token&#x27; 其他配置文件 在 【theme】-&gt;【pure】-&gt;【layout】-&gt;【_partial】-&gt;【post】文件夹中，新建gitalk.ejs 123456789101112131415&lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk@latest/dist/gitalk.css&quot;&gt;&lt;script src=&quot;https://unpkg.com/gitalk@latest/dist/gitalk.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://priesttomb.github.io/js/md5.min.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; new Gitalk(&#123; clientID: &#x27;上述&#x27;, clientSecret: &#x27;上述&#x27;, repo: &#x27;xxxx.github.io&#x27;, owner: &#x27;xxxx&#x27;, admin: &#x27;xxxx&#x27;, id: md5(location.pathname), distractionFreeMode: true, enable: true &#125;).render(&#x27;gitalk-container&#x27;)&lt;/script&gt; 在 【theme】-&gt;【pure】-&gt;【layout】-&gt;【_partial】下的article.ejs新增以下：(我报错enable是undefined，我直接把这个去掉了没想到也行) 12345&lt;% if (theme.gitalk.enable)&#123; %&gt; &lt;div id=&quot;gitalk-container&quot;&gt;&lt;/div&gt; &lt;%- include post/gitalk.ejs %&gt;&lt;% &#125; %&gt; 运行 现在运行hexo s应该就可以了 第一次登陆需要授权，后续就不需要了 可能会出现443或者128错误，就配置上面的proxy","categories":[{"name":"hexo博客配置","slug":"hexo博客配置","permalink":"https://gladdduck.github.io/categories/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"hexo博客配置gitalk","slug":"hexo博客配置gitalk","permalink":"https://gladdduck.github.io/tags/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEgitalk/"}]},{"title":"emoji在markdown的表情大全","slug":"杂谈-emoji表情代码","date":"2022-10-22T00:58:32.348Z","updated":"2023-11-26T05:20:32.764Z","comments":true,"path":"2022/10/22/杂谈-emoji表情代码/","link":"","permalink":"https://gladdduck.github.io/2022/10/22/%E6%9D%82%E8%B0%88-emoji%E8%A1%A8%E6%83%85%E4%BB%A3%E7%A0%81/","excerpt":"","text":"People :bowtie::bowtie: 😄:smile: 😆:laughing: 😊:blush: 😃:smiley: ☺️:relaxed: 😏:smirk: 😍:heart_eyes: 😘:kissing_heart: 😚:kissing_closed_eyes: 😳:flushed: 😌:relieved: 😆:satisfied: 😁:grin: 😉:wink: 😜:stuck_out_tongue_winking_eye: 😝:stuck_out_tongue_closed_eyes: 😀:grinning: 😗:kissing: 😙:kissing_smiling_eyes: 😛:stuck_out_tongue: 😴:sleeping: 😟:worried: 😦:frowning: 😧:anguished: 😮:open_mouth: 😬:grimacing: 😕:confused: 😯:hushed: 😑:expressionless: 😒:unamused: 😅:sweat_smile: 😓:sweat: 😥:disappointed_relieved: 😩:weary: 😔:pensive: 😞:disappointed: 😖:confounded: 😨:fearful: 😰:cold_sweat: 😣:persevere: 😢:cry: 😭:sob: 😂:joy: 😲:astonished: 😱:scream: :neckbeard::neckbeard: 😫:tired_face: 😠:angry: 😡:rage: 😤:triumph: 😪:sleepy: 😋:yum: 😷:mask: 😎:sunglasses: 😵:dizzy_face: 👿:imp: 😈:smiling_imp: 😐:neutral_face: 😶:no_mouth: 😇:innocent: 👽:alien: 💛:yellow_heart: 💙:blue_heart: 💜:purple_heart: ❤️:heart: 💚:green_heart: 💔:broken_heart: 💓:heartbeat: 💗:heartpulse: 💕:two_hearts: 💞:revolving_hearts: 💘:cupid: 💖:sparkling_heart: ✨:sparkles: ⭐️:star: 🌟:star2: 💫:dizzy: 💥:boom: 💥:collision: 💢:anger: ❗️:exclamation: ❓:question: ❕:grey_exclamation: ❔:grey_question: 💤:zzz: 💨:dash: 💦:sweat_drops: 🎶:notes: 🎵:musical_note: 🔥:fire: 💩:hankey: 💩:poop: 💩:shit: 👍:+1: 👍:thumbsup: 👎:-1: 👎:thumbsdown: 👌:ok_hand: 👊:punch: 👊:facepunch: ✊:fist: ✌️:v: 👋:wave: ✋:hand: ✋:raised_hand: 👐:open_hands: ☝️:point_up: 👇:point_down: 👈:point_left: 👉:point_right: 🙌:raised_hands: 🙏:pray: 👆:point_up_2: 👏:clap: 💪:muscle: 🤘:metal: 🖕:fu: 🚶:walking: 🏃:runner: 🏃:running: 👫:couple: 👪:family: 👬:two_men_holding_hands: 👭:two_women_holding_hands: 💃:dancer: 👯:dancers: 🙆:ok_woman: 🙅:no_good: 💁:information_desk_person: 🙋:raising_hand: 👰:bride_with_veil: 🙎:person_with_pouting_face: 🙍:person_frowning: 🙇:bow: 💏:couplekiss: 💑:couple_with_heart: 💆:massage: 💇:haircut: 💅:nail_care: 👦:boy: 👧:girl: 👩:woman: 👨:man: 👶:baby: 👵:older_woman: 👴:older_man: 👱:person_with_blond_hair: 👲:man_with_gua_pi_mao: 👳:man_with_turban: 👷:construction_worker: 👮:cop: 👼:angel: 👸:princess: 😺:smiley_cat: 😸:smile_cat: 😻:heart_eyes_cat: 😽:kissing_cat: 😼:smirk_cat: 🙀:scream_cat: 😿:crying_cat_face: 😹:joy_cat: 😾:pouting_cat: 👹:japanese_ogre: 👺:japanese_goblin: 🙈:see_no_evil: 🙉:hear_no_evil: 🙊:speak_no_evil: 💂:guardsman: 💀:skull: 🐾:feet: 👄:lips: 💋:kiss: 💧:droplet: 👂:ear: 👀:eyes: 👃:nose: 👅:tongue: 💌:love_letter: 👤:bust_in_silhouette: 👥:busts_in_silhouette: 💬:speech_balloon: 💭:thought_balloon: :feelsgood::feelsgood: :finnadie::finnadie: :goberserk::goberserk: :godmode::godmode: :hurtrealbad::hurtrealbad: :rage1::rage1: :rage2::rage2: :rage3::rage3: :rage4::rage4: :suspect::suspect: :trollface: :trollface: Nature ☀️:sunny: ☔️:umbrella: ☁️:cloud: ❄️:snowflake: ⛄️:snowman: ⚡️:zap: 🌀:cyclone: 🌁:foggy: 🌊:ocean: 🐱:cat: 🐶:dog: 🐭:mouse: 🐹:hamster: 🐰:rabbit: 🐺:wolf: 🐸:frog: 🐯:tiger: 🐨:koala: 🐻:bear: 🐷:pig: 🐽:pig_nose: 🐮:cow: 🐗:boar: 🐵:monkey_face: 🐒:monkey: 🐴:horse: 🐎:racehorse: 🐫:camel: 🐑:sheep: 🐘:elephant: 🐼:panda_face: 🐍:snake: 🐦:bird: 🐤:baby_chick: 🐥:hatched_chick: 🐣:hatching_chick: 🐔:chicken: 🐧:penguin: 🐢:turtle: 🐛:bug: 🐝:honeybee: 🐜:ant: 🐞:beetle: 🐌:snail: 🐙:octopus: 🐠:tropical_fish: 🐟:fish: 🐳:whale: 🐋:whale2: 🐬:dolphin: 🐄:cow2: 🐏:ram: 🐀:rat: 🐃:water_buffalo: 🐅:tiger2: 🐇:rabbit2: 🐉:dragon: 🐐:goat: 🐓:rooster: 🐕:dog2: 🐖:pig2: 🐁:mouse2: 🐂:ox: 🐲:dragon_face: 🐡:blowfish: 🐊:crocodile: 🐪:dromedary_camel: 🐆:leopard: 🐈:cat2: 🐩:poodle: 🐾:paw_prints: 💐:bouquet: 🌸:cherry_blossom: 🌷:tulip: 🍀:four_leaf_clover: 🌹:rose: 🌻:sunflower: 🌺:hibiscus: 🍁:maple_leaf: 🍃:leaves: 🍂:fallen_leaf: 🌿:herb: 🍄:mushroom: 🌵:cactus: 🌴:palm_tree: 🌲:evergreen_tree: 🌳:deciduous_tree: 🌰:chestnut: 🌱:seedling: 🌼:blossom: 🌾:ear_of_rice: 🐚:shell: 🌐:globe_with_meridians: 🌞:sun_with_face: 🌝:full_moon_with_face: 🌚:new_moon_with_face: 🌑:new_moon: 🌒:waxing_crescent_moon: 🌓:first_quarter_moon: 🌔:waxing_gibbous_moon: 🌕:full_moon: 🌖:waning_gibbous_moon: 🌗:last_quarter_moon: 🌘:waning_crescent_moon: 🌜:last_quarter_moon_with_face: 🌛:first_quarter_moon_with_face: 🌔:moon: 🌍:earth_africa: 🌎:earth_americas: 🌏:earth_asia: 🌋:volcano: 🌌:milky_way: ⛅️:partly_sunny: :octocat: :octocat: :squirrel::squirrel: Objects 🎍:bamboo: 💝:gift_heart: 🎎:dolls: 🎒:school_satchel: 🎓:mortar_board: 🎏:flags: 🎆:fireworks: 🎇:sparkler: 🎐:wind_chime: 🎑:rice_scene: 🎃:jack_o_lantern: 👻:ghost: 🎅:santa: 🎄:christmas_tree: 🎁:gift: 🔔:bell: 🔕:no_bell: 🎋:tanabata_tree: 🎉:tada: 🎊:confetti_ball: 🎈:balloon: 🔮:crystal_ball: 💿:cd: 📀:dvd: 💾:floppy_disk: 📷:camera: 📹:video_camera: 🎥:movie_camera: 💻:computer: 📺:tv: 📱:iphone: ☎️:phone: ☎️:telephone: 📞:telephone_receiver: 📟:pager: 📠:fax: 💽:minidisc: 📼:vhs: 🔉:sound: 🔈:speaker: 🔇:mute: 📢:loudspeaker: 📣:mega: ⌛️:hourglass: ⏳:hourglass_flowing_sand: ⏰:alarm_clock: ⌚️:watch: 📻:radio: 📡:satellite: ➿:loop: 🔍:mag: 🔎:mag_right: 🔓:unlock: 🔒:lock: 🔏:lock_with_ink_pen: 🔐:closed_lock_with_key: 🔑:key: 💡:bulb: 🔦:flashlight: 🔆:high_brightness: 🔅:low_brightness: 🔌:electric_plug: 🔋:battery: 📲:calling: ✉️:email: 📫:mailbox: 📮:postbox: 🛀:bath: 🛁:bathtub: 🚿:shower: 🚽:toilet: 🔧:wrench: 🔩:nut_and_bolt: 🔨:hammer: 💺:seat: 💰:moneybag: 💴:yen: 💵:dollar: 💷:pound: 💶:euro: 💳:credit_card: 💸:money_with_wings: 📧:e-mail: 📥:inbox_tray: 📤:outbox_tray: ✉️:envelope: 📨:incoming_envelope: 📯:postal_horn: 📪:mailbox_closed: 📬:mailbox_with_mail: 📭:mailbox_with_no_mail: 🚪:door: 🚬:smoking: 💣:bomb: 🔫:gun: 🔪:hocho: 💊:pill: 💉:syringe: 📄:page_facing_up: 📃:page_with_curl: 📑:bookmark_tabs: 📊:bar_chart: 📈:chart_with_upwards_trend: 📉:chart_with_downwards_trend: 📜:scroll: 📋:clipboard: 📆:calendar: 📅:date: 📇:card_index: 📁:file_folder: 📂:open_file_folder: ✂️:scissors: 📌:pushpin: 📎:paperclip: ✒️:black_nib: ✏️:pencil2: 📏:straight_ruler: 📐:triangular_ruler: 📕:closed_book: 📗:green_book: 📘:blue_book: 📙:orange_book: 📓:notebook: 📔:notebook_with_decorative_cover: 📒:ledger: 📚:books: 🔖:bookmark: 📛:name_badge: 🔬:microscope: 🔭:telescope: 📰:newspaper: 🏈:football: 🏀:basketball: ⚽️:soccer: ⚾️:baseball: 🎾:tennis: 🎱:8ball: 🏉:rugby_football: 🎳:bowling: ⛳️:golf: 🚵:mountain_bicyclist: 🚴:bicyclist: 🏇:horse_racing: 🏂:snowboarder: 🏊:swimmer: 🏄:surfer: 🎿:ski: ♠️:spades: ♥️:hearts: ♣️:clubs: ♦️:diamonds: 💎:gem: 💍:ring: 🏆:trophy: 🎼:musical_score: 🎹:musical_keyboard: 🎻:violin: 👾:space_invader: 🎮:video_game: 🃏:black_joker: 🎴:flower_playing_cards: 🎲:game_die: 🎯:dart: 🀄️:mahjong: 🎬:clapper: 📝:memo: 📝:pencil: 📖:book: 🎨:art: 🎤:microphone: 🎧:headphones: 🎺:trumpet: 🎷:saxophone: 🎸:guitar: 👞:shoe: 👡:sandal: 👠:high_heel: 💄:lipstick: 👢:boot: 👕:shirt: 👕:tshirt: 👔:necktie: 👚:womans_clothes: 👗:dress: 🎽:running_shirt_with_sash: 👖:jeans: 👘:kimono: 👙:bikini: 🎀:ribbon: 🎩:tophat: 👑:crown: 👒:womans_hat: 👞:mans_shoe: 🌂:closed_umbrella: 💼:briefcase: 👜:handbag: 👝:pouch: 👛:purse: 👓:eyeglasses: 🎣:fishing_pole_and_fish: ☕️:coffee: 🍵:tea: 🍶:sake: 🍼:baby_bottle: 🍺:beer: 🍻:beers: 🍸:cocktail: 🍹:tropical_drink: 🍷:wine_glass: 🍴:fork_and_knife: 🍕:pizza: 🍔:hamburger: 🍟:fries: 🍗:poultry_leg: 🍖:meat_on_bone: 🍝:spaghetti: 🍛:curry: 🍤:fried_shrimp: 🍱:bento: 🍣:sushi: 🍥:fish_cake: 🍙:rice_ball: 🍘:rice_cracker: 🍚:rice: 🍜:ramen: 🍲:stew: 🍢:oden: 🍡:dango: 🥚:egg: 🍞:bread: 🍩:doughnut: 🍮:custard: 🍦:icecream: 🍨:ice_cream: 🍧:shaved_ice: 🎂:birthday: 🍰:cake: 🍪:cookie: 🍫:chocolate_bar: 🍬:candy: 🍭:lollipop: 🍯:honey_pot: 🍎:apple: 🍏:green_apple: 🍊:tangerine: 🍋:lemon: 🍒:cherries: 🍇:grapes: 🍉:watermelon: 🍓:strawberry: 🍑:peach: 🍈:melon: 🍌:banana: 🍐:pear: 🍍:pineapple: 🍠:sweet_potato: 🍆:eggplant: 🍅:tomato: 🌽:corn: Places 🏠:house: 🏡:house_with_garden: 🏫:school: 🏢:office: 🏣:post_office: 🏥:hospital: 🏦:bank: 🏪:convenience_store: 🏩:love_hotel: 🏨:hotel: 💒:wedding: ⛪️:church: 🏬:department_store: 🏤:european_post_office: 🌇:city_sunrise: 🌆:city_sunset: 🏯:japanese_castle: 🏰:european_castle: ⛺️:tent: 🏭:factory: 🗼:tokyo_tower: 🗾:japan: 🗻:mount_fuji: 🌄:sunrise_over_mountains: 🌅:sunrise: 🌠:stars: 🗽:statue_of_liberty: 🌉:bridge_at_night: 🎠:carousel_horse: 🌈:rainbow: 🎡:ferris_wheel: ⛲️:fountain: 🎢:roller_coaster: 🚢:ship: 🚤:speedboat: ⛵️:boat: ⛵️:sailboat: 🚣:rowboat: ⚓️:anchor: 🚀:rocket: ✈️:airplane: 🚁:helicopter: 🚂:steam_locomotive: 🚊:tram: 🚞:mountain_railway: 🚲:bike: 🚡:aerial_tramway: 🚟:suspension_railway: 🚠:mountain_cableway: 🚜:tractor: 🚙:blue_car: 🚘:oncoming_automobile: 🚗:car: 🚗:red_car: 🚕:taxi: 🚖:oncoming_taxi: 🚛:articulated_lorry: 🚌:bus: 🚍:oncoming_bus: 🚨:rotating_light: 🚓:police_car: 🚔:oncoming_police_car: 🚒:fire_engine: 🚑:ambulance: 🚐:minibus: 🚚:truck: 🚋:train: 🚉:station: 🚆:train2: 🚅:bullettrain_front: 🚄:bullettrain_side: 🚈:light_rail: 🚝:monorail: 🚃:railway_car: 🚎:trolleybus: 🎫:ticket: ⛽️:fuelpump: 🚦:vertical_traffic_light: 🚥:traffic_light: ⚠️:warning: 🚧:construction: 🔰:beginner: 🏧:atm: 🎰:slot_machine: 🚏:busstop: 💈:barber: ♨️:hotsprings: 🏁:checkered_flag: 🎌:crossed_flags: 🏮:izakaya_lantern: 🗿:moyai: 🎪:circus_tent: 🎭:performing_arts: 📍:round_pushpin: 🚩:triangular_flag_on_post: 🇯🇵:jp: 🇰🇷:kr: 🇨🇳:cn: 🇺🇸:us: 🇫🇷:fr: 🇪🇸:es: 🇮🇹:it: 🇷🇺:ru: 🇬🇧:gb: 🇬🇧:uk: 🇩🇪:de: Symbols 1️⃣:one: 2️⃣:two: 3️⃣:three: 4️⃣:four: 5️⃣:five: 6️⃣:six: 7️⃣:seven: 8️⃣:eight: 9️⃣:nine: 🔟:keycap_ten: 🔢:1234: 0️⃣:zero: #️⃣:hash: 🔣:symbols: ◀️:arrow_backward: ⬇️:arrow_down: ▶️:arrow_forward: ⬅️:arrow_left: 🔠:capital_abcd: 🔡:abcd: 🔤:abc: ↙️:arrow_lower_left: ↘️:arrow_lower_right: ➡️:arrow_right: ⬆️:arrow_up: ↖️:arrow_upper_left: ↗️:arrow_upper_right: ⏬:arrow_double_down: ⏫:arrow_double_up: 🔽:arrow_down_small: ⤵️:arrow_heading_down: ⤴️:arrow_heading_up: ↩️:leftwards_arrow_with_hook: ↪️:arrow_right_hook: ↔️:left_right_arrow: ↕️:arrow_up_down: 🔼:arrow_up_small: 🔃:arrows_clockwise: 🔄:arrows_counterclockwise: ⏪:rewind: ⏩:fast_forward: ℹ️:information_source: 🆗:ok: 🔀:twisted_rightwards_arrows: 🔁:repeat: 🔂:repeat_one: 🆕:new: 🔝:top: 🆙:up: 🆒:cool: 🆓:free: 🆖:ng: 🎦:cinema: 🈁:koko: 📶:signal_strength: 🈹:u5272: 🈴:u5408: 🈺:u55b6: 🈯️:u6307: 🈷️:u6708: 🈶:u6709: 🈵:u6e80: 🈚️:u7121: 🈸:u7533: 🈳:u7a7a: 🈲:u7981: 🈂️:sa: 🚻:restroom: 🚹:mens: 🚺:womens: 🚼:baby_symbol: 🚭:no_smoking: 🅿️:parking: ♿️:wheelchair: 🚇:metro: 🛄:baggage_claim: 🉑:accept: 🚾:wc: 🚰:potable_water: 🚮:put_litter_in_its_place: ㊙️:secret: ㊗️:congratulations: Ⓜ️:m: 🛂:passport_control: 🛅:left_luggage: 🛃:customs: 🉐:ideograph_advantage: 🆑:cl: 🆘:sos: 🆔:id: 🚫:no_entry_sign: 🔞:underage: 📵:no_mobile_phones: 🚯:do_not_litter: 🚱:non-potable_water: 🚳:no_bicycles: 🚷:no_pedestrians: 🚸:children_crossing: ⛔️:no_entry: ✳️:eight_spoked_asterisk: ✴️:eight_pointed_black_star: 💟:heart_decoration: 🆚:vs: 📳:vibration_mode: 📴:mobile_phone_off: 💹:chart: 💱:currency_exchange: ♈️:aries: ♉️:taurus: ♊️:gemini: ♋️:cancer: ♌️:leo: ♍️:virgo: ♎️:libra: ♏️:scorpius: ♐️:sagittarius: ♑️:capricorn: ♒️:aquarius: ♓️:pisces: ⛎:ophiuchus: 🔯:six_pointed_star: ❎:negative_squared_cross_mark: 🅰️:a: 🅱️:b: 🆎:ab: 🅾️:o2: 💠:diamond_shape_with_a_dot_inside: ♻️:recycle: 🔚:end: 🔛:on: 🔜:soon: 🕐:clock1: 🕜:clock130: 🕙:clock10: 🕥:clock1030: 🕚:clock11: 🕦:clock1130: 🕛:clock12: 🕧:clock1230: 🕑:clock2: 🕝:clock230: 🕒:clock3: 🕞:clock330: 🕓:clock4: 🕟:clock430: 🕔:clock5: 🕠:clock530: 🕕:clock6: 🕡:clock630: 🕖:clock7: 🕢:clock730: 🕗:clock8: 🕣:clock830: 🕘:clock9: 🕤:clock930: 💲:heavy_dollar_sign: ©️:copyright: ®️:registered: ™️:tm: ❌:x: ❗️:heavy_exclamation_mark: ‼️:bangbang: ⁉️:interrobang: ⭕️:o: ✖️:heavy_multiplication_x: ➕:heavy_plus_sign: ➖:heavy_minus_sign: ➗:heavy_division_sign: 💮:white_flower: 💯:100: ✔️:heavy_check_mark: ☑️:ballot_box_with_check: 🔘:radio_button: 🔗:link: ➰:curly_loop: 〰️:wavy_dash: 〽️:part_alternation_mark: 🔱:trident: :black_square::black_square: :white_square::white_square: ✅:white_check_mark: 🔲:black_square_button: 🔳:white_square_button: ⚫️:black_circle: ⚪️:white_circle: 🔴:red_circle: 🔵:large_blue_circle: 🔷:large_blue_diamond: 🔶:large_orange_diamond: 🔹:small_blue_diamond: 🔸:small_orange_diamond: 🔺:small_red_triangle: 🔻:small_red_triangle_down: :shipit::shipit:","categories":[{"name":"快捷命令","slug":"快捷命令","permalink":"https://gladdduck.github.io/categories/%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"https://gladdduck.github.io/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"print(Hello hexo) & github connected error","slug":"配置-hello-hexo配置","date":"2022-10-22T00:58:32.348Z","updated":"2022-11-03T10:38:27.726Z","comments":true,"path":"2022/10/22/配置-hello-hexo配置/","link":"","permalink":"https://gladdduck.github.io/2022/10/22/%E9%85%8D%E7%BD%AE-hello-hexo%E9%85%8D%E7%BD%AE/","excerpt":"","text":"中间过程可能会出现链接不上github的情况，这个因人而异。 不是操作问题，是墙的问题。 自己尝试解决办法。 配置简单博客 安装前配置 git安装(下一步者)，测试：git -v nodejs安装(下一步者)，测试：node -v npm安装(装完node就有)，测试：npm -v hexo安装(npm install hexo -g)，测试：hexo -v 其他需要安装的依赖如下(主题部分会用到)(npm install depandence)，测试：npm init 12345678910111213141516+-- hexo-deployer-git@3.0.0+-- hexo-generator-archive@1.0.0+-- hexo-generator-baidu-sitemap@0.1.9+-- hexo-generator-category@1.0.0+-- hexo-generator-feed@3.0.0+-- hexo-generator-index@2.0.0+-- hexo-generator-json-content@4.2.3+-- hexo-generator-sitemap@3.0.1+-- hexo-generator-tag@1.0.0+-- hexo-renderer-ejs@1.0.0+-- hexo-renderer-markdown-it-plus@1.0.6+-- hexo-renderer-stylus@2.1.0+-- hexo-server@2.0.0+-- hexo-theme-landscape@0.0.3+-- hexo-wordcount@6.0.1+-- hexo@5.4.2 github上的操作 新建一个仓库(repository) 仓库名字一定是自己的用户名 xxxxx.github.io git命令板链接仓库生成公钥 1234567#如果第一次下git应该要设置一下，我没设置后面报错了git config --global user.name &quot;username&quot;git config --global user.email &quot;email&quot;# 生成公钥ssh-keygen -t rsa -C &quot;email&quot;# 会在C:\\Users\\你的用户名\\.ssh下生成id_rsa和id_rsa.pub# 复制id_rsa.pub内容 在setting中 title可以随便填，key就是id_rsa.pub中的内容 然后在git命令版中测试： 1ssh -T git@gitbuh.com 中间可能会输个yes 看见successfully就成功了 本地hexo的操作 本地建一个空文件夹—暂且叫他dir方便后面说，这个就是博客全部内容 执行完下面命令，文件夹内会多出东西， 12# 如果执行失败，去github找到hexo-starter的库，下载解压，记得改名字hexo init 3.如果不需要额外的hexo主题，执行下面命令就可以了完成了 123456789# hexo 把本地的东西，生成静态文件(html,css这些)hexo g# hexo s在本地运行，可以进自己的浏览器看看hexo s # hexo d 部署文件到githubhexo d# hexo d -g可以直接生成并部署# 访问xxxxx.github.io 就能看见自己的博客了 配置自己的信息 修改dir文件夹内的_config.yml配置文件 把链接什么的改成自己的链接就OK了 网站的配置 即dir文件夹下面的_config.yml 12345# 1. 配置主题的文字，不然主题都是英文，这个必须在dir中配置，在主题中配置没有用language: zh-CN# 2. 如果用主题，主题的配置，不是hexo-theme-pure，就是puretheme: pure hexo 配置自己喜欢的主题 如果不是自己特别喜欢的主题，建议找一个大众的用的人多的主题， 因为用的人多，出现的问题解决办法就多 以pure为例，更多的主题访问: hexo官网 在配置主题过程中，建议参考pure官方文档:hhexo-theme-pure 先把主题下载下来，除了git命令，其他的都建议在windows的cmd中使用 123456789# 如果失败了，同样可以去github，hexo-theme-pure 下载解压，注意改文件夹名字git clone https://github.com/cofess/hexo-theme-pure.git themes/pure# 然后把官方文档建议的一大堆依赖下下来# 第一部分下过的可以省略npm install hexo-wordcount --savenpm install hexo-generator-json-content --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 修改dir文件夹内的_config.yml中的theme 如果没有自己添加 1theme: pure 文章增删改查 增删改文件，直接在_post里修改md文件，上传即可。 踩坑 下面说几个自己踩过的坑，网站配置还好， 主题的配置一堆，而且pure用的人不多，问题全靠自己解决 以下的修改都在theme/pure/_cofig.yml文件中 网站的配置 网站的名字和logo 123456789101112site: logo: enabled: true width: 40 height: 40 url: ../images/logo.png title: Gladdduck # 页面title favicon: /favicon.png board: &lt;p&gt;分享所思所见所想,欢迎留言交流!6666&lt;/p&gt; # 站点公告 copyright: false # 底部版权信息# 修改logo一定不要修改logo.url里面的图片路径# 要修改favicon的路径，修改logo.url的路径没用，反而文章的详情页面不会出现logo了 关于home，archives等不是中文的问题 123456789menu: Home: . Archives: archives # 归档 Categories: categories # 分类 Tags: tags # 标签 Links: links # 友链 About: about # 关于# 把这个地方的Home等改了不起作用，应该修改dir文件夹下面的配置文件，增加language: zh-CN# ：后面的是访问url路径，需要和source文件夹下面的几个文件夹名字对应 菜单栏无法访问 Connot get 12345需要把theme/pure/source文件夹下面的几个文件夹移动到dir文件夹下面的source中# 现在hexo s 打开浏览器应该就可以看见自己的博客了，点击对应的菜单也会跳转 其他配置根据配置文件内的注释修改即可 – 后面会记录 GitHub+gitalk配置评论 七牛云+PicGO配置图床，方便markdown书写 连接Github显示code128(Time out error) 错误信息 1234567891011fatal: unable to access &#x27;https://github.com/gladdduck/gladdduck.github.io.git/&#x27;:Failed to connect to github.com port 443 after 21048 ms: Timed outFATAL &#123; err: Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (D:\\BaiduSyncdisk\\Blog\\node_modules\\hexo-util\\lib\\spawn.js:51:21) at ChildProcess.emit (node:events:513:28) at ChildProcess.cp.emit (D:\\BaiduSyncdisk\\Blog\\node_modules\\cross-spawn\\lib\\enoent.js:34:29) at Process.ChildProcess._handle.onexit (node:internal/child_process:293:12) &#123; code: 128 &#125;&#125; Something&#x27;s wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html 解决办法 设置host文件–没用 关闭VPN-- 没用 连手机热点–偶尔有用 取消代理–偶尔有用 1234取消全局代理：git config --global --unset http.proxy git config --global --unset https.proxy 配置host文件 在C:\\Windows\\System32\\drivers\\etc中的host文件下新增(没有访问权限可以copy一份在桌面修改完之后覆盖) 1234567140.82.113.4 github.com 199.232.69.194 github.global.ssl.fastly.net185.199.108.153 assets-cdn.github.com185.199.109.153 assets-cdn.github.com185.199.110.153 assets-cdn.github.com185.199.111.153 assets-cdn.github.com cmd中ipconfig /flushdns刷新dns缓存 !!! 😳 😳 😳 😳 单独刷新dns也能用! cmd中ipconfig /flushdns 然后hexo d -g 就完全Ok了 😍 😍 😍 😍","categories":[{"name":"hexo博客配置","slug":"hexo博客配置","permalink":"https://gladdduck.github.io/categories/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"hexo博客配置pure","slug":"hexo博客配置pure","permalink":"https://gladdduck.github.io/tags/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEpure/"}]},{"title":"print(Hello picgo)","slug":"配置-hello-picgo配置","date":"2022-10-22T00:58:32.348Z","updated":"2022-10-22T02:41:47.930Z","comments":true,"path":"2022/10/22/配置-hello-picgo配置/","link":"","permalink":"https://gladdduck.github.io/2022/10/22/%E9%85%8D%E7%BD%AE-hello-picgo%E9%85%8D%E7%BD%AE/","excerpt":"","text":"起因 在hexo配置完成开始写博客，但是markdown的图片在xxxx.githun.io中显示不出来 各方搜索，贴一个解决方法。 但是个人觉得有点麻烦，而且考虑到以后写markdown也实在不想再搞个文件夹存图片。 于是，找到七牛云+picgo配置图云，把图片转为在线的 七牛云配置 登陆注册略(50G的图片空间),七牛云 创建新的存储空间，名字随便起 配置key 记住分给自己的域名(这个能用一个月，一个月之后咋办我不知道) picgo配置 下载picgo 配置七牛云 AccessKey和SecretKey：上面记住的key Bucket：第2步自己起的名字 访问地址：分配给自己的域名 存储区域：七牛云的存储区域对应的代码（华东 z0，华北 z1，华南 z2，北美 na0，东南亚 as0 ） 设为默认图床之后就可以上传了，具体的使用方法可以自己摸索 补充，设置为默认图床之后应该还要再输一遍，然后点确定 复制图片之后点击，就可以直接Ctrl+V粘贴图片地址了","categories":[{"name":"hexo博客配置","slug":"hexo博客配置","permalink":"https://gladdduck.github.io/categories/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"hexo博客配置picgo","slug":"hexo博客配置picgo","permalink":"https://gladdduck.github.io/tags/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEpicgo/"}]}],"categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://gladdduck.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"杂七杂八配置","slug":"杂七杂八配置","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E9%85%8D%E7%BD%AE/"},{"name":"论文记录","slug":"论文记录","permalink":"https://gladdduck.github.io/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/"},{"name":"快捷命令","slug":"快捷命令","permalink":"https://gladdduck.github.io/categories/%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"},{"name":"杂谈","slug":"杂谈","permalink":"https://gladdduck.github.io/categories/%E6%9D%82%E8%B0%88/"},{"name":"hexo博客配置","slug":"hexo博客配置","permalink":"https://gladdduck.github.io/categories/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://gladdduck.github.io/tags/SQL/"},{"name":"实习面经","slug":"实习面经","permalink":"https://gladdduck.github.io/tags/%E5%AE%9E%E4%B9%A0%E9%9D%A2%E7%BB%8F/"},{"name":"MySQL","slug":"MySQL","permalink":"https://gladdduck.github.io/tags/MySQL/"},{"name":"实习笔试","slug":"实习笔试","permalink":"https://gladdduck.github.io/tags/%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AF%95/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://gladdduck.github.io/tags/Hadoop/"},{"name":"Kaggle","slug":"Kaggle","permalink":"https://gladdduck.github.io/tags/Kaggle/"},{"name":"Vscode","slug":"Vscode","permalink":"https://gladdduck.github.io/tags/Vscode/"},{"name":"算法刷题笔记","slug":"算法刷题笔记","permalink":"https://gladdduck.github.io/tags/%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"},{"name":"Few-shotObjectDetection","slug":"Few-shotObjectDetection","permalink":"https://gladdduck.github.io/tags/Few-shotObjectDetection/"},{"name":"代码阅读","slug":"代码阅读","permalink":"https://gladdduck.github.io/tags/%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"},{"name":"Hexo","slug":"Hexo","permalink":"https://gladdduck.github.io/tags/Hexo/"},{"name":"mmfewshot","slug":"mmfewshot","permalink":"https://gladdduck.github.io/tags/mmfewshot/"},{"name":"CSharp","slug":"CSharp","permalink":"https://gladdduck.github.io/tags/CSharp/"},{"name":"PaddleOCRSharp","slug":"PaddleOCRSharp","permalink":"https://gladdduck.github.io/tags/PaddleOCRSharp/"},{"name":"VS2022","slug":"VS2022","permalink":"https://gladdduck.github.io/tags/VS2022/"},{"name":"VSCode Github","slug":"VSCode-Github","permalink":"https://gladdduck.github.io/tags/VSCode-Github/"},{"name":"BingChat","slug":"BingChat","permalink":"https://gladdduck.github.io/tags/BingChat/"},{"name":"知识点","slug":"知识点","permalink":"https://gladdduck.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"name":"Zero-shot Detection","slug":"Zero-shot-Detection","permalink":"https://gladdduck.github.io/tags/Zero-shot-Detection/"},{"name":"BlazorLocalization","slug":"BlazorLocalization","permalink":"https://gladdduck.github.io/tags/BlazorLocalization/"},{"name":"Blazor","slug":"Blazor","permalink":"https://gladdduck.github.io/tags/Blazor/"},{"name":"Git","slug":"Git","permalink":"https://gladdduck.github.io/tags/Git/"},{"name":"目标检测会议","slug":"目标检测会议","permalink":"https://gladdduck.github.io/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BC%9A%E8%AE%AE/"},{"name":"垃圾检测","slug":"垃圾检测","permalink":"https://gladdduck.github.io/tags/%E5%9E%83%E5%9C%BE%E6%A3%80%E6%B5%8B/"},{"name":"python3 标准库","slug":"python3-标准库","permalink":"https://gladdduck.github.io/tags/python3-%E6%A0%87%E5%87%86%E5%BA%93/"},{"name":"搭建博客","slug":"搭建博客","permalink":"https://gladdduck.github.io/tags/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"name":"Python学习笔记","slug":"Python学习笔记","permalink":"https://gladdduck.github.io/tags/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"知识图谱表示","slug":"知识图谱表示","permalink":"https://gladdduck.github.io/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A8%E7%A4%BA/"},{"name":"快速傅里叶变换","slug":"快速傅里叶变换","permalink":"https://gladdduck.github.io/tags/%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"},{"name":"Linux快捷命令","slug":"Linux快捷命令","permalink":"https://gladdduck.github.io/tags/Linux%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"},{"name":"排序算法","slug":"排序算法","permalink":"https://gladdduck.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"git Time out","slug":"git-Time-out","permalink":"https://gladdduck.github.io/tags/git-Time-out/"},{"name":"Dataset","slug":"Dataset","permalink":"https://gladdduck.github.io/tags/Dataset/"},{"name":"Dataloader","slug":"Dataloader","permalink":"https://gladdduck.github.io/tags/Dataloader/"},{"name":"Sampler","slug":"Sampler","permalink":"https://gladdduck.github.io/tags/Sampler/"},{"name":"collate_fn","slug":"collate-fn","permalink":"https://gladdduck.github.io/tags/collate-fn/"},{"name":"Cypher","slug":"Cypher","permalink":"https://gladdduck.github.io/tags/Cypher/"},{"name":"Neo4j快捷命令","slug":"Neo4j快捷命令","permalink":"https://gladdduck.github.io/tags/Neo4j%E5%BF%AB%E6%8D%B7%E5%91%BD%E4%BB%A4/"},{"name":"neo4j安装","slug":"neo4j安装","permalink":"https://gladdduck.github.io/tags/neo4j%E5%AE%89%E8%A3%85/"},{"name":"多个域名访问同一个服务器","slug":"多个域名访问同一个服务器","permalink":"https://gladdduck.github.io/tags/%E5%A4%9A%E4%B8%AA%E5%9F%9F%E5%90%8D%E8%AE%BF%E9%97%AE%E5%90%8C%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Vscode 阿里云","slug":"Vscode-阿里云","permalink":"https://gladdduck.github.io/tags/Vscode-%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"hexo博客配置gitalk","slug":"hexo博客配置gitalk","permalink":"https://gladdduck.github.io/tags/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEgitalk/"},{"name":"快捷键","slug":"快捷键","permalink":"https://gladdduck.github.io/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"name":"hexo博客配置pure","slug":"hexo博客配置pure","permalink":"https://gladdduck.github.io/tags/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEpure/"},{"name":"hexo博客配置picgo","slug":"hexo博客配置picgo","permalink":"https://gladdduck.github.io/tags/hexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AEpicgo/"}]}